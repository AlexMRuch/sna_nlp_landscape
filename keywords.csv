Source Paper,Authors,Journal,Keywords,Abstract
Can x2vec Save Lives? Integrating Graph and Language Embeddings for Automatic Mental Health Classification,Alexander Ruch,arXiv,"graph embeddings, language embeddings, information networks, social media, mental health","Graph and language embedding models are becoming commonplace in large scale analyses given their ability to represent complex sparse data densely in low-dimensional space. Integrating these models' complementary relational and communicative data may be especially helpful if predicting rare events or classifying members of hidden populations - tasks requiring huge and sparse datasets for generalizable analyses. For example, due to social stigma and comorbidities, mental health support groups often form in amorphous online groups. Predicting suicidality among individuals in these settings using standard network analyses is prohibitive due to resource limits (e.g., memory), and adding auxiliary data like text to such models exacerbates complexity- and sparsity-related issues. Here, I show how merging graph and language embedding models (metapath2vec and doc2vec) avoids these limits and extracts unsupervised clustering data without domain expertise or feature engineering. Graph and language distances to a suicide support group have little correlation (\r{ho} < 0.23), implying the two models are not embedding redundant information. When used separately to predict suicidality among individuals, graph and language data generate relatively accurate results (69% and 76%, respectively); however, when integrated, both data produce highly accurate predictions (90%, with 10% false-positives and 12% false-negatives). Visualizing graph embeddings annotated with predictions of potentially suicidal individuals shows the integrated model could classify such individuals even if they are positioned far from the support group. These results extend research on the importance of simultaneously analyzing behavior and language in massive networks and efforts to integrate embedding models for different kinds of data when predicting and classifying, particularly when they involve rare events."
TGE-PS: Text-driven Graph Embedding with Pairs Sampling,"Liheng Chen, Yanru Qu, ZhenghuiWang, Lin Qiu, Weinan Zhang, KenChen, Shaodian Zhang, Yong Yu",AAAI,,"In graphs with rich text information, constructing expressive graph representations requires incorporating textual information with structural information. Graph embedding models are becoming more and more popular in representing graphs, yet they are faced with two issues: sampling efficiency and text utilization. Through analyzing existing models, we find their training objectives are composed of pairwise proximities, and there are large amounts of redundant node pairs in Random Walk-based methods. Besides, inferring graph structures directly from texts (also known as zero-shot scenario) is a problem that requires higher text utilization. To solve these problems, we propose a novel Text-driven Graph Embedding with Pairs Sampling (TGE-PS) framework. TGE-PS uses Pairs Sampling (PS) to generate training samples which reduces ∼99% training samples and is competitive compared to Random Walk. TGE-PS uses Text-driven Graph Embedding (TGE) which adopts word- and character-level embeddings to generate node embeddings. We evaluate TGE-PS on several real-world datasets, and experimental results demonstrate that TGE-PS produces state-of-the-art results in traditional and zero-shot link prediction tasks."
Learning Embeddings of Directed Networks with Text-Associated Nodes -with Applications in Software Package Dependency Networks,"Shudan Zhong, Hong Xu",arXiv,,"A network embedding consists of a vector representation for each node in the network. Its usefulness has been shown in many real-world application domains, such as social networks and web networks. Directed networks with text associated with each node, such as software package dependency networks, are commonplace. However, to the best of our knowledge, their embeddings have hitherto not been specifically studied. In this paper, we propose PCTADW-1 and PCTADW-2, two algorithms based on neural networks that learn embeddings of directed networks with text associated with each node. We create two new node-labeled such networks: The package dependency networks in two popular GNU/Linux distributions, Debian and Fedora. We experimentally demonstrate that the embeddings produced by our algorithms resulted in node classification with better quality than those of various baselines on these two networks. We observe that there exist systematic presence of analogies (similar to those in word embeddings) in the network embeddings of software package dependency networks. To the best of our knowledge, this is the first time that such systematic presence of analogies is observed in network and document embeddings. This may potentially open up a new instrument for better understanding networks and documents algorithmically using their embeddings as well as for better human understanding of network and document embeddings."
Compositional Network Embedding,"Tianshu Lyu, Fei Sun, Peng Jiang,Wenwu Ou, Yan Zhang",arXiv,"Network Embedding, Principle of Compositionally","Network embedding has proved extremely useful in a variety of network analysis tasks such as node classification, link prediction, and network visualization. Almost all the existing network embedding methods learn to map the node IDs to their corresponding node embeddings. This design principle, however, hinders the existing methods from being applied in real cases. Node ID is not generalizable and, thus, the existing methods have to pay great effort in cold-start problem. The heterogeneous network usually requires extra work to encode node types, as node type is not able to be identified by node ID. Node ID carries rare information, resulting in the criticism that the existing methods are not robust to noise. To address this issue, we introduce Compositional Network Embedding, a general inductive network representation learning framework that generates node embeddings by combining node features based on the “principle of compositionally”. Instead of directly optimizing an embedding lookup based on arbitrary node IDs, we learn a composition function that infers node embeddings by combining the corresponding node attribute embeddings through a graph based loss. For evaluation, we conduct the experiments on link prediction under four different settings. The results verified the effectiveness and generalization ability of compositional network  beddings, especially on unseen nodes."
P2V: large-scale academic paper embedding,"Yi Zhang, Fen Zhao, Jianguo Lu",Akadémiai Kiadó,"Embedding, Data Representation, Academic Paper","Academic papers not only contain text but also links via citation links. Representing such data is crucial for many tasks, such as classification, disambiguation, duplicates detection, recommendation and influence prediction. The success of the skip-gram model has inspired many algorithms for learning embeddings for words, documents, and networks. However, there is limited research on learning the representation of linked documents such as academic papers. In this paper, we propose a new neural network based algorithm, called P2V (paper2vector), to learn high-quality embeddings for academic papers on large-scale datasets. We compare our model with traditional non-neural network based algorithms and state-of-the-art neural network methods on four datasets of various sizes. The largest dataset we used contains 46.64 million papers and 528.68 million citation links. Experimental results show that P2V achieves state-of-the-art performance in paper classification, paper similarity, and paper influence prediction task."
Attributed Network Embedding for Incomplete Structure Information,"Chengbin Hou, Shan He, Ke Tang",arXiv,,"Attributed networks are ubiquitous since a network often comes with auxiliary attribute information e.g. a social network with user profiles. Attributed Network Embedding (ANE) has recently attracted considerable attention, which aims to learn unified low dimensional node embeddings while preserving both structural and attribute information. The resulting node embeddings can then facilitate various network downstream tasks e.g. link prediction. Although there are several ANE methods, most of them cannot deal with incomplete attributed networks with missing links and/or missing node attributes, which often occur in real-world scenarios. To address this issue, we propose a robust ANE method, the general idea of which is to reconstruct a unified denser network by fusing two sources of information for information enhancement, and then employ a random walks based network embedding method for learning node embeddings. The experiments of link prediction, node classification, visualization, and parameter sensitivity analysis on six real-world datasets validate the effectiveness of our method to incomplete attributed networks."
Sampled in Pairs and Driven by Text: A New Graph Embedding Framework,"Liheng Chen, Yanru Qu, Zhenghui Wang, Lin Qiu, Weinan Zhang, Ken Chen, Shaodian Zhang, Yong Yu",arXiv,"Graph Embedding, Data Mining, Link Prediction, Zero-shot ","In graphs with rich texts, incorporating textual information with structural information would benefit constructing expressive graph embeddings. Among various graph embedding models, random walk (RW)-based is one of the most popular and successful groups. However, it is challenged by two issues when applied on graphs with rich texts: (i) sampling efficiency: deriving from the training objective of RW-based models (e.g., DeepWalk and node2vec), we show that RW-based models are likely to generate large amounts of redundant training samples due to three main drawbacks. (ii) text utilization: these models have difficulty in dealing with zero-shot scenarios where graph embedding models have to infer graph structures directly from texts. To solve these problems, we propose a novel framework, namely Text-driven Graph Embedding with Pairs Sampling (TGE-PS). TGE-PS uses Pairs Sampling (PS) to improve the sampling strategy of RW, being able to reduce ~99% training samples while preserving competitive performance. TGE-PS uses Text-driven Graph Embedding (TGE), an inductive graph embedding approach, to generate node embeddings from texts. Since each node contains rich texts, TGE is able to generate high-quality embeddings and provide reasonable predictions on existence of links to unseen nodes. We evaluate TGE-PS on several real-world datasets, and experiment results demonstrate that TGE-PS produces state-of-the-art results on both traditional and zero-shot link prediction tasks."
Attributed Network Embedding for Incomplete Attributed Networks,"Chengbin Hou, Shan He, Ke Tang",arXiv,,"Attributed networks are ubiquitous since a network often comes with auxiliary attribute information e.g. a social network with user profiles. Attributed Network Embedding (ANE) has recently attracted considerable attention, which aims to learn unified low dimensional node embeddings while preserving both structural and attribute information. The resulting node embeddings can then facilitate various network downstream tasks e.g. link prediction. Although there are several ANE methods, most of them cannot deal with incomplete attributed networks with missing links and/or missing node attributes, which often occur in real-world scenarios. To address this issue, we propose a robust ANE method, the general idea of which is to reconstruct a unified denser network by fusing two sources of information for information enhancement, and then employ a random walks based network embedding method for learning node embeddings. The experiments of link prediction, node classification, visualization, and parameter sensitivity analysis on six real-world datasets validate the effectiveness of our method to incomplete attributed networks."
Node Embedding with Adaptive Similarities for Scalable Learning over Graphs,"Dimitris Berberidis, Georgios B.Giannakis",arXiv,"SVD, SVM, unsupervised, multiscale, random walks, spectral","Node embedding is the task of extracting informative and descriptive features over the nodes of a graph. The importance of node embeddings for graph analytics, as well as learning tasks such as node classification, link prediction and community detection, has led to increased interest on the problem leading to a number of recent advances. Much like PCA in the feature domain, node embedding is an inherently \emph{unsupervised} task; in lack of metadata used for validation, practical methods may require standardization and limiting the use of tunable hyperparameters. Finally, node embedding methods are faced with maintaining scalability in the face of large-scale real-world graphs of ever-increasing sizes. In the present work, we propose an adaptive node embedding framework that adjusts the embedding process to a given underlying graph, in a fully unsupervised manner. To achieve this, we adopt the notion of a tunable node similarity matrix that assigns weights on paths of different length. The design of the multilength similarities ensures that the resulting embeddings also inherit interpretable spectral properties. The proposed model is carefully studied, interpreted, and numerically evaluated using stochastic block models. Moreover, an algorithmic scheme is proposed for training the model parameters effieciently and in an unsupervised manner. We perform extensive node classification, link prediction, and clustering experiments on many real world graphs from various domains, and compare with state-of-the-art scalable and unsupervised node embedding alternatives. The proposed method enjoys superior performance in many cases, while also yielding interpretable information on the underlying structure of the graph."
Adaptive-similarity node embedding for scalable learning over graphs,"Dimitris Berberidis, Georgios B.Giannakis",arXiv,"SVD, SVM, unsupervised, multiscale, random walks, spectral
","Node embedding is the task of extracting informative and descriptive features over the nodes of a graph. The importance of node embeddings for graph analytics, as well as learning tasks such as node classification, link prediction and community detection, has led to increased interest on the problem leading to a number of recent advances. Much like PCA in the feature domain, node embedding is an inherently \emph{unsupervised} task; in lack of metadata used for validation, practical methods may require standardization and limiting the use of tunable hyperparameters. Finally, node embedding methods are faced with maintaining scalability in the face of large-scale real-world graphs of ever-increasing sizes. In the present work, we propose an adaptive node embedding framework that adjusts the embedding process to a given underlying graph, in a fully unsupervised manner. To achieve this, we adopt the notion of a tunable node similarity matrix that assigns weights on paths of different length. The design of the multilength similarities ensures that the resulting embeddings also inherit interpretable spectral properties. The proposed model is carefully studied, interpreted, and numerically evaluated using stochastic block models. Moreover, an algorithmic scheme is proposed for training the model parameters effieciently and in an unsupervised manner. We perform extensive node classification, link prediction, and clustering experiments on many real world graphs from various domains, and compare with state-of-the-art scalable and unsupervised node embedding alternatives. The proposed method enjoys superior performance in many cases, while also yielding interpretable information on the underlying structure of the graph."
Learning Network-to-Network Model for Content-rich Network Embedding,"Zhicheng He, Jie Liu, Ning Li, Yalou Huang",ACM,"Network Embedding, Network Representation Learning, Network to Network, Egocentric Embedding","Recently, network embedding (NE) has achieved great successes in learning low dimensional representations for network nodes and has been increasingly applied to various network analytic tasks. In this paper, we consider the representation learning problem for content-rich networks whose nodes are associated with rich content information. Content-rich network embedding is challenging in fusing the complex structural dependencies and the rich contents. To tackle the challenges, we propose a generative model, Network-to-Network Network Embedding (Net2Net-NE) model, which can effectively fuse the structure and content information into one continuous embedding vector for each node. Specifically, we regard the content-rich network as a pair of networks with different modalities, i.e., content network and node network. By exploiting the strong correlation between the focal node and the nodes to whom it is connected to, a multilayer recursively composable encoder is proposed to fuse the structure and content information of the entire ego network into the egocentric node embedding. Moreover, a cross-modal decoder is deployed to mapping the egocentric node embeddings into node identities in an interconnected network. By learning the identity of each node according to its content, the mapping from content network to node network is learned in a generative manner. Hence the latent encoding vectors learned by the Net2Net-NE can be used as effective node embeddings. Extensive experimental results on three real-world networks demonstrate the superiority of Net2Net-NE over state-of-the-art methods."
Measuring Graph Reconstruction Precisions: How Well Do Embeddings Preserve the Graph Proximity Structure?,"Xin Liu, Tsuyoshi Murata, Kyoung-SookKim",ACM,"Graph Embedding, Network Representation Learning, Graph Reconstruction, Dimension Reduction, Data Mining","Graph embedding aims at learning representations of nodes in a low dimensional vector space. Good embeddings should preserve proximity structure of the original graph and thus are expected to accurately reconstruct the graph. We propose a reconstruction procedure such that the reconstructed graph keeps the total number of weights of the original one. Then we assess the reconstruction precision using a global view based graph similarity metric called DeltaCon. Based on this metric, we found that the embeddings by the stateof-the-art techniques can only preserve part of the proximity
structure and is insufficient to achieve high reconstruction accuracy."
A General View for Network Embedding as Matrix Factorization,"Xin Liu, Tsuyoshi Murata, Kyoung-SookKim, Chatchawan Kotarasu, Chenyi Zhuang",ACM,"Graph Embedding, Network Representation Learning, Matrix Factorization, Node Similarity, Graph Mining, Social Networks","We propose a general view that demonstrates the relationship between network embedding approaches and matrix factorization. Unlike previous works that present the equivalence for the approaches from a skip-gram model perspective, we provide a more fundamental connection from an optimization (objective function) perspective. We demonstrate that matrix factorization is equivalent to optimizing two objectives: one is for bringing together the embeddings of similar nodes; the other is for separating the embeddings of distant nodes. The matrix to be factorized has a general form: S-β. The elements of $\mathbfS $ indicate pairwise node similarities. They can be based on any user-defined similarity/distance measure or learned from random walks on networks. The shift number β is related to a parameter that balances the two objectives. More importantly, the resulting embeddings are sensitive to β and we can improve the embeddings by tuning β. Experiments show that matrix factorization based on a new proposed similarity measure and β-tuning strategy significantly outperforms existing matrix factorization approaches on a range of benchmark networks."
MANELA: A Multi-Agent Algorithm for Learning Network Embeddings,"Han Zhang, Hanqi Xu",arXiv,,"Playing an essential role in data mining, machine learning has a long history of being applied to networks on multifarious tasks and has played an essential role in data mining. However, the discrete and sparse natures of networks often render it difficult to apply machine learning directly to networks. To circumvent this difficulty, one major school of thought to approach networks using machine learning is via network embeddings. On the one hand, this network embeddings have achieved huge success on aggregated network data in recent years. On the other hand, learning network embeddings on distributively stored networks still remained understudied: To the best of our knowledge, all existing algorithms for learning network embeddings have hitherto been exclusively centralized and thus cannot be applied to these networks. To accommodate distributively stored networks, in this paper, we proposed a multi-agent model. Under this model, we developed the multi-agent network embedding learning algorithm (MANELA) for learning network embeddings. We demonstrate MANELA's advantages over other existing centralized network embedding learning algorithms both theoretically and experimentally. Finally, we further our understanding in MANELA via visualization and exploration of its relationship to DeepWalk."
GESF: A Universal Discriminative Mapping Mechanism for Graph Representation Learning,"Shupeng Gui, Xiangliang Zhang,Shuang Qiu, Mingrui Wu, Jieping Ye, JiLiu",arXiv,,"Graph embedding is a central problem in social network analysis and many other applications, aiming to learn the vector representation for each node. While most existing approaches need to specify the neighborhood and the dependence form to the neighborhood, which may significantly degrades the flexibility of representation, we propose a novel graph node embedding method (namely GESF) via the set function technique. Our method can 1) learn an arbitrary form of representation function from neighborhood, 2) automatically decide the significance of neighbors at different distances, and 3) be applied to heterogeneous graph embedding, which may contain multiple types of nodes. Theoretical guarantee for the representation capability of our method has been proved for general homogeneous and heterogeneous graphs and evaluation results on benchmark data sets show that the proposed GESF outperforms the state-of-the-art approaches on producing node vectors for classification tasks."
Effective and Efficient Network Embedding Initialization via Graph Partitioning,"Wenqing Lin, Feng He, Faqiang Zhang,Xu Cheng, HongYun Cai",arXiv,"network embedding, initialization, graph partition, hyperparameter learning","Network embedding has been intensively studied in the literature and widely used in various applications, such as link prediction and node classification. While previous work focus on the design of new algorithms or are tailored for various problem settings, the discussion of initialization strategies in the learning process is often missed. In this work, we address this important issue of initialization for network embedding that could dramatically improve the performance of the algorithms on both effectiveness and efficiency. Specifically, we first exploit the graph partition technique that divides the graph into several disjoint subsets, and then construct an abstract graph based on the partitions. We obtain the initialization of the embedding for each node in the graph by computing the network embedding on the abstract graph, which is much smaller than the input graph, and then propagating the embedding among the nodes in the input graph. With extensive experiments on various datasets, we demonstrate that our initialization technique significantly improves the performance of the state-of-the-art algorithms on the evaluations of link prediction and node classification by up to 7.76% and 8.74% respectively. Besides, we show that the technique of initialization reduces the running time of the state-of-the-arts by at least 20%."
RUM: network Representation learning through Multi-level structural information preservation,"Yanlei Yu, Zhiwu Lu, Jiajun Liu, GuopingZhao, Ji-Rong Wen, Kai Zheng",arXiv,,"We have witnessed the discovery of many techniques for network representation learning in recent years, ranging from encoding the context in random walks to embedding the lower order connections, to finding latent space representations with auto-encoders. However, existing techniques are looking mostly into the local structures in a network, while higher-level properties such as global community structures are often neglected. We propose a novel network representations learning model framework called RUM (network Representation learning throUgh Multi-level structural information preservation). In RUM, we incorporate three essential aspects of a node that capture a network's characteristics in multiple levels: a node's affiliated local triads, its neighborhood relationships, and its global community affiliations. Therefore the framework explicitly and comprehensively preserves the structural information of a network, extending the encoding process both to the local end of the structural information spectrum and to the global end. The framework is also flexible enough to take various community discovery algorithms as its preprocessor. Empirical results show that the representations learned by RUM have demonstrated substantial performance advantages in real-life tasks."
A Comprehensive Comparison of Unsupervised Network Representation Learning Methods,"Megha Khosla, Avishek Anand, VinaySetty",arXiv,,"There has been appreciable progress in unsupervised network representation learning (UNRL) approaches over graphs recently with flexible random-walk approaches, new optimization objectives and deep architectures. However, there is no common ground for systematic comparison of embeddings to understand their behavior for different graphs and tasks. In this paper we theoretically group different approaches under a unifying framework and empirically investigate the effectiveness of different network representation methods. In particular, we argue that most of the UNRL approaches either explicitly or implicit model and exploit context information of a node. Consequently, we propose a framework that casts a variety of approaches -- random walk based, matrix factorization and deep learning based -- into a unified context-based optimization function. We systematically group the methods based on their similarities and differences. We study the differences among these methods in detail which we later use to explain their performance differences (on downstream tasks). We conduct a large-scale empirical study considering 9 popular and recent UNRL techniques and 11 real-world datasets with varying structural properties and two common tasks -- node classification and link prediction. We find that there is no single method that is a clear winner and that the choice of a suitable method is dictated by certain properties of the embedding methods, task and structural properties of the underlying graph. In addition we also report the common pitfalls in evaluation of UNRL methods and come up with suggestions for experimental design and interpretation of results."
Initialization for Network Embedding: A Graph Partition Approach,"Wenqing Lin, Feng He, Faqiang Zhang,Xu Cheng, HongYun Cai",arXiv,"Network Embedding, Initialization, Graph Partition, Hyperparameter Learning ","Network embedding has been intensively studied in the literature and widely used in various applications, such as link prediction and node classification. While previous work focus on the design of new algorithms or are tailored for various problem settings, the discussion of initialization strategies in the learning process is often missed. In this work, we address this important issue of initialization for network embedding that could dramatically improve the performance of the algorithms on both effectiveness and efficiency. Specifically, we first exploit the graph partition technique that divides the graph into several disjoint subsets, and then construct an abstract graph based on the partitions. We obtain the initialization of the embedding for each node in the graph by computing the network embedding on the abstract graph, which is much smaller than the input graph, and then propagating the embedding among the nodes in the input graph. With extensive experiments on various datasets, we demonstrate that our initialization technique significantly improves the performance of the state-of-the-art algorithms on the evaluations of link prediction and node classification by up to 7.76% and 8.74% respectively. Besides, we show that the technique of initialization reduces the running time of the state-of-the-arts by at least 20%."
MetaGraph2Vec: Complex Semantic Path Augmented Heterogeneous Network Embedding,"Daokun Zhang, Jie Yin, Xingquan Zhu,Chengqi Zhang",arXiv,,"Network embedding in heterogeneous information networks (HINs) is a challenging task, due to complications of different node types and rich relationships between nodes. As a result, conventional network embedding techniques cannot work on such HINs. Recently, metapath-based approaches have been proposed to characterize relationships in HINs, but they are ineffective in capturing rich contexts and semantics between nodes for embedding learning, mainly because (1) metapath is a rather strict single path node-node relationship descriptor, which is unable to accommodate variance in relationships, and (2) only a small portion of paths can match the metapath, resulting in sparse context information for embedding learning. In this paper, we advocate a new metagraph concept to capture richer structural contexts and semantics between distant nodes. A metagraph contains multiple paths between nodes, each describing one type of relationships, so the augmentation of multiple metapaths provides an effective way to capture rich contexts and semantic relations between nodes. This greatly boosts the ability of metapath-based embedding techniques in handling very sparse HINs. We propose a new embedding learning algorithm, namely MetaGraph2Vec, which uses metagraph to guide the generation of random walks and to learn latent embeddings of multi-typed HIN nodes. Experimental results show that MetaGraph2Vec is able to outperform the state-of-the-art baselines in various heterogeneous network mining tasks such as node classification, node clustering, and similarity search."
Co-Regularized Deep Multi-Network Embedding,"Jingchao Ni, Shiyu Chang, Xiao Liu, WeiCheng, Haifeng Chen, Dongkuan Xu, Xiang Zhang",IW3C2 (International World Wide Web Conference Committee),"Multi-network, Network Embedding, Representation Learning","Network embedding aims to learn a low-dimensional vector representation for each node in the social and information networks, with the constraint to preserve network structures. Most existing methods focus on single network embedding, ignoring the relationship between multiple networks. In many real-world applications, however, multiple networks may contain complementary information, which can lead to further refined node embeddings. Thus, in this paper, we propose a novel multi-network embedding method, DMNE. DMNE is flexible. It allows different networks to have different sizes, to be (un)weighted and (un)directed. It leverages multiple networks via cross-network relationships between nodes in different networks, which may form many-to-many node mappings, and be associated with weights. To model the non-linearity of the network data, we develop DMNE to have a new deep learning architecture, which coordinates multiple neural networks (one for each input network data) with a co-regularized loss function. With multiple layers of non-linear mappings, DMNE progressively transforms each input network to a highly non-linear latent space, and in the meantime, adapts different spaces to each other through a co-regularized learning schema. Extensive experimental results on real-life datasets demonstrate the effectiveness of our method."
BiasedWalk: Biased Sampling for Representation Learning on Graphs,"Duong Nguyen, Fragkiskos D. Malliaros",arXiv,"Network Representation Learning, Unsupervised Feature Learning, Node Sampling, Random Walks ","Network embedding algorithms are able to learn latent feature representations of nodes, transforming networks into lower dimensional vector representations. Typical key applications, which have effectively been addressed using network embeddings, include link prediction, multilabel classification and community detection. In this paper, we propose BiasedWalk, a scalable, unsupervised feature learning algorithm that is based on biased random walks to sample context information about each node in the network. Our random-walk based sampling can behave as Breath-First-Search (BFS) and Depth-First-Search (DFS) samplings with the goal to capture homophily and role equivalence between the nodes in the network. We have performed a detailed experimental evaluation comparing the performance of the proposed algorithm against various baseline methods, on several datasets and learning tasks. The experiment results show that the proposed method outperforms the baseline ones in most of the tasks and datasets."
Graph embedding with rich information through heterogeneous graph,"Guolei Sun, Xiangliang Zhang",arXiv,,"Graph embedding has attracted increasing attention due to its critical application in social network analysis. Most existing algorithms for graph embedding only rely on the typology information and fail to use the copious information in nodes as well as edges. As a result, their performance for many tasks may not be satisfactory. In this paper, we proposed a novel and general framework of representation learning for graph with rich text information through constructing a bipartite heterogeneous network. Specially, we designed a biased random walk to explore the constructed heterogeneous network with the notion of flexible neighborhood. The efficacy of our method is demonstrated by extensive comparison experiments with several baselines on various datasets. It improves the Micro-F1 and Macro-F1 of node classification by 10% and 7% on Cora dataset."
Which way? Direction-Aware Attributed Graph Embedding,"Zekarias T. Kefato, Nasrullah Sheikh,Alberto Montresor",arXiv,,"Graph embedding algorithms are used to efficiently represent (encode) a graph in a low-dimensional continuous vector space that preserves the most important properties of the graph. One aspect that is often overlooked is whether the graph is directed or not. Most studies ignore the directionality, so as to learn high-quality representations optimized for node classification. On the other hand, studies that capture directionality are usually effective on link prediction but do not perform well on other tasks. This preliminary study presents a novel text-enriched, direction-aware algorithm called DIAGRAM , based on a carefully designed multi-objective model to learn embeddings that preserve the direction of edges, textual features and graph context of nodes. As a result, our algorithm does not have to trade one property for another and jointly learns high-quality representations for multiple network analysis tasks. We empirically show that DIAGRAM significantly outperforms six state-of-the-art baselines, both direction-aware and oblivious ones,on link prediction and network reconstruction experiments using two popular datasets. It also achieves a comparable performance on node classification experiments against these baselines using the same datasets."
Hierarchical Taxonomy Aware Network Embedding,"Jianxin Ma, Peng Cui, Xiao Wang,Wenwu Zhu",ACM,"Network Embedding, Network Representation Learning, Hierarchical Taxonomy, Nested Chinese Restaurant Process","Network embedding learns the low-dimensional representations for vertices, while preserving the inter-vertex similarity reflected by the network structure. The neighborhood structure of a vertex is usually closely related with an underlying hierarchical taxonomy—the vertices are associated with successively broader categories that can be organized hierarchically. The categories of different levels reflects similarity of different granularity. The hierarchy of the taxonomy therefore requires that the learned representations support multiple levels of granularity. Moreover, the hierarchical taxonomy enables the information to flow between vertices via their common categories, and thus provides an effective mechanism for alleviating data scarcity. However, incorporating the hierarchical taxonomy into network embedding poses a great challenge (since the taxonomy is generally unknown), and it is neglected by the existing approaches. In this paper, we propose NetHiex, a NETwork embedding model that captures the latent HIErarchical taXonomy. In our model, a vertex representation consists of multiple components that are associated with categories of different granularity. The representations of both the vertices and the categories are co-regularized. We employ the nested Chinese restaurant process to guide the search of the most plausible hierarchical taxonomy. The network structure is then recovered from the latent representations via a Bernoulli distribution. The whole model is unified within a nonparametric probabilistic framework. A scalable
expectation-maximization algorithm is derived for optimization. Empirical results demonstrate that NetHiex achieves significant performance gain over the state-of-arts.
"
Scalable Graph Embeddings via Sparse Transpose Proximities,"Y. G. Yin, Zhewei Wei",arXiv,"Graph Embedding, Network Representation Learning, Personalized PageRank","Graph embedding learns low-dimensional representations for nodes in a graph and effectively preserves the graph structure. Recently, a significant amount of progress has been made toward this emerging research area. However, there are several fundamental problems that remain open. First, existing methods fail to preserve the out-degree distributions on directed graphs. Second, many existing methods employ random walk based proximities and thus suffer from conflicting optimization goals on undirected graphs. Finally, existing factorization methods are unable to achieve scalability and non-linearity simultaneously. This paper presents an in-depth study on graph embedding techniques on both directed and undirected graphs. We analyze the fundamental reasons that lead to the distortion of out-degree distributions and to the conflicting optimization goals. We propose {\em transpose proximity}, a unified approach that solves both problems. Based on the concept of transpose proximity, we design \strap, a factorization based graph embedding algorithm that achieves scalability and non-linearity simultaneously. \strap makes use of the {\em backward push} algorithm to efficiently compute the sparse {\em Personalized PageRank (PPR)} as its transpose proximities. By imposing the sparsity constraint, we are able to apply non-linear operations to the proximity matrix and perform efficient matrix factorization to derive the embedding vectors. Finally, we present an extensive experimental study that evaluates the effectiveness of various graph embedding algorithms, and we show that \strap outperforms the state-of-the-art methods in terms of effectiveness and scalability."
Gaussian Embedding of Large-scale Attributed Graphs,"Bhagya Hettige, Yuan-Fang Li, WeiqingWang, Wray L. Buntine",arXiv,"Graph Embedding, Link Prediction, Node Classification","Graph embedding methods transform high-dimensional and complex graph contents into low-dimensional representations. They are useful for a wide range of graph analysis tasks including link prediction, node classification, recommendation and visualization. Most existing approaches represent graph nodes as point vectors in a low-dimensional embedding space, ignoring the uncertainty present in the real-world graphs. Furthermore, many real-world graphs are large-scale and rich in content (e.g. node attributes). In this work, we propose GLACE, a novel, scalable graph embedding method that preserves both graph structure and node attributes effectively and efficiently in an end-to-end manner. GLACE effectively models uncertainty through Gaussian embeddings, and supports inductive inference of new nodes based on their attributes. In our comprehensive experiments, we evaluate GLACE on real-world graphs, and the results demonstrate that GLACE significantly outperforms state-of-the-art embedding methods on multiple graph analysis tasks."
Empirical Comparison of Graph Embeddings for Trust-Based Collaborative Filtering,"Tomislav Duricic, Hussain MusaHussain, Emanuel Lacic, DominikKowald, Denis Helic, Elisabeth Lex",arXiv,"Recommender Systems, Empirical Study, Graph Embeddings, Cold-Start, Trust Networks","In this work, we study the utility of graph embeddings to generate latent user representations for trust-based collaborative filtering. In a cold-start setting, on three publicly available datasets, we evaluate approaches from four method families: (i) factorization-based, (ii) random walk-based, (iii) deep learning-based, and (iv) the Large-scale Information Network Embedding (LINE) approach. We find that across the four families, random-walk-based approaches consistently achieve the best accuracy. Besides, they result in highly novel and diverse recommendations. Furthermore, our results show that the use of graph embeddings in trust-based collaborative filtering significantly improves user coverage."
Investigating Extensions to Random Walk Based Graph Embedding,"Jörg Schlötterer, Martin Wehking,Fatemeh Salehi Rizi, Michael Granitzer",arXiv,"Graph Embedding, Node Embedding, Random Walk, Feature Learning","Graph embedding has recently gained momentum in the research community, in particular after the introduction of random walk and neural network based approaches. However, most of the embedding approaches focus on representing the local neighborhood of nodes and fail to capture the global graph structure, i.e. to retain the relations to distant nodes. To counter that problem, we propose a novel extension to random walk based graph embedding, which removes a percentage of least frequent nodes from the walks at different levels. By this removal, we simulate farther distant nodes to reside in the close neighborhood of a node and hence explicitly represent their connection. Besides the common evaluation tasks for graph embeddings, such as node classification and link prediction, we evaluate and compare our approach against related methods on shortest path approximation. The results indicate, that extensions to random walk based methods (including our own) improve the predictive performance only slightly - if at all."
Billion-scale Commodity Embedding for E-commerce Recommendation in Alibaba,"Jizhe Wang, Pipei Huang, Huan Zhao,Zhibo Zhang, Binqiang Zhao, Dik LunLee",arXiv,"Recommendation System, Collaborative Filtering, Graph Embedding, E-commerce Recommendation","Recommender systems (RSs) have been the most important technology for increasing the business in Taobao, the largest online consumer-to-consumer (C2C) platform in China. The billion-scale data in Taobao creates three major challenges to Taobao's RS: scalability, sparsity and cold start. In this paper, we present our technical solutions to address these three challenges. The methods are based on the graph embedding framework. We first construct an item graph from users' behavior history. Each item is then represented as a vector using graph embedding. The item embeddings are employed to compute pairwise similarities between all items, which are then used in the recommendation process. To alleviate the sparsity and cold start problems, side information is incorporated into the embedding framework. We propose two aggregation methods to integrate the embeddings of items and the corresponding side information. Experimental results from offline experiments show that methods incorporating side information are superior to those that do not. Further, we describe the platform upon which the embedding methods are deployed and the workflow to process the billion-scale data in Taobao. Using online A/B test, we show that the online Click-Through-Rate (CTRs) are improved comparing to the previous recommendation methods widely used in Taobao, further demonstrating the effectiveness and feasibility of our proposed methods in Taobao's live production environment."
Global Vectors for Node Representations,"Robin Brochier, Adrien Guille, JulienVelcin",arXiv,"Representation Learning, Network Embedding, Matrix Factorization","Most network embedding algorithms consist in measuring co-occurrences of nodes via random walks then learning the embeddings using Skip-Gram with Negative Sampling. While it has proven to be a relevant choice, there are alternatives, such as GloVe, which has not been investigated yet for network embedding. Even though SGNS better handles non co-occurrence than GloVe, it has a worse time-complexity. In this paper, we propose a matrix factorization approach for network embedding, inspired by GloVe, that better handles non co-occurrence with a competitive time-complexity. We also show how to extend this model to deal with networks where nodes are documents, by simultaneously learning word, node and document representations. Quantitative evaluations show that our model achieves state-of-the-art performance, while not being so sensitive to the choice of hyper-parameters. Qualitatively speaking, we show how our model helps exploring a network of documents by generating complementary network-oriented and content-oriented keywords."
Constructing Graph Node Embeddings via Discrimination of Similarity Distributions,"Stanislav Tsepa, Maxim Panov",IEEE,"Graph node embeddings, representation learning, Wasserstein distance, unsupervised learning, link prediction","The problem of unsupervised learning node embeddings in graphs is one of the important directions in modern network science. In this work we propose a novel framework, which is aimed to find embeddings by discriminating distributions of similarities (DDoS) between nodes in the graph. The general idea is implemented by maximizing the earth mover distance between distributions of decoded similarities of similar and dissimilar nodes. The resulting algorithm generates embeddings which give a state-of-the-art performance in the problem of link prediction in real-world graphs."
Compositional network embedding for link prediction,"Tianshu Lyu, Fei Sun, Peng Jiang,Wenwu Ou, Yan Zhang",arXiv,"Network Embedding, Principle of Compositionally ","Network embedding has proved extremely useful in a variety of network analysis tasks such as node classification, link prediction, and network visualization. Almost all the existing network embedding methods learn to map the node IDs to their corresponding node embeddings. This design principle, however, hinders the existing methods from being applied in real cases. Node ID is not generalizable and, thus, the existing methods have to pay great effort in cold-start problem. The heterogeneous network usually requires extra work to encode node types, as node type is not able to be identified by node ID. Node ID carries rare information, resulting in the criticism that the existing methods are not robust to noise. To address this issue, we introduce Compositional Network Embedding, a general inductive network representation learning framework that generates node embeddings by combining node features based on the principle of compositionally. Instead of directly optimizing an embedding lookup based on arbitrary node IDs, we learn a composition function that infers node embeddings by combining the corresponding node attribute embeddings through a graph-based loss. For evaluation, we conduct the experiments on link prediction under four different settings. The results verified the effectiveness and generalization ability of compositional network embeddings, especially on unseen nodes."
Community Preserving Node Embedding Based on Seed-Expansion Sampling,"Yilin Yang, Nianwen Ning, Yunlei Zhang,Bin Wu",IEEE,"Node Embedding, Network Sampling, Seed Expansion, Community Structure","Social network analysis focuses on extraction of various network properties and facilitates many applications like link prediction and community detection. As one of those popular and promising analytical approaches, network embedding aims to represent the network in a low-dimensional space with preservation of the network's structure and inherent properties. Existing network embedding methods are mainly targeted at network's microscopic structure, particularly at first-order and second-order proximities of nodes. However, the demand of scalable community structural information preservation is ignored. In this paper, we propose a novel Seed-Expansion sampling based Network Embedding model (SENE) to capture mesoscale community information into our learned vectors. We also present an improved network sampling algorithm based on XS strategy to capture node sequences that contain more information. We then feed the sampled node context to Skip-Gram model. Extensive experimental results on several sorts of social networks demonstrate the superior performance of the proposed method over the state-of-the-arts."
motif2vec: Motif Aware Node Representation Learning for Heterogeneous Networks,"Manoj Reddy Dareddy, MahashwetaDas, Hao Yang",arXiv,"heterogeneous information networks, network embedding, network representation learning, feature learning, motifs","Recent years have witnessed a surge of interest in machine learning on graphs and networks with applications ranging from vehicular network design to IoT traffic management to social network recommendations. Supervised machine learning tasks in networks such as node classification and link prediction require us to perform feature engineering that is known and agreed to be the key to success in applied machine learning. Research efforts dedicated to representation learning, especially representation learning using deep learning, has shown us ways to automatically learn relevant features from vast amounts of potentially noisy, raw data. However, most of the methods are not adequate to handle heterogeneous information networks which pretty much represents most real-world data today. The methods cannot preserve the structure and semantic of multiple types of nodes and links well enough, capture higher-order heterogeneous connectivity patterns, and ensure coverage of nodes for which representations are generated. We propose a novel efficient algorithm, motif2vec that learns node representations or embeddings for heterogeneous networks. Specifically, we leverage higher-order, recurring, and statistically significant network connectivity patterns in the form of motifs to transform the original graph to motif graph(s), conduct biased random walk to efficiently explore higher order neighborhoods, and then employ heterogeneous skip-gram model to generate the embeddings. Unlike previous efforts that uses different graph meta-structures to guide the random walk, we use graph motifs to transform the original network and preserve the heterogeneity. We evaluate the proposed algorithm on multiple real-world networks from diverse domains and against existing state-of-the-art methods on multi-class node classification and link prediction tasks, and demonstrate its consistent superiority over prior work."
ADPE: Adaptive Dynamic Projected Embedding on Heterogeneous Information Networks,"Lei Yu, Guangluan Xu, Yang Wang,Yunyan Zhang, Feng Li",IEEE,"Dynamic projected embedding, heterogeneous information network, network representation learning.","Network embedding (NE) aims to represent network information appropriately by learning low-dimensional and dense vectors for the nodes and edges of information network. Actually, the real world is almost full of heterogeneous information networks, which stimulates the emergence of heterogeneous information networks (HINs) embedding models. However, parts of existing HIN embedding models like meta-path-based methods only capture limited and aggregated information of relations, whereas some models based on metric or distance learning are usually of high computational complexity and slow training speed. In this paper, we present a novel heterogeneous information network embedding model, which applies dynamic projection metrics and translation mechanisms to the complicated heterogeneous information networks including multiple nodes and different relations. In order to overcome the imbalance of the distribution of relations in HIN and optimize the training process, we introduce an adaptive loss function for model optimization. Further more, we propose a hybrid model with baseline method as the initialization of the model. Experiments have been implemented on some real-world HIN datasets. And empirical results show that our model significantly outperforms the state-of-the-art representation learning models."
SENSE: Semantically Enhanced Node Sequence Embedding,"Swati Rallapalli, Liang Ma, MudhakarSrivatsa, Ananthram Swami, HeesungKwon, Graham A. Bent, ChristopherSimpkin",arXiv,,"Effectively capturing graph node sequences in the form of vector embeddings is critical to many applications. We achieve this by (i) first learning vector embeddings of single graph nodes and (ii) then composing them to compactly represent node sequences. Specifically, we propose SENSE-S (Semantically Enhanced Node Sequence Embedding - for Single nodes), a skip-gram based novel embedding mechanism, for single graph nodes that co-learns graph structure as well as their textual descriptions. We demonstrate that SENSE-S vectors increase the accuracy of multi-label classification tasks by up to 50% and link-prediction tasks by up to 78% under a variety of scenarios using real datasets. Based on SENSE-S, we next propose generic SENSE to compute composite vectors that represent a sequence of nodes, where preserving the node order is important. We prove that this approach is efficient in embedding node sequences, and our experiments on real data confirm its high accuracy in node order decoding."
Benchmarks for Graph Embedding Evaluation,"Palash Goyal, Di Huang, AnkitaGoswami, Sujit Rokka Chhetri,Arquimedes Canedo, Emilio Ferrara",arXiv,"Graph Embedding Benchmarks, Graph embedding techniques, Graph embedding applications, Python Graph Embedding Methods GEM Library
","Graph embedding is the task of representing nodes of a graph in a low-dimensional space and its applications for graph tasks have gained significant traction in academia and industry. The primary difference among the many recently proposed graph embedding methods is the way they preserve the inherent properties of the graphs. However, in practice, comparing these methods is very challenging. The majority of methods report performance boosts on few selected real graphs. Therefore, it is difficult to generalize these performance improvements to other types of graphs. Given a graph, it is currently impossible to quantify the advantages of one approach over another. In this work, we introduce a principled framework to compare graph embedding methods. Our goal is threefold: (i) provide a unifying framework for comparing the performance of various graph embedding methods, (ii) establish a benchmark with real-world graphs that exhibit different structural properties, and (iii) provide users with a tool to identify the best graph embedding method for their data. This paper evaluates 4 of the most influential graph embedding methods and 4 traditional link prediction methods against a corpus of 100 real-world networks with varying properties. We organize the 100 networks in terms of their properties to get a better understanding of the embedding performance of these popular methods. We use the comparisons on our 100 benchmark graphs to define GFS-score, that can be applied to any embedding method to quantify its performance. We rank the state-of-the-art embedding approaches using the GFS-score and show that it can be used to understand and evaluate novel embedding approaches. We envision that the proposed framework (this https URL) will serve the community as a benchmarking platform to test and compare the performance of future graph embedding techniques."
Network Representation Learning for Link Prediction: Are we improving upon simple heuristics?,"Alexandru Mara, Jefrey Lijffijt, Tijl DeBie",arXiv,,"Network representation learning has become an active research area in recent years with many new methods showcasing their performance on downstream prediction tasks such as Link Prediction. Despite the efforts of the community to ensure reproducibility of research by providing method implementations, important issues remain. The complexity of the evaluation pipelines and abundance of design choices have led to difficulties in quantifying the progress in the field and identifying the state-of-the-art. In this work, we analyse 17 network embedding methods on 7 real-world datasets and find, using a consistent evaluation pipeline, only thin progress over the recent years. Also, many embedding methods are outperformed by simple heuristics. Finally, we discuss how standardized evaluation tools can repair this situation and boost progress in this field."
PINE: Universal Deep Embedding for Graph Nodes via Partial Permutation Invariant Set Functions,"Shupeng Gui, Xiangliang Zhang, PanZhong, Shuang Qiu, Mingrui Wu, JiepingYe, Zhengdao Wang, Ji Liu",arXiv,,"Graph node embedding aims at learning a vector representation for all nodes given a graph. It is a central problem in many machine learning tasks (e.g., node classification, recommendation, community detection). The key problem in graph node embedding lies in how to define the dependence to neighbors. Existing approaches specify (either explicitly or implicitly) certain dependencies on neighbors, which may lead to loss of subtle but important structural information within the graph and other dependencies among neighbors. This intrigues us to ask the question: can we design a model to give the maximal flexibility of dependencies to each node's neighborhood. In this paper, we propose a novel graph node embedding (named PINE) via a novel notion of partial permutation invariant set function, to capture any possible dependence. Our method 1) can learn an arbitrary form of the representation function from the neighborhood, withour losing any potential dependence structures, and 2) is applicable to both homogeneous and heterogeneous graph embedding, the latter of which is challenged by the diversity of node types. Furthermore, we provide theoretical guarantee for the representation capability of our method for general homogeneous and heterogeneous graphs. Empirical evaluation results on benchmark data sets show that our proposed PINE method outperforms the state-of-the-art approaches on producing node vectors for various learning tasks of both homogeneous and heterogeneous graphs."
Multi-Facet Network Embedding: Beyond the General Solution of Detection and Representation,"Liang Yang, Yuanfang Guo, XiaochunCao",AAAI,,"In network analysis, community detection and network embedding are two important topics. Community detection tends to obtain the most noticeable partition, while network embedding aims at seeking node representations which contains as many diverse properties as possible. We observe that the current community detection and network embedding problems are being resolved by a general solution, i.e., “maximizing the consistency between similar nodes while maximizing the distance between the dissimilar nodes”. This general solution only exploits the most noticeable structure (facet) of the network, which effectively satisfies the demands of the community detection. Unfortunately, most of the specific embedding algorithms, which are developed from the general solution, cannot achieve the goal of network embedding by exploring only one facet of the network. To improve the general solution for better modeling the real network, we propose a novel network embedding method, Multi-facet Network Embedding (MNE), to capture the multiple facets of the network. MNE learns multiple embeddings simultaneously, with the Hilbert Schmidt Independence Criterion (HSIC) being the a diversity constraint. To efficiently solve the optimization problem, we propose a Binary HSIC with linear complexity and solve the MNE objective function by adopting the Augmented Lagrange Multiplier (ALM) method. The overall complexity is linear with the scale of the network. Extensive results demonstrate that MNE gives efficient performances and outperforms the state-of-the-art network embedding methods."
Combining natural language processing and network analysis to examine how advocacy organizations stimulate conversation on social media.,Christopher A Bail,PMC,"Advocacy Organizations, Computational Social Science, Natural Language Processing, Networks, Public Deliberation","Social media sites are rapidly becoming one of the most important forums for public deliberation about advocacy issues. However, social scientists have not explained why some advocacy organizations produce social media messages that inspire far-ranging conversation among social media users, whereas the vast majority of them receive little or no attention. I argue that advocacy organizations are more likely to inspire comments from new social media audiences if they create ""cultural bridges,"" or produce messages that combine conversational themes within an advocacy field that are seldom discussed together. I use natural language processing, network analysis, and a social media application to analyze how cultural bridges shaped public discourse about autism spectrum disorders on Facebook over the course of 1.5 years, controlling for various characteristics of advocacy organizations, their social media audiences, and the broader social context in which they interact. I show that organizations that create substantial cultural bridges provoke 2.52 times more comments about their messages from new social media users than those that do not, controlling for these factors. This study thus offers a theory of cultural messaging and public deliberation and computational techniques for text analysis and application-based survey research."
Discovering Shifts to Suicidal Ideation from Mental Health Content in Social Media,"Munmun De Choudhury, Emre Kiciman,Mark Dredze, Glen Coppersmith, MrinalKumar",PMC,"Social Media, Suicide Ideation, Mental Health, Reddit","History of mental illness is a major factor behind suicide risk and ideation. However research efforts toward characterizing and forecasting this risk is limited due to the paucity of information regarding suicide ideation, exacerbated by the stigma of mental illness. This paper fills gaps in the literature by developing a statistical methodology to infer which individuals could undergo transitions from mental health discourse to suicidal ideation. We utilize semi-anonymous support communities on Reddit as unobtrusive data sources to infer the likelihood of these shifts. We develop language and interactional measures for this purpose, as well as a propensity score matching based statistical approach. Our approach allows us to derive distinct markers of shifts to suicidal ideation. These markers can be modeled in a prediction framework to identify individuals likely to engage in suicidal ideation in the future. We discuss societal and ethical implications of this research."
node2vec: Scalable Feature Learning for Networks,"Aditya Grover, Jure Leskovec",arXiv,"Information networks, Feature learning, Node embeddings, Graph representations","Prediction tasks over nodes and edges in networks require careful effort in engineering features used by learning algorithms. Recent research in the broader field of representation learning has led to significant progress in automating prediction by learning the features themselves. However, present feature learning approaches are not expressive enough to capture the diversity of connectivity patterns observed in networks. Here we propose node2vec, an algorithmic framework for learning continuous feature representations for nodes in networks. In node2vec, we learn a mapping of nodes to a low-dimensional space of features that maximizes the likelihood of preserving network neighborhoods of nodes. We define a flexible notion of a node's network neighborhood and design a biased random walk procedure, which efficiently explores diverse neighborhoods. Our algorithm generalizes prior work which is based on rigid notions of network neighborhoods, and we argue that the added flexibility in exploring neighborhoods is the key to learning richer representations. We demonstrate the efficacy of node2vec over existing state-of-the-art techniques on multi-label classification and link prediction in several real-world networks from diverse domains. Taken together, our work represents a new way for efficiently learning state-of-the-art task-independent representations in complex networks."
The Stanford Core NLP Natural Language Processing Toolkit,"Christopher D. Manning, MihaiSurdeanu, John Bauer, Jenny RoseFinkel, Steven Bethard, David McClosky",ACL,,"We describe the design and use of the Stanford CoreNLP toolkit, an extensible pipeline that provides core natural language analysis. This toolkit is quite widelyused, both in the research NLP community and also among commercial and government users of open source NLP technology. We suggest that this follows from a simple, approachable design, straightforward interfaces, the inclusion of robust and good quality analysis components, and not requiring use of a large amount of associated baggage."
Distributed Representations of Sentences and Documents,"Quoc V. Le, Shaobo He",arXiv,,"Many machine learning algorithms require the input to be represented as a fixed-length feature vector. When it comes to texts, one of the most common fixed-length features is bag-of-words. Despite their popularity, bag-of-words features have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words. For example, ""powerful,"" ""strong"" and ""Paris"" are equally distant. In this paper, we propose Paragraph Vector, an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents. Our algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-of-words models. Empirical results show that Paragraph Vectors outperform bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks."
Distributed Representations of Words and Phrases and their Compositionality,"Shaobo He, Ilya Sutskever, Kai Chen,Gregory S. Corrado, Jeffrey Dean",arXiv,,"The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of ""Canada"" and ""Air"" cannot be easily combined to obtain ""Air Canada"". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible."
Novel Use of Natural Language Processing (NLP) to Predict Suicidal Ideation and Psychiatric Symptoms in a Text-Based Mental Health Intervention in Madrid,"Benjamin Lê Cook, Ana M. Progovac,Pei Chen, Brian Mullin, Sherry Hou,Enrique Baca-García",PMC,,"Natural language processing (NLP) and machine learning were used to predict suicidal ideation and heightened psychiatric symptoms among adults recently discharged from psychiatric inpatient or emergency room settings in Madrid, Spain. Participants responded to structured mental and physical health instruments at multiple follow-up points. Outcome variables of interest were suicidal ideation and psychiatric symptoms (GHQ-12). Predictor variables included structured items (e.g., relating to sleep and well-being) and responses to one unstructured question, ""how do you feel today?"" We compared NLP-based models using the unstructured question with logistic regression prediction models using structured data. The PPV, sensitivity, and specificity for NLP-based models of suicidal ideation were 0.61, 0.56, and 0.57, respectively, compared to 0.73, 0.76, and 0.62 of structured data-based models. The PPV, sensitivity, and specificity for NLP-based models of heightened psychiatric symptoms (GHQ-12 ≥ 4) were 0.56, 0.59, and 0.60, respectively, compared to 0.79, 0.79, and 0.85 in structured models. NLP-based models were able to generate relatively high predictive values based solely on responses to a simple general mood question. These models have promise for rapidly identifying persons at risk of suicide or psychological distress and could provide a low-cost screening alternative in settings where lengthy structured item surveys are not feasible."
Understanding the impact of stigma on people with mental illness.,"Patrick W Corrigan, A. Clinton Watson",World Psychiatry,,
Enriching Word Vectors with Subword Information,"Piotr Bojanowski, Edouard Grave,Armand Joulin, Shaobo He",arXiv,,"Continuous word representations, trained on large unlabeled corpora are useful for many natural language processing tasks. Popular models that learn such representations ignore the morphology of words, by assigning a distinct vector to each word. This is a limitation, especially for languages with large vocabularies and many rare words. In this paper, we propose a new approach based on the skipgram model, where each word is represented as a bag of character n-grams. A vector representation is associated to each character n-gram; words being represented as the sum of these representations. Our method is fast, allowing to train models on large corpora quickly and allows us to compute word representations for words that did not appear in the training data. We evaluate our word representations on nine different languages, both on word similarity and analogy tasks. By comparing to recently proposed morphological word representations, we show that our vectors achieve state-of-the-art performance on these tasks."
Structural Equivalence: Meaning and Measures,"Stephen P. Borgatti, Travis J. Grosser",International Encyclopedia of the Social & Behavioral Sciences,"Blockmodeling, Clustering, Cohesion, Graph theory, Homomorphism, Isomorphism, Position, Regular equivalence, Role, Similarity, Social homogeneity, Social networks","In social network analysis, two nodes are considered structurally equivalent if they have the same neighborhoods – that is, they are connected to the same others. Initially introduced as a convenience for creating reduced models of networks, it was soon seen as a way to formalize the concept of relational role or position. To the extent that characteristics of nodes are shaped by their social environments, we expect structurally equivalent nodes to develop similar characteristics. Structural equivalence has been used to explain similarities in beliefs and attitudes, the adoption of innovation, the evolution of interfirm networks, political affiliation, the structure of trade among nations, and the effects of technology change."
"A Comprehensive Survey of Graph Embedding: Problems, Techniques, and Applications","HongYun Cai, Vincent Wenchen Zheng,Kevin Chen-Chuan Chang",arXiv,"Graph embedding, graph analytics, graph embedding survey, network embedding","Graph is an important data representation which appears in a wide diversity of real-world scenarios. Effective graph analytics provides users a deeper understanding of what is behind the data, and thus can benefit a lot of useful applications such as node classification, node recommendation, link prediction, etc. However, most graph analytics methods suffer the high computation and space cost. Graph embedding is an effective yet efficient way to solve the graph analytics problem. It converts the graph data into a low dimensional space in which the graph structural information and graph properties are maximally preserved. In this survey, we conduct a comprehensive review of the literature in graph embedding. We first introduce the formal definition of graph embedding as well as the related concepts. After that, we propose two taxonomies of graph embedding which correspond to what challenges exist in different graph embedding problem settings and how the existing work address these challenges in their solutions. Finally, we summarize the applications that graph embedding enables and suggest four promising future research directions in terms of computation efficiency, problem settings, techniques and application scenarios."
Distributed large-scale natural graph factorization,"Amr Ahmed, Nino Shervashidze,Shravan M. Narayanamurthy, VanjaJosifovski, Alexander J. Smola",IW3C2 ,"Large-scale Machine Learning, Distributed Optimization, Graph Factorization, Matrix Factorization, Asynchronous Algorithms, Graph Algorithms, Graph Partitioning","Natural graphs, such as social networks, email graphs, or instant messaging patterns, have become pervasive through the internet. These graphs are massive, often containing hundreds of millions of nodes and billions of edges. While some theoretical models have been proposed to study such graphs, their analysis is still difficult due to the scale and nature of the data. We propose a framework for large-scale graph decomposition and inference. To resolve the scale, our framework is distributed so that the data are partitioned over a sharednothing set of machines. We propose a novel factorization technique that relies on partitioning a graph so as to minimize the number of neighboring vertices rather than edges across partitions. Our decomposition is based on a streaming algorithm. It is network-aware as it adapts to the network topology of the underlying computational hardware. We use local copies of the variables and an efficient asynchronous communication protocol to synchronize the replicated values in order to perform most of the computation without having to incur the cost of network communication. On a graph of 200 million vertices and 10 billion edges, derived from an email communication network, our algorithm retains convergence properties while allowing for almost linear scalability in the number of computers."
Accurate Text-Enhanced Knowledge Graph Representation Learning,"Bo An, Bo Chen, Xianpei Han, Le Sun",ACL,,"Previous representation learning techniques for knowledge graph representation usually represent the same entity or relation in different triples with the same representation, without considering the ambiguity of relations and entities. To appropriately handle the semantic variety of entities/relations in distinct triples, we propose an accurate text-enhanced knowledge graph representation learning method, which can represent a relation/entity with different representations in different triples by exploiting additional textual information. Specifically, our method enhances representations by exploiting the entity descriptions and triple-specific relation mention. And a mutual attention mechanism between relation mention and entity description is proposed to learn more accurate textual representations for further improving knowledge graph representation. Experimental results show that our method achieves the state-of-the-art performance on both link prediction and triple classification tasks, and significantly outperforms previous text-enhanced knowledge representation models."
Stigmatization of people with mental illnesses: a follow-up study within the Changing Minds campaign of the Royal College of Psychiatrists.,"Arthur Crisp, Michael Gelder, E.Desmond Goddard, Howard Meltzer",World Psychiatry,"Stigmatization, public opinions, mental illness","A population survey before the start of the Changing Minds campaign showed that negative opinions about people with mental illnesses were widely held, and that opinions about different disorders differed in important ways. We repeated the survey 5 years later, when the campaign had ended. Interviews were again conducted with a representative population sample (1725 interviews; response rate 65%), enquiring about demographic variables, about eight opinions concerning seven common mental disorders, and whether the respondents knew anyone with one of these mental disorders. The pattern of response in this second survey resembled that in the first. However, there were significant changes. Though often small, apart from reported opinions concerning treatment and outcome, they were all reductions in the percentages of stigmatizing opinions. Seventy seven percent of respondents reported knowing someone with one of the seven disorders. Those who did so in respect of severe depression or panic and phobias were less likely to have stigmatizing opinions about people with the corresponding disorder, but the same did not apply to the other disorders. The greatest proportion of negative opinions was in the 16-19 year age group, and respondents with higher education were less likely than the rest to express such views. We conclude that stigmatizing opinions are frequent in the community but the various disorders are not stigmatized in the same way. Campaigns to reduce stigma should take account of these differences, and of the need to address young people."
Stigmatisation of people with mental illnesses.,"Arthur Crisp, Michael G. Gelder, S Rix, Howard Meltzer, O J Rowlands",The Royal College of Psychiatrists,,"Our background is the recognition of the additional social handicaps and distress that people with mental illnesses experience as a result of prejudice. We aim to determine opinions of the British adult population concerning those with mental illnesses as baseline data for a campaign to combat stigmatisation. Our method was a survey of adults (n=1737 interviewed; 65% response) regarding seven types of common mental disorders. Responses evaluated concerned eight specified perceptions. The results were that respondents commonly perceived people with schizophrenia, alcoholism and drug addiction as unpredictable and dangerous. The two latter conditions were also viewed as self-inflicted. People with any of the seven disorders were perceived as hard to talk with. Opinions about effects of treatment and prognosis suggested reasonable knowledge. About half the respondents reported knowing someone with a mental illness. The conclusions were that negative opinions indiscriminately overemphasise social handicaps that can accompany mental disorders. They contribute to social isolation, distress and difficulties in employment faced by sufferers. A campaign against stigma should take account of the differences in opinions about the seven disorders studied."
metapath2vec: Scalable Representation Learning for Heterogeneous Networks,"Yuxiao Dong, Nitesh V. Chawla,Ananthram Swami",ACM ,"Network Embedding, Heterogeneous Representation Learning, Latent Representations, Feature Learning, Heterogeneous Information Networks","We study the problem of representation learning in heterogeneous networks. Its unique challenges come from the existence of multiple types of nodes and links, which limit the feasibility of the conventional network embedding techniques. We develop two scalable representation learning models, namely metapath2vec and metapath2vec++. The metapath2vec model formalizes meta-pathbased random walks to construct the heterogeneous neighborhood of a node and then leverages a heterogeneous skip-gram model to perform node embeddings. The metapath2vec++ model further enables the simultaneous modeling of structural and semantic correlations in heterogeneous networks. Extensive experiments show that metapath2vec and metapath2vec++ are able to not only outperform state-of-the-art embedding models in various heterogeneous network mining tasks, such as node classification, clustering, and similarity search, but also discern the structural and semantic correlations between diverse network objects."
Resolution limit in community detection.,"Santo Fortunato, Marc Barthelemy",PNAS,"Complex Networks, Modular Structure, Metabolic Networks, Social Networks ","Detecting community structure is fundamental for uncovering the links between structure and function in complex networks and for practical applications in many disciplines such as biology and sociology. A popular method now widely used relies on the optimization of a quantity called modularity, which is a quality index for a partition of a network into communities. We find that modularity optimization may fail to identify modules smaller than a scale which depends on the total size of the network and on the degree of interconnectedness of the modules, even in cases where modules are unambiguously defined. This finding is confirmed through several examples, both in artificial and in real social, biological, and technological networks, where we show that modularity optimization indeed does not resolve a large number of modules. A check of the modules obtained through modularity optimization is thus necessary, and we provide here key elements for the assessment of the reliability of this community detection method."
Community detection in networks: A user guide,"Santo Fortunato, Darko Hric",arXiv,,"Community detection in networks is one of the most popular topics of modern network science. Communities, or clusters, are usually groups of vertices having higher probability of being connected to each other than to members of other groups, though other patterns are possible. Identifying communities is an ill-defined problem. There are no universal protocols on the fundamental ingredients, like the definition of community itself, nor on other crucial issues, like the validation of algorithms and the comparison of their performances. This has generated a number of confusions and misconceptions, which undermine the progress in the field. We offer a guided tour through the main aspects of the problem. We also point out strengths and weaknesses of popular methods, and give directions to their use."
Sampling A Large Network : How Small Can My Sample Be ?,"Zhiheng Huang, Alvin Chyan",arXiv,,"The underlying problem we would like to investigate is that of a researcher who has developed a computationally intensive algorithm he wishes to run on a large graph. The algorithm is too slow to run on the large graph so instead, he would like to sample the large graph to get a smaller similar graph where he can feasibly run the algorithm. By similar we mean that the smaller graph preserves the properties of the original graph as much as possible. This is the scale-down goal of [1] which is also discussed in [2] from which we take our primary inspiration for this project, whereas [3] and [4] discuss uniform sampling of nodes via exploration and sampling from dynamically evolving graphs, respectively."
Identifying cohesive subgroups,Kenneth A. Frank,Social Networks,,"Cohesive subgroups have always represented an important construct for sociologists who study individuals and organizations. In this article, I apply recent advances in the statistical modelling of social network data to the task of identifying cohesive subgroups from social network data. Further, through simulated data, I describe a process for obtaining the probability that a given sample of data could have been obtained from a network in which actors were no more likely to engage in interaction with subgroup members than with members of other subgroups. I obtain the probability for a specific data set, and then, through further simulations, develop a model which can be applied to future data sets. Also through simulated data, I characterize the extent to which a simple hill-climbing algorithm recovers known subgroup memberships. I apply the algorithm to data indicating the extent of professional discussion among teachers in a high school, and I show the relationship between membership in cohesive subgroups and teachers' orientations towards teaching."
Mapping interactions within and between cohesive subgroups,Kenneth A. Frank,Social Networks,,"The structure of interactions and the pattern of influence in an organization can be characterized in terms of a map of interactions within and between cohesive subgroups. I extend the work of Festinger, Schachter and Back (Social Pressures in Informal Groups, 1950, Stanford University Press) who constructed a map based on the pattern of communication within and between apartment courts. In order to generalize Festinger et al.'s approach, I substitute a posteriori subgroups for Festinger et al.'s apartment courts, and I replace the distances of a physical geography with those of a metric multidimensional scaling. I apply the technique to data indicating professional discussions among teachers in a high school. After confirming that discussions are concentrated within a posteriori subgroups at a level that is unlikely to have occurred by chance alone, I construct a map of discussions within and between the cohesive subgroups. The map allows me to characterize the processes of influence at the teacher and school levels through which the school responds to external conditions, and I argue that a map based on blocks of structurally similar actors does not sustain a comparable characterization."
Characterisation of mental health conditions in social media using Informed Deep Learning,"George Gkotsis, Anika Oellrich,Sumithra Velupillai, Maria Liakata, TimJ. P. Hubbard, Richard J. B. Dobson,Rina Dutta",Scientific Reports,,"The number of people affected by mental illness is on the increase and with it the burden on health and social care use, as well as the loss of both productivity and quality-adjusted life-years. Natural language processing of electronic health records is increasingly used to study mental health conditions and risk behaviours on a large scale. However, narrative notes written by clinicians do not capture first-hand the patients’ own experiences, and only record cross-sectional, professional impressions at the point of care. Social media platforms have become a source of ‘in the moment’ daily exchange, with topics including well-being and mental health. In this study, we analysed posts from the social media platform Reddit and developed classifiers to recognise and classify posts related to mental illness according to 11 disorder themes. Using a neural network and deep learning approach, we could automatically recognise mental illness-related posts in our balenced dataset with an accuracy of 91.08% and select the correct theme with a weighted average accuracy of 71.37%. We believe that these results are a first step in developing methods to characterise large amounts of user-generated content that could support content curation and targeted interventions."
The structure of political discussion networks: a model for the analysis of online deliberation,"Sandra González-Bailón, AndreasKaltenbrunner, Rafael E. Banchs",JIT Palgrave Macmillan,"e-democracy, e-deliberation, online forums, Slashdot, radial trees, social networks, political discussions","This paper shows that online political discussion networks are, on average, wider and deeper than the networks generated by other types of discussions: they engage a larger number of participants and cascade through more levels of nested comments. Using data collected from the Slashdot forum, this paper reconstructs the discussion threads as hierarchical networks and proposes a model for their comparison and classification. In addition to the substantive topic of discussion, which corresponds to the different sections of the forum (such as Developers, Games, or Politics), we classify the threads according to structural features like the maximum number of comments at any level of the network (i.e. the width) and the number of nested layers in the network (i.e. the depth). We find that political discussion networks display a tendency to cluster around the area that corresponds to wider and deeper structures, showing a significant departure from the structure exhibited by other types of discussions. We propose using this model to create a framework that allows the analysis and comparison of different internet technologies for the promotion of political deliberation."
"Graph Embedding Techniques, Applications, and Performance: A Survey","Palash Goyal, Emilio Ferrara",arXiv,"Graph embedding techniques, Graph embedding applications, Python Graph Embedding Methods GEM Library","Graphs, such as social networks, word co-occurrence networks, and communication networks, occur naturally in various real-world applications. Analyzing them yields insight into the structure of society, language, and different patterns of communication. Many approaches have been proposed to perform the analysis. Recently, methods which use the representation of graph nodes in vector space have gained traction from the research community. In this survey, we provide a comprehensive and structured analysis of various graph embedding techniques proposed in the literature. We first introduce the embedding task and its challenges such as scalability, choice of dimensionality, and features to be preserved, and their possible solutions. We then present three categories of approaches based on factorization methods, random walks, and deep learning, with examples of representative algorithms in each category and analysis of their performance on various tasks. We evaluate these state-of-the-art methods on a few common datasets and compare their performance against one another. Our analysis concludes by suggesting some potential applications and future directions. We finally present the open-source Python library we developed, named GEM (Graph Embedding Methods, available at this https URL), which provides all presented algorithms within a unified interface to foster and facilitate research on the topic."
Using Natural Language Processing on the Free Text of Clinical Documents to Screen for Evidence of Homelessness Among US Veterans,"Adi V. Gundlapalli, Marjorie Carter,Miland N. Palmer, Thomas Ginter,Andrew Redd, Steve Pickard, ShuyingShen, Brett R. South, Guy Divita, Scott L.DuVall, Thien M. Nguyen, Leonard W.D'Avolio, Matthew H. Samore",AMIA annual symposium proceedings archive,,"Information retrieval algorithms based on natural language processing (NLP) of the free text of medical records have been used to find documents of interest from databases. Homelessness is a high priority non-medical diagnosis that is noted in electronic medical records of Veterans in Veterans Affairs (VA) facilities. Using a human-reviewed reference standard corpus of clinical documents of Veterans with evidence of homelessness and those without, an open-source NLP tool (Automated Retrieval Console v2.0, ARC) was trained to classify documents. The best performing model based on document level work-flow performed well on a test set (Precision 94%, Recall 97%, F-Measure 96). Processing of a naïve set of 10,000 randomly selected documents from the VA using this best performing model yielded 463 documents flagged as positive, indicating a 4.7% prevalence of homelessness. Human review noted a precision of 70% for these flags resulting in an adjusted prevalence of homelessness of 3.3% which matches current VA estimates. Further refinements are underway to improve the performance. We demonstrate an effective and rapid lifecycle of using an off-the-shelf NLP tool for screening targets of interest from medical records."
On the bias of BFS (Breadth First Search),"Maciej Kurant, Athina Markopoulou,Patrick Thiran",IEEE,,"Breadth First Search (BFS) and other graph traversal techniques are widely used for measuring large unknown graphs, such as online social networks. It has been empirically observed that incomplete BFS is biased toward high degree nodes. In contrast to more studied sampling techniques, such as random walks, the bias of BFS has not been characterized to date. In this paper, we quantify the degree bias of BFS sampling. In particular, we calculate the node degree distribution expected to be observed by BFS as a function of the fraction of covered nodes, in a random graph RG(p k ) with a given (and arbitrary) degree distribution p k . Furthermore, we also show that, for RG(p k ), all commonly used graph traversal techniques (BFS, DFS, Forest Fire, and Snowball Sampling) lead to the same bias, and we show how to correct for this bias. To give a broader perspective, we compare this class of exploration techniques to random walks that are well-studied and easier to analyze. Next, we study by simulation the effect of graph properties not captured directly by our model. We find that the bias gets amplified in graphs with strong positive assortativity. Finally, we demonstrate the above results by sampling the Facebook social network, and we provide some practical guidelines for graph sampling in practice."
An Empirical Evaluation of doc2vec with Practical Insights into Document Embedding Generation,"Jey Han Lau, Timothy Baldwin",arXiv,,"Recently, Le and Mikolov (2014) proposed doc2vec as an extension to word2vec (Mikolov et al., 2013a) to learn document-level embeddings. Despite promising results in the original paper, others have struggled to reproduce those results. This paper presents a rigorous empirical evaluation of doc2vec over two tasks. We compare doc2vec to two baselines and two state-of-the-art document embedding methodologies. We found that doc2vec performs robustly when using models trained on large external corpora, and can be further improved by using pre-trained word embeddings. We also provide recommendations on hyper-parameter settings for general purpose applications, and release source code to induce document embeddings using our trained doc2vec models."
Sampling from large graphs,"Jure Leskovec, Christos Faloutsos",ACM,"graph sampling, graph mining, scaling laws","Given a huge real graph, how can we derive a representative sample? There are many known algorithms to compute interesting measures (shortest paths, centrality, betweenness, etc.), but several of them become impractical for large graphs. Thus graph sampling is essential. The natural questions to ask are (a) which sampling method to use, (b) how small can the sample size be, and (c) how to scale up the measurements of the sample (e.g., the diameter), to get estimates for the large graph. The deeper, underlying question is subtle: how do we measure success? We answer the above questions, and test our answers by thorough experiments on several, diverse datasets, spanning thousands nodes and edges. We consider several sampling methods, propose novel methods to check the goodness of sampling, and develop a set of scaling laws that describe relations between the properties of the original and the sample. In addition to the theoretical contributions, the practical conclusions from our work are: Sampling strategies based on edge selection do not perform well; simple uniform random node selection performs surprisingly well. Overall, best performing methods are the ones based on random-walks and “forest fire”; they match very accurately both static as well as evolutionary graph patterns, with sample sizes down to about 15% of the original graph."
A modified labeling theory approach to mental disorders: An empirical assessment.,"Bruce G Link, Francis T. Cullen, Elmer L.Struening, Patrick E Shrout, Bruce P.Dohrenwend",American Psychological Association,,"Proposes a modified labeling perspective that claims that even if labeling does not directly produce mental disorder, it can lead to negative outcomes. The authors' approach asserts that socialization leads individuals to develop a set of beliefs about how most people treat mental patients. When individuals enter treatment, these beliefs take on new meaning. The more patients believe that they will be devalued and discriminated against, the more they feel threatened by interacting with others. Such strategies can lead to negative consequences for social support networks, jobs, and self-esteem. The authors test this modified labeling perspective using samples of psychiatric patients (n = 164) and 429 untreated community residents (aged 19–59 yrs), and find that both believed that most people will reject mental patients. Additionally, patients endorsed strategies of secrecy, withdrawal, and education to cope with the threat they perceive."
UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction,"Leland McInnes, John Healy",arXiv,,"UMAP (Uniform Manifold Approximation and Projection) is a novel manifold learning technique for dimension reduction. UMAP is constructed from a theoretical framework based in Riemannian geometry and algebraic topology. The result is a practical scalable algorithm that applies to real world data. The UMAP algorithm is competitive with t-SNE for visualization quality, and arguably preserves more of the global structure with superior run time performance. Furthermore, UMAP has no computational restrictions on embedding dimension, making it viable as a general purpose dimension reduction technique for machine learning."
Extending Social Network Analysis with Discourse Analysis: Combining Relational with Interpretive Data,"Christine Moser, Peter L. M.Groenewegen, Marleen Huysman",The Influence of Technology on Social Network Analysis and Mining,"Degree Centrality, Social Network Analysis, Discourse Analysis, Online Community, Dominant Discourse","Online occupational communities are a rapidly growing phenomenon and will become increasingly important to firms in the future. This growth has been mirrored by scientific innovations: major advances have been made with regard to technology, software development and statistical modeling. However, we are often left with only partial information: although we might be able to gather very detailed and massive relational data from for example online communities, we often overlook information on the ties that bind. While we are provided with an increasingly detailed topology of a network this does not allude to what content is at stake. We therefore propose to combine Social Network Analysis (SNA) and Discourse Analysis (DA) in order to reach a deeper understanding of the community. Data from an ongoing study of an online occupational community were analyzed as an example using SNA and DA. We present findings from SNA and are able to complement this relational information with interpretive findings from DA. We contribute to the methodological literature on online communities, in particular in the fields of SNA and DA."
Asymmetric Transitivity Preserving Graph Embedding,"Mingdong Ou, Peng Cui, Jian Pei, ZiweiZhang, Wenwu Zhu",ACM,"asymmetric transitivity, directed graph, high-order proximity, graph embedding","Graph embedding algorithms embed a graph into a vector space where the structure and the inherent properties of the graph are preserved. The existing graph embedding methods cannot preserve the asymmetric transitivity well, which is a critical property of directed graphs. Asymmetric transitivity depicts the correlation among directed edges, that is, if there is a directed path from u to v, then there is likely a directed edge from u to v. Asymmetric transitivity can help in capturing structures of graphs and recovering from partially observed graphs. To tackle this challenge, we propose the idea of preserving asymmetric transitivity by approximating high-order proximity which are based on asymmetric transitivity. In particular, we develop a novel graph embedding algorithm, High-Order Proximity preserved Embedding (HOPE for short), which is scalable to preserve high-order proximities of large scale graphs and capable of capturing the asymmetric transitivity. More specifically, we first derive a general formulation that cover multiple popular highorder proximity measurements, then propose a scalable embedding algorithm to approximate the high-order proximity measurements based on their general formulation. Moreover, we provide a theoretical upper bound on the RMSE (Root Mean Squared Error) of the approximation. Our empirical experiments on a synthetic dataset and three realworld datasets demonstrate that HOPE can approximate the high-order proximities significantly better than the state-ofart algorithms and outperform the state-of-art algorithms in tasks of reconstruction, link prediction and vertex recommendation."
Hierarchical block structures and high-resolution model selection in large networks,Tiago P. Peixoto,arXiv,,"Discovering and characterizing the large-scale topological features in empirical networks are crucial steps in understanding how complex systems function. However, most existing methods used to obtain the modular structure of networks suffer from serious problems, such as being oblivious to the statistical evidence supporting the discovered patterns, which results in the inability to separate actual structure from noise. In addition to this, one also observes a resolution limit on the size of communities, where smaller but well-defined clusters are not detectable when the network becomes large. This phenomenon occurs not only for the very popular approach of modularity optimization, which lacks built-in statistical validation, but also for more principled methods based on statistical inference and model selection, which do incorporate statistical validation in a formally correct way. Here we construct a nested generative model that, through a complete description of the entire network hierarchy at multiple scales, is capable of avoiding this limitation, and enables the detection of modular structure at levels far beyond those possible with current approaches. Even with this increased resolution, the method is based on the principle of parsimony, and is capable of separating signal from noise, and thus will not lead to the identification of spurious modules even on sparse networks. Furthermore, it fully generalizes other approaches in that it is not restricted to purely assortative mixing patterns, directed or undirected graphs, and ad hoc hierarchical structures such as binary trees. Despite its general character, the approach is tractable, and can be combined with advanced techniques of community detection to yield an efficient algorithm that scales well for very large networks."
DeepWalk: online learning of social representations,"Bryan Perozzi, Rami Al-Rfou, StevenSkiena",arXiv,,"We present DeepWalk, a novel approach for learning latent representations of vertices in a network. These latent representations encode social relations in a continuous vector space, which is easily exploited by statistical models. DeepWalk generalizes recent advancements in language modeling and unsupervised feature learning (or deep learning) from sequences of words to graphs. DeepWalk uses local information obtained from truncated random walks to learn latent representations by treating walks as the equivalent of sentences. We demonstrate DeepWalk's latent representations on several multi-label network classification tasks for social networks such as BlogCatalog, Flickr, and YouTube. Our results show that DeepWalk outperforms challenging baselines which are allowed a global view of the network, especially in the presence of missing information. DeepWalk's representations can provide F1 scores up to 10% higher than competing methods when labeled data is sparse. In some experiments, DeepWalk's representations are able to outperform all baseline methods while using 60% less training data. DeepWalk is also scalable. It is an online learning algorithm which builds useful incremental results, and is trivially parallelizable. These qualities make it suitable for a broad class of real world applications such as network classification, and anomaly detection."
DeepInf: Social Influence Prediction with Deep Learning,"Jiezhong Qiu, Jian Tang, Hao Ma,Yuxiao Dong, Kuansan Wang, Jie Tang",arXiv,"Representation Learning, Network Embedding, Graph Convolution, Graph Attention, Social Influence, Social Networks","Social and information networking activities such as on Facebook, Twitter, WeChat, and Weibo have become an indispensable part of our everyday life, where we can easily access friends' behaviors and are in turn influenced by them. Consequently, an effective social influence prediction for each user is critical for a variety of applications such as online recommendation and advertising. Conventional social influence prediction approaches typically design various hand-crafted rules to extract user- and network-specific features. However, their effectiveness heavily relies on the knowledge of domain experts. As a result, it is usually difficult to generalize them into different domains. Inspired by the recent success of deep neural networks in a wide range of computing applications, we design an end-to-end framework, DeepInf, to learn users' latent feature representation for predicting social influence. In general, DeepInf takes a user's local network as the input to a graph neural network for learning her latent social representation. We design strategies to incorporate both network structures and user-specific features into convolutional neural and attention networks. Extensive experiments on Open Academic Graph, Twitter, Weibo, and Digg, representing different types of social and information networks, demonstrate that the proposed end-to-end model, DeepInf, significantly outperforms traditional feature engineering-based approaches, suggesting the effectiveness of representation learning for social applications."
Software Framework for Topic Modelling with Large Corpora,"Radim Rehurek, Petr Sojka",,,"Large corpora are ubiquitous in today’s world and memory quickly becomes the limiting factor in practical applications of the Vector Space Model (VSM). In this paper, we identify a gap in existing implementations of many of the popular algorithms, which is their scalability and ease of use. We describe a Natural Language Processing software framework which is based on the idea of document streaming, i.e. processing corpora document after document, in a memory independent fashion. Within this framework, we implement several popular algorithms for topical inference, including Latent Semantic Analysis and Latent Dirichlet Allocation, in a way that makes them completely independent of the training corpus size. Particular emphasis is placed on straightforward and intuitive framework design, so that modifications and extensions of the methods and/or their application by interested practitioners are effortless. We demonstrate the usefulness of our approach on a real-world scenario of computing document similarities within an existing digital library DML-CZ."
Measuring structural similarity in large online networks.,"Yongren Shi, Michael W. Macy",Social Science Research,"Bipartite, Jaccard, Cosine similarity, Twitter, Co-following","Structural similarity based on bipartite graphs can be used to detect meaningful communities, but the networks have been tiny compared to massive online networks. Scalability is important in applications involving tens of millions of individuals with highly skewed degree distributions. Simulation analysis holding underlying similarity constant shows that two widely used measures – Jaccard index and cosine similarity – are biased by the distribution of out-degree in web-scale networks. However, an alternative measure, the Standardized Co-incident Ratio (SCR), is unbiased. We apply SCR to members of Congress, musical artists, and professional sports teams to show how massive co-following on Twitter can be used to map meaningful affiliations among cultural entities, even in the absence of direct connections to one another. Our results show how structural similarity can be used to map cultural alignments and demonstrate the potential usefulness of social media data in the study of culture, politics, and organizations across the social and behavioral sciences."
LINE: Large-scale Information Network Embedding,"Jian Tang, Meng Qu, Mingzhe Wang,Ming Zhang, Jun Yan, Qiaozhu Mei",arXiv,"information network embedding, scalability, feature learning, dimension reduction","This paper studies the problem of embedding very large information networks into low-dimensional vector spaces, which is useful in many tasks such as visualization, node classification, and link prediction. Most existing graph embedding methods do not scale for real world information networks which usually contain millions of nodes. In this paper, we propose a novel network embedding method called the ""LINE,"" which is suitable for arbitrary types of information networks: undirected, directed, and/or weighted. The method optimizes a carefully designed objective function that preserves both the local and global network structures. An edge-sampling algorithm is proposed that addresses the limitation of the classical stochastic gradient descent and improves both the effectiveness and the efficiency of the inference. Empirical experiments prove the effectiveness of the LINE on a variety of real-world information networks, including language networks, social networks, and citation networks. The algorithm is very efficient, which is able to learn the embedding of a network with millions of vertices and billions of edges in a few hours on a typical single machine. The source code of the LINE is available online."
Structural Deep Network Embedding,"Daixin Wang, Peng Cui, Wenwu Zhu",ACM,"Network Embedding, Deep Learning, Network Analysis","Network embedding is an important method to learn low-dimensional representations of vertexes in networks, aiming to capture and preserve the network structure. Almost all the existing network embedding methods adopt shallow models. However, since the underlying network structure is complex, shallow models cannot capture the highly non-linear network structure, resulting in sub-optimal network representations. Therefore, how to find a method that is able to effectively capture the highly non-linear network structure and preserve the global and local structure is an open yet important problem. To solve this problem, in this paper we propose a Structural Deep Network Embedding method, namely SDNE. More specifically, we first propose a semi-supervised deep model, which has multiple layers of non-linear functions, thereby being able to capture the highly non-linear network structure. Then we propose to exploit the first-order and second-order proximity jointly to preserve the network structure. The second-order proximity is used by the unsupervised component to capture the global network structure. While the first-order proximity is used as the supervised information in the supervised component to preserve the local network structure. By jointly optimizing them in the semi-supervised deep model, our method can preserve both the local and global network structure and is robust to sparse networks. Empirically, we conduct the experiments on five real-world networks, including a language network, a citation network and three social networks. The results show that compared to the baselines, our method can reconstruct the original network significantly better and achieves substantial gains in three applications, i.e. multi-label classification, link prediction and visualization.
"
SSP: Semantic Space Projection for Knowledge Graph Embedding with Text Descriptions,"Han Xiao, Minlie Huang, Lian Meng,Xiao-Yan Zhu",AAAI,,"Knowledge graph embedding represents entities and relations in knowledge graph as low-dimensional, continuous vectors, and thus enables knowledge graph compatible with machine learning models. Though there have been a variety of models for knowledge graph embedding, most methods merely concentrate on the fact triples, while supplementary textual descriptions of entities and relations have not been fully employed. To this end, this paper proposes the semantic space projection (SSP) model which jointly learns from the symbolic triples and textual descriptions. Our model builds interaction between the two information sources, and employs textual descriptions to discover semantic relevance and offer precise semantic embedding. Extensive experiments show that our method achieves substantial improvements against baselines on the tasks of knowledge graph completion and entity classification."
Network Representation Learning with Rich Text Information,"Cheng Yang, Zhiyuan Liu, Deli Zhao,Maosong Sun, Edward Y. Chang",IJCAI,,"Representation learning has shown its effectiveness in many tasks such as image classification and text mining. Network representation learning aims at learning distributed vector representation for each vertex in a network, which is also increasingly recognized as an important aspect for network analysis. Most network representation learning methods investigate network structures for learning. In reality, network vertices contain rich information (such as text), which cannot be well applied with algorithmic frameworks of typical representation learning methods. By proving that DeepWalk, a state-ofthe-art network representation method, is actually equivalent to matrix factorization (MF), we propose text-associated DeepWalk (TADW). TADW incorporates text features of vertices into network representation learning under the framework of matrix factorization. We evaluate our method and various baseline methods by applying them to the task of multi-class classification of vertices. The experimental results show that, our method outperforms other baselines on all three datasets, especially when networks are noisy and training ratio is small."
"Homophily, Structure, and Content Augmented Network Representation Learning","Daokun Zhang, Jie Yin, Xingquan Zhu,Chengqi Zhang",IEEE,,"Advances in social networking and communication technologies have witnessed an increasing number of applications where data is not only characterized by rich content information, but also connected with complex relationships representing social roles and dependencies between individuals. To enable knowledge discovery from such networked data, network representation learning (NRL) aims to learn vector representations for network nodes, such that off-the-shelf machine learning algorithms can be directly applied. To date, existing NRL methods either primarily focus on network structure or simply combine node content and topology for learning. We argue that in information networks, information is mainly originated from three sources: (1) homophily, (2) topology structure, and (3) node content. Homophily states social phenomenon where individuals sharing similar attributes (content) tend to be directly connected through local relational ties, while topology structure emphasizes more on global connections. To ensure effective network representation learning, we propose to augment three information sources into one learning objective function, so that the interplay roles between three parties are enforced by requiring the learned network representations (1) being consistent with node content and topology structure, and also (2) following the social homophily constraints in the learned space. Experiments on multi-class node classification demonstrate that the representations learned by the proposed method consistently outperform state-of-the-art NRL methods, especially for very sparsely labeled networks."
Triplet Enhanced AutoEncoder: Model-free Discriminative Network Embedding,"Yao Yang, Haoran Chen, Junming Shao",IJCAI,,"Deep autoencoder is widely used in dimensionality reduction because of the expressive power of the neural network. Therefore, it is naturally suitable for embedding tasks, which essentially compresses high-dimensional information into a low-dimensional latent space. In terms of network representation, methods based on autoencoder such as SDNE and DNGR have achieved comparable results with the state-of-arts. However, all of them do not leverage label information, which leads to the embeddings lack the characteristic of discrimination. In this paper, we present Triplet Enhanced AutoEncoder (TEA), a new deep network embedding approach from the perspective of metric learning. Equipped with the triplet-loss constraint, the proposed approach not only allows capturing the topological structure but also preserving the discriminative information. Moreover, unlike existing discriminative embedding techniques, TEA is independent of any specific classifier, we call it the model-free property. Extensive empirical results on three public datasets (i.e, Cora, Citeseer and BlogCatalog) show that TEA is stable and achieves state-of-the-art performance compared with both supervised and unsupervised network embedding approaches on various percentages of labeled data."
Adversarial Training Methods for Network Embedding,"Quanyu Dai, Xiao Shen, Liang Zhang,Qiang Li, Dan Wang",arXiv,"Network Embedding, Adversarial Training, Robustness","Network Embedding is the task of learning continuous node representations for networks, which has been shown effective in a variety of tasks such as link prediction and node classification. Most of existing works aim to preserve different network structures and properties in low-dimensional embedding vectors, while neglecting the existence of noisy information in many real-world networks and the overfitting issue in the embedding learning process. Most recently, generative adversarial networks (GANs) based regularization methods are exploited to regularize embedding learning process, which can encourage a global smoothness of embedding vectors. These methods have very complicated architecture and suffer from the well-recognized non-convergence problem of GANs. In this paper, we aim to introduce a more succinct and effective local regularization method, namely adversarial training, to network embedding so as to achieve model robustness and better generalization performance. Firstly, the adversarial training method is applied by defining adversarial perturbations in the embedding space with an adaptive L2 norm constraint that depends on the connectivity pattern of node pairs. Though effective as a regularizer, it suffers from the interpretability issue which may hinder its application in certain real-world scenarios. To improve this strategy, we further propose an interpretable adversarial training method by enforcing the reconstruction of the adversarial examples in the discrete graph domain. These two regularization methods can be applied to many existing embedding models, and we take DeepWalk as the base model for illustration in the paper. Empirical evaluations in both link prediction and node classification demonstrate the effectiveness of the proposed methods."
Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking,"Aleksandar Bojchevski, StephanGünnemann",arXiv,,"Methods that learn representations of nodes in a graph play a critical role in network analysis since they enable many downstream learning tasks. We propose Graph2Gauss - an approach that can efficiently learn versatile node embeddings on large scale (attributed) graphs that show strong performance on tasks such as link prediction and node classification. Unlike most approaches that represent nodes as point vectors in a low-dimensional continuous space, we embed each node as a Gaussian distribution, allowing us to capture uncertainty about the representation. Furthermore, we propose an unsupervised method that handles inductive learning scenarios and is applicable to different types of graphs: plain/attributed, directed/undirected. By leveraging both the network structure and the associated node attributes, we are able to generalize to unseen nodes without additional training. To learn the embeddings we adopt a personalized ranking formulation w.r.t. the node distances that exploits the natural ordering of the nodes imposed by the network structure. Experiments on real world networks demonstrate the high performance of our approach, outperforming state-of-the-art network embedding methods on several different tasks. Additionally, we demonstrate the benefits of modeling uncertainty - by analyzing it we can estimate neighborhood diversity and detect the intrinsic latent dimensionality of a graph."
Learning Topological Representation for Networks via Hierarchical Sampling,"Guoji Fu, Chengbin Hou, Xin Yao",arXiv,,"The topological information is essential for studying the relationship between nodes in a network. Recently, Network Representation Learning (NRL), which projects a network into a low-dimensional vector space, has been shown their advantages in analyzing large-scale networks. However, most existing NRL methods are designed to preserve the local topology of a network, they fail to capture the global topology. To tackle this issue, we propose a new NRL framework, named HSRL, to help existing NRL methods capture both the local and global topological information of a network. Specifically, HSRL recursively compresses an input network into a series of smaller networks using a community-awareness compressing strategy. Then, an existing NRL method is used to learn node embeddings for each compressed network. Finally, the node embeddings of the input network are obtained by concatenating the node embeddings from all compressed networks. Empirical studies for link prediction on five real-world datasets demonstrate the advantages of HSRL over state-of-the-art methods."
Influence of Random Walk Parametrization on Graph Embeddings,"Fabian Schliski, Jörg Schlötterer,Michael Granitzer",Advances in Information Retrieval,"Feature Learning, Graph Embedding, Random Walk ","Network or graph embedding has gained increasing attention in the research community during the last years. In particular, many methods to create graph embeddings using random walk based approaches have been developed. node2vec [10] introduced means to control the random walk behavior, guiding the walks. We aim to reproduce parts of their work and introduce two additional modifications (jump probabilities and attention to hubs), in order to investigate how guiding and modifying the walks influences the learned embeddings. The reproduction includes the case study illustrating homophily and structural equivalence subject to the chosen strategy and a node classification task. We were not able to illustrate structural equivalence and further results show that modifications of the walks only slightly improve node classification, if at all."
Enhanced Network Representation Learning With Community Aware and Relational Attention,"Mingqiang Zhou, Dan Liu, Yihan Kong,Haijiang Jin",IEEE,"Community aware, relational attention, network representation learning","Network representation learning is proposed to make it easier to perform complex inference processes on large-scale networks. It aims to represent each node in the network as a low-dimensional potential representation while preserving the structure and inherent features of the network. Most existing learning methods do not consider the comprehensive structure or the rich semantics of between nodes, which lead to incomplete embeddings. We attempt to find a way to learn network representation while keeping the network structure and relations between nodes to address this issue. In this paper, we propose a Community Aware and Relational Attention (CARA) method to enhance network representation learning. In CARA, community aware random walks capture both the community and local context from a global perspective to enhance the structure embedding. And we design a two-layer attention mechanism to model the semantic relationships between nodes, which can learn different text embedding for different neighbors. Then, these two embeddings are combined together to obtain the node representation. Experiments on four real-world networks show that CARA has better performance than other methods in link prediction and node classification."
Graph embedding and its application in defect detection system,"Qifeng Huang, Aixia Zheng, XuesongShao, Xiaoquan Lu, Meimei Duan",IEEE,,"Recent years, auto meter reading system performance has been the focus of research. In this paper, we apply graph analysis method to embedding the node in the power system to detect the defect in auto meter reading system. We use decision tree algorithm to determine the problematic nodes. We tried five kinds of graph embedding methods to experiment. We find that these methods have improved the accuracy of fault diagnosis to a certain extend."
LouvainNE: Hierarchical Louvain Method for High Quality and Scalable Network Embedding,"Ayan Kumar Bhowmick, KoushikMeneni, Maximilien Danisch, Jean-LoupGuillaume, Bivas Mitra",ACM,"Network embedding, Scalability, real-world graph algorithms","Network embedding, that aims to learn low-dimensional vector representation of nodes such that the network structure is preserved, has gained significant research attention in recent years. However, most state-of-the-art network embedding methods are computationally expensive and hence unsuitable for representing nodes in billion-scale networks. In this paper, we present LouvainNE, a hierarchical clustering approach to network embedding. Precisely, we employ Louvain, an extremely fast and accurate community detection method, to build a hierarchy of successively smaller subgraphs. We obtain representations of individual nodes in the original graph at different levels of the hierarchy, then we aggregate these representations to learn the final embedding vectors. Our theoretical analysis shows that our proposed algorithm has quasi-linear runtime and memory complexity. Our extensive experimental evaluation, carried out on multiple real-world networks of different scales, demonstrates both (i) the scalability of our proposed approach that can handle graphs containing tens of billions of edges, as well as (ii) its effectiveness in performing downstream network mining tasks such as network reconstruction and node classification"
Shortest Path Distance Approximation Using Deep Learning Techniques,"Fatemeh Salehi Rizi, Jörg Schlötterer,Michael Granitzer",arXiv,,"Computing shortest path distances between nodes lies at the heart of many graph algorithms and applications. Traditional exact methods such as breadth-first-search (BFS) do not scale up to contemporary, rapidly evolving today's massive networks. Therefore, it is required to find approximation methods to enable scalable graph processing with a significant speedup. In this paper, we utilize vector embeddings learnt by deep learning techniques to approximate the shortest paths distances in large graphs. We show that a feedforward neural network fed with embeddings can approximate distances with relatively low distortion error. The suggested method is evaluated on the Facebook, BlogCatalog, Youtube and Flickr social networks."
Fast Network Embedding Enhancement via High Order Proximity Approximation,"Cheng Yang, Maosong Sun, ZhiyuanLiu, Cunchao Tu",IJCAI,,"Many Network Representation Learning (NRL) methods have been proposed to learn vector representations for vertices in a network recently. In this paper, we summarize most existing NRL methods into a unified two-step framework, including proximity matrix construction and dimension reduction. We focus on the analysis of proximity matrix construction step and conclude that an NRL method can be improved by exploring higher order proximities when building the proximity matrix. We propose Network Embedding Update (NEU) algorithm which implicitly approximates higher order proximities with theoretical approximation bound and can be applied on any NRL methods to enhance their performances. We conduct experiments on multi-label classification and link prediction tasks. Experimental results show that NEU can make a consistent and significant improvement over a number of NRL methods with almost negligible running time on all three publicly available datasets."
HONEM: Network Embedding Using Higher-Order Patterns in Sequential Data,"Mandana Saebi, Giovanni LucaCiampaglia, Lance M. Kaplan, Nitesh V.Chawla",arXiv,,"Representation learning offers a powerful alternative to the oft painstaking process of manual feature engineering, and as a result, has enjoyed considerable success in recent years. This success is especially striking in the context of graph mining, since networks can take advantage of vast troves of sequential data to encode information about interactions between entities of interest. But how do we learn embeddings on networks that have higher-order and sequential dependencies? Existing network embedding methods naively assume the Markovian property (first-order dependency) for node interactions, which may not capture the time-dependent and longer-range underlying complex interactions of the raw data. To address the limitation of current methods, we propose a network embedding method for higher-order networks (HON). We demonstrate that the higher-order network embedding (HONEM) method is able to extract higher-order dependencies from HON to construct the higher-order neighborhood matrix of the network, while existing methods are not able to capture these higher-order dependencies. We show that our method outperforms other state-of-the-art methods in node classification, network reconstruction, link prediction, and visualization."
Etworks via I Mportance S Ampling,"Jie Chen, Tengfei Ma, Cao Xiao",,,
FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling,"Jian Jhen Chen, Tengfei Ma, Cao Xiao",arXiv,,"The graph convolutional networks (GCN) recently proposed by Kipf and Welling are an effective graph model for semi-supervised learning. This model, however, was originally designed to be learned with the presence of both training and test data. Moreover, the recursive neighborhood expansion across layers poses time and memory challenges for training with large, dense graphs. To relax the requirement of simultaneous availability of test data, we interpret graph convolutions as integral transforms of embedding functions under probability measures. Such an interpretation allows for the use of Monte Carlo approaches to consistently estimate the integrals, which in turn leads to a batched training scheme as we propose in this work---FastGCN. Enhanced with importance sampling, FastGCN not only is efficient for training but also generalizes well for inference. We show a comprehensive set of experiments to demonstrate its effectiveness compared with GCN and related models. In particular, training is orders of magnitude more efficient while predictions remain comparably accurate."
ICE: Item Concept Embedding via Textual Information,"Chuan-Ju Wang, Ting-Hsiang Wang,Hsiu-Wei Yang, Bo-Sin Chang, Ming-Feng Tsai",ACM,conceptual retrieval; concept embedding; textual information; information network,"This paper proposes an item concept embedding (ICE) framework to model item concepts via textual information. Specifically, in the proposed framework there are two stages: graph construction and embedding learning. In the first stage, we propose a generalized network construction method to build a network involving heterogeneous nodes and a mixture of both homogeneous and heterogeneous relations. The second stage leverages the concept of neighborhood proximity to learn the embeddings of both items and words. With the proposed carefully designed ICE networks, the resulting embedding facilitates both homogeneous and heterogeneous retrieval, including item-to-item and word-to-item retrieval. Moreover, as a distributed embedding approach, the proposed ICE approach not only generates related retrieval results but also delivers more diverse results than traditional keyword-matching-based approaches. As our experiments on two real-world datasets show, ICE encodes useful textual information and thus outperforms traditional methods in various item classification and retrieval tasks."
Learning Heterogeneous Network Embedding From Text and Links,"Yunfei Long, Rong Xiang, Qin Lu, DanXiong, Chu-Ren Huang, Chenglin Bi,Minglei Li",IEEE,,"Finding methods to represent multiple types of nodes in heterogeneous networks is both challenging and rewarding, as there is much less work in this area compared with that of homogeneous networks. In this paper, we propose a novel approach to learn node embedding for heterogeneous networks through a joint learning framework of both network links and text associated with nodes. A novel attention mechanism is also used to make good use of text extended through links to obtain much larger network context. Link embedding is first learned through a random-walk-based method to process multiple types of links. Text embedding is separately learned at both sentence level and document level to capture salient semantic information more comprehensively. Then, both types of embeddings are jointly fed into a hierarchical neural network model to learn node representation through mutual enhancement. The attention mechanism follows linked edges to obtain context of adjacent nodes to extend context for node representation. The evaluation on a link prediction task in a heterogeneous network data set shows that our method outperforms the current state-of-the-art method by 2.5%–5.0% in AUC values with p-value less than 10−9 , indicating very significant improvement."
Interpretable Feature Learning of Graphs using Tensor Decomposition,"Shah Muhammad Hamdi, Rafal A.Angryk",IEEE,,"In recent years, node embedding algorithms, which learn low dimensional vector representations for nodes in a graph, have been one of the key research interests of the graph mining community. The existing algorithms either rely on computationally expensive eigendecomposition of the large matrices, or require tuning of the word embedding-based hyperparameters as a result of representing the graph as a node sequence similar to the sentences in a document. Moreover, the latent features produced by these algorithms are hard to interpret. In this paper, we present two novel tensor decomposition-based node embedding algorithms, that can learn node features from arbitrary types of graphs: undirected, directed, and/or weighted, without relying on eigendecomposition or word embedding-based hyperparameters. Both algorithms preserve the local and global structural properties of the graph by using k-step transition probability matrices to construct third-order multidimensional arrays or tensors and perform CANDECOMP/PARAFAC (CP) decomposition in order to produce an interpretable and low dimensional vector space for the nodes. Our experiments encompass different types of graphs (undirected/directed, unweighted/weighted, sparse/dense) of different domains such as social networking and neuroscience. Our experimental evaluation proves our models to be interpretable with respect to the understandability of the feature space, precise with respect to the network reconstruction and link prediction, and accurate with respect to node classification and graph classification."
Sequence to Sequence Network for Learning Network Representation,"Qi Liang, Mei Lin Zhou, Lu Ma, Dan Luo,Peng Zhang, Bin Wang",IEEE,,"Network representation learning is an important way for learning the low dimensional vector of nodes in the network, with preserving certain structural information between nodes in the original graph. Most existing network embedding models use truncated random walks and shallow architectures which do not fully obtain the nonlinear information and neighborhood information of the network. In this article, we propose a novel method for network representation learning which generates low-dimensional representation vectors for each node in the graph by obtaining the local and global structure information of the network. Unlike previous work, we use the hybrid BFS and DFS methods to sample the neighbor information of each node instead of using the uniform sampling method in DeepWalk to generate the linear sequences. After obtaining the linear sequences, we use a sequence to sequence network that contains a teaching sequence which is proved effective in capturing the nonlinear information of graph, to learn the reconstruction error of the input sequence and the output sequence. We named our method SSNR which is not only preserve both the local and global network structure information, but also capture the nonlinear information from network to achieve more discriminative node representation. To verify the effectiveness of SSNR, we employ the learned node representation as features in downstream experiments with node classification and graph visualization tasks. The experimental results of different datasets demonstrate that SSNR outperforms many state-of-the-art baseline models in these tasks."
Network Embedding: on Compression and Learning,"Esra Akbaş, Mehmet Emin Aktas",arXiv,,"Recently, network embedding that encodes structural information of graphs into a vector space has become popular for network analysis. Although recent methods show promising performance for various applications, the huge sizes of graphs may hinder a direct application of existing network embedding method to them. This paper presents NECL, a novel efficient Network Embedding method with two goals. 1) Is there an ideal Compression of a network? 2) Will the compression of a network significantly boost the representation Learning of the network? For the first problem, we propose a neighborhood similarity based graph compression method that compresses the input graph to get a smaller graph without losing any/much information about the global structure of the graph and the local proximity of the vertices in the graph. For the second problem, we use the compressed graph for network embedding instead of the original large graph to bring down the embedding cost. NECL is a general meta-strategy to improve the efficiency of all of the state-of-the-art graph embedding algorithms based on random walks, including DeepWalk and Node2vec, without losing their effectiveness. Extensive experiments on large real-world networks validate the efficiency of NECL method that yields an average improvement of 23 - 57% embedding time, including walking and learning time without decreasing classification accuracy as evaluated on single and multi-label classification tasks on real-world graphs such as DBLP, BlogCatalog, Cora and Wiki."
Scalable Graph Embeddings via Sparse Transpose Proximities,"Yuan Yin, Zhewei Wei",arXiv,,"Graph embedding learns low-dimensional representations for nodes in a graph and effectively preserves the graph structure. Recently, a significant amount of progress has been made toward this emerging research area. However, there are several fundamental problems that remain open. First, existing methods fail to preserve the out-degree distributions on directed graphs. Second, many existing methods employ random walk based proximities and thus suffer from conflicting optimization goals on undirected graphs. Finally, existing factorization methods are unable to achieve scalability and non-linearity simultaneously. This paper presents an in-depth study on graph embedding techniques on both directed and undirected graphs. We analyze the fundamental reasons that lead to the distortion of out-degree distributions and to the conflicting optimization goals. We propose {\em transpose proximity}, a unified approach that solves both problems. Based on the concept of transpose proximity, we design \strap, a factorization based graph embedding algorithm that achieves scalability and non-linearity simultaneously. \strap makes use of the {\em backward push} algorithm to efficiently compute the sparse {\em Personalized PageRank (PPR)} as its transpose proximities. By imposing the sparsity constraint, we are able to apply non-linear operations to the proximity matrix and perform efficient matrix factorization to derive the embedding vectors. Finally, we present an extensive experimental study that evaluates the effectiveness of various graph embedding algorithms, and we show that \strap outperforms the state-of-the-art methods in terms of effectiveness and scalability."
Network2Vec: Learning Node Representation Based on Space Mapping in Networks,"Zhenhua Huang, Zhenyu Wang, RuiZhang, Yangyang Zhao, Xiaohui Xie,Sharad Mehrotra",arXiv,,"Complex networks represented as node adjacency matrices constrains the application of machine learning and parallel algorithms. To address this limitation, network embedding (i.e., graph representation) has been intensively studied to learn a fixed-length vector for each node in an embedding space, where the node properties in the original graph are preserved. Existing methods mainly focus on learning embedding vectors to preserve nodes proximity, i.e., nodes next to each other in the graph space should also be closed in the embedding space, but do not enforce algebraic statistical properties to be shared between the embedding space and graph space. In this work, we propose a lightweight model, entitled Network2Vec, to learn network embedding on the base of semantic distance mapping between the graph space and embedding space. The model builds a bridge between the two spaces leveraging the property of group homomorphism. Experiments on different learning tasks, including node classification, link prediction, and community visualization, demonstrate the effectiveness and efficiency of the new embedding method, which improves the state-of-the-art model by 19% in node classification and 7% in link prediction tasks at most. In addition, our method is significantly faster, consuming only a fraction of the time used by some famous methods."
Node Representation Learning for Directed Graphs,"Megha Khosla, Jurek Leonhardt,Wolfgang Nejdl, Avishek Anand",arXiv,"Directed Graphs, Node Representations, Link Prediction, Graph Reconstruction, Node Classification","We propose a novel approach for learning node representations in directed graphs, which maintains separate views or embedding spaces for the two distinct node roles induced by the directionality of the edges. We argue that the previous approaches either fail to encode the edge directionality or their encodings cannot be generalized across tasks. With our simple \emph{alternating random walk} strategy, we generate role specific vertex neighborhoods and train node embeddings in their corresponding source/target roles while fully exploiting the semantics of directed graphs. We also unearth the limitations of evaluations on directed graphs in previous works and propose a clear strategy for evaluating link prediction and graph reconstruction in directed graphs. We conduct extensive experiments to showcase our effectiveness on several real-world datasets on link prediction, node classification and graph reconstruction tasks. We show that the embeddings from our approach are indeed robust, generalizable and well performing across multiple kinds of tasks and graphs. We show that we consistently outperform all baselines for node classification task. In addition to providing a theoretical interpretation of our method we also show that we are considerably more robust than the other directed graph approaches."
Multi-View Network Representation Learning Algorithm Research,"Zhonglin Ye, Haixing Zhao, Ke Zhang,Yu Zhu",Algorithms,"network embedding, network representation, network embedding learning, network representation learning, network classification","Network representation learning is a key research field in network data mining. In this paper, we propose a novel multi-view network representation algorithm (MVNR), which embeds multi-scale relations of network vertices into the low dimensional representation space. In contrast to existing approaches, MVNR explicitly encodes higher order information using k-step networks. In addition, we introduce the matrix forest index as a kind of network feature, which can be applied to balance the representation weights of different network views. We also research the relevance amongst MVNR and several excellent research achievements, including DeepWalk, node2vec and GraRep and so forth. We conduct our experiment on several real-world citation datasets and demonstrate that MVNR outperforms some new approaches using neural matrix factorization. Specifically, we demonstrate the efficiency of MVNR on network classification, visualization and link prediction tasks."
Customized Graph Embedding: Tailoring the Embedding Vector to a Specific Application,"Bitan Hou, Yujing Wang, Ming Zeng,Shan Jiang, Ole J. Mengshoel, YunhaiTong, Jing Bai",arXiv,,"Graph is a natural representation of data for a variety of real-word applications, such as knowledge graph mining, social network analysis and biological network comparison. For these applications, graph embedding is crucial as it provides vector representations of the graph. One limitation of existing graph embedding methods is that their embedding optimization procedures are disconnected from the target application. In this paper, we propose a novel approach, namely Customized Graph Embedding (CGE) to tackle this problem. The CGE algorithm learns customized vector representations of graph nodes by differentiating the importance of distinct graph paths automatically for a specific application. Extensive experiments were carried out on a diverse set of node classification datasets, which demonstrate strong performances of CGE and provide deep insights into the model."
FeatNet: Large-scale Fraud Device Detection by Network Representation Learning with Rich Features,"Chao Xu, Zhentan Feng, Yizheng Chen,Minghua Wang, Tao Wei",ACM,"fraud detection, heterogeneous information network, network representation learning, node embedding","Online fraud such as search engine poisoning, groups of fake accounts and opinion fraud is conducted by fraudsters controlling a large number of mobile devices. The key to detect such fraudulent activities is to identify devices controlled by fraudsters. Traditional approaches that fingerprint devices based on device metadata only consider single device information. However, these techniques do not utilize the relationship among different devices, which is crucial to detect fraudulent activities. In this paper, we propose an effective device fraud detection framework called FeatNet, which incorporates device features and device relationships in network representation learning. Specifically, we partition the device network into bipartite graphs and generate the neighborhoods of vertices by revised truncated random walk. Then, we generate the feature signature according to device features to learn the representation of devices. Finally, the embedding vectors of all bipartite graphs are used for fraud detection. We conduct experiments on a large-scale data set and the result shows that our approach can achieve better accuracy than existing algorithms and can be deployed in the real production environment with high performance."
Representation Learning for Recommender Systems with Application to the Scientific Literature,Robin Brochier,arXiv,"representation learning, recommender systems, network embedding, scientific literature","The scientific literature is a large information network linking various actors (laboratories, companies, institutions, etc.). The vast amount of data generated by this network constitutes a dynamic heterogeneous attributed network (HAN), in which new information is constantly produced and from which it is increasingly difficult to extract content of interest. In this article, I present my first thesis works in partnership with an industrial company, Digital Scientific Research Technology. This later offers a scientific watch tool, Peerus, addressing various issues, such as the real time recommendation of newly published papers or the search for active experts to start new collaborations. To tackle this diversity of applications, a common approach consists in learning representations of the nodes and attributes of this HAN and use them as features for a variety of recommendation tasks. However, most works on attributed network embedding pay too little attention to textual attributes and do not fully take advantage of recent natural language processing techniques. Moreover, proposed methods that jointly learn node and document representations do not provide a way to effectively infer representations for new documents for which network information is missing, which happens to be crucial in real time recommender systems. Finally, the interplay between textual and graph data in text-attributed heterogeneous networks remains an open research direction."
gat2vec: representation learning for attributed graphs,"Nasrullah Sheikh, Zekarias T. Kefato,Alberto Montresor",Computing ,"Attributed graphs, Network embedding, Unsupervised learning, Deep learning","Network representation learning (NRL) enables the application of machine learning tasks such as classification, prediction and recommendation to networks. Apart from their graph structure, networks are often associated with diverse information in the form of attributes. Most NRL methods have focused just on structural information, and separately apply a traditional representation learning on attributes. When multiple sources of information are available, using a combination of them may be beneficial as they complement each other in generating accurate contexts; moreover, their combined use may be fundamental when the information sources are sparse. The learning methods should thus preserve both the structural and attribute aspects. In this paper, we investigate how attributes can be modeled, and subsequently used along with structural information in learning the representation. We introduce the GAT2VEC framework that uses structural information to generate structural contexts, attributes to generate attribute contexts, and employs a shallow neural network model to learn a joint representation from them. We evaluate our proposed method against state-of-the-art baselines, using real-world datasets on vertex classification (multi-class and multi-label), link-prediction, and visualization tasks. The experiments show that GAT2VEC is effective in exploiting multiple sources of information, thus learning accurate representations and outperforming the state-of-the-art in the aforementioned tasks. Finally, we perform query tasks on learned representation and show how the qualitative analysis of results has better performance as well."
Network Embedding: An Overview,"Nino Arsov, Georgina Mirceva",arXiv,,"Networks are one of the most powerful structures for modeling problems in the real world. Downstream machine learning tasks defined on networks have the potential to solve a variety of problems. With link prediction, for instance, one can predict whether two persons will become friends on a social network. Many machine learning algorithms, however, require that each input example is a real vector. Network embedding encompasses various methods for unsupervised, and sometimes supervised, learning of feature representations of nodes and links in a network. Typically, embedding methods are based on the assumption that the similarity between nodes in the network should be reflected in the learned feature representations. In this paper, we review significant contributions to network embedding in the last decade. In particular, we look at four methods: Spectral Clustering, DEEPWALK, Large-scale Information Network Embedding (LINE), and node2vec. We describe each method and list its advantages and shortcomings. In addition, we give examples of real-world machine learning problems on networks in which the embedding is critical in order to maximize the predictive performance of the machine learning task. Finally, we take a look at research trends and state-of-the art methods in the research on network embedding."
Neural-Brane: Neural Bayesian Personalized Ranking for Attributed Network Embedding,"Vachik S. Dave, Baichuan Zhang, Pin-YuChen, Mohammad Al Hasan",arXiv,,"Network embedding methodologies, which learn a distributed vector representation for each vertex in a network, have attracted considerable interest in recent years. Existing works have demonstrated that vertex representation learned through an embedding method provides superior performance in many real-world applications, such as node classification, link prediction, and community detection. However, most of the existing methods for network embedding only utilize topological information of a vertex, ignoring a rich set of nodal attributes (such as, user profiles of an online social network, or textual contents of a citation network), which is abundant in all real-life networks. A joint network embedding that takes into account both attributional and relational information entails a complete network information and could further enrich the learned vector representations. In this work, we present Neural-Brane, a novel Neural Bayesian Personalized Ranking based Attributed Network Embedding. For a given network, Neural-Brane extracts latent feature representation of its vertices using a designed neural network model that unifies network topological information and nodal attributes; Besides, it utilizes Bayesian personalized ranking objective, which exploits the proximity ordering between a similar node-pair and a dissimilar node-pair. We evaluate the quality of vertex embedding produced by Neural-Brane by solving the node classification and clustering tasks on four real-world datasets. Experimental results demonstrate the superiority of our proposed method over the state-of-the-art existing methods."
Paper2vec: Combining Graph and Text Information for Scientific Paper Representation,"Soumyajit Ganguly, Vikram Pudi",Advances in Information Retrieval,"Citation Networks, Representation Learning, Text and Graph","We present Paper2vec, a novel neural network embedding based approach for creating scientific paper representations which make use of both textual and graph-based information. An academic citation network can be viewed as a graph where individual nodes contain rich textual information. With the current trend of open-access to most scientific literature, we presume that this full text of a scientific article contain vital source of information which aids in various recommendation and prediction tasks concerning this domain. To this end, we propose an approach, Paper2vec, which comprises of information from both the modalities and results in a rich representation for scientific papers. Over the recent past representation learning techniques have been studied extensively using neural networks. However, they are modeled independently for text and graph data. Paper2vec leverages recent research in the broader field of unsupervised feature learning from both graphs and text documents. We demonstrate the efficacy of our representations on three real world academic datasets in two tasks - node classification and link prediction where Paper2vec is able to outperform state-of-the-art by a considerable margin."
Graph Recurrent Networks With Attributed Random Walks,"Xiao Huang, Qingquan Song, YueningLi, X. X. Hu",ACM,,"Random walks are widely adopted in various network analysis tasks ranging from network embedding to label propagation. It could capture and convert geometric structures into structured sequences while alleviating the issues of sparsity and curse of dimensionality. Though random walks on plain networks have been intensively studied, in real-world systems, nodes are often not pure vertices, but own different characteristics, described by the rich set of data associated with them. These node attributes contain plentiful information that often complements the network, and bring opportunities to the random-walk-based analysis. However, it is unclear how random walks could be developed for attributed networks towards an effective joint information extraction. Node attributes make the node interactions more complicated and are heterogeneous with respect to topological structures. To bridge the gap, we explore to perform joint random walks on attributed networks, and utilize them to boost the deep node representation learning. The proposed framework GraphRNA consists of two major components, i.e., a collaborative walking mechanism - AttriWalk, and a tailored deep embedding architecture for random walks, named graph recurrent networks (GRN). AttriWalk considers node attributes as a bipartite network and uses it to propel the walking more diverse and mitigate the tendency of converging to nodes with high centralities. AttriWalk enables us to advance the prominent deep network embedding model, graph convolutional networks, towards a more effective architecture - GRN. GRN empowers node representations to interact in the same way as nodes interact in the original attributed network. Experimental results on real-world datasets demonstrate the effectiveness of GraphRNA compared with the state-of-the-art embedding algorithms."
Attributed Network Embedding via a Siamese Neural Network,"Jiong Wang, Neng Gao, Jia Jian Peng,Jingjie Mo",IEEE,,"Recently, network embedding has attracted a surge of attention due to its ability to automatically extract features from graph-structured data. Though network embedding method has been intensively studied, most of the existing approaches pay attention to either structures or attributes. In this paper, we propose a novel attributed network embedding method based on a Siamese neural network, named SANE, to capture both the network structure and node attribute information in a principled way. Specifically, to preserve local semantic proximity, we adopt a Siamese neural network, which can directly learn the similarity of paired nodes with their attributes as input. Then, a skip-gram module is connected with the final shared hidden layer to capture high-order proximity based on the latent representation of node attributes. Thus, we can learn the complex interrelations between nodes. Empirically, we evaluate our model on several real-world datasets and the experimental results have verified the effectiveness of our proposed approach."
Variation Autoencoder Based Network Representation Learning for Classification,"Huang Li, Haozheng Wang, ZhengluYang, Masato Odagaki",ACL,,"Network representation is the basis of many applications and of extensive interest in various fields, such as information retrieval, social network analysis, and recommendation systems. Most previous methods for network representation only consider the incomplete aspects of a problem, including link structure, node information, and partial integration. The present study introduces a deep network representation model that seamlessly integrates the text information and structure of a network. The model captures highly non-linear relationships between nodes and complex features of a network by exploiting the variational autoencoder (VAE), which is a deep unsupervised generation algorithm. The representation learned with a paragraph vector model is merged with that learned with the VAE to obtain the network representation, which preserves both structure and text information. Comprehensive experiments is conducted on benchmark datasets and find that the introduced model performs better than state-of-the-art techniques."
SPINE: Structural Identity Preserved Inductive Network Embedding,"Junliang Guo, Linli Xu, Enhong Chen",IJCAI,,"Recent advances in the field of network embedding have shown that low-dimensional network representation is playing a critical role in network analysis. Most existing network embedding methods encode the local proximity of a node, such as the first- and second-order proximities. While being efficient, these methods are short of leveraging the global structural information between nodes distant from each other. In addition, most existing methods learn embeddings on one single fixed network, and thus cannot be generalized to unseen nodes or networks without retraining. In this paper we present SPINE, a method that can jointly capture the local proximity and proximities at any distance, while being inductive to efficiently deal with unseen nodes or networks. Extensive experimental results on benchmark datasets demonstrate the superiority of the proposed framework over the state of the art."
Network-Word Embedding for Dynamic Text Attributed Networks,"Hiroyoshi Ito, Takahiro Komamizu,Toshiyuki Amagasa, Hiroyuki Kitagawa",IEEE,,"Network embedding enables to apply off-the-shelf machine learning methods to the nodes on the network. Leveraging the textual information associated with nodes into network embedding methods is advantageous. However, only a few works try to leverage textual information to network embeddings. Moreover, the structure of networks and associated texts could be dynamically changed over time, this property leads shifts of the vector representation of nodes and words. However, to the best of our knowledge, none of previous network embedding methods considers chronological changes of vector representations of nodes and words. In this paper, we propose a dynamic text attribute network embedding method, which embeds the nodes and the words in a cooperative manner and takes chronological changes of vector representations of nodes and words into account. Experimental results show that (1) vector representations of nodes of our method achieve higher accuracy than baseline methods in classification and clustering tasks; (2) The vector representations of nodes and words successfully capture semantic similarity; And (3) our method successfully capture the chronological change of the vector representations over time."
Graph Attention Auto-Encoders,"Amin Salehi, Hasan Davulcu",arXiv,"Attributed graph representation learning, attributed network embedding, unsupervised graph learning, inductive graph learning","Auto-encoders have emerged as a successful framework for unsupervised learning. However, conventional auto-encoders are incapable of utilizing explicit relations in structured data. To take advantage of relations in graph-structured data, several graph auto-encoders have recently been proposed, but they neglect to reconstruct either the graph structure or node attributes. In this paper, we present the graph attention auto-encoder (GATE), a neural network architecture for unsupervised representation learning on graph-structured data. Our architecture is able to reconstruct graph-structured inputs, including both node attributes and the graph structure, through stacked encoder/decoder layers equipped with self-attention mechanisms. In the encoder, by considering node attributes as initial node representations, each layer generates new representations of nodes by attending over their neighbors' representations. In the decoder, we attempt to reverse the encoding process to reconstruct node attributes. Moreover, node representations are regularized to reconstruct the graph structure. Our proposed architecture does not need to know the graph structure upfront, and thus it can be applied to inductive learning. Our experiments demonstrate competitive performance on several node classification benchmark datasets for transductive and inductive tasks, even exceeding the performance of supervised learning baselines in most cases."
Performance of Common Classifiers on node2vec Network Representations,"Mislav Požek, Lucija Sikic, Petar Afric,Adrian S. Kurdija, Klemo Vladimir,Goran Delač, Marin Silic",IEEE,,"In this paper we evaluate the performance of different multi-class classifiers on network graphs. Since the node embedding techniques have been widely used to represent and analyze networks structures, we decide to transform network data (nodes and links) into attributes which are descriptive and contain correct information of its structure. For this purpose, we use a state-of-the-art algorithmic framework node2vec, which has been shown to outperform other popular methods when applied to multilabel classification as it manages to efficiently learn a mapping of nodes to a low-dimensional space of features. Applying this framework, we generate a set of representations for nodes of multiple network data sets. Using the generated representations, we evaluate the performance of common classifiers. We perform crossvalidation and parameter tuning to get the best possible model of each classifier type. To compare their performance, we computed Precision, Recall and F1-score for each model on each data set. Following that, the obtained results are analyzed and compared."
Co-Embedding Attributed Networks,"Zaiqiao Meng, Shangsong Liang,Hongyan Bao, Xiangliang Zhang",ACM,"Attributed Network, Network Embedding, Variational Auto-encoder","Existing embedding methods for attributed networks aim at learning low-dimensional vector representations for nodes only but not for both nodes and attributes, resulting in the fact that they cannot capture the affinities between nodes and attributes. However, capturing such affinities is of great importance to the success of many real-world attributed network applications, such as attribute inference and user profiling. Accordingly, in this paper, we introduce a Co-embedding model for Attributed Networks (CAN), which learns low-dimensional representations of both attributes and nodes in the same semantic space such that the affinities between them can be effectively captured and measured. To obtain high-quality embeddings, we propose a variational auto-encoder that embeds each node and attribute with means and variances of Gaussian distributions. Experimental results on real-world networks demonstrate that our model yields excellent performance in a number of applications compared with state-of-the-art techniques."
DeepMove: Learning Place Representations through Large Scale Movement Data,"Yang Zhou, Ying Huang",arXiv,"Place Embedding, Points of Interest, Skip-gram, Latent Representation","Understanding and reasoning about places and their relationships are critical for many applications. Places are traditionally curated by a small group of people as place gazetteers and are represented by an ID with spatial extent, category, and other descriptions. However, a place context is described to a large extent by movements made from/to other places. Places are linked and related to each other by these movements. This important context is missing from the traditional representation. We present DeepMove, a novel approach for learning latent representations of places. DeepMove advances the current deep learning based place representations by directly model movements between places. We demonstrate DeepMove's latent representations on place categorization and clustering tasks on large place and movement datasets with respect to important parameters. Our results show that DeepMove outperforms state-of-the-art baselines. DeepMove's representations can provide up to 15% higher than competing methods in matching rate of place category and result in up to 39% higher silhouette coefficient value for place clusters. DeepMove is spatial and temporal context aware. It is scalable. It outperforms competing models using much smaller training dataset (a month or 1/12 of data). These qualities make it suitable for a broad class of real-world applications."
MCNE: An End-to-End Framework for Learning Multiple Conditional Network Representations of Social Network,"Hao Wang, Tong Xu, Qi Liu, Defu Lian,Enhong Chen, Dongfang Du, Han Wu,Wen Su",arXiv,"Network Embedding, Social Network, Conditional Representation","Recently, the Network Representation Learning (NRL) techniques, which represent graph structure via low-dimension vectors to support social-oriented application, have attracted wide attention. Though large efforts have been made, they may fail to describe the multiple aspects of similarity between social users, as only a single vector for one unique aspect has been represented for each node. To that end, in this paper, we propose a novel end-to-end framework named MCNE to learn multiple conditional network representations, so that various preferences for multiple behaviors could be fully captured. Specifically, we first design a binary mask layer to divide the single vector as conditional embeddings for multiple behaviors. Then, we introduce the attention network to model interaction relationship among multiple preferences, and further utilize the adapted message sending and receiving operation of graph neural network, so that multi-aspect preference information from high-order neighbors will be captured. Finally, we utilize Bayesian Personalized Ranking loss function to learn the preference similarity on each behavior, and jointly learn multiple conditional node embeddings via multi-task learning framework. Extensive experiments on public datasets validate that our MCNE framework could significantly outperform several state-of-the-art baselines, and further support the visualization and transfer learning tasks with excellent interpretability and robustness."
A United Approach to Learning Sparse Attributed Network Embedding,"Hao Wang, Enhong Chen, Qi Liu, TongXu, Dongfang Du, Wen Su, XiaopengZhang",IEEE,,"Recently, the Network Representation Learning (NRL) techniques, which target at learning the low-dimension vector representation of graph structures, have attracted wide attention due to the effectiveness on various social-oriented application. Though large efforts have been made on the joint analysis combining node attributes with the network structure, they may usually fail to summarize the weighted correlations within nodes and attributes, especially when the nodes suffer extremely sparse attributes. To that end, in this paper, we propose a novel Sparse Attributed Network Embedding (SANE) framework to learn the network structure and sparse attribute information simultaneously in a united approach. Specifically, we first embed the nodes and attributes into a low-dimensional vector space. Then we introduce the pairwise method to capture the interaction between nodes and sparse attributes, and aggregate the attribute information of neighbors to alleviate sparsity for obtaining a better vector representation of node embeddings, which will be used in following network representation learning task. Along this line, we maintain the network structure by maximizing the probability of predicting the center node according to surrounding context nodes. Different from previous work, we introduce an attention mechanism to adaptively weigh the strength of interactions between each context node and the center node, according to the node attribute similarity. Furthermore, we combine the attention network with CBOW model to learn the similarity of the network structure and node attributes simultaneously. Extensive experiments on public datasets have validated the effectiveness of our SANE model with significant margin compared with the state-of-the-art baselines, which demonstrates the potential of adaptively attribute analysis in network embedding"
Attributed network embedding via subspace discovery,"Daokun Zhang, Jie Yin, Xingquan Zhu,Chengqi Zhang",arXiv,,"Network embedding aims to learn a latent, low-dimensional vector representations of network nodes, effective in supporting various network analytic tasks. While prior arts on network embedding focus primarily on preserving network topology structure to learn node representations, recently proposed attributed network embedding algorithms attempt to integrate rich node content information with network topological structure for enhancing the quality of network embedding. In reality, networks often have sparse content, incomplete node attributes, as well as the discrepancy between node attribute feature space and network structure space, which severely deteriorates the performance of existing methods. In this paper, we propose a unified framework for attributed network embedding-attri2vec-that learns node embeddings by discovering a latent node attribute subspace via a network structure guided transformation performed on the original attribute space. The resultant latent subspace can respect network structure in a more consistent way towards learning high-quality node representations. We formulate an optimization problem which is solved by an efficient stochastic gradient descent algorithm, with linear time complexity to the number of nodes. We investigate a series of linear and non-linear transformations performed on node attributes and empirically validate their effectiveness on various types of networks. Another advantage of attri2vec is its ability to solve out-of-sample problems, where embeddings of new coming nodes can be inferred from their node attributes through the learned mapping function. Experiments on various types of networks confirm that attri2vec is superior to state-of-the-art baselines for node classification, node clustering, as well as out-of-sample link prediction tasks."
Inductive Document Network Embedding with Topic-Word Attention,"Robin Brochier, Adrien Guille, JulienVelcin",arXiv,"Document Network Embedding, Interpretability, Attention Mechanism","Document network embedding aims at learning representations for a structured text corpus i.e. when documents are linked to each other. Recent algorithms extend network embedding approaches by incorporating the text content associated with the nodes in their formulations. In most cases, it is hard to interpret the learned representations. Moreover, little importance is given to the generalization to new documents that are not observed within the network. In this paper, we propose an interpretable and inductive document network embedding method. We introduce a novel mechanism, the Topic-Word Attention (TWA), that generates document representations based on the interplay between word and topic representations. We train these word and topic vectors through our general model, Inductive Document Network Embedding (IDNE), by leveraging the connections in the document network. Quantitative evaluations show that our approach achieves state-of-the-art performance on various networks and we qualitatively show that our model produces meaningful and interpretable representations of the words, topics and documents."
POI Representation Learning by a Hybrid Model,"Yu-rui Li, Hongmei Chen, Lizhen Wang,Qing Xiao",IEEE,"distributed representation, POI, hybrid model, check-in data ","Point of Interest (POI) is the core element of check-in data. It is an effective way to represent POI by distributed representation which can encode the information of POI into a continuous vector space. In this work, we present a hybrid model that map the concepts of network representation learning (NRL) to learn the position of POI and map the concepts of nature language processing (NLP) to learn the category of POI. The results, which are in vector form, can be widely applied to various location based services (LBS) without complicated artificial feature extraction. Further, it can also improve the performance of LBS. By a range of experiments on real datasets, we demonstrate our model's capability at characterizing POI. We also verify the effectiveness of the hybrid model on POI recommendation."
Robust Negative Sampling for Network Embedding,"Mohammadreza Armandpour, PatrickDing, Jianhua Huang, Xia Hu",AAAI,,"Many recent network embedding algorithms use negative sampling (NS) to approximate a variant of the computationally expensive Skip-Gram neural network architecture (SGA) objective. In this paper, we provide theoretical arguments that reveal how NS can fail to properly estimate the SGA objective, and why it is not a suitable candidate for the network embedding problem as a distinct objective. We show NS can learn undesirable embeddings, as the result of the “Popular Neighbor Problem.” We use the theory to develop a new method “R-NS” that alleviates the problems of NS by using a more intelligent negative sampling scheme and careful penalization of the embeddings. R-NS is scalable to large-scale networks, and we empirically demonstrate the superiority of R-NS over NS for multi-label classification on a variety of real-world networks including social networks and language networks."
SINE: Scalable Incomplete Network Embedding,"Daokun Zhang, Jie Yin, Xingquan Zhu,Chengqi Zhang",arXiv,,"Attributed network embedding aims to learn lowdimensional vector representations for nodes in a network, where each node contains rich attributes/features describing node content. Because network topology structure and node attributes often exhibit high correlation, incorporating node attribute proximity into network embedding is beneficial for learning good vector representations. In reality, large-scale networks often have incomplete/missing node content or linkages, yet existing attributed network embedding algorithms all operate under the assumption that networks are complete. Thus, their performance is vulnerable to missing data and suffers from poor scalability. In this paper, we propose a Scalable Incomplete Network Embedding (SINE) algorithm for learning node representations from incomplete graphs. SINE formulates a probabilistic learning framework that separately models pairs of node-context and node-attribute relationships. Different from existing attributed network embedding algorithms, SINE provides greater flexibility to make the best of useful information and mitigate negative effects of missing information on representation learning. A stochastic gradient descent based online algorithm is derived to learn node representations, allowing SINE to scale up to large-scale networks with high learning efficiency. We evaluate the effectiveness and efficiency of SINE through extensive experiments on real-world networks. Experimental results confirm that SINE outperforms state-of-the-art baselines in various tasks, including node classification, node clustering, and link prediction, under settings with missing links and node attributes. SINE is also shown to be scalable and efficient on large-scale networks with millions of nodes/edges and high-dimensional node features."
A3embed: Attribute Association Aware Network Embedding,"Jihwan Lee, Sunil Prabhakar",IW3C2 ,,"Network embedding aims to learn low-dimensional vector representations for nodes in a network that preserve structural characteristics. It has been shown that such representations are helpful in several graph mining tasks such as node classification, link prediction, and community detection. Some recent works have attempted to extend the approach to attributed networks in which each node is associated with a set of attribute values. They have focused on homophily relationships by forcing nodes with similar attribute values to obtain similar vector representations. This is unnecessarily restrictive and misses the opportunity to harness other types of relationships revealed by patterns in attribute values of connected nodes for learning insightful relationships. In this paper, we propose a new network attributed embedding framework called A3embed that is aware of attribute associations. A3embed favors significant attribute associations, not merely homophily relationships, which contributes to its robustness to diverse attribute vectors and noisy links. The experimental results on real-world datasets demonstrate that the proposed framework achieves better performance on different graph mining tasks compared to existing models."
Learning job representation using directed graph embedding,"Haiyan Luo, Shichuan Ma, AnandSelvaraj, Y. Q. Sun",ACM,"directed graph embedding, job recommendation, representation learning","In recent years, embedding technologies have gained popularity in many areas of machine learning, such as NLP, computer vision, information retrieval, etc.. In this paper, we propose a latent representation of job positions consisting of job title and company pairs, which can capture not only similarity relations but also ordering relations among job positions. We first construct a directed graph of job positions from the user's job transition history in the resume data, then we train the job position embedding using an asymmetric relation preserving graph embedding algorithm. Experimental results on a career move prediction task using real-world data set demonstrated that the proposed embedding solution can outperform state-of-the-art embedding methods."
Discerning Edge Influence for Network Embedding,"Yaojing Wang, Yuan Yao, HanghangTong, Feng Xu, Jian Lu",ACM,"Network Embedding, Edge Influence, Network Topological Properties","Network embedding, which learns the low-dimensional representations of nodes, has gained significant research attention. Despite its superior empirical success, often measured by the prediction performance of downstream tasks (e.g., multi-label classification), it is unclear \em why a given embedding algorithm outputs the specific node representations, and \em how the resulting node representations relate to the structure of the input network. In this paper, we propose to discern the edge influence as the first step towards understanding skip-gram basd network embedding methods. For this purpose, we propose an auditing framework Near, whose key part includes two algorithms (Near-add \ and Near-del ) to effectively and efficiently quantify the influence of each edge. Based on the algorithms, we further identify high-influential edges by exploiting the linkage between edge influence and the network structure. Experimental results demonstrate that the proposed algorithms (Near-add \ and Near-del ) are significantly faster (up to $2,000\times$) than straightforward methods with little quality loss. Moreover, the proposed framework can efficiently identify the most influential edges for network embedding in the context of downstream prediction task and adversarial attacking."
Heterogeneous Graph Neural Network,"Chuxu Zhang, Dongjin Song, ChaoHuang, Ananthram Swami, Nitesh V.Chawla",ACM,"Heterogeneous graphs, Graph neural networks, Graph embedding","Representation learning in heterogeneous graphs aims to pursue a meaningful vector representation for each node so as to facilitate downstream applications such as link prediction, personalized recommendation, node classification, etc. This task, however, is challenging not only because of the demand to incorporate heterogeneous structural (graph) information consisting of multiple types of nodes and edges, but also due to the need for considering heterogeneous attributes or contents (e.g., text or image) associated with each node. Despite a substantial amount of effort has been made to homogeneous (or heterogeneous) graph embedding, attributed graph embedding as well as graph neural networks, few of them can jointly consider heterogeneous structural (graph) information as well as heterogeneous contents information of each node effectively. In this paper, we propose HetGNN, a heterogeneous graph neural network model, to resolve this issue. Specifically, we first introduce a random walk with restart strategy to sample a fixed size of strongly correlated heterogeneous neighbors for each node and group them based upon node types. Next, we design a neural network architecture with two modules to aggregate feature information of those sampled neighboring nodes. The first module encodes ""deep"" feature interactions of heterogeneous contents and generates content embedding for each node. The second module aggregates content (attribute) embeddings of different neighboring groups (types) and further combines them by considering the impacts of different groups to obtain the ultimate node embedding. Finally, we leverage a graph context loss and a mini-batch gradient descent procedure to train the model in an end-to-end manner. Extensive experiments on several datasets demonstrate that HetGNN can outperform state-of-the-art baselines in various graph mining tasks, i.e., link prediction, recommendation, node classification & clustering and inductive node classification & clustering."
Enhanced Network Embedding with Text Information,"Shuang Yang, Bo Yang",IEEE,,"Network embedding aims at learning the low-dimensional and continuous vector representation for each node in networks, which is useful in many real applications. While most existing network embedding methods only focus on the network structure, the rich text information associated with nodes, which is often closely related to network structure, is widely neglected. Thus, how to effectively incorporate text information into network embedding is a problem worth studying. To solve the problem, we propose a Text Enhanced Network Embedding (TENE) method under the framework of non-negative matrix factorization to integrate network structure and text information together. We explore the consistent relationship between node representations and text cluster structure to make the network embedding more informative and discriminative. TENE learns the representations of nodes under the guidance of both proximity matrix which captures the network structure and text cluster membership matrix derived from clustering for text information. We evaluate the quality of network embedding on the task of multi-class classification of nodes. Experimental results on all three real-world datasets show the superior performance of TENE compared with baselines."
Apprentissage de Représentation appliquéà la Recommandation pour la Littérature Scientifique,Robin Brochier,Revue d'Intelligence Artificielle,"scientific literature, recommender system, information retrieval","The scientific literature is a large information network linking various actors (laboratories, companies, institutions, etc.). The vast amount of data generated by this network constitutes a dynamic attributed heterogeneous network, in which new information is constantly produced and from which it is increasingly difficult to extract content of interest. In this article, I present my first thesis works in partnership with an industrial company. This later offers a scientific watch tool addressing various issues, such as the recommendation of articles and the search for experts. First, I detail the data usually associated with the scientific literature. Then I present the problem of expert finding, its evaluation and I suggest a new method to juge the quality of an algorithm. Finally, I introduce a representation learning algorithm for the problem of embedding the nodes of a graph in a vector space of small dimension, extended to integrate the textual information related to these nodes."
Node Centralities and Classification Performance for Characterizing Node Embedding Algorithms,"Kento Nozawa, Masanari Kimura,Atsunori Kanemura",arXiv,,"Embedding graph nodes into a vector space can allow the use of machine learning to e.g. predict node classes, but the study of node embedding algorithms is immature compared to the natural language processing field because of a diverse nature of graphs. We examine the performance of node embedding algorithms with respect to graph centrality measures that characterize diverse graphs, through systematic experiments with four node embedding algorithms, four or five graph centralities, and six datasets. Experimental results give insights into the properties of node embedding algorithms, which can be a basis for further research on this topic."
Mineral: Multi-modal Network Representation Learning,"Zekarias T. Kefato, Nasrullah Sheikh,Alberto Montresor","Machine Learning, Optimization, and Big Data","NRL, Diffusion Patterns, Cascades","Network representation learning (NRL) is a task of learning an embedding of nodes in a low-dimensional space. Recent advances in this area have achieved interesting results; however, as there is no solution that fits all kind of networks, NRL algorithms need to be specialized to preserve specific aspects of the networks, such as topology, information content, and community structure. One aspect that has been neglected so far is how a network reacts to the diffusion of information. This aspect is particularly relevant in the context of social networks. Studies have found out that diffusion reveals complex patterns in the network structure that are otherwise difficult to be discovered by other means. In this work, we describe a novel algorithm that combines topology, information content and diffusion process, and jointly learns a high quality embedding of nodes. We performed several experiments using multiple datasets and demonstrate that our algorithm performs significantly better in many network analysis tasks over existing studies."
Semi-Supervised Heterogeneous Information Network Embedding for Node Classification Using 1D-CNN,"Nasrullah Sheikh, Zekarias T. Kefato,Alberto Montresor",IEEE,,"Network Representation Learning (NRL) is a method to learn a representation of a graph in a low-dimensional space, such that the representation can be later utilized easily in various machine learning tasks such as classification, recommendation, and prediction. In contrast to homogeneous networks, heterogeneous information networks (HINs) contain rich semantics and structural information due to multiple types of nodes and edges. Due to heterogeneity, the conventional representation learning methods are not directly applicable. In this paper, we propose a semi-supervised HIN embedding model, adopted from the natural language processing community. The model uses sequences of nodes obtained by random walks constrained on edge types such that the structural and semantic properties are preserved. These sequences correspond to sentences in a document. Each sequence is labeled based on the nodes contained in it. We adopt a 1D-Convolutional Neural Network sentence classification model that seeks to fit a sequence classifier while optimizing the representation of the nodes. We have performed experiments on vertex classification on two widely used realworld datasets, showing better or comparable performance with respect to the state-of-the-art."
SepNE: Bringing Separability to Network Embedding,"Ziyao Li, Liang Zhang, Guojie Song",arXiv,,"Many successful methods have been proposed for learning low dimensional representations on large-scale networks, while almost all existing methods are designed in inseparable processes, learning embeddings for entire networks even when only a small proportion of nodes are of interest. This leads to great inconvenience, especially on super-large or dynamic networks, where these methods become almost impossible to implement. In this paper, we formalize the problem of separated matrix factorization, based on which we elaborate a novel objective function that preserves both local and global information. We further propose SepNE, a simple and flexible network embedding algorithm which independently learns representations for different subsets of nodes in separated processes. By implementing separability, our algorithm reduces the redundant efforts to embed irrelevant nodes, yielding scalability to super-large networks, automatic implementation in distributed learning and further adaptations. We demonstrate the effectiveness of this approach on several real-world networks with different scales and subjects. With comparable accuracy, our approach significantly outperforms state-of-the-art baselines in running times on large networks."
A Brief Review of Network Embedding,"Yaojing Wang, Yuan Yao, HanghangTong, Feng Xu, Jian Lu",BIG DATA MINING AND ANALYTICS,"network embedding, node representations, context construction","Learning the representations of nodes in a network can benefit various analysis tasks such as node classification, link prediction, clustering, and anomaly detection. Such a representation learning problem is referred to as network embedding, and it has attracted significant attention in recent years. In this article, we briefly review the existing network embedding methods by two taxonomies. The technical taxonomy focuses on the specific techniques used and divides the existing network embedding methods into two stages, i.e., context construction and objective design. The non-technical taxonomy focuses on the problem setting aspect and categorizes existing work based on whether to preserve special network properties, to consider special network types, or to incorporate additional inputs. Finally, we summarize the main findings based on the two taxonomies, analyze their usefulness, and discuss future directions in this area."
The Applications of Stochastic Models in Network Embedding: A Survey,"Minglong Lei, Yong Shi, Lingfeng Niu",IEEE,,"Network embedding is a promising topic that maps the vertices to the latent space while keeps the structural proximity in the original space. The network embedding task is difficult since the network vertices have no specific time or space orders. Models that used to extract information from images and texts with regular space or time structures can not be directly applied in network heading. The key feature of network embedding methods should be further exploited. Previous network embedding reviews mainly focus on the models and algorithms used in different methods. In this survey, we review the network embedding works in the stochastic perspective either in data side or model side. Roughly, the network embedding methods fall into three main categories: matrix based methods, random walk based methods and aggregated based methods. We focus on the applications of stochastic models in solving the challenges of network embedding in data processing and modeling following the line of the three categories"
EpiRep: Learning Node Representations through Epidemic Dynamics on Networks,"Benyun Shi, Jianan Zhong, Qing Bao,Hongjun Qiu, Jiming Liu",ACM,"Network embedding, Susceptible-Infectious model, Random walks, Continuous Bag-of-Words, Epidemic dynamics","Understanding the dynamic properties of epidemic spreading on complex social networks is essential to make effective and efficient public health policies for epidemic prevention and control. In recent years, the concept of network embedding has attracted lots of attention to deal with various network analytic tasks, the purpose of which is to encode relationships or information of networked elements into a low-dimensional vector space. However, most existing embedding methods have focused mainly on preserving static network information, such as structural proximity, node/edge attributes, and labels. On the contrary, in this paper, we focus on the embedding problem of preserving dynamic characteristics of epidemic spreading on social networks. We propose a novel embedding method, namely EpiRep, to learn node representations of a network by maximizing the likelihood of preserving groups of infected nodes due to the epidemics starting from every single node on the network. Specifically, the Susceptible-Infectious model is adopted to simulate the epidemic dynamics on networks, and the Continuous Bag-of-Words model with negative sampling is used to obtain node representations. Experimental results show that the EpiRep method outperforms two benchmark random-walk based embedding methods in terms of node clustering and classification on several synthetic and real-world networks. The proposed method and findings in this paper may offer new insight for source identification and infection prevention in the face of epidemic spreading on social networks."
A2CMHNE: Attention-Aware Collaborative Multimodal Heterogeneous Network Embedding,"Jun Hu, Shengsheng Qian, Quan Fang,Xueliang Liu, Changsheng Xu",ACM,"Network embedding, multimodal, heterogeneous network","Network representation learning is playing an important role in network analysis due to its effectiveness in a variety of applications. However, most existing network embedding models focus on homogeneous networks and neglect the diverse properties such as different types of network structures and associated multimedia content information. In this article, we learn node representations for multimodal heterogeneous networks, which contain multiple types of nodes and/or links as well as multimodal content such as texts and images. We propose a novel attention-aware collaborative multimodal heterogeneous network embedding method (A2CMHNE), where an attention-based collaborative representation learning approach is proposed to promote the collaboration of structure-based embedding and content-based embedding, and generate the robust node representation by introducing an attention mechanism that enables informative embedding integration. In experiments, we compare our model with existing network embedding models on two real-world datasets. Our method leads to dramatic improvements in performance by 5%, and 9% compared with five state-of-the-art embedding methods on one benchmark (M10 Dataset), and on a multi-modal heterogeneous network dataset (WeChat dataset) for node classification, respectively. Experimental results demonstrate the effectiveness of our proposed method on both node classification and link prediction tasks."
Diffusion Maps for Textual Network Embedding,"Xinyuan Zhang, Yitong Li, DinghanShen, Lawrence Carin",arXiv,,"Textual network embedding leverages rich text information associated with the network to learn low-dimensional vectorial representations of vertices. Rather than using typical natural language processing (NLP) approaches, recent research exploits the relationship of texts on the same edge to graphically embed text. However, these models neglect to measure the complete level of connectivity between any two texts in the graph. We present diffusion maps for textual network embedding (DMTE), integrating global structural information of the graph to capture the semantic relatedness between texts, with a diffusion-convolution operation applied on the text inputs. In addition, a new objective function is designed to efficiently preserve the high-order proximity using the graph diffusion. Experimental results show that the proposed approach outperforms state-of-the-art methods on the vertex-classification and link-prediction tasks."
Temporal Network Representation Learning via Historical Neighborhoods Aggregation,"Shixun Huang, Zhifeng Bao, GuoliangLi, Yanghao Zhou, J Culpepper",arXiv,,"Network embedding is an effective method to learn low-dimensional representations of nodes, which can be applied to various real-life applications such as visualization, node classification, and link prediction. Although significant progress has been made on this problem in recent years, several important challenges remain, such as how to properly capture temporal information in evolving networks. In practice, most networks are continually evolving. Some networks only add new edges or nodes such as authorship networks, while others support removal of nodes or edges such as internet data routing. If patterns exist in the changes of the network structure, we can better understand the relationships between nodes and the evolution of the network, which can be further leveraged to learn node representations with more meaningful information. In this paper, we propose the Embedding via Historical Neighborhoods Aggregation (EHNA) algorithm. More specifically, we first propose a temporal random walk that can identify relevant nodes in historical neighborhoods which have impact on edge formations. Then we apply a deep learning model which uses a custom attention mechanism to induce node embeddings that directly capture temporal information in the underlying feature representation. We perform extensive experiments on a range of real-world datasets, and the results demonstrate the effectiveness of our new approach in the network reconstruction task and the link prediction task."
Multi-dimensional Graph Convolutional Networks,"Yao Ma, Suhang Wang, Charu C.Aggarwal, Dawei Yin, Jiliang Tang",arXiv,"ACM proceedings, LATEX, text tagging","Convolutional neural networks (CNNs) leverage the great power in representation learning on regular grid data such as image and video. Recently, increasing attention has been paid on generalizing CNNs to graph or network data which is highly irregular. Some focus on graph-level representation learning while others aim to learn node-level representations. These methods have been shown to boost the performance of many graph-level tasks such as graph classification and node-level tasks such as node classification. Most of these methods have been designed for single-dimensional graphs where a pair of nodes can only be connected by one type of relation. However, many real-world graphs have multiple types of relations and they can be naturally modeled as multi-dimensional graphs with each type of relation as a dimension. Multi-dimensional graphs bring about richer interactions between dimensions, which poses tremendous challenges to the graph convolutional neural networks designed for single-dimensional graphs. In this paper, we study the problem of graph convolutional networks for multi-dimensional graphs and propose a multi-dimensional convolutional neural network model mGCN aiming to capture rich information in learning node-level representations for multi-dimensional graphs. Comprehensive experiments on real-world multi-dimensional graphs demonstrate the effectiveness of the proposed framework."
How much topological structure is preserved by graph embeddings?,"Xin Liu, Chenyi Zhuang, TsuyoshiMurata, Kyoung-Sook Kim, NatthawutKertkeidkachorn",Computer Science and Information Systems,"graph embedding, network representation learning, graph reconstruction, dimension reduction, graph mining.","Graph embedding aims at learning representations of nodes in a low dimensional vector space. Good embeddings should preserve the graph topological structure. To study how much such structure can be preserved, we propose evaluation methods from four aspects: 1) How well the graph can be reconstructed based on the embeddings, 2) The divergence of the original link distribution and the embedding-derived distribution, 3) The consistency of communities discovered from the graph and embeddings, and 4) To what extent we can employ embeddings to facilitate link prediction. We find that it is insufficient to rely on the embeddings to reconstruct the original graph, to discover communities, and to predict links at a high precision. Thus, the embeddings by the state-of-the-art approaches can only preserve part of the topological structure."
Multi-Level Network Embedding with Boosted Low-Rank Matrix Approximation,"Jundong Li, Liang Wu, Huan Liu",arXiv,,"As opposed to manual feature engineering which is tedious and difficult to scale, network representation learning has attracted a surge of research interests as it automates the process of feature learning on graphs. The learned lowdimensional node vector representation is generalizable and eases the knowledge discovery process on graphs by enabling various off-the-shelf machine learning tools to be directly applied. Recent research has shown that the past decade of network embedding approaches either explicitly factorize a carefully designed matrix to obtain the low-dimensional node vector representation or are closely related to implicit matrix factorization, with the fundamental assumption that the factorized node connectivity matrix is low-rank. Nonetheless, the global low-rank assumption does not necessarily hold especially when the factorized matrix encodes complex node interactions, and the resultant single low-rank embedding matrix is insufficient to capture all the observed connectivity patterns. In this regard, we propose a novel multi-level network embedding framework BoostNE, which can learn multiple network embedding representations of different granularity from coarse to fine without imposing the prevalent global low-rank assumption. The proposed BoostNE method is also in line with the successful gradient boosting method in ensemble learning as multiple weak embeddings lead to a stronger and more effective one. We assess the effectiveness of the proposed BoostNE framework by comparing it with existing state-of-the-art network embedding methods on various datasets, and the experimental results corroborate the superiority of the proposed BoostNE network embedding framework."
AliGraph: A Comprehensive Graph Neural Network Platform,"Rong Zhu, Kun Zhao, Hongxia Yang,Wei Lin, Chang Zhou, Baole Ai, YuemingLi, Jingren Zhou",arXiv,,"An increasing number of machine learning tasks require dealing with large graph datasets, which capture rich and complex relationship among potentially billions of elements. Graph Neural Network (GNN) becomes an effective way to address the graph learning problem by converting the graph data into a low dimensional space while keeping both the structural and property information to the maximum extent and constructing a neural network for training and referencing. However, it is challenging to provide an efficient graph storage and computation capabilities to facilitate GNN training and enable development of new GNN algorithms. In this paper, we present a comprehensive graph neural network system, namely AliGraph, which consists of distributed graph storage, optimized sampling operators and runtime to efficiently support not only existing popular GNNs but also a series of in-house developed ones for different scenarios. The system is currently deployed at Alibaba to support a variety of business scenarios, including product recommendation and personalized search at Alibaba's E-Commerce platform. By conducting extensive experiments on a real-world dataset with 492.90 million vertices, 6.82 billion edges and rich attributes, AliGraph performs an order of magnitude faster in terms of graph building (5 minutes vs hours reported from the state-of-the-art PowerGraph platform). At training, AliGraph runs 40%-50% faster with the novel caching strategy and demonstrates around 12 times speed up with the improved runtime. In addition, our in-house developed GNN models all showcase their statistically significant superiorities in terms of both effectiveness and efficiency (e.g., 4.12%-17.19% lift by F1 scores)."
Multi-perspective Network Representation Based on Human Curation,"Haiying Liu, Meng Jian, Bowen Yang,Heng Zhang",ACM,"Network representation, Subnetworks, Multi-perspective, Human curation","Network representation learning represents nodes in networks as low-dimension vectors which has been attracting increasing attention recently due to its effectiveness in network analysis tasks such as classification and link prediction. In this paper, our focus is on content curation social networks (CCSNs). There are more than one user relation subnetworks formed by different user relations in a social media network. However, most of existing representation learning algorithms usually study only one subnetwork which cannot study users from different views. On the other hand, most of the existing approaches are designed for universal networks which do not consider the unique characteristics of different networks. We propose a multi-perspective network representation based on human curation (MNHC) model, which aims to infer network representations across multiple relations in CCSNs. The network representation model utilizes the unique structure of networks and human curation signals in CCSNs which combines two user relation subnetworks and human curation signals for informative network representations. Experiment results show that the model could obtain good performance in both classification and link prediction tasks."
Improving the Robustness of Wasserstein Embedding by Adversarial PAC-Bayesian Learning,"Daizong Ding, Mi Zhang, Xudong Pan,Min Yang, Xiangnan He",AAAI,,"Node embedding is a crucial task in graph analysis. Recently, several methods are proposed to embed a node as a distribution rather than a vector to capture more information. Although these methods achieved noticeable improvements, their extra complexity brings new challenges. For example, the learned representations of nodes could be sensitive to external noises on the graph and vulnerable to adversarial behaviors. In this paper, we first derive an upper bound on generalization error for Wasserstein embedding via the PACBayesian theory. Based on this, we propose an algorithm called Adversarial PAC-Bayesian Learning (APBL) in order to minimize the generalization error bound. Furthermore, we provide a model called Regularized Adversarial Wasserstein Embedding Network (RAWEN) as an implementation of APBL. Besides our comprehensive analysis of the robustness of RAWEN, our work for the first time explores more kinds of embedded distributions. For evaluations, we conduct extensive experiments to demonstrate the effectiveness and robustness of our proposed embedding model compared with the state-of-the-art methods."
ImVerde: Vertex-Diminished Random Walk for Learning Network Representation from Imbalanced Data,"Jingjing Wu, Jingrui He, Yongming Liu",arXiv,"Network representation, random walk, imbalanced data","Imbalanced data widely exists in many high-impact applications. An example is in air traffic control, where we aim to identify the leading indicators for each type of accident cause from historical records. Among all three types of accident causes, historical records with 'personnel issues' are much more than the other two types ('aircraft issues' and 'environmental issues') combined. Thus, the resulting dataset is highly imbalanced, and can be naturally modeled as a network. Up until now, most existing work on imbalanced data analysis focused on the classification setting, and very little is devoted to learning the node representation from imbalanced networks. To address this problem, in this paper, we propose Vertex-Diminished Random Walk (VDRW) for imbalanced network analysis. The key idea is to encourage the random particle to walk within the same class by adjusting the transition probabilities each step. It resembles the existing Vertex Reinforced Random Walk in terms of the dynamic nature of the transition probabilities, as well as some convergence properties. However, it is more suitable for analyzing imbalanced networks as it leads to more separable node representations in the embedding space. Then, based on VDRW, we propose a semi-supervised network representation learning framework named ImVerde for imbalanced networks, in which context sampling uses VDRW and the label information to create node-context pairs, and balanced-batch sampling adopts a simple under-sampling method to balance these pairs in different classes. Experimental results demonstrate that ImVerde based on VDRW outperforms state-of-the-art algorithms for learning network representation from imbalanced data."
SHNE: Representation Learning for Semantic-Associated Heterogeneous Networks,"Chuxu Zhang, Ananthram Swami,Nitesh V. Chawla",ACM,"Semantic-Associated Heterogeneous Networks, Representation Learning, Network Embedding, Deep Learning","Representation learning in heterogeneous networks faces challenges due to heterogeneous structural information of multiple types of nodes and relations, and also due to the unstructured attribute or content (e.д., text) associated with some types of nodes. While many recent works have studied homogeneous, heterogeneous, and attributed networks embedding, there are few works that have collectively solved these challenges in heterogeneous networks. In this paper, we address them by developing a Semanticaware Heterogeneous Network Embedding model (SHNE). SHNE performs joint optimization of heterogeneous SkipGram and deep semantic encoding for capturing both heterogeneous structural closeness and unstructured semantic relations among all nodes, as function of node content, that exist in the network. Extensive experiments demonstrate that SHNE outperforms state-of-the-art baselines in various heterogeneous network mining tasks, such as link prediction, document retrieval, node recommendation, relevance search, and class visualization."
IntentGC: A Scalable Graph Convolution Framework Fusing Heterogeneous Information for Recommendation,"Jun Zhao, Zhou Zhou, Ziyu Guan, WeiZhao, Wei Ning, Guang Qiu, Xiaofei He",arXiv,"Graph Convolutional Networks, Recommendation, Heterogeneous Information Network","The remarkable progress of network embedding has led to state-of-the-art algorithms in recommendation. However, the sparsity of user-item interactions (i.e., explicit preferences) on websites remains a big challenge for predicting users' behaviors. Although research efforts have been made in utilizing some auxiliary information (e.g., social relations between users) to solve the problem, the existing rich heterogeneous auxiliary relationships are still not fully exploited. Moreover, previous works relied on linearly combined regularizers and suffered parameter tuning. In this work, we collect abundant relationships from common user behaviors and item information, and propose a novel framework named IntentGC to leverage both explicit preferences and heterogeneous relationships by graph convolutional networks. In addition to the capability of modeling heterogeneity, IntentGC can learn the importance of different relationships automatically by the neural model in a nonlinear sense. To apply IntentGC to web-scale applications, we design a faster graph convolutional model named IntentNet by avoiding unnecessary feature interactions. Empirical experiments on two large-scale real-world datasets and online A/B tests in Alibaba demonstrate the superiority of our method over state-of-the-art algorithms."
A Representation Learning Framework for Property Graphs,"Yifan Hou, Hongzhi Chen, Changji Li,James Cheng, Ming-Chang Yang",ACM,"graph neural networks, graph embedding, property graphs, representation learning","Representation learning on graphs, also called graph embedding, has demonstrated its significant impact on a series of machine learning applications such as classification, prediction and recommendation. However, existing work has largely ignored the rich information contained in the properties (or attributes) of both nodes and edges of graphs in modern applications, e.g., those represented by property graphs. To date, most existing graph embedding methods either focus on plain graphs with only the graph topology, or consider properties on nodes only. We propose PGE, a graph representation learning framework that incorporates both node and edge properties into the graph embedding procedure. PGE uses node clustering to assign biases to differentiate neighbors of a node and leverages multiple data-driven matrices to aggregate the property information of neighbors sampled based on a biased strategy. PGE adopts the popular inductive model for neighborhood aggregation. We provide detailed analyses on the efficacy of our method and validate the performance of PGE by showing how PGE achieves better embedding results than the state-of-the-art graph embedding methods on benchmark applications such as node classification and link prediction over real-world datasets."
Unifying Structural Proximity and Equivalence for Network Embedding,"Benyun Shi, Chunpeng Zhou, HongjunQiu, Xiaobin Xu, Jiming Liu",IEEE,"Graphlet degree vector, structural proximity, structural equivalence, network embedding, node classification","The fundamental purpose of network embedding is to automatically encode each node in a network as a low-dimensional vector, while at the same time preserving certain characteristics of the network. Based on the nodes' embeddings, downstream network analytic tasks such as community mining, node classification, and link prediction, can then be easily implemented using traditional machine learning methods. In recent years, extensive network embedding methods have been proposed based on factorization, random walks, deep learning, and so on. However, most of them focus mainly on preserving the structural proximity of network nodes, where highly interconnected nodes in a network will be represented closely together in the embedded vector space. While in many real-world networks, existing studies have revealed that high-order organizations (e.g., network motifs and graphlets) may be related to specific network functions. In this case, nodes far apart but with a similar organization in a network (i.e., structural equivalence) may have similar network functions. Accordingly, in this paper, we present a hybrid embedding method that unifies both structural proximity and equivalence (SPaE) of a network. Specifically, we adopt the concept of graphlet degree vector (GDV) to measure structural equivalence between network nodes. Through carrying out experiments on both synthetic and real-world datasets, we evaluate the performance of the hybrid embedding method in tasks of node clustering, node classification, and visualization. The results demonstrate that the proposed SPaE method outperforms several state-of-the-art methods when the network analytic tasks are not merely related to structural proximity. Finally, we also conduct experiments to evaluate the flexibility, robustness, and parameter sensitivity of the hybrid embedding method."
DHNE: Network Representation Learning Method for Dynamic Heterogeneous Networks,"Ying Yin, Lixin Ji, Jianpeng Zhang,Yulong Pei",IEEE,"Dynamic heterogeneous networks, network representation learning, random walk, skip-gram model","Analyzing the rich information behind heterogeneous networks through network representation learning methods is signifcant for many application tasks such as link prediction, node classifcation and similarity research. As the networks evolve over times, the interactions among the nodes in networks make heterogeneous networks exhibit dynamic characteristics. However, almost all the existing heterogeneous network representation learning methods focus on static networks which ignore dynamic characteristics. In this paper, we propose a novel approach DHNE to learn the representations of nodes in dynamic heterogeneous networks. The key idea of our approach is to construct comprehensive historical-current networks based on subgraphs of snapshots in time step to capture both the historical and current information in the dynamic heterogeneous network. And then under the guidance of meta paths, DHNE performs random walks on the constructed historical-current graphs to capture semantic information. After getting the node sequences through random walks, we propose the dynamic heterogeneous skip-gram model to learn the embeddings. Experiments on large-scale real-world networks demonstrate that the embeddings learned by the proposed DHNE model achieve better performances than state-of-the-art methods in various downstream tasks including node classifcation and visualization."
Learning Embeddings for Academic Papers,Yi Zhang,University of Windsor,,"Academic papers contain both text and citation links. Representing such data is crucial for many downstream tasks, such as classification, disambiguation, duplicates detection, recommendation and influence prediction. The success of Skip-gram with Negative Sampling model (hereafter SGNS) has inspired many algorithms to learn embeddings for words, documents, and networks. However, there is limited research on learning the representation of linked documents such as academic papers. This dissertation first studies the norm convergence issue in SGNS and propose to use an L2 regularization to fix the problem. Our experiments show that our method improves SGNS and its variants on different types of data. We observe improvements upto 17.47% for word embeddings, 1.85% for document embeddings, and 46.41% for network embeddings. To learn the embeddings for academic papers, we propose several neural network based algorithms that can learn high-quality embeddings from different types of data. The algorithms we proposed are N2V (network2vector) for networks, D2V (document2vector) for documents, and P2V (paper2vector) for academic papers. Experiments show that our models outperform traditional algorithms and the state-of-the-art neural network methods on various datasets under different machine learning tasks. With the high quality embeddings, we design and present four applications on real-world datasets, i.e., academic paper and author search engines, author name disambiguation, and paper influence prediction."
Improve Network Embeddings with Regularization,"Yi Zhang, Jianguo Lu, Ofer Shai",ACM,"Network embeddings, Skip-gram, Regularization, LINE, DeepWalk, node2vec","Learning network representations is essential for many downstream tasks such as node classification, link prediction, and recommendation. Many algorithms derived from SGNS (skip-gram with negative sampling) have been proposed, such as LINE, DeepWalk, and node2vec. In this paper, we show that these algorithms suffer from norm convergence problem, and propose to use L2 regularization to rectify the problem. The proposed method improves the embeddings consistently. This is verified on seven different datasets with various sizes and structures. The best improvement is 46.41% for the task of node classification."
Low-Norm Graph Embedding,"Yihan Gao, Chao Zhang, Jian Peng,Aditya G. Parameswaran",arXiv,,"Learning distributed representations for nodes in graphs has become an important problem that underpins a wide spectrum of applications. Existing methods to this problem learn representations by optimizing a softmax objective while constraining the dimension of embedding vectors. We argue that the generalization performance of these methods are probably not due to the dimensionality constraint as commonly believed, but rather the small norm of embedding vectors. Both theoretical and empirical evidences are provided to support this argument: (a) we prove that the generalization error of these methods can be bounded regardless of embedding dimension by limiting the norm of vectors; (b) we show empirically that the generalization performance of existing embedding methods are likely due to the early stopping of stochastic gradient descent. Motivated by our analysis, we propose a new low-norm formulation of the graph embedding problem, which seeks to preserve graph structures while constraining the total squared l2 norm of embedding vectors. With extensive experiments, we demonstrate that the empirical performance of the proposed method well backs our theoretical analysis. Furthermore, it notably outperforms state-of-the-art graph embedding methods in the tasks of link prediction and node classification."
The Importance of Norm Regularization in Linear Graph Embedding: Theoretical Analysis and Empirical Demonstration,"Yihan Gao, Chao Zhang, Jian Peng,Aditya Parameswaran",arXiv,,"Learning distributed representations for nodes in graphs is a crucial primitive in network analysis with a wide spectrum of applications. Linear graph embedding methods learn such representations by optimizing the likelihood of both positive and negative edges while constraining the dimension of the embedding vectors. We argue that the generalization performance of these methods is not due to the dimensionality constraint as commonly believed, but rather the small norm of embedding vectors. Both theoretical and empirical evidence are provided to support this argument: (a) we prove that the generalization error of these methods can be bounded by limiting the norm of vectors, regardless of the embedding dimension; (b) we show that the generalization performance of linear graph embedding methods is correlated with the norm of embedding vectors, which is small due to the early stopping of SGD and the vanishing gradients. We performed extensive experiments to validate our analysis and showcased the importance of proper norm regularization in practice."
Multi-Type Itemset Embedding for Learning Behavior Success,"Daheng Wang, Meng Jiang, QingkaiZeng, Zachary Eberhart, Nitesh V.Chawla",ACM,"Behavior modeling, Representation learning, Behavior data embedding, Itemset embedding, Recommender systems","Contextual behavior modeling uses data from multiple contexts to discover patterns for predictive analysis. However, existing behavior prediction models often face diculties when scaling for massive datasets. In this work, we formulate a behavior as a set of context items of dierent types (such as decision makers, operators, goals and resources), consider an observable itemset as a behavior success, and propose a novel scalable method, “multi-type itemset embedding”, to learn the context items’ representations preserving the success structures. Unlike most of existing embedding methods that learn pair-wise proximity from connection between a behavior and one of its items, our method learns item embeddings collectively from interaction among all multi-type items of a behavior, based on which we develop a novel framework, LearnSuc, for (1) predicting the success rate of any set of items and (2) nding complementary items which maximize the probability of success when incorporated into an itemset. Extensive experiments demonstrate both eectiveness and ecency of the proposed framework."
A General Framework for Content-enhanced Network Representation Learning,"Xiaofei Sun, Jiang Guo, Xiao Ding, TingLiu",arXiv,,"This paper investigates the problem of network embedding, which aims at learning low-dimensional vector representation of nodes in networks. Most existing network embedding methods rely solely on the network structure, i.e., the linkage relationships between nodes, but ignore the rich content information associated with it, which is common in real world networks and beneficial to describing the characteristics of a node. In this paper, we propose content-enhanced network embedding (CENE), which is capable of jointly leveraging the network structure and the content information. Our approach integrates text modeling and structure modeling in a general framework by treating the content information as a special kind of node. Experiments on several real world net- works with application to node classification show that our models outperform all existing network embedding methods, demonstrating the merits of content information and joint learning."
Near-duplicated Documents in CiteSeerX,"Yi Zhang, Jian-guo Lu",AAAI,,"Academic literatures, especially those in the field of computer science, are often posted multiple times on the Web. Scholarly index engines, such as Google Scholar and CiteSeerX, crawl such documents from the open web as well as publishers. To improve the quality of the search result, there is a need to detect and coalesce duplicate or very similar (hereafter called near-duplicate) papers. Near-duplicate detection is computationally expensive. Pair-wise comparison of millions of papers is not feasible even for the most advanced machines. We combine SimHash and Jaccard similarity to discover near-duplicate documents in a CiteSeerX data set, which contains 2,118,122 full-text academic papers. We observe that 12% documents in CiteSeerX have near-duplicates with Jaccard similarity larger than 0.9. Then we study the near-duplicates and summarize six leading causes. We also compare these near-duplicates with those appeared only once on the web. We find that the citation count grows almost linearly with the number of duplications."
Learning Content-rich Diffusion Network Embedding 1,"Guangyuan Wang, Zongyi Wang",,,"Information networks are ubiquitous in the real world, while embedding, as a kind of network representation, has received attention from many researchers because of its effectiveness in preserving the semantics of the network and its broad application including classification, link prediction etc. Previously, many methods have been proposed to learn network embedding from non-attributed and static networks. Networks are treated simply as nodes and links. However, information is not merely encoded in the structure, nodes itself may have their intrinsic attributes and little research have been done to incorporate this information. Furthermore, outside information will also diffuse on the network over the time and for a specific time we can have a different diffusion structure. In this paper, we will be introducing the idea of diffusion network, and we propose two models for embedding learning that aim to efficiently capture the rich content of nodes as well as that of the diffusion. We then evaluate the quality of our embedding by conducting node classification experiments, the result of which shows that our method for generating embedding outperforms other baselines."
On Joint Representation Learning of Network Structure and Document Content,"Jörg Schlötterer, Christin Seifert,Michael Granitzer",IFIP,"Representation learning, Network embeddings, Document embeddings","Inspired by the advancements of representation learning for natural language processing, learning continuous feature representations of nodes in networks has recently gained attention. Similar to word embeddings, node embeddings have been shown to capture certain semantics of the network structure. Combining both research directions into a joint representation learning of network structure and document content seems a promising direction to increase the quality of the learned representations. However, research is typically focused on either word or network embeddings and few approaches that learn a joint representation have been proposed. We present an overview of that field, starting at word representations, moving over document and network node representations to joint representations. We make the connections between the different models explicit and introduce a novel model for learning a joint representation. We present different methods for the novel model and compare the presented approaches in an evaluation. This paper explains how the different models recently proposed in the literature relate to each other and compares their performance."
Preserving Local and Global Information for Network Embedding,"Yao Ma, Suhang Wang, Zhaochun Ren,Dawei Yin, Jiliang Tang",arXiv,,"Networks such as social networks, airplane networks, and citation networks are ubiquitous. The adjacency matrix is often adopted to represent a network, which is usually high dimensional and sparse. However, to apply advanced machine learning algorithms to network data, low-dimensional and continuous representations are desired. To achieve this goal, many network embedding methods have been proposed recently. The majority of existing methods facilitate the local information i.e. local connections between nodes, to learn the representations, while completely neglecting global information (or node status), which has been proven to boost numerous network mining tasks such as link prediction and social recommendation. Hence, it also has potential to advance network embedding. In this paper, we study the problem of preserving local and global information for network embedding. In particular, we introduce an approach to capture global information and propose a network embedding framework LOG, which can coherently model {\bf LO}cal and {\bf G}lobal information. Experimental results demonstrate the ability to preserve global information of the proposed framework. Further experiments are conducted to demonstrate the effectiveness of learned representations of the proposed framework."
A Tutorial on Network Embeddings,"Haochen Chen, Bryan Perozzi, Rami Al-Rfou, Steven Skiena",arXiv,,"Network embedding methods aim at learning low-dimensional latent representation of nodes in a network. These representations can be used as features for a wide range of tasks on graphs such as classification, clustering, link prediction, and visualization. In this survey, we give an overview of network embeddings by summarizing and categorizing recent advancements in this research field. We first discuss the desirable properties of network embeddings and briefly introduce the history of network embedding algorithms. Then, we discuss network embedding methods under different scenarios, such as supervised versus unsupervised learning, learning embeddings for homogeneous networks versus for heterogeneous networks, etc. We further demonstrate the applications of network embeddings, and conclude the survey with future work in this area."
Network Embedding for Cross-network Node Classification,"Xiao Shen, Korris Fu-Lai Chung",arXiv,"Cross-network embedding, cross-network node classification, deep learning, deep network embedding, domain adaptation, network transfer learning","Network embedding is a highly effective method to learn low-dimensional node vector representations with original network structures being well preserved. However, existing network embedding algorithms are mostly developed for a single network, which fail to learn generalized feature representations across different networks. In this paper, we study a cross-network node classification problem, which aims at leveraging the abundant labeled information from a source network to help classify the unlabeled nodes in a target network. To succeed in such a task, transferable features should be learned for nodes across different networks. To this end, a novel cross-network deep network embedding (CDNE) model is proposed to incorporate domain adaptation into deep network embedding so as to learn label-discriminative and network-invariant node vector representations. On one hand, CDNE leverages network structures to capture the proximities between nodes within a network, by mapping more strongly connected nodes to have more similar latent vector representations. On the other hand, node attributes and labels are leveraged to capture the proximities between nodes across different networks by making the same labeled nodes across networks have aligned latent vector representations. Extensive experiments have been conducted, demonstrating that the proposed CDNE model significantly outperforms the state-of-the-art network embedding algorithms in cross-network node classification."
Dynamic Network Embedding by Semantic Evolution,"Y Zhou, Weile Liu, Yang Pei, Lei Wang,Daren Zha, Tianshu Fu",IEEE,"Dynamic Network, Semantic Evolution, Nonrandom Initialization, Network Embedding","Network embedding, which aims to learn the lowdimensional representations of nodes, has attracted increasing attention in various fields such as social networks, paper citation networks and knowledge graphs. At present, most of the network embedding works are based on static networks, that is, the evolution of networks over time is not taken into account. It is more realistic to consider temporal information in network embedding and it could also make the embedding get more abundant information. In this paper, we propose a dynamic network embedding model DynSEM with semantic evolution, to train node embeddings in a sequence of networks over time. The advantage of our method is that it presents an effective inheritance of historical information. Our method uses nonrandom initialization and orthogonal procrustes method to align the node embeddings into common space which makes node embedding able to inheritance information. In particular, in the common space, we train a model to capture the dynamics information of the networks and smooth temporal node embeddings. We evaluate our method comparing it with other methods on three real-world datasets. The experimental results prove the effectiveness of dynamic network embeddings generated by DynSEM model."
Enhancing Attributed Network Embedding via Similarity Measure,"Bin Yu, Yitong Li, Chen Zhang, Ke Pan,Yu Xie",IEEE,"Attributed network embedding, similarity measure, high-order proximity","Network embedding aims to represent network structural and attributed information with low-dimensional vectors, which has been demonstrated to be beneficial for many network analysis tasks, such as link prediction, node classification and visualization. However, nodes in networks are commonly associated with rich contents, which are facilitated to characterize the properties of nodes. Most existing attributed network embedding algorithms tend to learn attribute representations separated from structure representations, which require a subsequent processing of combination. Besides, these traditional approaches ignore the potential high-order proximity introduced by attributes. Motivated by this, we investigate how structures and attributes can be captured simultaneously and introduce similarity measure to preserve highorder proximity in an attributed network. In this paper, we propose a novel attributed network embedding framework, Similarity Enhancing Attributed Network Embedding (SEANE), which jointly preserves structural and attributed information, and adopts similarity measure to enhance the node embedding. We evaluate our proposed framework by using four real-world datasets on link prediction, node classification and nearest nodes searching. The experimental results demonstrate the outperformance of SEANE on link prediction and node classification tasks."
MONET: Debiasing Graph Embeddings via the Metadata-Orthogonal Training Unit,"John Palowitch, Bryan Perozzi",arXiv,,"In many real world graphs, the formation of edges can be influenced by certain sensitive features of the nodes (e.g. their gender, community, or reputation). In this paper we argue that when such influences exist, any downstream Graph Neural Network (GNN) will be implicitly biased by these structural correlations. To allow control over this phenomenon, we introduce the Metadata-Orthogonal Node Embedding Training (MONET) unit, a general neural network architecture component for performing training-time linear debiasing of graph embeddings. MONET operates by ensuring that the node embeddings are trained on a hyperplane orthogonal to that of the node features (metadata). Unlike debiasing approaches in similar domains, our method offers exact guarantees about the correlation between the resulting embeddings and any sensitive metadata. We illustrate the effectiveness of MONET though our experiments on a variety of real world graphs against challenging baselines (e.g. adversarial debiasing), showing superior performance in tasks such as preventing the leakage of political party affiliation in a blog network, and preventing the gaming of embedding-based recommendation systems."
Dynamic Network Embedding via Incremental Skip-gram with Negative Sampling,"Hao Peng, Jianxin Li, Hao Yan, QiranGong, Senzhang Wang, Lin Liu, LihongWang, Xiang Ren",arXiv,"Dynamic Network Embedding, Bound and Convergence Analysis, Multi-label Classification, Link Prediction","Network representation learning, as an approach to learn low dimensional representations of vertices, has attracted considerable research attention recently. It has been proven extremely useful in many machine learning tasks over large graph. Most existing methods focus on learning the structural representations of vertices in a static network, but cannot guarantee an accurate and efficient embedding in a dynamic network scenario. To address this issue, we present an efficient incremental skip-gram algorithm with negative sampling for dynamic network embedding, and provide a set of theoretical analyses to characterize the performance guarantee. Specifically, we first partition a dynamic network into the updated, including addition/deletion of links and vertices, and the retained networks over time. Then we factorize the objective function of network embedding into the added, vanished and retained parts of the network. Next we provide a new stochastic gradient-based method, guided by the partitions of the network, to update the nodes and the parameter vectors. The proposed algorithm is proven to yield an objective function value with a bounded difference to that of the original objective function. Experimental results show that our proposal can significantly reduce the training time while preserving the comparable performance. We also demonstrate the correctness of the theoretical analysis and the practical usefulness of the dynamic network embedding. We perform extensive experiments on multiple real-world large network datasets over multi-label classification and link prediction tasks to evaluate the effectiveness and efficiency of the proposed framework, and up to 22 times speedup has been achieved."
Multi-scale Attributed Node Embedding,"Benedek Rozemberczki, Carl E Allen,Rik Sarkar",arXiv,,"We present network embedding algorithms that capture information about a node from the local distribution over node attributes around it, as observed over random walks following an approach similar to Skip-gram. Observations from neighborhoods of different sizes are either pooled (AE) or encoded distinctly in a multi-scale approach (MUSAE). Capturing attribute-neighborhood relationships over multiple scales is useful for a diverse range of applications, including latent feature identification across disconnected networks with similar attributes. We prove theoretically that matrices of node-feature pointwise mutual information are implicitly factorized by the embeddings. Experiments show that our algorithms are robust, computationally efficient and outperform comparable models on social networks and web graphs."
NetSMF: Large-Scale Network Embedding as Sparse Matrix Factorization,"Jiezhong Qiu, Yuxiao Dong, Hao Ma,Jun Yu Li, Chi Wang, Kuansan Wang,Jie Tang",arXiv,,"We study the problem of large-scale network embedding, which aims to learn latent representations for network mining applications. Previous research shows that 1) popular network embedding benchmarks, such as DeepWalk, are in essence implicitly factorizing a matrix with a closed form, and 2)the explicit factorization of such matrix generates more powerful embeddings than existing methods. However, directly constructing and factorizing this matrix---which is dense---is prohibitively expensive in terms of both time and space, making it not scalable for large networks. In this work, we present the algorithm of large-scale network embedding as sparse matrix factorization (NetSMF). NetSMF leverages theories from spectral sparsification to efficiently sparsify the aforementioned dense matrix, enabling significantly improved efficiency in embedding learning. The sparsified matrix is spectrally close to the original dense one with a theoretically bounded approximation error, which helps maintain the representation power of the learned embeddings. We conduct experiments on networks of various scales and types. Results show that among both popular benchmarks and factorization based methods, NetSMF is the only method that achieves both high efficiency and effectiveness. We show that NetSMF requires only 24 hours to generate effective embeddings for a large-scale academic collaboration network with tens of millions of nodes, while it would cost DeepWalk months and is computationally infeasible for the dense matrix factorization solution"
Citation recommendation based on citation tendency,"Xi Chen, Huan-jing Zhao, Shu Zhi Zhao,Jie Chen, Yanping Zhang",Akadémiai Kiadó,"Citation recommendation, Citation tendency, Heterogeneous information network, Network representation","Due to the development of academic, more and more attentions are paid to citation recommendation. To solve the citation recommendation problem, researchers begin to focus on the network representation, because it fuses semantic information and structural information well. It is a big challenge that how to map articles in a heterogeneous information network into a low-dimensional space while preserving the potential associations between articles. We propose a novel citation recommendation algorithm based on citation tendency, named CIRec which learns more about the potential relationship of articles in the process of network embedding. Citation tendency means if an article can be selected as a reference, it probability satisfes some kinds of conditions. In our algorithm, fve weight matrices which represent the probability of entity-to-entity migration based on citation tendency are defned to build weighted heterogeneous network frst. Second, we design a biased random walk procedure which efciently explores articles’ characteristics and citations information. Finally, the skip-gram model is used to learn the neighborhood relationship of the nodes in the walk sequence and map the nodes to the vector space. Comparing with existing state-of-the-art technique, experiment results show that our algorithm CIRec has better recall, precision, NDCG on AAN and DBLP dataset."
Improving Document Representation Using Retrofitting,Zeeshan Mansoor,University of Windsor,"data mining, document embedding, multi-view learning, natural language processing","Data-driven learning of document vectors that capture linkage between them is of immense importance in natural language processing (NLP). These document vectors can, in turn, be used for tasks like information retrieval, document classification, and clustering. Inherently, documents are linked together in the form of links or citations in case of web pages or academic papers respectively. Methods like PV-DM or PVDBOW try to capture the semantic representation of the document using only the text information. These methods ignore the network information altogether while learning the representation. Similarly, methods developed for network representation learning like node2vec or DeepWalk, capture the linkage information between the documents but they ignore the text information altogether. In this thesis, we proposed a method based on Retrofit for learning word embeddings using a semantic lexicon, which tries to incorporate both the text and network information together while learning the document representation. We also analyze the optimum weight for adding network information that will give us the best embedding. Our experimentation result shows that our method improves the classification score by 4% and we also introduce a new dataset containing both network and content information."
Relation Structure-Aware Heterogeneous Information Network Embedding,"Yuanfu Lu, Chuan Shi, Linmei Hu,Zhiyuan Liu",arXiv,,"Heterogeneous information network (HIN) embedding aims to embed multiple types of nodes into a low-dimensional space. Although most existing HIN embedding methods consider heterogeneous relations in HINs, they usually employ one single model for all relations without distinction, which inevitably restricts the capability of network embedding. In this paper, we take the structural characteristics of heterogeneous relations into consideration and propose a novel Relation structure-aware Heterogeneous Information Network Embedding model (RHINE). By exploring the real-world networks with thorough mathematical analysis, we present two structure-related measures which can consistently distinguish heterogeneous relations into two categories: Affiliation Relations (ARs) and Interaction Relations (IRs). To respect the distinctive characteristics of relations, in our RHINE, we propose different models specifically tailored to handle ARs and IRs, which can better capture the structures and semantics of the networks. At last, we combine and optimize these models in a unified and elegant manner. Extensive experiments on three real-world datasets demonstrate that our model significantly outperforms the state-of-the-art methods in various tasks, including node clustering, link prediction, and node classification."
3-in-1 Correlated Embedding via Adaptive Exploration of the Structure and Semantic Subspaces,"Liang Yang, Yuanfang Guo, Di Jin,Huazhu Fu, Xiaochun Cao",IJCAI,,"Combinational network embedding, which learns the node representation by exploring both topological and non-topological information, becomes popular due to the fact that the two types of information are complementing each other. Most of the existing methods either consider the topological and non-topological information being aligned or possess predetermined preferences during the embedding process. Unfortunately, previous methods fail to either explicitly describe the correlations between topological and non-topological information or adaptively weight their impacts. To address the existing issues, three new assumptions are proposed to better describe the embedding space and its properties. With the proposed assumptions, nodes, communities and topics are mapped into one embedding space. A novel generative model is proposed to formulate the generation process of the network and content from the embeddings, with respect to the Bayesian framework. The proposed model automatically leans to the information which is more discriminative. The embedding result can be obtained by maximizing the posterior distribution by adopting the variational inference and reparameterization trick. Experimental results indicate that the proposed method gives superior performances compared to the state-of-the-art methods when a variety of real-world networks is analyzed."
A Block-based Generative Model for Attributed Networks Embedding,"Xueyan Liu, Wenzhuo Song, WanLi Zuo,Katarzyna Musial, Bo Yang",arXiv,"Attributed networks, Network Embedding, Generative model, Clustering","Attributed network embedding has attracted plenty of interests in recent years. It aims to learn task-independent, low-dimension, and continuous vectors for nodes preserving both topology and attribute information. Most existing methods, such as GCN and its variations, mainly focus on the local information, i.e., the attributes of the neighbors. Thus, they have been well studied for assortative networks but ignored disassortative networks, which are common in real scenes. To address this issue, we propose a block-based generative model for attributed network embedding on a probability perspective inspired by the stochastic block model (SBM). Specifically, the nodes are assigned to several blocks wherein the nodes in the same block share the similar link patterns. These patterns can define assortative networks containing communities or disassortative networks with the multipartite, hub, or any hybrid structures. Concerning the attribute information, we assume that each node has a hidden embedding related to its assigned block, and then we use a neural network to characterize the nonlinearity between the node embedding and its attribute. We perform extensive experiments on real-world and synthetic attributed networks, and the experimental results show that our proposed method remarkably outperforms state-of-the-art embedding methods for both clustering and classification tasks, especially on disassortative networks."
Sparse Graph Attention Networks,"Yang Ye, Shihao Ji",arXiv,,"Graph Neural Networks (GNNs) have proved to be an effective representation learning framework for graph-structured data, and have achieved state-of-the-art performance on all sorts of practical tasks, such as node classification, link prediction and graph classification. Among the variants of GNNs, Graph Attention Networks (GATs) learn to assign dense attention coefficients over all neighbors of a node for feature aggregation, and improve the performance of many graph learning tasks. However, real-world graphs are often very large and noisy, and GATs are plagued to overfitting if not regularized properly. In this paper, we propose Sparse Graph Attention Networks (SGATs) that learn sparse attention coefficients under an L0-norm regularization, and the learned sparse attentions are then used for all GNN layers, resulting in an edge-sparsified graph. By doing so, we can identify noisy / insignificant edges, and thus focus computation on more important portion of a graph. Extensive experiments on synthetic and real-world graph learning benchmarks demonstrate the superior performance of SGATs. In particular, SGATs can remove about 50\%-80\% edges from large graphs, such as PPI and Reddit, while retaining similar classification accuracies. Furthermore, the removed edges can be interpreted intuitively and quantitatively. To the best of our knowledge, this is the first graph learning algorithm that sparsifies graphs for the purpose of identifying important relationship between nodes and for robust training."
A Capsule Network-based Model for Learning Node Embeddings,"Dai Quoc Nguyen, Tu Dinh Nguyen, DatQuoc Nguyen, Dinh Q. Phung",arXiv,,"In this paper, we focus on learning low-dimensional embeddings of entity nodes from graph-structured data, where we can use the learned node embeddings for a downstream task of node classification. Existing node embedding models often suffer from a limitation of exploiting graph information to infer plausible embeddings of unseen nodes. To address this issue, we propose Caps2NE---a new unsupervised embedding model using a network of two capsule layers. Given a target node and its context nodes, Caps2NE applies a routing process to aggregate features of the context nodes at the first capsule layer, then feed these features into the second capsule layer to produce an embedding vector. This embedding vector is then used to infer a plausible embedding for the target node. Experimental results for the node classification task on six well-known benchmark datasets show that our Caps2NE obtains state-of-the-art performances."
Enhancing Network Embedding with Auxiliary Information: An Explicit Matrix Factorization Perspective,"Junliang Guo, Linli Xu, Xunpeng Huang,Enhong Chen",arXiv,,"Recent advances in the field of network embedding have shown the low-dimensional network representation is playing a critical role in network analysis. However, most of the existing principles of network embedding do not incorporate auxiliary information such as content and labels of nodes flexibly. In this paper, we take a matrix factorization perspective of network embedding, and incorporate structure, content and label information of the network simultaneously. For structure, we validate that the matrix we construct preserves high-order proximities of the network. Label information can be further integrated into the matrix via the process of random walk sampling to enhance the quality of embedding in an unsupervised manner, i.e., without leveraging downstream classifiers. In addition, we generalize the Skip-Gram Negative Sampling model to integrate the content of the network in a matrix factorization framework. As a consequence, network embedding can be learned in a unified framework integrating network structure and node content as well as label information simultaneously. We demonstrate the efficacy of the proposed model with the tasks of semi-supervised node classification and link prediction on a variety of real-world benchmark network datasets."
ProGAN: Network Embedding via Proximity Generative Adversarial Network,"Hongchang Gao, Jian Pei, Heng Huang",ACM,"Network Embedding, Generative Adversarial Networks, Proximity","Network embedding has attracted increasing attention in recent few years, which is to learn a low-dimensional representation for each node of a network to benefit downstream tasks, such as node classification, link prediction, and network visualization. Essentially, the task of network embedding can be decoupled into discovering the proximity in the original space and preserving it in the lowdimensional space. Only with the well-discovered proximity can we preserve it in the low-dimensional space. Thus, it is critical to discover the proximity between different nodes to learn good node representations. To address this problem, in this paper, we propose a novel proximity generative adversarial network (ProGAN) which can generate proximities. As a result, the generated proximity can help to discover the complicated underlying proximity to benefit network embedding. To generate proximities, we design a novel neural network architecture to fulfill it. In particular, the generation of proximities is instantiated to the generation of triplets of nodes, which encodes the similarity relationship between different nodes. In this way, the proposed ProGAN can generate proximities successfully to benefit network embedding. At last, extensive experimental results have verified the effectiveness of ProGAN."
Recurrent Attention Walk for Semi-supervised Classification,"Uchenna Akujuobi, Qiannan Zhang, Han Yufei, Xiangliang Zhang",arXiv,,"In this paper, we study the graph-based semi-supervised learning for classifying nodes in attributed networks, where the nodes and edges possess content information. Recent approaches like graph convolution networks and attention mechanisms have been proposed to ensemble the first-order neighbors and incorporate the relevant neighbors. However, it is costly (especially in memory) to consider all neighbors without a prior differentiation. We propose to explore the neighborhood in a reinforcement learning setting and find a walk path well-tuned for classifying the unlabelled target nodes. We let an agent (of node classification task) walk over the graph and decide where to direct to maximize classification accuracy. We define the graph walk as a partially observable Markov decision process (POMDP). The proposed method is flexible for working in both transductive and inductive setting. Extensive experiments on four datasets demonstrate that our proposed method outperforms several state-of-the-art methods. Several case studies also illustrate the meaningful movement trajectory made by the agent"
Outlier Resistant Unsupervised Deep Architectures for Attributed Network Embedding,"Sambaran Bandyopadhyay, N Lokesh,Saley Vishal Vivek, M. Narasimha Murty",ACM,"network representation learning, community outliers, adversarial learning, deep autoencoder, graph mining, social networks","Attributed network embedding is the task to learn a lower dimensional vector representation of the nodes of an attributed network, which can be used further for downstream network mining tasks. Nodes in a network exhibit community structure and most of the network embedding algorithms work well when the nodes, along with their attributes, adhere to the community structure of the network. But real life networks come with community outlier nodes, which deviate significantly in terms of their link structure or attribute similarities from the other nodes of the community they belong to. These outlier nodes, if not processed carefully, can even affect the embeddings of the other nodes in the network. Thus, a node embedding framework for dealing with both the link structure and attributes in the presence of outliers in an unsupervised setting is practically important. In this work, we propose a deep unsupervised autoencoders based solution which minimizes the effect of outlier nodes while generating the network embedding. We use both stochastic gradient descent and closed form updates for faster optimization of the network parameters. We further explore the role of adversarial learning for this task, and propose a second unsupervised deep model which learns by discriminating the structure and the attribute based embeddings of the network and minimizes the effect of outliers in a coupled way. Our experiments show the merit of these deep models to detect outliers and also the superiority of the generated network embeddings for different downstream mining tasks. To the best of our knowledge, these are the first unsupervised non linear approaches that reduce the effect of the outlier nodes while generating Network Embedding."
NEGAN:Network Embedding based on Generative Adversarial Networks,"Yinfeng Ban, Juhua Pu, Yujun Chen,Yuanhong Wang",IEEE,"network embedding, generative adversarial networks, unsupervised representation learning","Network embedding, also known as graph representation, is a classical topic in data mining. It has been widely used in real-world network applications such as node classification and community detection. However, it remains open to find a method that is scalable and preserves both structure and content information. Based on generative adversarial networks, we propose an unsupervised network embedding framework NEGAN, which is featured by combining graph topology and node content. In NEGAN, network nodes are mapped to the target space in a highly flexible non-linear way, guided by the content of the nodes. This mapping is learned from the generator of the generative adversarial networks, and node adjacency in the input network is preserved. Experiments on real datasets show that NEGAN outperforms all the existing methods on many scenarios including node classification, visualization and community detection tasks."
Flexible Attributed Network Embedding,"Enya Shen, Zhidong Cao, ChangqingZou, Jianmin Wang",arXiv,,"Network embedding aims to find a way to encode network by learning an embedding vector for each node in the network. The network often has property information which is highly informative with respect to the node's position and role in the network. Most network embedding methods fail to utilize this information during network representation learning. In this paper, we propose a novel framework, FANE, to integrate structure and property information in the network embedding process. In FANE, we design a network to unify heterogeneity of the two information sources, and define a new random walking strategy to leverage property information and make the two information compensate. FANE is conceptually simple and empirically powerful. It improves over the state-of-the-art methods on Cora dataset classification task by over 5%, more than 10% on WebKB dataset classification task. Experiments also show that the results improve more than the state-of-the-art methods as increasing training size. Moreover, qualitative visualization show that our framework is helpful in network property information exploration. In all, we present a new way for efficiently learning state-of-the-art task-independent representations in complex attributed networks"
Hybrid High-order in Graph Attention Layer,"Haihong E, Di Zeng, Meina Song",ACM,"GC-layer, Attention, Explicit information flow, High-order, Hybrid learning","As a result of approximating the Eigenbasis of the graph Laplacian proposed by GC-layer of Kipf & Welling [5], the convolution operation is efficiently applied from Euclidean domain to graph domain, and the end-to-end deep graph neural network is widely used and developed. However, fixed neighborhood limits the learning ability of the model, and GAT [7] models global node pairs to avoid information loss. In the form, this modeling is equivalent to only considering the firstorder proximity relation of the network, which leads to the indirect and lossy transmission of the higher-order information of the network, even if the multi-layer attention mechanism is used to expand the order of the network. In order to avoid the above situation and obtain higher-order information better, this paper tries to establish the concept of higher-order neighborhood mixed learning of graphs. In our work, unlike the implicit propagation of neighborhood information through activation functions in the past, our model called H-GAT explicitly obtain the information of high-order neighborhood of nodes, and use attention mechanism to model different weights between high-step nodes."
Representation Learning for Attributed Multiplex Heterogeneous Network,"Yukuo Cen, Xu Zou, Jianwei Zhang,Hongxia Yang, Jingren Zhou, Jie Tang",arXiv,"Network embedding, Multiplex network, Heterogeneous network","Network embedding (or graph embedding) has been widely used in many real-world applications. However, existing methods mainly focus on networks with single-typed nodes/edges and cannot scale well to handle large networks. Many real-world networks consist of billions of nodes and edges of multiple types, and each node is associated with different attributes. In this paper, we formalize the problem of embedding learning for the Attributed Multiplex Heterogeneous Network and propose a unified framework to address this problem. The framework supports both transductive and inductive learning. We also give the theoretical analysis of the proposed framework, showing its connection with previous works and proving its better expressiveness. We conduct systematical evaluations for the proposed framework on four different genres of challenging datasets: Amazon, YouTube, Twitter, and Alibaba. Experimental results demonstrate that with the learned embeddings from the proposed framework, we can achieve statistically significant improvements (e.g., 5.99-28.23% lift by F1 scores; p<<0.01, t-test) over previous state-of-the-art methods for link prediction. The framework has also been successfully deployed on the recommendation system of a worldwide leading e-commerce company, Alibaba Group. Results of the offline A/B tests on product recommendation further confirm the effectiveness and efficiency of the framework in practice."
PRRE: Personalized Relation Ranking Embedding for Attributed Networks,"Sheng Zhou, Hongxia Yang, Xin Wang,Jiajun Bu, Martin Ester, Pinggang Yu,Jianwei Zhang, Can Wang",ACM,"Attributed network embedding, partial correlation, relation ranking","Attributed network embedding focuses on learning low-dimensional latent representations of nodes which can well preserve the original topological and node attributed proximity at the same time. Existing works usually assume that nodes with similar topology or similar attributes should also be close in the embedding space. This assumption ignores the phenomenon of partial correlation between network topological and node attributed similarities i.e. nodes with similar topology may be dissimilar in their attributes and vice versa. Partial correlation between the two information sources should be considered especially when there exist fraudulent edges (i.e., information from one source is vague) or unbalanced data distributions (i.e, topology structure similarity and node attribute similarity have different distributions). However, it is very challenging to consider the partial correlation between topology and attributes due to the heterogeneity of these two information sources. In this paper, we take partial correlation between topology and attributes into account and propose the Personalized Relation Ranking Embedding (PRRE) method for attributed networks which is capable of exploiting the partial correlation between node topology and attributes. The proposed PRRE model utilizes two thresholds to define different node relations and employs the Expectation-Maximization (EM) algorithm to learn these thresholds as well as other embedding parameters. Extensive experiments results on multiple real-world datasets show that the proposed PRRE model significantly outperforms the state-of-the-art methods in terms of various evaluation metrics."
Gossip and Attend: Context-Sensitive Graph Representation Learning,"Zekarias T. Kefato, SarunasGirdzijauskas",arXiv,,"Graph representation learning (GRL) is a powerful technique for learning low-dimensional vector representation of high-dimensional and often sparse graphs. Most studies explore the structure and metadata associated with the graph using random walks and employ an unsupervised or semi-supervised learning schemes. Learning in these methods is context-free, resulting in only a single representation per node. Recently studies have argued on the adequacy of a single representation and proposed context-sensitive approaches, which are capable of extracting multiple node representations for different contexts. This proved to be highly effective in applications such as link prediction and ranking. However, most of these methods rely on additional textual features that require complex and expensive RNNs or CNNs to capture high-level features or rely on a community detection algorithm to identify multiple contexts of a node. In this study we show that in-order to extract high-quality context-sensitive node representations it is not needed to rely on supplementary node features, nor to employ computationally heavy and complex models. We propose GOAT, a context-sensitive algorithm inspired by gossip communication and a mutual attention mechanism simply over the structure of the graph. We show the efficacy of GOAT using 6 real-world datasets on link prediction and node clustering tasks and compare it against 12 popular and state-of-the-art (SOTA) baselines. GOAT consistently outperforms them and achieves up to 12% and 19% gain over the best performing methods on link prediction and clustering tasks, respectively."
Dual Graph Representation Learning,"Huiling Zhu, Xin Luo, Hankz HankuiZhuo",arXiv,,"Graph representation learning embeds nodes in large graphs as low-dimensional vectors and is of great benefit to many downstream applications. Most embedding frameworks, however, are inherently transductive and unable to generalize to unseen nodes or learn representations across different graphs. Although inductive approaches can generalize to unseen nodes, they neglect different contexts of nodes and cannot learn node embeddings dually. In this paper, we present a context-aware unsupervised dual encoding framework, \textbf{CADE}, to generate representations of nodes by combining real-time neighborhoods with neighbor-attentioned representation, and preserving extra memory of known nodes. We exhibit that our approach is effective by comparing to state-of-the-art methods."
Neural-Brane: An inductive approach for attributed network embedding,"Vachik S. Dave, Baichuan Zhang, Pin-YuChen, Mohammad Al Hasan",ACM,"Inductive attributed network embedding, Bayesian personalized ranking, Node classification","Network embedding methodologies, which learn a distributed vector representation for each vertex in a network, have shown to achieve superior performance in many realworld applications, such as node classification, link prediction, and community detection. However, the existing methods for network embedding are unable to generate representation vectors for unseen vertices; besides, these methods only utilize topological information from the network ignoring a rich set of nodal attributes, which is abundant in all real-life networks. In this paper, we present a novel network embedding approach called Neural-Brane, which overcomes both of the above limitations. For a given network, Neural-Brane extracts latent feature representation of its vertices using a designed neural network model that unifies network topological information and nodal attributes. Additionally, Neural-Brane is an inductive embedding approach, which enables generating embedding vectors for unseen future vertices of the attributed network. We evaluate the quality of vertex embedding produced by NeuralBrane by solving the node classification task on four realworld graph datasets. Experimental results demonstrate the superiority of Neural-Brane over the state-of-the-art existing methods."
Constrained Consistency Modeling for Attributed Network Embedding,"Xuan Zang, Bo Yang, Shuang Yang,Hechang Chen",IEEE,"Attributed network, network embedding, representation learning","Network embedding has emerged as a fundamental approach to network analysis tasks. Its main purpose is to learn a suitable mapping function to convert nodes in networks into a low-dimensional representations. The majority of existing studies concentrate solely on network topology structure. However, nodes are commonly associated with sufficient attribute information in real-world networks. Therefore, network embedding combining network topology structure and attribute information could be promisingly beneficial. Given this, we propose a novel attributed network embedding method called Consistency Constrained Attributed Network Embedding (CCANE), which preserves more complete information for nodes when learning the embedding representations. On the basis of the consistency of topology structure and node attributes, the CCANE is capable of learning the structure embeddings and attribute embeddings of nodes simultaneously, and then concatenate them to obtain the integrated vector representations. Moreover, the CCANE is scalable of dealing with large-scale of networks by decomposing the complicated optimization process into multiple sub-tasks in parallel. Experimental results testify the feasibility and superiority of the CCANE compared to the state-of-the-arts."
Survey of network embedding techniques for social networks,"Pranav Nerurkar, Madhav Chandane, S.G. Bhirud",Turkish Journal of Electrical Engineering & Computer Sciences,"Dimensionality reduction, network embedding, latent space","High dimensionality of data is a challenging scenario in the current era as the digital transformation of the society is in process. This problem is particularly complex in social networks as in such systems, it is coupled with other challenges such as interdependency of data points and heterogeneity of data sources. To overcome such disadvantages and aid in creation of downstream applications for social network analysis, network embedding techniques have been proposed. These techniques, in themselves, are not important but are the backbone of various network-based applications. Due to the scientific interest in this domain there has been a mushrooming of embedding techniques. It has therefore become crucial to learn the intuitions behind these techniques in order to compare and contrast them. The current analytical study is drawn with the following broad objectives: providing practitioners with understanding of network representative learning mathematical study of state-of-the-art techniques and highlighting the evolution of the literature in this field."
Network Representation Learning: A Survey,"Daokun Zhang, Jie Yin, Xingquan Zhu,Chengqi Zhang",arXiv,"Information networks, graph mining, network representation learning, network embedding","With the widespread use of information technologies, information networks are becoming increasingly popular to capture complex relationships across various disciplines, such as social networks, citation networks, telecommunication networks, and biological networks. Analyzing these networks sheds light on different aspects of social life such as the structure of societies, information diffusion, and communication patterns. In reality, however, the large scale of information networks often makes network analytic tasks computationally expensive or intractable. Network representation learning has been recently proposed as a new learning paradigm to embed network vertices into a low-dimensional vector space, by preserving network topology structure, vertex content, and other side information. This facilitates the original network to be easily handled in the new vector space for further analysis. In this survey, we perform a comprehensive review of the current literature on network representation learning in the data mining and machine learning field. We propose new taxonomies to categorize and summarize the state-of-the-art network representation learning techniques according to the underlying learning mechanisms, the network information intended to preserve, as well as the algorithmic designs and methodologies. We summarize evaluation protocols used for validating network representation learning including published benchmark datasets, evaluation methods, and open source algorithms. We also perform empirical studies to compare the performance of representative algorithms on common datasets, and analyze their computational complexity. Finally, we suggest promising research directions to facilitate future study."
Community Aware Random Walk for Network Embedding,"Mohammad Mehdi Keikha, MasoudRahgozar, Masoud Asadpour",arXiv,"Representation learning, Network embedding, Community detection, Skip-gram model, Link prediction","Social network analysis provides meaningful information about behavior of network members that can be used for diverse applications such as classification, link prediction. However, network analysis is computationally expensive because of feature learning for different applications. In recent years, many researches have focused on feature learning methods in social networks. Network embedding represents the network in a lower dimensional representation space with the same properties which presents a compressed representation of the network. In this paper, we introduce a novel algorithm named ""CARE"" for network embedding that can be used for different types of networks including weighted, directed and complex. Current methods try to preserve local neighborhood information of nodes, whereas the proposed method utilizes local neighborhood and community information of network nodes to cover both local and global structure of social networks. CARE builds customized paths, which are consisted of local and global structure of network nodes, as a basis for network embedding and uses the Skip-gram model to learn representation vector of nodes. Subsequently, stochastic gradient descent is applied to optimize our objective function and learn the final representation of nodes. Our method can be scalable when new nodes are appended to network without information loss. Parallelize generation of customized random walks is also used for speeding up CARE. We evaluate the performance of CARE on multi label classification and link prediction tasks. Experimental results on various networks indicate that the proposed method outperforms others in both Micro and Macro-f1 measures for different size of training data."
Graph Embedding with Rich Information through Bipartite Heterogeneous Network,"Guolei Sun, Xiangliang Zhang",arXiv,,"Graph embedding has attracted increasing attention due to its critical application in social network analysis. Most existing algorithms for graph embedding only rely on the typology information and fail to use the copious information in nodes as well as edges. As a result, their performance for many tasks may not be satisfactory. In this paper, we proposed a novel and general framework of representation learning for graph with rich text information through constructing a bipartite heterogeneous network. Specially, we designed a biased random walk to explore the constructed heterogeneous network with the notion of flexible neighborhood. The efficacy of our method is demonstrated by extensive comparison experiments with several baselines on various datasets. It improves the Micro-F1 and Macro-F1 of node classification by 10% and 7% on Cora dataset."
Learning Graph Embedding with Adversarial Training Methods,"Shirui Pan, Ruiqi Hu, Sai-Fu Fung,Guodong Long, Jing Jiang, ChengqiZhang",arXiv,"Graph Embedding, Graph Clustering, Link Prediction, Graph Convolutional Networks, Adversarial Regularization, Graph Autoencoder","Graph embedding aims to transfer a graph into vectors to facilitate subsequent graph analytics tasks like link prediction and graph clustering. Most approaches on graph embedding focus on preserving the graph structure or minimizing the reconstruction errors for graph data. They have mostly overlooked the embedding distribution of the latent codes, which unfortunately may lead to inferior representation in many cases. In this paper, we present a novel adversarially regularized framework for graph embedding. By employing the graph convolutional network as an encoder, our framework embeds the topological information and node content into a vector representation, from which a graph decoder is further built to reconstruct the input graph. The adversarial training principle is applied to enforce our latent codes to match a prior Gaussian or Uniform distribution. Based on this framework, we derive two variants of adversarial models, the adversarially regularized graph autoencoder (ARGA) and its variational version, adversarially regularized variational graph autoencoder (ARVGA), to learn the graph embedding effectively. We also exploit other potential variations of ARGA and ARVGA to get a deeper understanding on our designs. Experimental results compared among twelve algorithms for link prediction and twenty algorithms for graph clustering validate our solutions."
Multi-Task Learning Based Network Embedding,"Shan-Feng Wang, Qixiang Wang,Maoguo Gong",Frontiers in Neuroscience,"network representation learning, multi-task learning, network embedding, high-order proximity, low-order proximity","The goal of network representation learning, also called network embedding, is to encode the network structure information into a continuous low-dimensionality embedding space where geometric relationships among the vectors can reflect the relationships of nodes in the original network. The existing network representation learning methods are always single-task learning, in which case these methods focus on preserving the proximity of nodes from one aspect. However, the proximity of nodes is dependent on both the local and global structure, resulting in a limitation on the node embeddings learned by these methods. In order to solve this problem, in this paper, we propose a novel method, Multi-Task Learning-Based Network Embedding, termed MLNE. There are two tasks in this method so as to preserve the proximity of nodes. The aim of the first task is to preserve the high-order proximity between pairwise nodes in the whole network. The second task is to preserve the low-order proximity in the one-hop area of each node. By jointly learning these tasks in the supervised deep learning model, our method can obtain node embeddings that can sufficiently reflect the roles that nodes play in networks. In order to demonstrate the efficacy of our MLNE method over existing state-of-the-art methods, we conduct experiments on multi-label classification, link prediction, and visualization in five real-world networks. The experimental results show that our method performs competitively."
Network Embedding: on Compression and Learning,"Esra Akbaş, Mehmet Emin Aktas",arXiv,,"Recently, network embedding that encodes structural information of graphs into a vector space has become popular for network analysis. Although recent methods show promising performance for various applications, the huge sizes of graphs may hinder a direct application of existing network embedding method to them. This paper presents NECL, a novel efficient Network Embedding method with two goals. 1) Is there an ideal Compression of a network? 2) Will the compression of a network significantly boost the representation Learning of the network? For the first problem, we propose a neighborhood similarity based graph compression method that compresses the input graph to get a smaller graph without losing any/much information about the global structure of the graph and the local proximity of the vertices in the graph. For the second problem, we use the compressed graph for network embedding instead of the original large graph to bring down the embedding cost. NECL is a general meta-strategy to improve the efficiency of all of the state-of-the-art graph embedding algorithms based on random walks, including DeepWalk and Node2vec, without losing their effectiveness. Extensive experiments on large real-world networks validate the efficiency of NECL method that yields an average improvement of 23 - 57% embedding time, including walking and learning time without decreasing classification accuracy as evaluated on single and multi-label classification tasks on real-world graphs such as DBLP, BlogCatalog, Cora and Wiki."
Network Representation Learning Guided by Partial Community Structure,"Hanlin Sun, Wei Jie, Zhongmin Wang,Haoru Wang, Sugang Ma",IEEE,"Network embedding, network representation learning, partial community structure, community structure, multi-label classification, link prediction","Network Representation Learning (NRL) is an effective way to analyze large scale networks (graphs). In general, it maps network nodes, edges, subgraphs, etc. onto independent vectors in a low dimension space, thus facilitating network analysis tasks. As community structure is one of the most prominent mesoscopic structure properties of real networks, it is necessary to preserve community structure of networks during NRL. In this paper, the concept of k-step partial community structure is defined and two Partial Community structure Guided Network Embedding (PCGNE) methods, based on two popular NRL algorithms (DeepWalk and node2vec respectively), for node representation learning are proposed. The idea behind this is that it is easier and more cost-effective to find a higher quality 1-step partial community structure than a higher quality whole community structure for networks; the extracted partial community information is then used to guide random walks in DeepWalk or node2vec. As a result, the learned node representations could preserve community structure property of networks more effectively. The two proposed algorithms and six state-of-the-art NRL algorithms were examined through multi-label classification and (inner community) link prediction on eight synthesized networks: one where community structure property could be controlled, and one real world network. The results suggested that the two PCGNE methods could improve the performance of their own based algorithm significantly and were competitive for node representation learning. Especially, comparing against used baseline algorithms, PCGNE methods could capture overlapping community structure much better, and thus could achieve better performance for multi-label classification on networks that have more overlapping nodes and/or larger overlapping memberships."
A Unified Framework for Community Detection and Network Representation Learning,"Cunchao Tu, Xiangkai Zeng, Hao Wang,Zhengyan Zhang, Zhiyuan Liu,Maosong Sun, Bo Zhang, Leyu Lin",IEEE,"Network representation learning, community detection, link prediction, social networks","Network representation learning (NRL) aims to learn low-dimensional vectors for vertices in a network. Most existing NRL methods focus on learning representations from local context of vertices (such as their neighbors). Nevertheless, vertices in many complex networks also exhibit significant global patterns widely known as communities. It’s intuitive that vertices in the same community tend to connect densely and share common attributes. These patterns are expected to improve NRL and benefit relevant evaluation tasks, such as link prediction and vertex classification. Inspired by the analogy between network representation learning and text modeling, we propose a unified NRL framework by introducing community information of vertices, named as Community-enhanced Network Representation Learning (CNRL). CNRL simultaneously detects community distribution of each vertex and learns embeddings of both vertices and communities. Moreover, the proposed community enhancement mechanism can be applied to various existing NRL models. In experiments, we evaluate our model on vertex classification, link prediction, and community detection using several real-world datasets. The results demonstrate that CNRL significantly and consistently outperforms other state-of-the-art methods while verifying our assumptions on the correlations between vertices and communities."
Generalized Neural Graph Embedding with Matrix Factorization,"Junliang Guo, Linli Xu, Xunpeng Huang,Enhong Chen",arXiv,,"Recent advances in language modeling such as word2vec motivate a number of graph embedding approaches by treating random walk sequences as sentences to encode structural proximity in a graph. However, most of the existing principles of neural graph embedding do not incorporate auxiliary information such as node content flexibly. In this paper we take a matrix factorization perspective of graph embedding which generalizes to structural embedding as well as content embedding in a natural way. For structure embedding, we validate that the matrix we construct and factorize preserves the high-order proximities of the graph. Label information can be further integrated into the matrix via the process of random walk sampling to enhance the quality of embedding. In addition, we generalize the Skip-Gram Negative Sampling model to integrate the content of the graph in a matrix factorization framework. As a consequence, graph embedding can be learned in a unified framework integrating graph structure and node content as well as label information simultaneously. We demonstrate the efficacy of the proposed model with the tasks of semi-supervised node classification and link prediction on a variety of real-world benchmark network datasets."
Embedding Temporal Network via Neighborhood Formation,"Yuan Zuo, Guannan Liu, Hao Lin, JiaGuo, Xiaoqian Hu, Junjie Wu",ACM,"Temporal Network, Network Embedding, Learning Representation, Hawkes Process","Given the rich real-life applications of network mining as well as the surge of representation learning in recent years, network embedding has become the focal point of increasing research interests in both academic and industrial domains. Nevertheless, the complete temporal formation process of networks characterized by sequential interactive events between nodes has yet seldom been modeled in the existing studies, which calls for further research on the so-called temporal network embedding problem. In light of this, in this paper, we introduce the concept of neighborhood formation sequence to describe the evolution of a node, where temporal excitation effects exist between neighbors in the sequence, and thus we propose a Hawkes process based Temporal Network Embedding (HTNE) method. HTNE well integrates the Hawkes process into network embedding so as to capture the influence of historical neighbors on the current neighbors. In particular, the interactions of low-dimensional vectors are fed into the Hawkes process as base rate and temporal influence, respectively. In addition, attention mechanism is also integrated into HTNE to better determine the influence of historical neighbors on current neighbors of a node. Experiments on three large-scale real-life networks demonstrate that the embeddings learned from the proposed HTNE model achieve better performance than state-of-the-art methods in various tasks including node classification, link prediction, and embedding visualization. In particular, temporal recommendation based on arrival rate inferred from node embeddings shows excellent predictive power of the proposed model.
"
A Survey on Network Embedding,"Peng Cui, Xiao Wang, Jian Pei, WenwuZhu",arXiv,,"Network embedding assigns nodes in a network to low-dimensional representations and effectively preserves the network structure. Recently, a significant amount of progresses have been made toward this emerging network analysis paradigm. In this survey, we focus on categorizing and then reviewing the current development on network embedding methods, and point out its future research directions. We first summarize the motivation of network embedding. We discuss the classical graph embedding algorithms and their relationship with network embedding. Afterwards and primarily, we provide a comprehensive overview of a large number of network embedding methods in a systematic manner, covering the structure- and property-preserving network embedding methods, the network embedding methods with side information and the advanced information preserving network embedding methods. Moreover, several evaluation approaches for network embedding and some useful online resources, including the network data sets and softwares, are reviewed, too. Finally, we discuss the framework of exploiting these network embedding methods to build an effective system and point out some potential future directions."
A Survey on Network Embedding,"Peng Cui, Xiao Wang, Jian Pei, WenwuZhu",arXiv,,"Network embedding assigns nodes in a network to low-dimensional representations and effectively preserves the network structure. Recently, a significant amount of progresses have been made toward this emerging network analysis paradigm. In this survey, we focus on categorizing and then reviewing the current development on network embedding methods, and point out its future research directions. We first summarize the motivation of network embedding. We discuss the classical graph embedding algorithms and their relationship with network embedding. Afterwards and primarily, we provide a comprehensive overview of a large number of network embedding methods in a systematic manner, covering the structure- and property-preserving network embedding methods, the network embedding methods with side information and the advanced information preserving network embedding methods. Moreover, several evaluation approaches for network embedding and some useful online resources, including the network data sets and softwares, are reviewed, too. Finally, we discuss the framework of exploiting these network embedding methods to build an effective system and point out some potential future directions."
ANRL: Attributed Network Representation Learning via Deep Neural Networks,"Zhen Zhang, Hongxia Yang, Jiajun Bu,Sheng Zhou, Pinggang Yu, JianweiZhang, Martin Ester, Can Wang",IJCAI,,"Network representation learning (RL) aims to transform the nodes in a network into lowdimensional vector spaces while preserving the inherent properties of the network. Though network RL has been intensively studied, most existing works focus on either network structure or node attribute information. In this paper, we propose a novel framework, named ANRL, to incorporate both the network structure and node attribute information in a principled way. Specifically, we propose a neighbor enhancement autoencoder to model the node attribute information, which reconstructs its target neighbors instead of itself. To capture the network structure, attribute-aware skipgram model is designed based on the attribute encoder to formulate the correlations between each node and its direct or indirect neighbors. We conduct extensive experiments on six real-world networks, including two social networks, two citation networks and two user behavior networks. The results empirically show that ANRL can achieve relatively significant gains in node classification and link prediction tasks."
DynWalks: Global Topology and Recent Changes Awareness Dynamic Network Embedding,"Chengbin Hou, Han Zhang, Ke Tang,Shan He",arXiv,,"Learning topological representation of a network in dynamic environments has recently attracted considerable attention due to the time-evolving nature of many real-world networks i.e. nodes/links might be added/removed as time goes on. Dynamic network embedding aims to learn low dimensional embeddings for unseen and seen nodes by using any currently available snapshots of a dynamic network. For seen nodes, the existing methods either treat them equally important or focus on the k most affected nodes at each time step. However, the former solution is time-consuming, and the later solution that relies on incoming changes may lose the global topology---an important feature for downstream tasks. To address these challenges, we propose a dynamic network embedding method called DynWalks, which includes two key components: 1) An online network embedding framework that can dynamically and efficiently learn embeddings based on the selected nodes; 2) A novel online node selecting scheme that offers the flexible choices to balance global topology and recent changes, as well as to fulfill the real-time constraint if needed. The empirical studies on six real-world dynamic networks under three different slicing ways show that DynWalks significantly outperforms the state-of-the-art methods in graph reconstruction tasks, and obtains comparable results in link prediction tasks. Furthermore, the wall-clock time and complexity analysis demonstrate its excellent time and space efficiency."
Exponential Family Graph Embeddings,"Abdulkadir Çelikkanat, Fragkiskos D.Malliaros",arXiv,,"Representing networks in a low dimensional latent space is a crucial task with many interesting applications in graph learning problems, such as link prediction and node classification. A widely applied network representation learning paradigm is based on the combination of random walks for sampling context nodes and the traditional \textit{Skip-Gram} model to capture center-context node relationships. In this paper, we emphasize on exponential family distributions to capture rich interaction patterns between nodes in random walk sequences. We introduce the generic \textit{exponential family graph embedding} model, that generalizes random walk-based network representation learning techniques to exponential family conditional distributions. We study three particular instances of this model, analyzing their properties and showing their relationship to existing unsupervised learning models. Our experimental evaluation on real-world datasets demonstrates that the proposed techniques outperform well-known baseline methods in two downstream machine learning tasks."
Edge Content Enhanced Network Embedding,"Hongcui Wang, Erwei Wang, Di Jin, XiaoWang, Jing Wang, Dongxiao He",IEEE,"network embedding, edge content, network analysis tasks","Network embedding, aiming at learning the lowdimensional representations of nodes in a network, is a key to many network analysis tasks. All the current network embedding methods primarily explore the network topology or node attributes, while no effort has been made to analyze the edge content for network embedding. The edge content, such as the email content between two users in an email network, is often naturally associated with edges. They carry rich information to describe the interaction between nodes, and provide valuable supervision to learn the representations of nodes. In this paper, we propose a novel edge content enhanced network embedding model, which incorporates the edge content to guide the network representation learning process. We provide the efficient updating rules to infer the parameters in the model, along with theoretical analysis on correctness and convergence guarantees. Extensive experiments, in comparison with the state-of-the-arts, show the superior performance of our proposed new approach on different network analysis tasks."
Spectral Network Embedding: A Fast and Scalable Method via Sparsity,"Jie Zhang, Yan Wang, Jie Tang, MingDing",arXiv,"network embedding, unsupervised learning, network spectral analysis, scalability","Network embedding aims to learn low-dimensional representations of nodes in a network, while the network structure and inherent properties are preserved. It has attracted tremendous attention recently due to significant progress in downstream network learning tasks, such as node classification, link prediction, and visualization. However, most existing network embedding methods suffer from the expensive computations due to the large volume of networks. In this paper, we propose a 10× ∼ 100× faster network embedding method, called Progle, by elegantly utilizing the sparsity property of online networks and spectral analysis. In Progle, we first construct a sparse proximity matrix and train the network embedding efficiently via sparse matrix decomposition. Then we introduce a network propagation pattern via spectral analysis to incorporate local and global structure information into the embedding. Besides, this model can be generalized to integrate network information into other insufficiently trained embeddings at speed. Benefiting from sparse spectral network embedding, our experiment on four different datasets shows that Progle outperforms or is comparable to state-of-the-art unsupervised comparison approaches—DeepWalk, LINE, node2vec, GraRep, and HOPE, regarding accuracy, while is 10× faster than the fastest word2vec-based method. Finally, we validate the scalability of Progle both in real large-scale networks and multiple scales of synthetic networks."
On the Interpretability and Evaluation of Graph Representation Learning,"Antonia Gogoglou, C. Bayan Bruss,Keegan Hines",arXiv,,"With the rising interest in graph representation learning, a variety of approaches have been proposed to effectively capture a graph's properties. While these approaches have improved performance in graph machine learning tasks compared to traditional graph techniques, they are still perceived as techniques with limited insight into the information encoded in these representations. In this work, we explore methods to interpret node embeddings and propose the creation of a robust evaluation framework for comparing graph representation learning algorithms and hyperparameters. We test our methods on graphs with different properties and investigate the relationship between embedding training parameters and the ability of the produced embedding to recover the structure of the original graph in a downstream task."
User Profile Preserving Social Network Embedding,"Daokun Zhang, Jie Yin, Xingquan Zhu,Chengqi Zhang",IJCAI,,"This paper addresses social network embedding, which aims to embed social network nodes, including user profile information, into a latent lowdimensional space. Most of the existing works on network embedding only consider network structure, but ignore user-generated content that could be potentially helpful in learning a better joint network representation. Different from rich node content in citation networks, user profile information in social networks is useful but noisy, sparse, and incomplete. To properly utilize this information, we propose a new algorithm called User Profile Preserving Social Network Embedding (UPPSNE), which incorporates user profile with network structure to jointly learn a vector representation of a social network. The theme of UPPSNE is to embed user profile information via a nonlinear mapping into a consistent subspace, where network structure is seamlessly encoded to jointly learn informative node representations. Extensive experiments on four real-world social networks show that compared to state-of-the-art baselines, our method learns better social network representations and achieves substantial performance gains in node classification and clustering tasks."
MODEL: Motif-Based Deep Feature Learning for Link Prediction,"Lei Wang, Jing Ren, Bin Xu, Jianxin Li,Wei Luo, Fan Xia",IEEE,"Autoencoder, deep learning, link prediction, network embedding, network motif","Link prediction plays an important role in network analysis and applications. Recently, approaches for link prediction have evolved from traditional similarity-based algorithms into embedding-based algorithms. However, most existing approaches fail to exploit the fact that real-world networks are different from random networks. In particular, real-world networks are known to contain motifs, natural network building blocks reflecting the underlying network-generating processes. In this article, we propose a novel embedding algorithm that incorporates network motifs to capture higher order structures in the network. To evaluate its effectiveness for link prediction, experiments were conducted on three types of networks: social networks, biological networks, and academic networks. The results demonstrate that our algorithm outperforms both the traditional similarity-based algorithms (by 20%) and the stateof-the-art embedding-based algorithms (by 19%)."
Research on Bipartite Network Embedding with Auxiliary Information,"Hasnat Ahmed, Shahbaz Ali",IEEE,"Attributed Bipartite Networks, Network Representation Learning, Link Prediction, Recommendation","Learning a low-dimensional vector representation for each node in a network is called network embedding. These learned embeddings have shown promising results on network mining tasks such as link prediction, recommendation, and node classification. Most of the published work preserve network structure only; however, there also exist rich auxiliary information (i.e., attributes, text) along with network structure in a real-world scenario. One can consider that information along with network structure to measure and enhance the capacity of representation learning methods. Many real-world applications such as user/movies (recommendation system), traders/stocks (financial system) can be demonstrated as a bipartite network (a particular class of network). In our work, we present a method named ABiNE, short for Attributed Bipartite Network Embedding, to learn the latent representations of nodes for attributed bipartite networks. We investigate and develop to incorporate both structural information, in the context of explicit, implicit relations, and attributes proximity under the framework of bipartite network embedding (BiNE). We evaluate our method by conducting experiments on a real-world dataset, i.e., MovieLens. The results have shown the improvement in link prediction, and recommendation (personalized ranking) tasks as compared to other attributed or plain network embedding methods."
Is a Single Vector Enough?: Exploring Node Polysemy for Network Embedding,"Ninghao Liu, Qiaoyu Tan, Yuening Li,Hongxia Yang, Jingren Zhou, Xia Hu",arXiv,"Network Embedding, Disentangled Representation Learning, Recommender Systems, Graph Mining
","Networks have been widely used as the data structure for abstracting real-world systems as well as organizing the relations among entities. Network embedding models are powerful tools in mapping nodes in a network into continuous vector-space representations in order to facilitate subsequent tasks such as classification and link prediction. Existing network embedding models comprehensively integrate all information of each node, such as links and attributes, towards a single embedding vector to represent the node's general role in the network. However, a real-world entity could be multifaceted, where it connects to different neighborhoods due to different motives or self-characteristics that are not necessarily correlated. For example, in a movie recommender system, a user may love comedies or horror movies simultaneously, but it is not likely that these two types of movies are mutually close in the embedding space, nor the user embedding vector could be sufficiently close to them at the same time. In this paper, we propose a polysemous embedding approach for modeling multiple facets of nodes, as motivated by the phenomenon of word polysemy in language modeling. Each facet of a node is mapped as an embedding vector, while we also maintain association degree between each pair of node and facet. The proposed method is adaptive to various existing embedding models, without significantly complicating the optimization process. We also discuss how to engage embedding vectors of different facets for inference tasks including classification and link prediction. Experiments on real-world datasets help comprehensively evaluate the performance of the proposed method."
"A Comprehensive Survey of Graph Embedding: Problems, Techniques and Applications","HongYun Cai, Vincent Wenchen Zheng,Kevin Chen-Chuan Chang",IEEE,"Graph embedding, graph analytics, graph embedding survey, network embedding","Graph is an important data representation which appears in a wide diversity of real-world scenarios. Effective graph analytics provides users a deeper understanding of what is behind the data, and thus can benefit a lot of useful applications such as node classification, node recommendation, link prediction, etc. However, most graph analytics methods suffer the high computation and space cost. Graph embedding is an effective yet efficient way to solve the graph analytics problem. It converts the graph data into a low dimensional space in which the graph structural information and graph properties are maximumly preserved. In this survey, we conduct a comprehensive review of the literature in graph embedding. We first introduce the formal definition of graph embedding as well as the related concepts. After that, we propose two taxonomies of graph embedding which correspond to what challenges exist in different graph embedding problem settings and how the existing work address these challenges in their solutions. Finally, we summarize the applications that graph embedding enables and suggest four promising future research directions in terms of computation efficiency, problem settings, techniques and application scenarios."
Optimizing Generalized PageRank Methods for Seed-Expansion Community Detection,"Pengcheng Li, I Chien, OlgicaMilenkovic",arXiv,,"Landing probabilities (LP) of random walks (RW) over graphs encode rich information regarding graph topology. Generalized PageRanks (GPR), which represent weighted sums of LPs of RWs, utilize the discriminative power of LP features to enable many graph-based learning studies. Previous work in the area has mostly focused on evaluating suitable weights for GPRs, and only a few studies so far have attempted to derive the optimal weights of GRPs for a given application. We take a fundamental step forward in this direction by using random graph models to better our understanding of the behavior of GPRs. In this context, we provide a rigorous non-asymptotic analysis for the convergence of LPs and GPRs to their mean-field values on edge-independent random graphs. Although our theoretical results apply to many problem settings, we focus on the task of seed-expansion community detection over stochastic block models. There, we find that the predictive power of LPs decreases significantly slower than previously reported based on asymptotic findings. Given this result, we propose a new GPR, termed Inverse PR (IPR), with LP weights that increase for the initial few steps of the walks. Extensive experiments on both synthetic and real, large-scale networks illustrate the superiority of IPR compared to other GPRs for seeded community detection."
A Graph Auto-Encoder for Attributed Network Embedding,"Keting Cen, Huawei Shen, Jinhua Gao,Qi Cao, Bingbing Xu, Xueqi Cheng",arXiv,"Attributed Network Embedding, Graph Auto-encoder, Attributed local subgraph","Attributed network embedding aims to learn low-dimensional node representations from both network structure and node attributes. Existing methods can be categorized into two groups: (1) the first group learns two separated node representations from network structure and node attribute respectively and concatenating them together; (2) the other group obtains node representations by translating node attributes into network structure or vice versa. However, both groups have their drawbacks. The first group neglects the correlation between these two types of information, while the second group assumes strong dependence between network structure and node attributes. In this paper, we address attributed network embedding from a novel perspective, i.e., learning representation of a target node via modeling its attributed local subgraph. To achieve this goal, we propose a novel graph auto-encoder framework, namely GraphAE. For a target node, GraphAE first aggregates the attribute information from its attributed local subgrah, obtaining its low-dimensional representation. Next, GraphAE diffuses its representation to nodes in its local subgraph to reconstruct their attribute information. Our proposed perspective transfroms the problem of learning node representations into the problem of modeling the context information manifested in both network structure and node attributes, thus having high capacity to learn good node representations for attributed network. Extensive experimental results on real-world datasets demonstrate that the proposed framework outperforms the state-of-the-art network approaches at the tasks of link prediction and node classification."
Node classification framework.,"Keting Cen, Huawei Shen, Jinhua Gao,Qi Cao, Bingbing Xu, Xueqi Cheng",arXiv,"Attributed Network Embedding, Attributed Network Auto-encoder, Attributed local subgraph, Node Context Representation, Link Prediction, Node Classification","Attributed network embedding aims to learn low-dimensional node representations from both network structure and node attributes. Existing methods can be categorized into two groups: (1) the first group learns two separated node representations from network structure and node attribute respectively and concatenates them together; (2) the other group obtains node representations by translating node attributes into network structure or vice versa. However, both groups have their drawbacks. The first group neglects the correlation between network structure and node attributes, while the second group assumes strong dependence between these two types of information. In this paper, we address attributed network embedding from a novel perspective, i.e., learning node context representation for each node via modeling its attributed local subgraph. To achieve this goal, we propose a novel attributed network auto-encoder framework, namely ANAE. For a target node, ANAE first aggregates the attribute information from its attributed local subgraph, obtaining its low-dimensional representation. Next, ANAE diffuses the representation of the target node to nodes in its local subgraph to reconstruct their attributes. Such an encoder-decoder framework allows the learned representations to better preserve the context information manifested in both network structure and node attributes, thus having high capacity to learn good node representations for attributed network. Extensive experimental results on real-world datasets demonstrate that the proposed framework outperforms the state-of-the-art approaches at the tasks of link prediction and node classification."
Deep Mutual Encode Model for Network Embedding From Structural Identity,"Hongyao Ke, Yinghui Wang, Xuan Guo,Lin Pan, Pengfei Jiao, Wenjun Wang,Xiaoping Yang",IEEE,"Network representation learning, node embedding, feature learning, structural identity","Network Embedding (NE) is one of the most popular learning methods in complex networks. It aims at learning the low-dimensional representations of nodes in networks and has been applied in a variety of network analytic tasks. Most existing methods of NE are designed by merely using the local, high-order or global proximity to preserve the network structure; hence they are incapable of fully capturing the structural identity of nodes, which is a concept of symmetry defined by the network structure and their relationship to other nodes. There are two limitations to existing NE models. First, the local and global node dependency information is not considered simultaneously. Second, there is no adequate framework that can reveal the role property of each node. In this paper, we propose an intuitive and unified deep learning framework named DMER, short for Deep Mutual Encode for Embedding, to learn node embeddings from structural identity. In our model, Graph Convolution Network (GCN) is adopted to model the dependency relations between nodes from a global perspective. An Auto-Encoder (AE) framework is proposed to reconstruct the features of nodes, and it can conclusively reveal the structural identity from network structure. By integrating the GCN and AE components with a shared and constrained mechanism, the proposed model implements mutual enhancement for node embedding from structural identity. Experimental results based on structural role classification and visualization demonstrate that our model achieves better performance compared with the state-of-the-art methods."
Representation Learning on Graphs by Integrating Content and Structure Information,"Ayush Maheshwari, Ayush Goyal, AmitKumar, Manjesh Kumar Hanawal,Ganesh Ramakrishnan",IEEE,"graph representation learning, node embedding, link prediction, node classification","The problem of representation learning on graph can be difficult due to limited knowledge of training data and large presence of missing edges. Real-world social networks do not provide complete information about the network due to hidden information and privacy constraints. In such scenarios, typical representation learning methods are not able to capture network information effectively. In order to make them more useful, any available feature information can be used in addition to the network structure. In this paper, we aim to learn better representations by exploiting both content (or feature) information of nodes and structural information of the network. Our approach leverages generative adversarial networks to learn embedding for generator and discriminator in a minimax game. While the generator estimates the neighborhood of a node, the discriminator distinguishes between the presence or absence of a link for a pair of nodes. We demonstrate the effectiveness of our approach on five real-world publicly available datasets on the problems of link prediction and node classification. On both tasks, we achieve significant gains, outperforming current stateof-the-art methods by considerable margins. Our code is available on Github"
Deep Graph Embedding for Ranking Optimization in E-commerce,"Chen Chu, Zhao Li, Beibei Xin,Fengchao Peng, Chuanren Liu, RemoRohs, Qiong Luo, Jingren Zhou",ACM,"Deep Learning, Graph Embedding, Structure Learning, E-commerce Ranking, Customer Matching, A/B Test","Matching buyers with most suitable sellers providing relevant items (e.g., products) is essential for e-commerce platforms to guarantee customer experience. This matching process is usually achieved through modeling inter-group (buyer-seller) proximity by e-commerce ranking systems. However, current ranking systems often match buyers with sellers of various qualities, and the mismatch is  detrimental to not only buyers’ level of satisfaction but also the platforms’ return on investment (ROI). In this paper, we address this problem by incorporating intra-group structural information (e.g., buyer-buyer proximity implied by buyer attributes) into the ranking systems. Specifically, we propose Deep Graph Embedding (DEGREE), a deep learning based method, to exploit both inter-group and intra-group proximities jointly for structural learning. With a sparse filtering technique, DEGREE can significantly improve the matching performance with computation resources less than that of alternative deep learning based methods. Experimental results demonstrate that DEGREE outperforms state-of-the-art graph embedding methods on realworld e-commence datasets. In particular, our solution boosts the average unit price in purchases during an online A/B test by up to 11.93%, leading to better operational efficiency and shopping experience.
"
Homogeneous Network Embedding for Massive Graphs via Personalized PageRank,"Ren-chi Yang, Jieming Shi, XiaokuiXiao, Sourav S. Bhowmick, Yin XianYang",arXiv,,"Given an input graph G and a node v in G, homogeneous network embedding (HNE) maps the graph structure in the vicinity of v to a compact, fixed-dimensional feature vector. This paper focuses on HNE for massive graphs, e.g., with billions of edges. On this scale, most existing approaches fail, as they incur either prohibitively high costs, or severely compromised result utility. Our proposed solution, called Node-Reweighted PageRank (NRP), is based on a classic idea of deriving embedding vectors from pairwise personalized PageRank (PPR) values. Our contributions are twofold: first, we design a simple and efficient baseline HNE method based on PPR that is capable of handling billion-edge graphs on commodity hardware; second and more importantly, we identify an inherent drawback of vanilla PPR, and address it in our main proposal NRP. Specifically, PPR was designed for a very different purpose, i.e., ranking nodes in G based on their relative importance from a source node's perspective. In contrast, HNE aims to build node embeddings considering the whole graph. Consequently, node embeddings derived directly from PPR are of suboptimal utility. The proposed NRP approach overcomes the above deficiency through an effective and efficient node reweighting algorithm, which augments PPR values with node degree information, and iteratively adjusts embedding vectors accordingly. Overall, NRP takes O(mlogn) time and O(m) space to compute all node embeddings for a graph with m edges and n nodes. Our extensive experiments that compare NRP against 18 existing solutions over 7 real graphs demonstrate that NRP achieves higher result utility than all the solutions for link prediction, graph reconstruction and node classification, while being up to orders of magnitude faster. In particular, on a billion-edge Twitter graph, NRP terminates within 4 hours, using a single CPU core."
Fast and Accurate Network Embeddings via Very Sparse Random Projection,"Haochen Chen, Syed Fahad Sultan,Yingtao Tian, Muhao Chen, StevenSkiena",arXiv,"network embeddings, network representation learning, random projection","We present FastRP, a scalable and performant algorithm for learning distributed node representations in a graph. FastRP is over 4,000 times faster than state-of-the-art methods such as DeepWalk and node2vec, while achieving comparable or even better performance as evaluated on several real-world networks on various downstream tasks. We observe that most network embedding methods consist of two components: construct a node similarity matrix and then apply dimension reduction techniques to this matrix. We show that the success of these methods should be attributed to the proper construction of this similarity matrix, rather than the dimension reduction method employed. FastRP is proposed as a scalable algorithm for network embeddings. Two key features of FastRP are: 1) it explicitly constructs a node similarity matrix that captures transitive relationships in a graph and normalizes matrix entries based on node degrees; 2) it utilizes very sparse random projection, which is a scalable optimization-free method for dimension reduction. An extra benefit from combining these two design choices is that it allows the iterative computation of node embeddings so that the similarity matrix need not be explicitly constructed, which further speeds up FastRP. FastRP is also advantageous for its ease of implementation, parallelization and hyperparameter tuning. 
"
Capturing Edge Attributes via Network Embedding,"Palash Goyal, Homa Hosseinmardi,Emilio Ferrara, Aram Galstyan",arXiv,"Graph Embedding, Deep Learning, Network Representation","Network embedding, which aims to learn low-dimensional representations of nodes, has been used for various graph related tasks including visualization, link prediction and node classification. Most existing embedding methods rely solely on network structure. However, in practice we often have auxiliary information about the nodes and/or their interactions, e.g., content of scientific papers in co-authorship networks, or topics of communication in Twitter mention networks. Here we propose a novel embedding method that uses both network structure and edge attributes to learn better network representations. Our method jointly minimizes the reconstruction error for higher-order node neighborhood, social roles and edge attributes using a deep architecture that can adequately capture highly non-linear interactions. We demonstrate the efficacy of our model over existing state-of-the-art methods on a variety of real-world networks including collaboration networks, and social networks. We also observe that using edge attributes to inform network embedding yields better performance in downstream tasks such as link prediction and node classification."
Content to Node: Self-Translation Network Embedding,"Jie Liu, Zhicheng He, Lai Wei, YalouHuang",IEEE,"Network embedding, network representation learning, feature learning, content-rich network, sequence to sequence","This paper concerns the problem of network embedding (NE), which aims to learn low-dimensional representations for network nodes. Such dense representations offer great promises for many network analysis problems. However, existing approaches are still faced with challenges posed by the characteristics of complex real-world networks. First, for networks associated with rich content information, previous methods often learn separated content and structure representations, which requires post-processing of combination. Empirical combination strategies often make the final vectors suboptimal. Second, existing methods preserve the structure information by considering short and fixed neighborhood scope, such as the first- and/or the second-order proximities. However, it is hard to decide the neighborhood scope in complex problems. To this end, we propose a novel sequence to sequence model based NE framework referred to as Self-Translation Network Embedding (STNE). With the sampled node sequences, STNE translates each sequence itself from the content sequence to the node sequence. On the one hand, the bi-directional LSTM encoder fuses the content and structure information seamlessly from the raw input. On the other hand, high-order proximity can be flexibly learned with the memories of LSTM to capture long-range structural information. Experimental results on three real-world datasets demonstrate the superiority of STNE."
ICANE: interaction content-aware network embedding via co-embedding of nodes and edges,"Linchuan Xu, Xiaokai Wei, JiannongCao, Philip S. Yu",International Journal of Data Science and Analytics,,"Network embedding has been increasingly employed in network analysis as it can learn node representations that encode the network structure resulting from node interactions. In this paper, besides the network structure, the interaction content within which each interaction arises is also embedded because it reveals interaction preferences of the two nodes involved, and interaction preferences are essential characteristics that nodes expose in the network environment. Specifically, we propose interaction content aware network embedding (ICANE) via co-embedding of nodes and edges. The embedding of edges is to learn edge representations that preserve the interaction content. Then the interaction content can be incorporated into node representations through edge representations. Comprehensive evaluation demonstrates ICANE outperforms five recent network embedding models in applications including visualization, link prediction and classification."
Network Embedding with Deep Metric Learning,"Xiaotao Cheng, Lixin Ji, Ruiyang Huang,Ruifei Cui","The Institute of Electronics, Information and Communication Engineers","deep metric learning, network representation learning, likelihood label, anchor initialization, semi-supervised learning","Network embedding has attracted an increasing amount of attention in recent years due to its wide-ranging applications in graph mining tasks such as vertex classification, community detection, and network visualization. Network embedding is an important method to learn low-dimensional representations of vertices in networks, aiming to capture and preserve the network structure. Almost all the existing network embedding methods adopt the so-called Skip-gram model in Word2vec. However, as a bag-of-words model, the skip-gram model mainly utilized the local structure information. The lack of information metrics for vertices in global network leads to the mix of vertices with different labels in the new embedding space. To solve this problem, in this paper we propose a Network Representation Learning method with Deep Metric Learning, namely DML-NRL. By setting the initialized anchor vertices and adding the similarity measure in the training progress, the distance information between different labels of vertices in the network is integrated into the vertex representation, which improves the accuracy of network embedding algorithm effectively. We compare our method with baselines by applying them to the tasks of multi-label classification and data visualization of vertices. The experimental results show that our method outperforms the baselines in all three datasets, and the method has proved to be effective and robust."
On Exploring Semantic Meanings of Links for Embedding Social Networks,"Linchuan Xu, Xiaokai Wei, JiannongCao, Philip S. Yu",ACM,"Network embedding, social networks, data mining","There are increasing interests in learning low-dimensional and dense node representations from the network structure which is usually high-dimensional and sparse. However, most existing methods fail to consider semantic meanings of links. Different links may have different semantic meanings because the similarities between two nodes can be different, e.g., two nodes share common neighbors and two nodes share similar interests which are demonstrated in node-generated content. In this paper, the former type of links are referred to as structure-close links while the latter type are referred to as content-close links. These two types of links naturally indicate there are two types of characteristics that nodes expose in a social network. Hence, we propose to learn two representations for each node, and render each representation responsible for encoding the corresponding type of node characteristics, which is achieved by jointly embedding the network structure and inferring the type of each link. In the experiments, the proposed method is demonstrated to be more effective than five recent methods on four social networks through applications including visualization, link prediction and multi-label classification."
Incorporating label and attribute information for enhanced network representation learning,"Zhengming Liu, Hong Ma, Shuxin Liu,Xing Li",IEEE,"network representation learning, complex network, machine learning, deep learning","recently, network representation learning has shown its super performance in many network analysis tasks. Traditional network representation learning algorithms mainly mine unilateral network structure information. However, as we move to the age of big data, we can obtain rich auxiliary information from many real-world networks. In this paper, we propose an enhanced network representation learning algorithm by incorporating label and attribute Information. Inspired by natural language model, we propose two novel models: label enhanced attribute information representing model and label enhanced structure information representing model. Then, through parameter sharing strategy and jointly training based on a unified optimization objective function, we can obtain representations of nodes in network preserving network structure, attribute information and label information simultaneously. Experimental results demonstrate that representation vectors obtained by our model outperform state-of-art network representation learning methods on two real-world networks."
SaC2Vec: Information Network Representation with Structure and Content,"Sambaran Bandyopadhyay, Harsh Kara,Anirban Biswas, M. Narasimha Murty",arXiv,,"Network representation learning (also known as information network embedding) has been the central piece of research in social and information network analysis for the last couple of years. An information network can be viewed as a linked structure of a set of entities. A set of linked web pages and documents, a set of users in a social network are common examples of information network. Network embedding learns low dimensional representations of the nodes, which can further be used for downstream network mining applications such as community detection or node clustering. Information network representation techniques traditionally use only the link structure of the network. But in real world networks, nodes come with additional content such as textual descriptions or associated images. This content is semantically correlated with the network structure and hence using the content along with the topological structure of the network can facilitate the overall network representation. In this paper, we propose Sac2Vec, a network representation technique that exploits both the structure and content. We convert the network into a multi-layered graph and use random walk and language modeling technique to generate the embedding of the nodes. Our approach is simple and computationally fast, yet able to use the content as a complement to structure and vice-versa. We also generalize the approach for networks having multiple types of content in each node. Experimental evaluations on four real world publicly available datasets show the merit of our approach compared to state-of-the-art algorithms in the domain."
Evolutionarily Learning Multi-Aspect Interactions and Influences from Network Structure and Node Content,"Songlei Jian, Liang Hu, Longbing Cao,Kai Lu, Hang Gao",AAAI,,"The formation of a complex network is highly driven by multi-aspect node influences and interactions, reflected on network structures and the content embodied in network nodes. Limited work has jointly modeled all these aspects, which typically focuses on topological structures but overlooks the heterogeneous interactions behind node linkage and contributions of node content to the interactive heterogeneities. Here, we propose a multi-aspect interaction and influence-unified evolutionary coupled system (MAI-ECS) for network representation by involving node content and linkage-based network structure. MAI-ECS jointly and iteratively learns two systems: a multi-aspect interaction learning system to capture heterogeneous hidden interactions between nodes and an influence propagation system to capture multiaspect node influences and their propagation between nodes. MAI-ECS couples, unifies and optimizes the two systems toward an effective representation of explicit node content and network structure, and implicit node interactions and influences. MAI-ECS shows superior performance in node classification and link prediction in comparison with the stateof-the-art methods on two real-world datasets. Further, we demonstrate the semantic interpretability of the results generated by MAI-ECS."
Learning embeddings of a heterogeneous behavior network for potential behavior prediction,"Yue-yang Wang, Wei-hao Jiang,Shiliang Pu, Yueting Zhuang",Frontiers of Information Technology & Electronic Engineering,"Network embedding, Representation learning, Human behavior, Social networks, Heterogeneous information network, Attribute","Potential behavior prediction involves understanding the latent human behavior of specific groups, and can assist organizations in making strategic decisions. Progress in information technology has made it possible to acquire more and more data about human behavior. In this paper, we examine behavior data obtained in real world scenarios as an information network composed of two types of objects (humans and actions) associated with various attributes and three types of relationships (human-human, human-action, and action-action), which we call the heterogeneous behavior network (HBN). To exploit the abundance and heterogeneity of the HBN, we propose a novel network embedding method, human-action-attribute-aware heterogeneous network embedding (a4HNE), which jointly considers structural proximity, attribute resemblance, and heterogeneity fusion. Experiments on two real-world datasets show that this approach outperforms other similar methods on various heterogeneous information network mining tasks for potential behavior prediction."
MDAL: Multi-task Dual Attention LSTM Model for Semi-supervised Network Embedding,"Longcan Wu, Daling Wang, Shi Feng,Yifei Zhang, Ge Yu",Database Systems for Advanced Applications,"Dual attention, Network embedding, Multi-task learning","In recent years, both the academic and commercial communities have paid great attentions on embedding methods to analyze all kinds of network data. Despite of the great successes of DeepWalk and the following neural models, only a few of them have the ability to incorporate contents and labels into low-dimensional representation vectors of nodes. Besides, most network embedding methods only consider universal representations and the optimal representations could not be learned for specific tasks. In this paper, we propose a Multi-task Dual Attention LSTM model (dubbed as MDAL), which can capture structure, content, and label information of network and adjust representation vectors according to the concrete downstream task simultaneously. For the target node, MDAL leverages Tree-LSTM structure to extract structure, text and label information from its neighborhood. With the help of dual attention mechanism, the content related and label related neighbor nodes are emphasized during embedding. MDAL utilizes a multi-task learning framework that considering both network embedding and downstream tasks. The appropriate loss functions are proposed for task adaption and a joint optimization process is conducted for task-specific network embedding. We compare MDAL with the state-of-the-art and strong baselines for node classification, network visualization and link prediction tasks. Experimental results show the effectiveness and superiority of our proposed MDAL model."
Network Embedding via a Bi-Mode and Deep Neural Network Model,"Yang Fang, Xiang Zhao, Zhen Tan",MDPI,"Network Embedding, Neural Network, Relation Extraction","Network Embedding (NE) is an important method to learn the representations of network 9 via a low-dimensional space. Conventional NE models focus on capturing the structure information 10 and semantic information of vertices while neglecting such information for edges. In this work, we 11 propose a novel NE model named BimoNet to capture both the structure and semantic information 12 of edges. BimoNet is composed of two parts, i.e., the bi-mode embedding part and the deep neural 13 network part. For bi-mode embedding part, the first mode named add-mode is used to express the 14 entity-shared features of edges and the second mode named subtract-mode is employed to represent 15 the entity-specific features of edges. These features actually reflect the semantic information. For 16 deep neural network part, we firstly regard the edges in a network as nodes, and the vertices as links, 17 which will not change the overall structure of the whole network. Then we take the nodes’ adjacent 18 matrix as the input of the deep neural network as it can obtain similar representations for nodes 19 with similar structure. Afterwards, by jointly optimizing the objective function of these two parts, 20 BimoNet could preserve both the semantic and structure information of edges. In experiments, 21 we evaluate BimoNet on three real-world datasets and task of relation extraction, and BimoNet is 22 demonstrated to outperform state-of-the-art baseline models consistently and significantly"
Network Embedding Based on a Quasi-Local Similarity Measure,"Xin Liu, Natthawut Kertkeidkachorn,Tsuyoshi Murata, Kyoung-Sook Kim,Julien Leblay, Steven J. Lynden",PRICAI 2018: Trends in Artificial Intelligence,,"Network embedding based on the random walk and skipgram model such as the DeepWalk and Node2Vec algorithms have received wide attention. We identify that these algorithms essentially estimate the node similarities by random walk simulation, which is unreliable, inefficient, and inflexible. We propose to explicitly use node similarity measures instead of random walk simulation. Based on this strategy and a new proposed similarity measure, we present a fast and scalable algorithm AA+Emb. Experiments show that AA+Emb outperforms state-of-the-art network embedding algorithms on several commonly used benchmark networks."
HARP: Hierarchical Representation Learning for Networks,"Haochen Chen, Bryan Perozzi, Yifan Hu,Steven Skiena",arXiv,,"We present HARP, a novel method for learning low dimensional embeddings of a graph's nodes which preserves higher-order structural features. Our proposed method achieves this by compressing the input graph prior to embedding it, effectively avoiding troublesome embedding configurations (i.e. local minima) which can pose problems to non-convex optimization. HARP works by finding a smaller graph which approximates the global structure of its input. This simplified graph is used to learn a set of initial representations, which serve as good initializations for learning representations in the original, detailed graph. We inductively extend this idea, by decomposing a graph in a series of levels, and then embed the hierarchy of graphs from the coarsest one to the original graph. HARP is a general meta-strategy to improve all of the state-of-the-art neural algorithms for embedding graphs, including DeepWalk, LINE, and Node2vec. Indeed, we demonstrate that applying HARP's hierarchical paradigm yields improved implementations for all three of these methods, as evaluated on both classification tasks on real-world graphs such as DBLP, BlogCatalog, CiteSeer, and Arxiv, where we achieve a performance gain over the original implementations by up to 14% Macro F1."
Local and Global Information Preserved Network Embedding,"Yao Ma, Suhang Wang, Jiliang Tang",arXiv,,"Networks such as social networks, airplane networks, and citation networks are ubiquitous. The adjacency matrix is often adopted to represent a network, which is usually high dimensional and sparse. However, to apply advanced machine learning algorithms to network data, low-dimensional and continuous representations are desired. To achieve this goal, many network embedding methods have been proposed recently. The majority of existing methods facilitate the local information i.e. local connections between nodes, to learn the representations, while completely neglecting global information (or node status), which has been proven to boost numerous network mining tasks such as link prediction and social recommendation. Hence, it also has potential to advance network embedding. In this paper, we study the problem of preserving local and global information for network embedding. In particular, we introduce an approach to capture global information and propose a network embedding framework LOG, which can coherently model LOcal and Global information. Experimental results demonstrate the ability to preserve global information of the proposed framework. Further experiments are conducted to demonstrate the effectiveness of learned representations of the proposed framework."
NodeSketch: Highly-Efficient Graph Embeddings via Recursive Sketching,"Dingqi Yang, Paolo Rosso, Bin Li,Philippe Cudré-Mauroux",ACM,"Graph embedding, Recursive sketching, Data independent hashing","Embeddings have become a key paradigm to learn graph representations and facilitate downstream graph analysis tasks. Existing graph embedding techniques either sample a large number of node pairs from a graph to learn node embeddings via stochastic optimization, or factorize a high-order proximity/adjacency matrix of the graph via expensive matrix factorization. However, these techniques usually require significant computational resources for the learning process, which hinders their applications on largescale graphs. Moreover, the cosine similarity preserved by these techniques shows suboptimal efficiency in downstream graph analysis tasks, compared to Hamming similarity, for example. To address these issues, we propose NodeSketch, a highly-efficient graph embedding technique preserving high-order node proximity via recursive sketching. Specifically, built on top of an efficient dataindependent hashing/sketching technique, NodeSketch generates node embeddings in Hamming space. For an input graph, it starts by sketching the self-loop-augmented adjacency matrix of the graph to output low-order node embeddings, and then recursively generates k-order node embeddings based on the self-loop-augmented adjacency matrix and (k-1)-order node embeddings. Our extensive evaluation compares NodeSketch against a sizable collection of state-of-the-art techniques using five real-world graphs on two graph analysis tasks. The results show that NodeSketch achieves state-of-the-art performance compared to these techniques, while showing significant speedup of 9x-372x in the embedding learning process and 1.19x-1.68x speedup when performing downstream graph analysis tasks."
"Fast, Warped Graph Embedding: Unifying Framework and One-Click Algorithm","Siheng Chen, Sufeng Niu, LemanAkoglu, Jelena Kovacevic, ChristosFaloutsos",arXiv,"Representation learning, graph embedding, random walk","What is the best way to describe a user in a social network with just a few numbers? Mathematically, this is equivalent to assigning a vector representation to each node in a graph, a process called graph embedding. We propose a novel framework, GEM-D that unifies most of the past algorithms such as LapEigs, DeepWalk and node2vec. GEM-D achieves its goal by decomposing any graph embedding algorithm into three building blocks: node proximity function, warping function and loss function. Based on thorough analysis of GEM-D, we propose a novel algorithm, called UltimateWalk, which outperforms the most-recently proposed state-of-the-art DeepWalk and node2vec. The contributions of this work are: (1) The proposed framework, GEM-D unifies the past graph embedding algorithms and provides a general recipe of how to design a graph embedding; (2) the nonlinearlity in the warping function contributes significantly to the quality of embedding and the exponential function is empirically optimal; (3) the proposed algorithm, UltimateWalk is one-click (no user-defined parameters), scalable and has a closed-form solution."
STwalk: learning trajectory representations in temporal graphs,"Supriya Pandhre, Himangi Mittal,Manish Gupta, Vineeth N.Balasubramanian",arXiv,"Representation Learning, Deep Learning, Temporal Graph Analysis","Analyzing the temporal behavior of nodes in time-varying graphs is useful for many applications such as targeted advertising, community evolution and outlier detection. In this paper, we present a novel approach, STWalk, for learning trajectory representations of nodes in temporal graphs. The proposed framework makes use of structural properties of graphs at current and previous time-steps to learn effective node trajectory representations. STWalk performs random walks on a graph at a given time step (called space-walk) as well as on graphs from past time-steps (called time-walk) to capture the spatio-temporal behavior of nodes. We propose two variants of STWalk to learn trajectory representations. In one algorithm, we perform space-walk and time-walk as part of a single step. In the other variant, we perform space-walk and time-walk separately and combine the learned representations to get the final trajectory embedding. Extensive experiments on three real-world temporal graph datasets validate the effectiveness of the learned representations when compared to three baseline methods. We also show the goodness of the learned trajectory embeddings for change point detection, as well as demonstrate that arithmetic operations on these trajectory representations yield interesting and interpretable results."
Learning Graph Embeddings from WordNet-based Similarity Measures,"Andrey Kutuzov, Alexander Panchenko,Sarah Kohail, Mohammad Dorgham,Oleksiy Oliynyk, Christian Biemann",ACL,,"We present path2vec, a new approach for learning graph embeddings that relies on structural measures of pairwise node similarities. The model learns representations for nodes in a dense space that approximate a given userdefined graph distance measure, such as e.g. the shortest path distance or distance measures that take information beyond the graph structure into account. Evaluation of the proposed model on semantic similarity and word sense disambiguation tasks, using various WordNetbased similarity measures, show that our approach yields competitive results, outperforming strong graph embedding baselines. The model is computationally efficient, being orders of magnitude faster than the direct computation of graph-based distances."
Multi-Relational Classification via Bayesian Ranked Non-Linear Embeddings,"Ahmed Rashed, Josif Grabocka, LarsSchmidt-Thieme",ACM,"Multi-Relational Classification, Multi-Relational Learning, Documents Classification, Network Representation","The task of classifying multi-relational data spans a wide range of domains such as document classification in citation networks, classification of emails, and protein labeling in proteins interaction graphs. Current state-of-the-art classification models rely on learning per-entity latent representations by mining the whole structure of the relations’ graph, however, they still face two major problems. Firstly, it is very challenging to generate expressive latent representations in sparse multi-relational settings with implicit feedback relations as there is very little information per-entity. Secondly, for entities with structured properties such as titles and abstracts (text) in documents, models have to be modified ad-hoc. In this paper, we aim to overcome these two main drawbacks by proposing a flexible nonlinear latent embedding model (BRNLE) for the classification of multi-relational data. The proposed model can be applied to entities with structured properties such as text by utilizing the numerical vector representations of those properties. To address the sparsity problem of implicit feedback relations, the model is optimized via a sparsely-regularized multi-relational pair-wise Bayesian personalized ranking loss (BPR). Experiments on four different real-world datasets show that the proposed model significantly outperforms state-of-the-art models for multi-relational classification."
CANE: Context-Aware Network Embedding for Relation Modeling,"Cunchao Tu, Han Liu, Zhiyuan Liu,Maosong Sun",ACL,,"Network embedding (NE) is playing a critical role in network analysis, due to its ability to represent vertices with efficient low-dimensional embedding vectors. However, existing NE models aim to learn a fixed context-free embedding for each vertex and neglect the diverse roles when interacting with other vertices. In this paper, we assume that one vertex usually shows different aspects when interacting with different neighbor vertices, and should own different embeddings respectively. Therefore, we present ContextAware Network Embedding (CANE), a novel NE model to address this issue. CANE learns context-aware embeddings for vertices with mutual attention mechanism and is expected to model the semantic relationships between vertices more precisely. In experiments, we compare our model with existing NE models on three real-world datasets. Experimental results show that CANE achieves significant improvement than state-of-the-art methods on link prediction and comparable performance on vertex classification."
Supervised Q-walk for Learning Vector Representation of Nodes in Networks,"Naimish Agarwal, Gora Chand Nandi",arXiv,,"Automatic feature learning algorithms are at the forefront of modern day machine learning research. We present a novel algorithm, supervised Q-walk, which applies Q-learning to generate random walks on graphs such that the walks prove to be useful for learning node features suitable for tackling with the node classification problem. We present another novel algorithm, k-hops neighborhood based confidence values learner, which learns confidence values of labels for unlabelled nodes in the network without first learning the node embedding. These confidence values aid in learning an apt reward function for Q-learning. We demonstrate the efficacy of supervised Q-walk approach over existing state-of-the-art random walk based node embedding learners in solving the single / multi-label multi-class node classification problem using several real world datasets. Summarising, our approach represents a novel state-of-the-art technique to learn features, for nodes in networks, tailor-made for dealing with the node classification problem.
"
Graph Embedding Based Hybrid Social Recommendation System,"Vishwas Sathish, Tanya Mehrotra,Simran Dhinwa, Bhaskarjyoti Das",arXiv,"Graph Embedding, Social networks, Recommendation System, Social graph, Spectral Clustering, hybrid models","Item recommendation tasks are a widely studied topic. Recent developments in deep learning and spectral methods paved a path towards efficient graph embedding techniques. But little research has been done on applying these graph embedding to social graphs for recommendation tasks. This paper focuses at performance of various embedding methods applied on social graphs for the task of item recommendation. Additionally, a hybrid model is proposed wherein chosen embedding models are combined together to give a collective output. We put forward the hypothesis that such a hybrid model would perform better than individual embedding for recommendation task. With recommendation using individual embedding as a baseline, performance for hybrid model for the same task is evaluated and compared. Standard metrics are used for qualitative comparison. It is found that the proposed hybrid model outperforms the baseline."
Towards Machine Learning Enabled Automatic Design of IT-Network Architectures,LOVA WÅHLIN,KTH ROYAL INSTITUTE OF TECHNOLOGY,"IT-Architecture graph, Node Embedding, Graph Embedding, Reinforcement Learning, Machine Learning","There are many machine learning techniques that cannot be performed on graph-data. Techniques such as graph embedding, i.e mapping a graph to a vector, can open up a variety of machine learning solutions. This thesis addresses to what extent static graph embedding techniques can capture important characteristics of an IT-architecture graph, with the purpose of embedding the graphs in a common euclidean vector space that can serve as the state space in a reinforcement learning setup. The metric used for evaluating the performance of the embedding is the security of the graph, i.e the time it would take for an unauthorized attacker to penetrate the ITarchitecture graph. The algorithms evaluated in this work are the node embedding methods node2vec and gat2vec and the graph embedding method graph2vec. The predictive results of the embeddings are compared with two baseline methods. The results of each of the algorithms mostly display a significant predictive performance improvement compared to the baseline, where the F1 score in some cases is doubled. Indeed, the results indicate that static graph embedding methods can in fact capture some information about the security of an ITarchitecture. However, no conclusion can be made whether a static graph embedding is actually the best contender for posing as the state space in a reinforcement learning framework. To make a certain conclusion other options has to be researched, such as dynamic graph embedding methods."
Arbitrary-Order Proximity Preserved Network Embedding,"Ziwei Zhang, Peng Cui, Xiao Wang, JianPei, Xuanrong Yao, Wenwu Zhu",ACM,"Network Embedding, Arbitrary-Order Proximity, Network Representation Learning","Network embedding has received increasing research attention in recent years. The existing methods show that the high-order proximity plays a key role in capturing the underlying structure of the network. However, two fundamental problems in preserving the high-order proximity remain unsolved. First, all the existing methods can only preserve fixed-order proximities, despite that proximities of different orders are often desired for distinct networks and target applications. Second, given a certain order proximity, the existing methods cannot guarantee accuracy and efficiency simultaneously. To address these challenges, we propose AROPE (arbitrary-order proximity preserved embedding), a novel network embedding method based on SVD framework. We theoretically prove the eigen-decomposition reweighting theorem, revealing the intrinsic relationship between proximities of different orders. With this theorem, we propose a scalable eigen-decomposition solution to derive the embedding vectors and shift them between proximities of arbitrary orders. Theoretical analysis is provided to guarantee that i) our method has a low marginal cost in shifting the embedding vectors across different orders, ii) given a certain order, our method can get the global optimal solutions, and iii) the overall time complexity of our method is linear with respect to network size. Extensive experimental results on several large-scale networks demonstrate that our proposed method greatly and consistently outperforms the baselines in various tasks including network reconstruction, link prediction and node classification."
Billion-Scale Network Embedding with Iterative Random Projection,"Ziwei Zhang, Peng Cui, Haoyang Li,Xiao Wang, Wenwu Zhu",arXiv,"Network Embedding, High-order Proximity, Billion-Scale, Dynamic Networks, Distributed Computing","Network embedding, which learns low-dimensional vector representation for nodes in the network, has attracted considerable research attention recently. However, the existing methods are incapable of handling billion-scale networks, because they are computationally expensive and, at the same time, difficult to be accelerated by distributed computing schemes. To address these problems, we propose RandNE (Iterative Random Projection Network Embedding), a novel and simple billion-scale network embedding method. Specifically, we propose a Gaussian random projection approach to map the network into a low-dimensional embedding space while preserving the high-order proximities between nodes. To reduce the time complexity, we design an iterative projection procedure to avoid the explicit calculation of the high-order proximities. Theoretical analysis shows that our method is extremely efficient, and friendly to distributed computing schemes without any communication cost in the calculation. We also design a dynamic updating procedure which can efficiently incorporate the dynamic changes of the networks without error aggregation. Extensive experimental results demonstrate the efficiency and efficacy of RandNE over state-of-the-art methods in several tasks including network reconstruction, link prediction and node classification on multiple datasets with different scales, ranging from thousands to billions of nodes and edges."
"Network Embedding as Matrix Factorization: Unifying DeepWalk, LINE,PTE, and node2vec","Jiezhong Qiu, Yuxiao Dong, Hao Ma,Jian Li, Kuansan Wang, Jie Tang",arXiv,,"Since the invention of word2vec, the skip-gram model has significantly advanced the research of network embedding, such as the recent emergence of the DeepWalk, LINE, PTE, and node2vec approaches. In this work, we show that all of the aforementioned models with negative sampling can be unified into the matrix factorization framework with closed forms. Our analysis and proofs reveal that: (1) DeepWalk empirically produces a low-rank transformation of a network's normalized Laplacian matrix; (2) LINE, in theory, is a special case of DeepWalk when the size of vertices' context is set to one; (3) As an extension of LINE, PTE can be viewed as the joint factorization of multiple networks' Laplacians; (4) node2vec is factorizing a matrix related to the stationary distribution and transition probability tensor of a 2nd-order random walk. We further provide the theoretical connections between skip-gram based network embedding algorithms and the theory of graph Laplacian. Finally, we present the NetMF method as well as its approximation algorithm for computing network embedding. Our method offers significant improvements over DeepWalk and LINE for conventional network mining tasks. This work lays the theoretical foundation for skip-gram based network embedding methods, leading to a better understanding of latent network representation learning."
VERSE: Versatile Graph Embeddings from Similarity Measures,"Anton Tsitsulin, Davide Mottin,Panagiotis Karras, Emmanuel Müller",arXiv,,"Embedding a web-scale information network into a low-dimensional vector space facilitates tasks such as link prediction, classification, and visualization. Past research has addressed the problem of extracting such embeddings by adopting methods from words to graphs, without defining a clearly comprehensible graph-related objective. Yet, as we show, the objectives used in past works implicitly utilize similarity measures among graph nodes. In this paper, we carry the similarity orientation of previous works to its logical conclusion; we propose VERtex Similarity Embeddings (VERSE), a simple, versatile, and memory-efficient method that derives graph embeddings explicitly calibrated to preserve the distributions of a selected vertex-to-vertex similarity measure. VERSE learns such embeddings by training a single-layer neural network. While its default, scalable version does so via sampling similarity information, we also develop a variant using the full information per vertex. Our experimental study on standard benchmarks and real-world datasets demonstrates that VERSE, instantiated with diverse similarity measures, outperforms state-of-the-art methods in terms of precision and recall in major data mining tasks and supersedes them in time and space efficiency, while the scalable sampling-based variant achieves equally good results as the non-scalable full variant."
Density-aware Local Siamese Autoencoder Network Embedding with Autoencoder Graph Clustering,"Yang Zhou, Amnay Amimeur, ChaoJiang, Dejing Dou, Ruoming Jin,Pengwei Wang",IEEE,"Data sparsity, skewed graph distribution, density-aware network embedding, autoencoder graph clustering, local Siamese network embedding","Network embedding aims to learn latent low dimensional representation of vertices in graphs while preserving the intrinsic characteristics of graph data. In this paper, we propose a density-aware local autoencoder embedding architecture, DALSAE, with three features. First, we develop a flexible densityaware local deep autoencoder embedding method to perform local embedding on each of K clustering-based subgraphs with the optimization at both vertex and subgraph levels, in response to imbalanced density-based local characteristics of vertices and subgraphs. We design K local autoencoder embedding models, each with individual parameters and structure, to jointly train K subgraphs and optimize the loss functions within and across clusters. Second, we design an autoencoder graph clustering method to optimize local embedding and graph clustering simultaneously and capture local, clustering, and global network structure in the learning process. Third but last, a density-aware local Siamese autoencoder embedding approach can be utilized to train multiple clustering-based subgraphs with similar local characteristics on the common Siamese networks, to save the memory consumption of multiple local embedding models as well as maintain the similar embedding features."
Network Representation Learning: Consolidation and Renewed Bearing,"Saket Gurukar, Priyesh Vijayan, AakashSrinivasan, Goonmeet Bajaj, Chen Cai,Moniba Keymanesh, Saravana Kumar,Pranav Maneriker, Anasua Mitra,Vedang Patel, Balaraman Ravindran,Srinivasan Parthasarathy",arXiv,,"Graphs are a natural abstraction for many problems where nodes represent entities and edges represent a relationship across entities. An important area of research that has emerged over the last decade is the use of graphs as a vehicle for non-linear dimensionality reduction in a manner akin to previous efforts based on manifold learning with uses for downstream database processing, machine learning and visualization. In this systematic yet comprehensive experimental survey, we benchmark several popular network representation learning methods operating on two key tasks: link prediction and node classification. We examine the performance of 12 unsupervised embedding methods on 15 datasets. To the best of our knowledge, the scale of our study -- both in terms of the number of methods and number of datasets -- is the largest to date. Our results reveal several key insights about work-to-date in this space. First, we find that certain baseline methods (task-specific heuristics, as well as classic manifold methods) that have often been dismissed or are not considered by previous efforts can compete on certain types of datasets if they are tuned appropriately. Second, we find that recent methods based on matrix factorization offer a small but relatively consistent advantage over alternative methods (e.g., random-walk based methods) from a qualitative standpoint. Specifically, we find that MNMF, a community preserving embedding method, is the most competitive method for the link prediction task. While NetMF is the most competitive baseline for node classification. Third, no single method completely outperforms other embedding methods on both node classification and link prediction tasks. We also present several drill-down analysis that reveals settings under which certain algorithms perform well (e.g., the role of neighborhood context on performance) -- guiding the end-user."
Homogeneous network embedding formassive graphs via reweighted personalized PageRank,"Renchi Yang, Jieming Shi, Xiaokui Xiao,Sourav S. Bhowmick, Yin Yang",arXiv,,"Given an input graph G and a node v in G, homogeneous network embedding (HNE) maps the graph structure in the vicinity of v to a compact, fixed-dimensional feature vector. This paper focuses on HNE for massive graphs, e.g., with billions of edges. On this scale, most existing approaches fail, as they incur either prohibitively high costs, or severely compromised result utility. Our proposed solution, called Node-Reweighted PageRank (NRP), is based on a classic idea of deriving embedding vectors from pairwise personalized PageRank (PPR) values. Our contributions are twofold: first, we design a simple and efficient baseline HNE method based on PPR that is capable of handling billion-edge graphs on commodity hardware; second and more importantly, we identify an inherent drawback of vanilla PPR, and address it in our main proposal NRP. Specifically, PPR was designed for a very different purpose, i.e., ranking nodes in G based on their relative importance from a source node's perspective. In contrast, HNE aims to build node embeddings considering the whole graph. Consequently, node embeddings derived directly from PPR are of suboptimal utility. The proposed NRP approach overcomes the above deficiency through an effective and efficient node reweighting algorithm, which augments PPR values with node degree information, and iteratively adjusts embedding vectors accordingly. Overall, NRP takes O(mlogn) time and O(m) space to compute all node embeddings for a graph with m edges and n nodes. Our extensive experiments that compare NRP against 18 existing solutions over 7 real graphs demonstrate that NRP achieves higher result utility than all the solutions for link prediction, graph reconstruction and node classification, while being up to orders of magnitude faster. In particular, on a billion-edge Twitter graph, NRP terminates within 4 hours, using a single CPU core."
Tutorial on NLP-Inspired Network Embedding,Boaz Shmueli,arXiv,,"This tutorial covers a few recent papers in the field of network embedding. Network embedding is a collective term for techniques for mapping graph nodes to vectors of real numbers in a multidimensional space. To be useful, a good embedding should preserve the structure of the graph. The vectors can then be used as input to various network and graph analysis tasks, such as link prediction. The papers discussed develop methods for the online learning of such embeddings, and include DeepWalk, LINE, node2vec, struc2vec and megapath2vec. These new methods and developments in online learning of network embeddings have major applications for the analysis of graphs and networks, including online social networks."
Adversarial Network Embedding,"Quanyu Dai, Qiang Li, Jian Tang, DanWang",arXiv,,"Learning low-dimensional representations of networks has proved effective in a variety of tasks such as node classification, link prediction and network visualization. Existing methods can effectively encode different structural properties into the representations, such as neighborhood connectivity patterns, global structural role similarities and other high-order proximities. However, except for objectives to capture network structural properties, most of them suffer from lack of additional constraints for enhancing the robustness of representations. In this paper, we aim to exploit the strengths of generative adversarial networks in capturing latent features, and investigate its contribution in learning stable and robust graph representations. Specifically, we propose an Adversarial Network Embedding (ANE) framework, which leverages the adversarial learning principle to regularize the representation learning. It consists of two components, i.e., a structure preserving component and an adversarial learning component. The former component aims to capture network structural properties, while the latter contributes to learning robust representations by matching the posterior distribution of the latent representations to given priors. As shown by the empirical results, our method is competitive with or superior to state-of-the-art approaches on benchmark network embedding tasks."
Adversarial Representation Learning on Large-Scale Bipartite Graphs,"Chaoyang He, Tian Xie, Yu Rong,Wenbing Huang, Junzhou Huang, XiangRen, Cyrus Shahabi",arXiv,,"Graph representation on large-scale bipartite graphs is central for a variety of applications, ranging from social network analysis to recommendation system development. Existing methods exhibit two key drawbacks: 1. unable to characterize the inconsistency of the node features within the bipartite-specific structure; 2. unfriendly to support large-scale bipartite graphs. To this end, we propose ABCGraph, a scalable model for unsupervised learning on large-scale bipartite graphs. At its heart, ABCGraph utilizes the proposed Bipartite Graph Convolutional Network (BGCN) as the encoder and adversarial learning as the training loss to learn representations from nodes in two different domains and bipartite structures, in an unsupervised manner. Moreover, we devise a cascaded architecture to capture the multi-hop relationship in bipartite structure and improves the scalability as well. Extensive experiments on multiple datasets of varying scales verify the effectiveness of ABCGraph compared to state-of-the-arts. For the experiment on a real-world large-scale bipartite graph system, fast training speed and low memory cost demonstrate the scalability of ABCGraph model."
Graph-based Semi-supervised Classification with CRF and RNN,"Zhili Ye, Yang Du, Fengge Wu",IEEE,,"Given a partially labeled graph, the semi-supervised problem of node classification is to infer the unknown labels of the unlabeled nodes. We intend to train graph-based classifiers end-to-end based on graph embedding. From the perspective of classification and feature embedding, we present two novel neural network architectures respectively for semi-supervised node classification. Motivated by pixel-level labeling tasks, we introduce Conditional Random Fields (CRFs) to smooth the classification results of Graph Convolutional Network (GCN). By formulating mean-field approximate inference for CRFs as Recurrent Neural Networks, we develop a deep end-to-end network called GCN-CRF, trained with the usual backpropagation algorithm. Moreover, in order to capture k-step relational information, we present Graph Gated Recurrent Units (Graph-GRU), implementing GRU to graph-structured data as a feed-forward process with k hidden layers. Experiments on three benchmark citation network datasets demonstrate that our two approaches outperform several recently proposed methods."
Heterogeneous Hyper-Network Embedding,"Inci M. Baytas, Cao Xiao, Fei Wang, AnilK. Jain, Jiayu Zhou",IEEE,"Heterogeneous hypergraph, network embedding, similarity learning","Heterogeneous hyper-networks is used to represent multi-modal and composite interactions between data points. In such networks, several different types of nodes form a hyperedge. Heterogeneous hyper-network embedding learns a distributed node representation under such complex interactions while preserving the network structure. However, this is a challenging task due to the multiple modalities and composite interactions. In this study, a deep approach is proposed to embed heterogeneous attributed hyper-networks with complicated and non-linear node relationships. In particular, a fully-connected and graph convolutional layers are designed to project different types of nodes into a common low-dimensional space, a tuple-wise similarity function is proposed to preserve the network structure, and a ranking based loss function is used to improve the similarity scores of hyperedges in the embedding space. The proposed approach is evaluated on synthetic and real world datasets and a better performance is obtained compared with baselines."
Representation Learning on Graphs: Methods and Applications,"William L. Hamilton, Rex Ying, JureLeskovec",arXiv,,"Machine learning on graphs is an important and ubiquitous task with applications ranging from drug design to friendship recommendation in social networks. The primary challenge in this domain is finding a way to represent, or encode, graph structure so that it can be easily exploited by machine learning models. Traditionally, machine learning approaches relied on user-defined heuristics to extract features encoding structural information about a graph (e.g., degree statistics or kernel functions). However, recent years have seen a surge in approaches that automatically learn to encode graph structure into low-dimensional embeddings, using techniques based on deep learning and nonlinear dimensionality reduction. Here we provide a conceptual review of key advancements in this area of representation learning on graphs, including matrix factorization-based methods, random-walk based algorithms, and graph neural networks. We review methods to embed individual nodes as well as approaches to embed entire (sub)graphs. In doing so, we develop a unified framework to describe these recent approaches, and we highlight a number of important applications and directions for future work."
Keep It Simple: Graph Autoencoders Without Graph Convolutional Networks,"Guillaume Salha, Romain Hennequin,Michalis Vazirgiannis",arXiv,,"Graph autoencoders (AE) and variational autoencoders (VAE) recently emerged as powerful node embedding methods, with promising performances on challenging tasks such as link prediction and node clustering. Graph AE, VAE and most of their extensions rely on graph convolutional networks (GCN) to learn vector space representations of nodes. In this paper, we propose to replace the GCN encoder by a simple linear model w.r.t. the adjacency matrix of the graph. For the two aforementioned tasks, we empirically show that this approach consistently reaches competitive performances w.r.t. GCN-based models for numerous realworld graphs, including the widely used Cora, Citeseer and Pubmed citation networks that became the de facto benchmark datasets for evaluating graph AE and VAE. This result questions the relevance of repeatedly using these three datasets to compare complex graph AE and VAE models. It also emphasizes the effectiveness of simple node encoding schemes for many real-world applications."
dynnode2vec: Scalable Dynamic Network Embedding,"Sedigheh Mahdavi, Shima Khoshraftar,Aijun An",arXiv,,"Network representation learning in low dimensional vector space has attracted considerable attention in both academic and industrial domains. Most real-world networks are dynamic with addition/deletion of nodes and edges. The existing graph embedding methods are designed for static networks and they cannot capture evolving patterns in a large dynamic network. In this paper, we propose a dynamic embedding method, dynnode2vec, based on the well-known graph embedding method node2vec. Node2vec is a random walk based embedding method for static networks. Applying static network embedding in dynamic settings has two crucial problems: 1) Generating random walks for every time step is time consuming 2) Embedding vector spaces in each timestamp are different. In order to tackle these challenges, dynnode2vec uses evolving random walks and initializes the current graph embedding with previous embedding vectors. We demonstrate the advantages of the proposed dynamic network embedding by conducting empirical evaluations on several large dynamic network datasets."
Temporal Graph Offset Reconstruction: Towards Temporally Robust Graph Representation Learning,"Stephen Bonner, John Brennan, IbadKureshi, Georgios Theodoropoulos, A.Stephen McGough, Boguslaw Obara",arXiv,"graph representation learning, dynamic graphs","Graphs are a commonly used construct for representing relationships between elements in complex high dimensional datasets. Many real-world phenomenon are dynamic in nature, meaning that any graph used to represent them is inherently temporal. However, many of the machine learning models designed to capture knowledge about the structure of these graphs ignore this rich temporal information when creating representations of the graph. This results in models which do not perform well when used to make predictions about the future state of the graph -- especially when the delta between time stamps is not small. In this work, we explore a novel training procedure and an associated unsupervised model which creates graph representations optimised to predict the future state of the graph. We make use of graph convolutional neural networks to encode the graph into a latent representation, which we then use to train our temporal offset reconstruction method, inspired by auto-encoders, to predict a later time point -- multiple time steps into the future. Using our method, we demonstrate superior performance for the task of future link prediction compared with none-temporal state-of-the-art baselines. We show our approach to be capable of outperforming non-temporal baselines by 38% on a real world dataset."
Adversarially Regularized Graph Autoencoder for Graph Embedding,"Shirui Pan, Ruiqi Hu, Guodong Long,Jing Jiang, Lina Yao, Chengqi Zhang",IJCAI,,"Graph embedding is an effective method to represent graph data in a low dimensional space for graph analytics. Most existing embedding algorithms typically focus on preserving the topological structure or minimizing the reconstruction errors of graph data, but they have mostly ignored the data distribution of the latent codes from the graphs, which often results in inferior embedding in realworld graph data. In this paper, we propose a novel adversarial graph embedding framework for graph data. The framework encodes the topological structure and node content in a graph to a compact representation, on which a decoder is trained to reconstruct the graph structure. Furthermore, the latent representation is enforced to match a prior distribution via an adversarial training scheme. To learn a robust embedding, two variants of adversarial approaches, adversarially regularized graph autoencoder (ARGA) and adversarially regularized variational graph autoencoder (ARVGA), are developed. Experimental studies on real-world graphs validate our design and demonstrate that our algorithms outperform baselines by a wide margin in link prediction, graph clustering, and graph visualization tasks."
Event2vec: Heterogeneous Hypergraph Embedding for Event Data,"Yunfei Chu, Chunyan Feng, Caili Guo,Yaqing Wang, Jenq-Neng Hwang",IEEE,"network embedding, hypergraph, graph representation learning I","Network embedding learns low-dimensional representations of nodes with the goal of preserving the original network structure. However, most existing embedding methods lack the ability to handle event data, which are ubiquitous in the real world, due to the following three challenges: (1) participating objects in an event are often of different types, which limit the feasibility of using homogeneous network embedding methods; (2) relations among nodes in each event are much more complicated, i.e., more than two objects are involved in one event, thus it is far from enough to only preserve pairwise proximity; (3) there may exist relevance among different events, which has effects on the representations. In this paper, we model event data as a heterogeneous hypergraph, where participating objects in one event are represented as a hyperedge, and propose a novel embedding framework, namely event2vec, for learning effective representations of objects by preserving both the intra-event proximity and inter-event proximity. Extensive experiments on large-scale real-world datasets demonstrate that the representations learned by event2vec can outperform state-of-the-art methods."
Simple and Effective Graph Autoencoders with One-Hop Linear Models,"Guillaume Salha, Romain Hennequin,Michalis Vazirgiannis",arXiv,"Graphs, Autoencoders, Variational Autoencoders, Graph Convolutional Networks, Linear Encoders, Graph Representation Learning, Node Embedding, Link Prediction, Node Clustering","Over the last few years, graph autoencoders (AE) and variational autoencoders (VAE) emerged as powerful node embedding methods, with promising performances on challenging tasks such as link prediction and node clustering. Graph AE, VAE and most of their extensions rely on multi-layer graph convolutional networks (GCN) encoders to learn vector space representations of nodes. In this paper, we show that GCN encoders are actually unnecessarily complex for many applications. We propose to replace them by significantly simpler and more interpretable linear models w.r.t. the direct neighborhood (one-hop) adjacency matrix of the graph, involving fewer operations, fewer parameters and no activation function. For the two aforementioned tasks, we show that this simpler approach consistently reaches competitive performances w.r.t. GCN-based graph AE and VAE for numerous real-world graphs, including all benchmark datasets commonly used to evaluate graph AE and VAE. Based on these results, we also question the relevance of repeatedly using these datasets to compare complex graph AE and VAE."
Inductive Representation Learning on Large Graphs,"William L. Hamilton, Zhitao Ying, JureLeskovec",arXiv,,"Low-dimensional embeddings of nodes in large graphs have proved extremely useful in a variety of prediction tasks, from content recommendation to identifying protein functions. However, most existing approaches require that all nodes in the graph are present during training of the embeddings; these previous approaches are inherently transductive and do not naturally generalize to unseen nodes. Here we present GraphSAGE, a general, inductive framework that leverages node feature information (e.g., text attributes) to efficiently generate node embeddings for previously unseen data. Instead of training individual embeddings for each node, we learn a function that generates embeddings by sampling and aggregating features from a node's local neighborhood. Our algorithm outperforms strong baselines on three inductive node-classification benchmarks: we classify the category of unseen nodes in evolving information graphs based on citation and Reddit post data, and we show that our algorithm generalizes to completely unseen graphs using a multi-graph dataset of protein-protein interactions."
TemporalNode2vec: Temporal Node Embedding in Temporal Networks,"Mounir Haddad, Cécile Bothorel,Philippe Lenca, Dominique Bedart",Complex Networks and Their Applications VIII,"Dynamic network embeddings, Graph representation learning, Latent representations ","The goal of graph embedding is to learn a representation of graphs vertices in a latent low-dimensional space in order to encode the structural information that lies in graphs. While real-world networks evolve over time, the majority of research focuses on static networks, ignoring local and global evolution patterns. A simplistic approach consists of learning nodes embeddings independently for each time step. This can cause unstable and inefficient representations over time. We present a novel dynamic graph embedding approach that learns continuous time-aware node representations. Overall, we demonstrate that our method improves node classification tasks comparing to previous static and dynamic approaches as it achieves up to 14% gain regarding to the F1 score metric. We also prove that our model is more data-efficient than several baseline methods, as it affords to achieve good performances with a limited number of vertex representation features."
Unsupervised Graph Representation Learning With Variable Heat Kernel,"Yongjun Jing, Hao Wang, Kun Shao,Xing Huo, Yangyang Zhang",IEEE,"Graph representation learning, variable heat kernel, heat diffusion, node classification, link prediction","Graph representation learning aims to learn a low-dimension latent representation of nodes, and the learned representation is used for downstream graph analysis tasks. However, most of the existing graph embedding models focus on how to aggregate all the neighborhood node features to encode the semantic information into the representation and neglect the global structural features of the node such as community structure and centrality. In the paper, we propose a novel unsupervised graph representation learning method (VHKRep), where a variable heat kernel is designed to better capture implicit global features via heat diffusion with the different time scale and generate the robust node representation. We conduct extensive experiment on three real-world datasets for node classification and link prediction tasks. Compared with the state-of-the-art seven models, the experimental results demonstrate the effectiveness of our proposed method on both node classification and link prediction tasks."
COSINE: Compressive Network Embedding on Large-scale Information Networks,"Zhengyan Zhang, Cheng Yang, ZhiyuanLiu, Maosong Sun, Zhichong Fang, BoZhang, Leyu Lin",arXiv,"Vertex Classification, Link Prediction, Large-scale Real-world Network, Network Embedding, Model Compression","There is recently a surge in approaches that learn low-dimensional embeddings of nodes in networks. As there are many large-scale real-world networks, it’s inefficient for existing approaches to store amounts of parameters in memory and update them edge after edge. With the knowledge that nodes having similar neighborhood will be close to each other in embedding space, we propose COSINE (COmpresSIve NE) algorithm which reduces the memory footprint and accelerates the training process by parameters sharing among similar nodes. COSINE applies graph partitioning algorithms to networks and builds parameter sharing dependency of nodes based on the result of partitioning. With parameters sharing among similar nodes, COSINE injects prior knowledge about higher structural information into training process which makes network embedding more efficient and effective. COSINE can be applied to any embedding lookup method and learn high-quality embeddings with limited memory and shorter training time. We conduct experiments of multi-label classification and link prediction, where baselines and our model have the same memory usage. Experimental results show that COSINE gives baselines up to 23% increase on classification and up to 25% increase on link prediction. Moreover, time of all representation learning methods using COSINE decreases from 30% to 70%."
Multimodality Fusion for Node Classification in D2D Communications,"Zufan Zhang, X. Rong Li, Chenquan Gan",IEEE,"D2D communications, node classification, multimodality fusion, network embedding, attribute information.","With the rapid development of 5G technology, D2D communications will be widely used in content distribution scenarios. An important prerequisite for realizing data transmission in D2D scenarios is to correctly classify each node in the network. However, most of existing node classification methods need huge computational overhead in large-scale networks. Inspired by network structure and attribute information, a multimodality fusion-based node classification scheme is proposed to obtain the tradeoff between classification accuracy and costs. First, in order to summarize label dependences to perform node classification, structure and information features are constructed. Structure features are obtained by embedding network data into a low-dimensional representation space, and information features are extracted from attribute information. Second, a multimodality fusion model is applied to integrate knowledge learned from different modalities, which can further improve the overall performance. Besides, the multilayer neural network based on softmax regression is used for multi-label classification. Finally, extensive experiments on two public datasets are conducted to verify the validity of the proposed scheme. Specifically, experimental results demonstrate the superior performance of our method over existing solutions in terms of accuracy and overhead."
A Fast Network Embedding Approach with Preserving Hierarchical Proximities,"Jie Zhang, Yan Wang, Jie Tang",IEEE,"network embedding, network representation learning, network analysis, data mining","Network embedding projects nodes in a network to a low-dimensional continuous space while the network structure and inherent properties are preserved. It has attracted tremendous attention recently due to its significant progress in network learning tasks, such as node classification, link prediction, and visualization. However, many network embedding works focus on the pairwise co-occurrence to depict nodes’ proximity and suffer from the expensive computations due to the large volume of networks. In this paper, we take into consideration the multiple step hitting probability to model hierarchical proximities, and propose a fast and scalable spectral network embedding method, NetPHP, which learns different order embeddings and can be trained faster than SGD based methods. To evaluate the performance, we conduct the multi-label classification experiments in different large-scale real networks. The empirical results demonstrate the NetPHP algorithm outperforms other state-ofthe-art methods. Besides, we also investigate the effect of different order proximities and non-adjacent node’s proximities."
Inter-Intra Information Preserving Attributed Network Embedding,"Kai Wang, Lei Xu, Ling Huang, Chang-Dong Wang, Yong Tang, Chengzhou Fu",IEEE,"Network embedding, attributed network, inter-relation, intra-characteristic","To alleviate the problem caused by the sparsity of network structure which is often the case in large-scale network, attributed network embedding has attracted an increasing amount of attention. Some existing attributed network embedding models integrate linkage structure and node attribute by adding a consistency criterion on the structure representation and attribute representation, whereby the similarity between them can be ensured. However, to enforce the structure and attribute representations to be similar may cause the information distortion due to the inherent difference between these two kinds of information. Additionally, the existing models mainly focus on learning the inter-relation between structure and attribute information, while the intra-characteristic of each information is ignored, leading to the information loss. To address the above two problems, we propose a novel model named Inter-Intra Information Preserving Attributed Network Embedding (IINE) to effectively learn the node representations of attributed network, which can not only capture the inter-relation between structure and attribute information with less information distortion but also effectively preserve the intra-characteristic of each information. The proposed model is composed of a primary model named coupled autoencoder and two auxiliary models named structure miner and attribute miner. The coupled autoencoder trains the node representation by smoothly combining both structure and attribute information, while the structure miner and attribute miner are utilized to further mine the intra-characteristic from the corresponding information so as to assist the primary model. The Extensive experiments are conducted on seven real-world datasets, and the results confirm the superior performance of IINE over several state-of-the-art models."
GraphGAN: Graph Representation Learning with Generative Adversarial Nets,"Hongwei Wang, Jia Wang, Jialin Wang,Miao Zhao, Weinan Zhang, FuzhengZhang, Xing Xie, Minyi Guo",arXiv,,"The goal of graph representation learning is to embed each vertex in a graph into a low-dimensional vector space. Existing graph representation learning methods can be classified into two categories: generative models that learn the underlying connectivity distribution in the graph, and discriminative models that predict the probability of edge existence between a pair of vertices. In this paper, we propose GraphGAN, an innovative graph representation learning framework unifying above two classes of methods, in which the generative model and discriminative model play a game-theoretical minimax game. Specifically, for a given vertex, the generative model tries to fit its underlying true connectivity distribution over all other vertices and produces ""fake"" samples to fool the discriminative model, while the discriminative model tries to detect whether the sampled vertex is from ground truth or generated by the generative model. With the competition between these two models, both of them can alternately and iteratively boost their performance. Moreover, when considering the implementation of generative model, we propose a novel graph softmax to overcome the limitations of traditional softmax function, which can be proven satisfying desirable properties of normalization, graph structure awareness, and computational efficiency. Through extensive experiments on real-world datasets, we demonstrate that GraphGAN achieves substantial gains in a variety of applications, including link prediction, node classification, and recommendation, over state-of-the-art baselines."
Reconstruction of network topology using status-time-series data,"Pradumn Kumar Pandey, V. Badarla",Physica A: Statistical Mechanics and its Applications,"Reconstruction, SIS model, Status-time-series, Diffusion","Uncovering the heterogeneous connection pattern of a networked system from the available status-time-series (STS) data of a dynamical process on the network is of great interest in network science and known as a reverse engineering problem. Dynamical processes on a network are affected by the structure of the network. The dependency between the diffusion dynamics and structure of the network can be utilized to retrieve the connection pattern from the diffusion data. Information of the network structure can help to devise the control of dynamics on the network. In this paper, we consider the problem of network reconstruction from the available status-time-series (STS) data using matrix analysis. The proposed method of network reconstruction from the STS data is tested successfully under susceptible–infected–susceptible (SIS) diffusion dynamics on real-world and computer-generated benchmark networks. High accuracy and efficiency of the proposed reconstruction procedure from the status-time-series data define the novelty of the method. Our proposed method outperforms compressed sensing theory (CST) based method of network reconstruction using STS data. Further, the same procedure of network reconstruction is applied to the weighted networks. The ordering of the edges in the weighted networks is identified with high accuracy."
Adversarial Capsule Learning for Network Embedding,"Di Jin, Zhigang Li, Liang Yang,Dongxiao He, Pengfei Jiao, Lu Zhai",IEEE,"Network Embedding, Generative Adversarial Networks (GAN), Capsule Networks, Graph Convolutional Networks, Deep Learning","The purpose of network embedding is to learn a low-dimensional representation for each node in the network. One can then use this low-dimensional representation to solve some network analysis tasks, such as node classification and node clustering. At present, there are several network embedding learning methods based on GAN (Generative Adversarial Networks) to enhance the robustness of representations. However, these methods have two drawbacks. First, they are often too difficult to be trained stably. Second, they only learn the robust representations by matching the posterior distribution of the latent representations to the given priors. On the contrary, Capsule Networks can learn a more equivariant representation of images that is more robust to the changes in pose and spatial relationships of parts of objects in images. However, there is still no research using Capsule Network for network embedding since the social network is essentially different from images. For this problem, we propose a new approach of adversarial capsule learning (ACL) for network embedding, which is the first time to use Capsule Network in the network analysis tasks. To be specific, the new model consists of two parts, a generator and discriminator. We use Graph Convolutional Networks (GCN) as the generator to learn the embedding of nodes, and use Capsule Network as the discriminator to distinguish between the real and fake samples as accurately as possible. The experimental results demonstrate the effectiveness of the proposed new method."
Context Attention Heterogeneous Network Embedding,"Wei Zhuo, Qianyi Zhan, Y. L. Liu,Zhenping Xie, Jing Lu",Computational Intelligence and Neuroscience,,"Network embedding (NE), which maps nodes into a low-dimensional latent Euclidean space to represent effective features of each node in the network, has obtained considerable attention in recent years. Many popular NE methods, such as DeepWalk, Node2vec, and LINE, are capable of handling homogeneous networks. However, nodes are always fully accompanied by heterogeneous information (e.g., text descriptions, node properties, and hashtags) in the real-world network, which remains a great challenge to jointly project the topological structure and different types of information into the fixed-dimensional embedding space due to heterogeneity. Besides, in the unweighted network, how to quantify the strength of edges (tightness of connections between nodes) accurately is also a difficulty faced by existing methods. To bridge the gap, in this paper, we propose CAHNE (context attention heterogeneous network embedding), a novel network embedding method, to accurately determine the learning result. Specifically, we propose the concept of node importance to measure the strength of edges, which can better preserve the context relations of a node in unweighted networks. Moreover, text information is a widely ubiquitous feature in realworld networks, e.g., online social networks and citation networks. On account of the sophisticated interactions between the network structure and text features of nodes, CAHNE learns context embeddings for nodes by introducing the context node sequence, and the attention mechanism is also integrated into our model to better reflect the impact of context nodes on the current node. To corroborate the efficacy of CAHNE, we apply our method and various baseline methods on several real-world datasets. ,e experimental results show that CAHNE achieves higher quality compared to a number of state-of-the-art network embedding methods on the tasks of network reconstruction, link prediction, node classification, and visualization."
Embedding Learning by Aspects in Heterogeneous Information Networks,"Yu Shi, Huan Gui, Qi Zhu, Lance Kaplan,Jiawei Han",arXiv,"Heterogeneous information networks, network embedding, graph mining, representation learning","Heterogeneous information networks (HINs) are ubiquitous in real-world applications. Due to the heterogeneity in HINs, the typed edges may not fully align with each other. In order to capture the semantic subtlety, we propose the concept of aspects with each aspect being a unit representing one underlying semantic facet. Meanwhile, network embedding has emerged as a powerful method for learning network representation, where the learned embedding can be used as features in various downstream applications. Therefore, we are motivated to propose a novel embedding learning framework---AspEm---to preserve the semantic information in HINs based on multiple aspects. Instead of preserving information of the network in one semantic space, AspEm encapsulates information regarding each aspect individually. In order to select aspects for embedding purpose, we further devise a solution for AspEm based on dataset-wide statistics. To corroborate the efficacy of AspEm, we conducted experiments on two real-words datasets with two types of applications---classification and link prediction. Experiment results demonstrate that AspEm can outperform baseline network embedding learning methods by considering multiple aspects, where the aspects can be selected from the given HIN in an unsupervised manner."
Representation Learning for Large-Scale Dynamic Networks,"Yanwei Yu, Huaxiu Yao, Hongjian Wang,Xianfeng Tang, Zhenhui Li",Database Systems for Advanced Applications,"Large-scale Dynamic Networks, Network Embedding, Second-order Proximity, DeepWalk Edge Deletion ","Representation leaning on networks aims to embed networks into a low-dimensional vector space, which is useful in many tasks such as node classification, network clustering, link prediction and recommendation. In reality, most real-life networks constantly evolve over time with various kinds of changes to the network structure, e.g., creation and deletion of edges. However, existing network embedding methods learn the representation vectors for nodes in a static manner, which are not suitable for dynamic network embedding. In this paper, we propose a dynamic network embedding approach for large-scale networks. The method incrementally updates the embeddings by considering the changes of the network structures and is able to dynamically learn the embedding for networks with millions of nodes within a few seconds. Extensive experimental results on three real large-scale networks demonstrate the efficiency and effectiveness of our proposed methods."
Effective Representing of Information Network by Variational Autoencoder,"Huang Li, Haozheng Wang, ZhengluYang, Haochen Liu",IJCAI,,"Network representation is the basis of many applications and of extensive interest in various fields, such as information retrieval, social network analysis, and recommendation systems. Most previous methods for network representation only consider the incomplete aspects of a problem, including link structure, node information, and partial integration. The present study proposes a deep network representation model that seamlessly integrates the text information and structure of a network. Our model captures highly non-linear relationships between nodes and complex features of a network by exploiting the variational autoencoder (VAE), which is a deep unsupervised generation algorithm. We also merge the representation learned with a paragraph vector model and that learned with the VAE to obtain the network representation that preserves both structure and text information. We conduct comprehensive empirical experiments on benchmark datasets and find our model performs better than state-of-the-art techniques by a large margin."
Graph Representation Learning and Graph Classification ,Sara Riazi,University of Oregon,,"Many real-world problems are represented by using graphs. For example, given a graph of a chemical compound, we want do determine whether it causes a gene mutation or not. As another example, given a graph of a social network, we want to predict a potential friendship that does not exist but it is likely to appear soon. Many of these questions can be answered by using machine learning methods if we have vector representations of the inputs, which are either graphs or vertices, depending on the problem. A general approach to extracting such vectors is to learn a latent vector representation for the vertices or the entire graph such that these vectors can be used in machine learning tasks, such as training a classifier or a predictive model (Bengio et al., 2013). The learned vectors should reflect the graph’s structure and its attributes, including vertex and edge attributes. For example, two adjacent vertices in a graph should have similar vector representations. The problem of learning a latent vector representation for graphs or vertices is called graph representation learning or graph embedding. In this document, we mainly focus on recent developments in graph representation learning in different settings and its connection to various problems, such as graph classification or graph clustering."
Learning Community Embedding with Community Detection and Node Embedding on Graphs,"Sandro Cavallari, Vincent WenchenZheng, HongYun Cai, Kevin Chen-ChuanChang, Erik Cambria",ACM,"community embedding, graph embedding","In this paper, we study an important yet largely under-explored setting of graph embedding, i.e., embedding communities instead of each individual nodes. We find that community embedding is not only useful for community-level applications such as graph visualization, but also beneficial to both community detection and node classification. To learn such embedding, our insight hinges upon a closed loop among community embedding, community detection and node embedding. On the one hand, node embedding can help improve community detection, which outputs good communities for fitting better community embedding. On the other hand, community embedding can be used to optimize the node embedding by introducing a community-aware high-order proximity. Guided by this insight, we propose a novel community embedding framework that jointly solves the three tasks together. We evaluate such a framework on multiple real-world datasets, and show that it improves graph visualization and outperforms state-of-the-art baselines in various application tasks, e.g., community detection and node classification."
Feature-Dependent Graph Convolutional Autoencoders with Adversarial Training Methods,"Di Wu, Ruiqi Hu, Yu Zheng, Jing Jiang,Nabin Sharma, Michael Blumenstein",IEEE,"Graph Embedding, Graph Convolutional Neural Networks, Generative Adversarial Network","Graphs are ubiquitous for describing and modeling complicated data structures, and graph embedding is an effective solution to learn a mapping from a graph to a low-dimensional vector space while preserving relevant graph characteristics. Most existing graph embedding approaches either embed the topological information and node features separately or learn one regularized embedding with both sources of information, however, they mostly overlook the interdependency between structural characteristics and node features when processing the graph data into the models. Moreover, existing methods only reconstruct the structural characteristics, which are unable to fully leverage the interaction between the topology and the features associated with its nodes during the encoding-decoding procedure. To address the problem, we propose a framework using autoencoder for graph embedding (GED) and its variational version (VEGD). The contribution of our work is two-fold: 1) the proposed frameworks exploit a feature-dependent graph matrix (FGM) to naturally merge the structural characteristics and node features according to their interdependency; and 2) the Graph Convolutional Network (GCN) decoder of the proposed framework reconstructs both structural characteristics and node features, which naturally possesses the interaction between these two sources of information while learning the embedding. We conducted the experiments on three real-world graph datasets such as Cora, Citeseer and PubMed to evaluate our framework and algorithms, and the results outperform baseline methods on both link prediction and graph clustering tasks."
Marc: Multi-Granular Representation Learning for Networks Based on the 3-Clique,"Zhenghua Xin, Jianyun Chen, GuolongChen, Shu Zhao",IEEE,"Multi-granular representation learning, multi-label classification, network representation learning, 3-clique.","Network embedding is of paramount importance in many real applications, such as node classification, network visualization, and link prediction. Existing methods can effectively encode different structural properties into representations. Most of them are single-granular representation learning methods that do not enable the network to be easily analyzed at various scales. There are many kinds of hierarchical structures in reality. In this paper, we propose a novel algorithm multi-granular representation learning for networks based on the 3-clique named Marc. It makes the representations of the current network be formed by both considering the structure of this granular network and inheriting the coarser network representation results. Firstly, we propose the 3-clique coarsening strategy. A 3-clique is coarsened to be a supernode in the coarser network. These coarsened networks with different granularities, preserve the original network’s main structure. Secondly, we use the single-granular optimization objective function to obtain the nodes’ representations of each granular network. Finally, the refinement model learns the nodes’ representations, starting from the coarsest network. The learned representations of supernodes serve as good initializations for embedding the corresponding coarsened nodes from the finer network. This process is repeated until we obtain an embedding for each node in the original network which preserves the relationship among multigranular networks. The experimental results on five public datasets, Wiki, BlogCatalog, Cora, CiteSeer, and DBLP, demonstrate that Marc has a better Macro F1 value for classification tasks than the baseline methods"
CARL: Content-Aware Representation Learning for Heterogeneous Networks,"Chuxu Zhang, Ananthram Swami,Nitesh V. Chawla",arXiv,"Heterogeneous Information Networks, Representation Learning, Network Embedding","Heterogeneous networks not only present a challenge of heterogeneity in the types of nodes and relations, but also the attributes and content associated with the nodes. While recent works have looked at representation learning on homogeneous and heterogeneous networks, there is no work that has collectively addressed the following challenges: (a) the heterogeneous structural information of the network consisting of multiple types of nodes and relations; (b) the unstructured semantic content (e.g., text) associated with nodes; and (c) online updates due to incoming new nodes in growing network. We address these challenges by developing a Content-Aware Representation Learning model (CARL). CARL performs joint optimization of heterogeneous SkipGram and deep semantic encoding for capturing both heterogeneous structural closeness and unstructured semantic relations among all nodes, as function of node content, that exist in the network. Furthermore, an additional online update module is proposed for efficiently learning representations of incoming nodes. Extensive experiments demonstrate that CARL outperforms state-of-the-art baselines in various heterogeneous network mining tasks, such as link prediction, document retrieval, node recommendation and relevance search. We also demonstrate the effectiveness of the CARL's online update module through a category visualization study."
Attention Based Meta Path Fusion for Heterogeneous Information Network Embedding,"Houye Ji, Chuan Shi, Bai Wang",PRICAI 2018: Trends in Artificial Intelligence,,"Recently, there is a surge of network embedding algorithms, which embed information network into a low dimensional space. However, contemporary network embedding algorithms focus on homogeneous networks, while we know that many real-world systems can be constructed with heterogeneous information networks (HINs). Compare to homogeneous networks, HINs contain heterogeneity types of nodes and edges, which leads to new challenges for traditional network embedding: handing mixed heterogeneous nodes and fusing rich semantic information. Although several HIN embedding algorithms have been proposed, these challenges have not been well dressed. How to explore the rich semantic information and integrate these information still remain to be solved. In this paper, we propose a novel attention based meta path fusion model for HIN embedding (called AMPE). In order to handle node heterogeneity and extract rich information, AMPE first extracts multiple homogeneous networks from HIN with meta paths, and then employs adopted AutoEncoders to embed these homogeneous networks. After that, AMPE fuses these embeddings learned from homogeneous networks with attention mechanism. Experimental results on two real-world datasets demonstrate the effectiveness of the proposed model."
Representation learning for heterogeneous network with multiple link attributes,"Kaiwen Song, Xinao Wang, YidanZhang, Jie Zuo",ACM,"Heterogeneous Network, Representation Learning, Multi-Aspect, Link Attributes","The strategies of learning node representation in network, which try to reduce the dimension of adjacency matrix in network, have been drawn much attention recently. Existing approaches focus on preserving structure property and heterogeneity in a low dimensional space with simplex link. However, in the real world, link between each object containing rich attributes information will lead to treat links as multi-variables. In this paper, we split network into multiple aspects according to multiple link attributes and preserve structural and semantic properties for each aspect simultaneously. Then, we introduce an attention strategy, which is capable of combining each aspect with relevant weight, to extract more informative aspect for nodes. Results of experiment verified with link prediction task on a real world dataset show that our approach is able to capture the most contributory attribute of link, which outperforms the state of the art network representation learning techniques regarding each attribute equally"
Are Meta-Paths Necessary?: Revisiting Heterogeneous Graph Embeddings,"Rana Hussein, Dingqi Yang, PhilippeCudré-Mauroux",ACM,"Graph embedding, Heterogeneous graph, Random walk","The graph embedding paradigm projects nodes of a graph into a vector space, which can facilitate various downstream graph analysis tasks such as node classification and clustering. To efficiently learn node embeddings from a graph, graph embedding techniques usually preserve the proximity between node pairs sampled from the graph using random walks. In the context of a heterogeneous graph, which contains nodes from different domains, classical random walks are biased towards highly visible domains where nodes are associated with a dominant number of paths. To overcome this bias, existing heterogeneous graph embedding techniques typically rely on meta-paths (i.e., fixed sequences of node types) to guide random walks. However, using these meta-paths either requires prior knowledge from domain experts for optimal meta-path selection, or requires extended computations to combine all meta-paths shorter than a predefined length. In this paper, we propose an alternative solution that does not involve any meta-path. Specifically, we propose JUST, a heterogeneous graph embedding technique using random walks with JUmp and STay strategies to overcome the aforementioned bias in an more efficient manner. JUST can not only gracefully balance between homogeneous and heterogeneous edges, it can also balance the node distribution over different domains (i.e., node types). By conducting a thorough empirical evaluation of our method on three heterogeneous graph datasets, we show the superiority of our proposed technique. In particular, compared to a state-of-the-art heterogeneous graph embedding technique Hin2vec, which tries to optimally combine all meta-paths shorter than a predefined length, our technique yields better results in most experiments, with a dramatically reduced embedding learning time (about 3x speedup)."
Heterogeneous Information Network Embedding for Recommendation,"Chuan Shi, Binbin Hu, Wayne Xin Zhao,Philip S. Yu",arXiv,"Heterogeneous information network, Network embedding, Matrix factorization, Recommender system","Due to the flexibility in modelling data heterogeneity, heterogeneous information network (HIN) has been adopted to characterize complex and heterogeneous auxiliary data in recommender systems, called HIN based recommendation. It is challenging to develop effective methods for HIN based recommendation in both extraction and exploitation of the information from HINs. Most of HIN based recommendation methods rely on path based similarity, which cannot fully mine latent structure features of users and items. In this paper, we propose a novel heterogeneous network embedding based approach for HIN based recommendation, called HERec. To embed HINs, we design a meta-path based random walk strategy to generate meaningful node sequences for network embedding. The learned node embeddings are first transformed by a set of fusion functions, and subsequently integrated into an extended matrix factorization (MF) model. The extended MF model together with fusion functions are jointly optimized for the rating prediction task. Extensive experiments on three real-world datasets demonstrate the effectiveness of the HERec model. Moreover, we show the capability of the HERec model for the cold-start problem, and reveal that the transformed embedding information from HINs can improve the recommendation performance."
TransPath: Representation Learning for Heterogeneous Information Networks via Translation Mechanism,"Yang Fang, Xiang Zhao, Zhen Tan,Weidong Xiao",IEEE,"Heterogeneous information network, representation learning","In this paper, we propose a novel network representation learning model TransPath to encode heterogeneous information networks (HINs). Traditional network representation learning models aim to learn the embeddings of a homogeneous network. TransPath is able to capture the rich semantic and structure information of a HIN via meta-paths. We take advantage of the concept of translation mechanism in knowledge graph which regards a meta-path, instead of an edge, as a translating operation from the first node to the last node. Moreover, we propose a user-guided meta-path sampling strategy which takes users’ preference as a guidance, which could explore the semantics of a path more precisely, and meanwhile improve model efficiency via the avoidance of other noisy and meaningless meta-paths. We evaluate our model on two large-scale real-world data sets database systems and logic programming (DBLP) and YELP, and two benchmark tasks similarity search and node classification. We observe that TransPath outperforms other state-of-the-art baselines consistently and significantly"
AspEm: Embedding Learning by Aspects in Heterogeneous Information Networks,"Yu Shi, Huan Gui, Qi Zhu, Lance M.Kaplan, Jiawei Han",arXiv,"Heterogeneous information networks, network embedding, graph mining, representation learning","Heterogeneous information networks (HINs) are ubiquitous in real-world applications. Due to the heterogeneity in HINs, the typed edges may not fully align with each other. In order to capture the semantic subtlety, we propose the concept of aspects with each aspect being a unit representing one underlying semantic facet. Meanwhile, network embedding has emerged as a powerful method for learning network representation, where the learned embedding can be used as features in various downstream applications. Therefore, we are motivated to propose a novel embedding learning framework—ASPEM—to preserve the semantic information in HINs based on multiple aspects. Instead of preserving information of the network in one semantic space, ASPEM encapsulates information regarding each aspect individually. In order to select aspects for embedding purpose, we further devise a solution for ASPEM based on datasetwide statistics. To corroborate the efficacy of ASPEM, we conducted experiments on two real-words datasets with two types of applications—classification and link prediction. Experiment results demonstrate that ASPEM can outperform baseline network embedding learning methods by considering multiple aspects, where the aspects can be selected from the given HIN in an unsupervised manner."
NetMerger: Predicting Cross-network Links in Merged Heterogeneous Networks,"Yao Zhang, Yun Xiong, Lu Ruan,Xiangnan Kong, Yangyong Zhu",ACM,"Heterogeneous Networks, Network Embedding, Link Prediction","Previous work on link prediction focuses on single network settings or transferring knowledge between two networks for predicting intra-network links. However, many real-world applications involve multiple networks, and we need to predict cross-network links in these networks instead. For example, when mergers or acquisitions happen between two companies, the two business networks need to be merged into one. We may want to promote cross-network links, such as connections between the users in PayPal with those in x.com, to speed up the merger and integration of the two business networks. Considering recommending cross-network links can significantly speed up the business integration, in this paper, we study the problem of cross-network link prediction in merged heterogeneous networks. The goal is to predict potential links between multiple kinds of nodes across the two merged networks. It is also highly challenging because little or no information is previously known about the cross-network links, i.e., a cold-start problem. We proposed an approach, called NetMerger, which first learns network embeddings of the merged networks based upon their network structures and then makes cross-network link predictions. We compared our method with baselines on two real-world datasets. The results demonstrated the effectiveness of our proposal."
Easing Embedding Learning by Comprehensive Transcription of Heterogeneous Information Networks,"Yu Shi, Qi Zhu, Fang Guo, Chao Zhang,Jiawei Han",arXiv,"Heterogeneous information networks, network embedding, graph mining, representation learning","Heterogeneous information networks (HINs) are ubiquitous in real-world applications. In the meantime, network embedding has emerged as a convenient tool to mine and learn from networked data. As a result, it is of interest to develop HIN embedding methods. However, the heterogeneity in HINs introduces not only rich information but also potentially incompatible semantics, which poses special challenges to embedding learning in HINs. With the intention to preserve the rich yet potentially incompatible information in HIN embedding, we propose to study the problem of comprehensive transcription of heterogeneous information networks. The comprehensive transcription of HINs also provides an easy-to-use approach to unleash the power of HINs, since it requires no additional supervision, expertise, or feature engineering. To cope with the challenges in the comprehensive transcription of HINs, we propose the HEER algorithm, which embeds HINs via edge representations that are further coupled with properly-learned heterogeneous metrics. To corroborate the efficacy of HEER, we conducted experiments on two large-scale real-words datasets with an edge reconstruction task and multiple case studies. Experiment results demonstrate the effectiveness of the proposed HEER model and the utility of edge representations and heterogeneous metrics."
AHINE: Adaptive Heterogeneous Information Network Embedding,"Yucheng Lin, Xiaoqing Yang, Zang Li,Jieping Ye",arXiv,"Network embedding, heterogeneous information network, deep learning","Network embedding is an effective way to solve the network analytics problems such as node classification, link prediction, etc. It represents network elements using low dimensional vectors such that the graph structural information and properties are maximumly preserved. Many prior works focused on embeddings for networks with the same type of edges or vertices, while some works tried to generate embeddings for heterogeneous network using mechanisms like specially designed meta paths. In this paper, we propose two novel algorithms, GHINE (General Heterogeneous Information Network Embedding) and AHINE (Adaptive Heterogeneous Information Network Embedding), to compute distributed representations for elements in heterogeneous networks. Specially, AHINE uses an adaptive deep model to learn network embeddings that maximizes the likelihood of preserving the relationship chains between non-adjacent nodes. We apply our embeddings to a large network of points of interest (POIs) and achieve superior accuracy on some prediction problems on a ride-hailing platform. In addition, we show that AHINE outperforms state-of-the-art methods on a set of learning tasks on public datasets, including node labelling and similarity ranking in bibliographic networks."
Enhancing the Network Embedding Quality with Structural Similarity,Tianshu Lyu,ACM,"Network Embedding, Graphlet, Latent Representation","Neural network techniques are widely used in network embedding, boosting the result of node classification, link prediction, visualization and other tasks in both aspects of efficiency and quality. All the state of art algorithms put effort on the neighborhood information and try to make full use of it. However, it is hard to recognize core periphery structures simply based on neighborhood. In this paper, we first discuss the influence brought by randomwalk based sampling strategies to the embedding results. Theoretical and experimental evidences show that random-walk based sampling strategies fail to fully capture structural equivalence. We present a new method, SNS, that performs network embeddings using structural information (namely graphlets) to enhance its quality. SNS effectively utilizes both neighbor information and localsubgraphs similarity to learn node embeddings. This is the first framework that combines these two aspects as far as we know, positively merging two important areas in graph mining and machine learning. Moreover, we investigate what kinds of local-subgraph features matter the most on the node classification task, which enables us to further improve the embedding quality. Experiments show that our algorithm outperforms other unsupervised and semisupervised neural network embedding algorithms on several realworld datasets."
Heterogeneous Information Network Embedding for Meta Path based Proximity,"Zhipeng Huang, Nikos Mamoulis",arXiv,heterogeneous information network; meta path; network embedding,"A network embedding is a representation of a large graph in a low-dimensional space, where vertices are modeled as vectors. The objective of a good embedding is to preserve the proximity between vertices in the original graph. This way, typical search and mining methods can be applied in the embedded space with the help of off-the-shelf multidimensional indexing approaches. Existing network embedding techniques focus on homogeneous networks, where all vertices are considered to belong to a single class."
A Unified Network Embedding Algorithm for Multi-type Similarity Measures,"Rui Feng, Yang Yang, Yizhou Sun,Chunping Wang",GRLA,"Network embedding, Social network, Probabilistic influence model","Traditional network embedding aims to learn representations by capturing a predefined vertex-to-vertex similarity measure. However, in practice, there are different types of similarity measures (e.g., connectivity and structural similarity), which are appropriate for different downstream applications. Meanwhile, it is hard to select the “best” similarity measure that can mostly benefit the application, considering the required domain knowledge of both application scenario and network science. It sometimes requires to cooperate these similarity measures with each other for achieving better performance. Therefore, automatically integrate multiple types of similarity measures into a uniform network embedding framework is critical to obtain effective vertex representations for a downstream application. In this paper, we address the above problem in social networks, and propose a semi-supervised representation learning algorithm. The general idea of our approach is to impose social influence, which occurs when one’s opinions, emotions, or behaviors are affected by others in a social network. Particularly, we build the connection between a user’s representation vector and the probability of her being influenced by another user to have a particular label (e.g., fraud, personal interest, etc.). We conduct efficient experiments based on six real-world datasets and find a clear improvement of our approach comparing with several state-of-the-art baselines."
Author Set Identification via Quasi-Clique Discovery,"Yuyan Zheng, Chuan Shi, XiangnanKong, Yanfang Ye",ACM,Author set identification; Quasi-clique; Heterogeneous network construction; Network embedding; Meta path,"Author identification based on heterogeneous bibliographic networks, which is to identify potential authors given an anonymous paper, has been studied in recent years. However, most of the existing works merely consider the relationship between authors and anonymous papers, while ignore the relationships between authors. In this paper, we take the relationships among authors into consideration to study the problem of author set identification, which is to identify an author set rather than an individual author related to an anonymous paper. The proposed problem has important applications to new collaborator discovery and group building. We propose a novel Author Set Identification approach, namely ASI. ASI first extracts a task-guided embedding to learn the low-dimensional representations of nodes in bibliographic network. And then ASI leverages the learned embedding to construct a weighted paper-ego-network, which contains anonymous paper and candidate authors. Finally, converting the optimal author set identification to the quasi-clique discovery in the constructed network, ASI utilizes a local-search heuristic mechanism under the guidance of the devised density function to find the optimal quasiclique. Extensive experiments on bibliographic networks demonstrate that ASI outperforms the state-of-art baselines in author set identification."
Heterogeneous Graph Attention Network,"Xiao Wang, Houye Ji, Chuan Shi, BaiWang, Peng Cui, Puxuan Yu, YanfangYe",arXiv,"Social Network, Neural Network, Graph Analysis","Graph neural network, as a powerful graph representation technique based on deep learning, has shown superior performance and attracted considerable research interest. However, it has not been fully considered in graph neural network for heterogeneous graph which contains different types of nodes and links. The heterogeneity and rich semantic information bring great challenges for designing a graph neural network for heterogeneous graph. Recently, one of the most exciting advancements in deep learning is the attention mechanism, whose great potential has been well demonstrated in various areas. In this paper, we first propose a novel heterogeneous graph neural network based on the hierarchical attention, including node-level and semantic-level attentions. Specifically, the node-level attention aims to learn the importance between a node and its metapath based neighbors, while the semantic-level attention is able to learn the importance of different meta-paths. With the learned importance from both node-level and semantic-level attention, the importance of node and meta-path can be fully considered. Then the proposed model can generate node embedding by aggregating features from meta-path based neighbors in a hierarchical manner. Extensive experimental results on three real-world heterogeneous graphs not only show the superior performance of our proposed model over the state-of-the-arts, but also demonstrate its potentially good interpretability for graph analysis."
Camel: Content-Aware and Meta-path Augmented Metric Learning for Author Identification,"Chuxu Zhang, Chao Huang, Lu Yu,Xiangliang Zhang, Nitesh V. Chawla",ACM,"Author Identification, Heterogeneous Networks, Representation Learning, Metric Learning, Deep Learning","In this paper, we study the problem of author identification in big scholarly data, which is to effectively rank potential authors for each anonymous paper by using historical data. Most of the existing de-anonymization approaches predict relevance score of paper-author pair via feature engineering, which is not only time and storage consuming, but also introduces irrelevant and redundant features or miss important attributes. Representation learning can automate the feature generation process by learning node embeddings in academic network to infer the correlation of paper-author pair. However, the learned embeddings are often for general purpose (independent of the specific task), or based on network structure only (without considering the node content). To address these issues and make a further progress in solving the author identification problem, we propose Camel, a content-aware and meta-path augmented metric learning model. Specifically, first, the directly correlated paper-author pairs are modeled based on distance metric learning by introducing a push loss function. Next, the paper content embedding encoded by the gated recurrent neural network is integrated into the distance loss. Moreover, the historical bibliographic data of papers is utilized to construct an academic heterogeneous network, wherein a meta-path guided walk integrative learning module based on the task-dependent and content-aware Skipgram model is designed to formulate the correlations between each paper and its indirect author neighbors, and further augments the model. Extensive experiments demonstrate that Camel outperforms the state-of-the-art baselines. It achieves an average improvement of 6.3% over the best baseline method."
Personalized Question Routing via Heterogeneous Network Embedding,"Zeyu Li, Jyun-Yu Jiang, Yizhou Sun, WeiWang",AAAI,,"Question Routing (QR) on Community-based Question Answering (CQA) websites aims at recommending answerers that have high probabilities of providing the “accepted answers” to new questions. The existing question routing algorithms simply predict the ranking of users based on query content. As a consequence, the question raiser information is ignored. On the other hand, they lack learnable scoring functions to explicitly compute ranking scores. To tackle these challenges, we propose NeRank that (1) jointly learns representations of question content, question raiser, and question answerers by a heterogeneous information network embedding algorithm and a long short-term memory (LSTM) model. The embeddings of the three types of entities are unified in the same latent space, and (2) conducts question routing for personalized queries, i.e., queries with two entities (question content, question raiser), by a convolutional scoring function taking the learned embeddings of all three types of entities as input. Using the scores, NeRank routes new questions to high-ranking answerers that are skillfulness in the question domain and have similar backgrounds to the question raiser. Experimental results show that NeRank significantly outperforms competitive baseline question routing models that ignore the raiser information in three ranking metrics. In addition, NeRank is convergeable in several thousand iterations and insensitive to parameter changes, which prove its effectiveness, scalability, and robustness."
Probabilistic Random Walks for Churn Prediction using Representation Learning,Sandra Mitrovic,ACM,"Probabilistic Random Walks, Node Embedding, RFM-Augmented Networks, Churn Prediction","Unleashing the full potential of data is oftentimes a cumbersome task, especially when dealing with network data. It is therefore possible that while focusing on one part of the solution, other valuable pieces of information remain under-treated leading to under-performing results. In this work, we zoom into the nature of an augmentation of call graphs devised for addressing churn prediction in telco. By shifting the focus from a homogeneous to a heterogeneous perspective, by defining different probabilistic meta paths, and by applying representation learning on graphs using these defined meta paths, we demonstrate the benefits of this approach, not only by means of improvements of predictive results, but also with promising insights regarding the interplay of meta path type and predictive outcome. As such, this is still a work in progress but the current results have also been submitted to (and are currently under review at) another conference."
HeteSpaceyWalk: A Heterogeneous Spacey Random Walk for Heterogeneous Information Network Embedding,"Yu He, Yangqiu Song, Jianxin Li, ChengJi, Jian Peng, Hao Peng",arXiv,"Heterogeneous networks, Network embedding, Random walk","Heterogeneous information network (HIN) embedding has gained increasing interests recently. However, the current way of random-walk based HIN embedding methods have paid few attention to the higher-order Markov chain nature of meta-path guided random walks, especially to the stationarity issue. In this paper, we systematically formalize the meta-path guided random walk as a higher-order Markov chain process, and present a heterogeneous personalized spacey random walk to efficiently and effectively attain the expected stationary distribution among nodes. Then we propose a generalized scalable framework to leverage the heterogeneous personalized spacey random walk to learn embeddings for multiple types of nodes in an HIN guided by a meta-path, a meta-graph, and a meta-schema respectively. We conduct extensive experiments in several heterogeneous networks and demonstrate that our methods substantially outperform the existing state-of-the-art network embedding algorithms."
Hyperbolic Heterogeneous Information Network Embedding,"Xiao Wang, Yiding Zhang, Chuan Shi",AAAI,,"Heterogeneous information network (HIN) embedding, aiming to project HIN into a low-dimensional space, has attracted considerable research attention. Most of the exiting HIN embedding methods focus on preserving the inherent network structure and semantic correlations in Euclidean spaces. However, one fundamental problem is that whether the Euclidean spaces are the appropriate or intrinsic isometric spaces of HIN? Recent researches argue that the complex network may have the hyperbolic geometry underneath, because the underlying hyperbolic geometry can naturally reflect some properties of complex network, e.g., hierarchical and power-law structure. In this paper, we make the first effort toward HIN embedding in hyperbolic spaces. We analyze the structures of two real-world HINs and discover some properties, e.g., the power-law distribution, also exist in HIN. Therefore, we propose a novel hyperbolic heterogeneous information network embedding model. Specifically, to capture the structure and semantic relations between nodes, we employ the meta-path guided random walk to sample the sequences for each node. Then we exploit the distance in hyperbolic spaces as the proximity measurement. The hyperbolic distance is able to meet the triangle inequality and well preserve the transitivity in HIN. Our model enables the nodes and their neighborhoods have small hyperbolic distances. We further derive the effective optimization strategy to update the hyperbolic embeddings iteratively. The experimental results, in comparison with the state-of-the-art, demonstrate that our proposed model not only has superior performance on network reconstruction and link prediction tasks but also shows its ability of capture hierarchy structure in HIN via visualization."
Multi-Layered Network Embedding,"Jundong Li, Chen Chen, HanghangTong, Huan Liu",SIAM International Conference on Data Mining,,"Network embedding has gained more attentions in recent years. It has been shown that the learned lowdimensional node vector representations could advance a myriad of graph mining tasks such as node classification, community detection, and link prediction. A vast majority of the existing efforts are overwhelmingly devoted to single-layered networks or homogeneous networks with a single type of nodes and node interactions. However, in many real-world applications, a variety of networks could be abstracted and presented in a multilayered fashion. Typical multi-layered networks include critical infrastructure systems, collaboration platforms, social recommender systems, to name a few. Despite the widespread use of multi-layered networks, it remains a daunting task to learn vector representations of different types of nodes due to the bewildering combination of both within-layer connections and cross-layer network dependencies. In this paper, we study a novel problem of multi-layered network embedding. In particular, we propose a principled framework - MANE to model both within-layer connections and cross-layer network dependencies simultaneously in a unified optimization framework for embedding representation learning. Experiments on real-world multi-layered networks corroborate the effectiveness of the proposed framework."
Learning Deep Network Representations with Adversarially Regularized Autoencoders,"Wenchao Yu, Cheng Zheng, Wei Cheng,Charu C. Aggarwal, Dongjin Song, BoZong, Haifeng Chen, Wei Wang",ACM,"Network embedding, autoencoder, generative adversarial networks","The problem of network representation learning, also known as network embedding, arises in many machine learning tasks assuming that there exist a small number of variabilities in the vertex representations which can capture the “semantics” of the original network structure. Most existing network embedding models, with shallow or deep architectures, learn vertex representations from the sampled vertex sequences such that the low-dimensional embeddings preserve the locality property and/or global reconstruction capability. The resultant representations, however, are difficult for model generalization due to the intrinsic sparsity of sampled sequences from the input network. As such, an ideal approach to address the problem is to generate vertex representations by learning a probability density function over the sampled sequences. However, in many cases, such a distribution in a low-dimensional manifold may not always have an analytic form. In this study, we propose to learn the network representations with adversarially regularized autoencoders (NetRA). NetRA learns smoothly regularized vertex representations that well capture the network structure through jointly considering both locality-preserving and global reconstruction constraints. The joint inference is encapsulated in a generative adversarial training process to circumvent the requirement of an explicit prior distribution, and thus obtains better generalization performance. We demonstrate empirically how well key properties of the network structure are captured and the effectiveness of NetRA on a variety of tasks, including network reconstruction, link prediction, and multi-label classification."
TLVANE: a two-level variation model for attributed network embedding,"Zhichao Huang, Xutao Li, Yunming Ye,Feng Li, Feng Liu, Yuan Yao",Neural Computing and Applications,"Attribute network, Embedding, Variational autoencoder","Network embedding aims to learn low-dimensional representations for nodes in social networks, which can serve many applications, such as node classification, link prediction and visualization. Most of network embedding methods focus on learning the representations solely from the topological structure. Recently, attributed network embedding, which utilizes both the topological structure and node content to jointly learn latent representations, becomes a hot topic. However, previous studies obtain the joint representations by directly concatenating the one from each aspect, which may lose the correlations between the topological structure and node content. In this paper, we propose a new attributed network embedding method, TLVANE, which can address the drawback by exploiting the deep variational autoencoders (VAEs). Particularly, a two-level VAE model is built, where the first-level accounts for the joint representations while the second for the embeddings of each aspect. Extensive experiments on three real-world datasets have been conducted, and the results demonstrate the superiority of the proposed method against state-of-the-art competitors."
SNE: Signed Network Embedding,"Shuhan Yuan, Xintao Wu, Yang Xiang",arXiv,,"Several network embedding models have been developed for unsigned networks. However, these models based on skip-gram cannot be applied to signed networks because they can only deal with one type of link. In this paper, we present our signed network embedding model called SNE. Our SNE adopts the log-bilinear model, uses node representations of all nodes along a given path, and further incorporates two signed-type vectors to capture the positive or negative relationship of each edge along the path. We conduct two experiments, node classification and link prediction, on both directed and undirected signed networks and compare with four baselines including a matrix factorization method and three state-of-the-art unsigned network embedding models. The experimental results demonstrate the effectiveness of our signed network embedding."
Representation Learning in Heterogeneous Professional Social Networks with Ambiguous Social Connections,"Baoxu Shi, Jaewon Yang, TimWeninger, How Jing, Qi He",arXiv,"Network representation, Heterogeneous professional social networks","Network representations have been shown to improve performance within a variety of tasks, including classification, clustering, and link prediction. However, most models either focus on moderate-sized, homogeneous networks or require a significant amount of auxiliary input to be provided by the user. Moreover, few works have studied network representations in real-world heterogeneous social networks with ambiguous social connections and are often incomplete. In the present work, we investigate the problem of learning low-dimensional node representations in heterogeneous professional social networks (HPSNs), which are incomplete and have ambiguous social connections. We present a general heterogeneous network representation learning model called Star2Vec that learns entity and person embeddings jointly using a social connection strength-aware biased random walk combined with a node-structure expansion function. Experiments on LinkedIn's Economic Graph and publicly available snapshots of Facebook's network show that Star2Vec outperforms existing methods on members' industry and social circle classification, skill and title clustering, and member-entity link predictions. We also conducted large-scale case studies to demonstrate practical applications of the Star2Vec embeddings trained on LinkedIn's Economic Graph such as next career move, alternative career suggestions, and general entity similarity searches."
Binarized attributed network embedding,"Hong Yang, Shirui Pan, Peng Zhang,Ling Chen, Defu Lian, Chengqi Zhang",IEEE,"Attributed network embedding, Weisfeiler Lehman graph kernels, Learning to hash","Attributed network embedding enables joint representation learning of node links and attributes. Existing attributed network embedding models are designed in continuous Euclidean spaces which often introduce data redundancy and impose challenges to storage and computation costs. To this end, we present a Binarized Attributed Network Embedding model (BANE for short) to learn binary node representation. Specifically, we define a new Weisfeiler-Lehman proximity matrix to capture data dependence between node links and attributes by aggregating the information of node attributes and links from neighboring nodes to a given target node in a layer-wise manner. Based on the Weisfeiler-Lehman proximity matrix, we formulate a new Weisfiler-Lehman matrix factorization learning function under the binary node representation constraint. The learning problem is a mixed integer optimization and an efficient cyclic coordinate descent (CCD) algorithm is used as the solution. Node classification and link prediction experiments on real-world datasets show that the proposed BANE model outperforms the state-of-the-art network embedding methods."
Network Embedding Using Semi-Supervised Kernel Nonnegative Matrix Factorization,"Chaobo He, Qiong Zhang, Yong Tang,Shuangyin Liu, Hai Liu",IEEE,"Kernel method, network analysis, network embedding, nonnegative matrix factorization, semi-supervised learning","Network embedding, aiming to learn low-dimensional representations of nodes in networks, is very useful for many vector-based machine learning algorithms and has become a hot research topic in network analysis. Although many methods for network embedding have been proposed before, most of them are unsupervised, which ignores the role of prior information available in the network. In this paper, we propose a novel method for network embedding using semi-supervised kernel nonnegative matrix factorization (SSKNMF), which can incorporate prior information and thus to learn more useful features from the network through introducing kernel methodology. Besides, it can improve robustness against noises by using the objective function based on L2,1 norm. Efficient iterative update rules are derived to resolve the network embedding model using the SSKNMF, and the convergence of these rules are strictly proved from the perspective of mathematics. The results from extensive experiments on several real-world networks show that our proposed algorithm is effective and has better performance than the existing representative methods."
MEMN: Multiple Vectors Embedding for Multi-Label Networks,"Juhua Pu, Zhuang Liu, Yujun Chen,Xingwu Liu",IEEE,"Network embedding, multiple vectors, multi-label classification, link prediction","Network embedding, which assigns vectors to network nodes in a manner that preserves the network features, is a hotspot of network research in recent years. A salient common feature of the existing approaches is that each node is mapped to exactly one vector. This one-vector mapping is insufficient to represent the nodes’ attribution in those extensively existed networks whose nodes’ have multiple labels. In this paper, we present MEMN, a novel approach of multiple vectors embedding for multi-labeled networks. For any node in the network, MEMN employs Node2vecWalk to generate its neighbor nodes. We maintain a neighbor cluster center for each label of the node and induce its label by clustering the embeddings of the neighbor nodes. Then, we assign vectors, one per label, to the node. This method can be non-parameterized, namely, NP-MEMN method. That is, if the number of label vectors for a node is not given, NP-MEMN can learn during embedding. Empirical studies on real datasets show that either MEMN or NP-MEMN outperforms many widely used methods in both multi-label classification and link prediction."
Node embedding for network community discovery,"Christy Lin, Prakash Ishwar, WeicongDing",IEEE,"Community Detection, Stochastic Block Model, Neural Embedding","Neural node embedding has been recently developed as a powerful representation for supervised tasks with graph data. We leverage this recent advance and propose a novel approach for unsupervised community discovery in graphs. Through extensive experimental studies on simulated and real-world data, we demonstrate consistent improvement of the proposed approach over the current state-of-the-arts. Specifically, our approach empirically attains the information theoretic li~n~ts under the benchmark Stochastic Block Models and exhIbIts better stability and accuracy over the best known algorithms in the community recovery limits."
TNE: A Latent Model for Representation Learning on Networks,"Abdulkadir Çelikkanat, Fragkiskos D.Malliaros",arXiv,,"Network representation learning (NRL) methods aim to map each vertex into a low dimensional space by preserving the local and global structure of a given network, and in recent years they have received a significant attention thanks to their success in several challenging problems. Although various approaches have been proposed to compute node embeddings, many successful methods benefit from random walks in order to transform a given network into a collection of sequences of nodes and then they target to learn the representation of nodes by predicting the context of each vertex within the sequence. In this paper, we introduce a general framework to enhance the embeddings of nodes acquired by means of the random walk-based approaches. Similar to the notion of topical word embeddings in NLP, the proposed method assigns each vertex to a topic with the favor of various statistical models and community detection methods, and then generates the enhanced community representations. We evaluate our method on two downstream tasks: node classification and link prediction. The experimental results demonstrate that the incorporation of vertex and topic embeddings outperform widely-known baseline NRL methods."
Diffusion Based Network Embedding,"Yong Shi, Minglong Lei, Peng Zhang,Lingfeng Niu",arXiv,"Network Embedding, Cascades, Diffusion, Network Inference, Dimension Reduction","In network embedding, random walks play a fundamental role in preserving network structures. However, random walk based embedding methods have two limitations. First, random walk methods are fragile when the sampling frequency or the number of node sequences changes. Second, in disequilibrium networks such as highly biases networks, random walk methods often perform poorly due to the lack of global network information. In order to solve the limitations, we propose in this paper a network diffusion based embedding method. To solve the first limitation, our method employs a diffusion driven process to capture both depth information and breadth information. The time dimension is also attached to node sequences that can strengthen information preserving. To solve the second limitation, our method uses the network inference technique based on cascades to capture the global network information. To verify the performance, we conduct experiments on node classification tasks using the learned representations. Results show that compared with random walk based methods, diffusion based models are more robust when samplings under each node is rare. We also conduct experiments on a highly imbalanced network. Results shows that the proposed model are more robust under the biased network structure."
Information cartography based on syncretic representation of scientific papers,"Tianmu Ma, Wei Fang",IEEE,"information retrieval, information systems, representation learning, document classification, link prediction","In this paper, we challenged the traditional way of information retrieval and proposed information cartography in scientific research domain which generates an information map for users to mitigate information overload in current systems. A legible information map embodies not only the results retrieved by a fine-designed mechanism, but also the complex relationships between them. Our framework of information cartography consists of three parts: document representation, network reconstruction and network compression. A novel syncretic representation learning method(SR) was proposed to learn a low-dimensional representation for each document, where a double-layer SkipGram model was leveraged to absorb heterogeneous information simultaneously. We carried out a series of experiments on CORA dataset to demonstrate the satisfying performance of SR for tasks such as text classification and link prediction. We also showed the effectiveness of our network compression method in preserving connectivity while optimizing legibility. Finally, pilot user studies manifested that our information map indeed improved the experience of information retrieval."
High-Order Proximity Preserved Embedding for Dynamic Networks,"Dingyuan Zhu, Peng Cui, Ziwei Zhang,Jian Pei, Wenwu Zhu",IEEE,"Dynamic network, high-order proximity, network embedding","Network embedding, aiming to embed a network into a low dimensional vector space while preserving the inherent structural properties of the network, has attracted considerable attention. However, most existing embedding methods focus on the static network while neglecting the evolving characteristic of real-world networks. Meanwhile, most of previous methods cannot well preserve the high-order proximity, which is a critical structural property of networks. These problems motivate us to seek an effective and efficient way to preserve the high-order proximity in embedding vectors when the networks evolve over time. In this paper, we propose a novel method of Dynamic High-order Proximity preserved Embedding (DHPE). Specifically, we adopt the generalized SVD (GSVD) to preserve the high-order proximity. Then, by transforming the GSVD problem to a generalized eigenvalue problem, we propose a generalized eigen perturbation to incrementally update the results of GSVD to incorporate the changes of dynamic networks. Further, we propose an accelerated solution to the DHPE model so that it achieves a linear time complexity with respect to the number of nodes and number of changed edges in the network. Our empirical experiments on one synthetic network and several real-world networks demonstrate the effectiveness and efficiency of the proposed method."
Graph Embedding with Rich Information through Heterogeneous Network,"Guolei Sun, Xiangliang Zhang",arXiv,,"Graph embedding has attracted increasing attention due to its critical application in social network analysis. Most existing algorithms for graph embedding only rely on the typology information and fail to use the copious information in nodes as well as edges. As a result, their performance for many tasks may not be satisfactory. In this paper, we proposed a novel and general framework of representation learning for graph with rich text information through constructing a bipartite heterogeneous network. Specially, we designed a biased random walk to explore the constructed heterogeneous network with the notion of flexible neighborhood. The efficacy of our method is demonstrated by extensive comparison experiments with several baselines on various datasets. It improves the Micro-F1 and Macro-F1 of node classification by 10% and 7% on Cora dataset."
Multi-Path Relationship Preserved Social Network Embedding,"Jianfeng Lin, Lei Zhang, Ming He, HefuZhang, Guiquan Liu, Xiuyuan Chen,Zhongming Chen",IEEE,"Social network embedding, multi-path relationship, node profile information, RNN","Social network embedding, namely, embedding social network nodes into a low-dimensional space, is the foundation of social network analysis, such as node classification and link prediction. Although many existing methods attempt to address this task, most of them only consider the shallow relationship between two nodes in the network, which ignore capturing multiple and semantic-rich social relationships between users. To this end, we define such multiple and semantic-rich relationships as multi-path relationships, and propose a multi-path relationship preserved social network embedding method named MPR-SNE, which is based on the recurrent neural network framework that incorporates both social network structure and node profile information. Specifically, we first utilize random walks to explore the multiple social relationship paths between nodes. Then, a new recurrent unit called bi-directional multi-path relationship unit is proposed to better capture the properties of multi-path relationships. Finally, two objective functions are designed to seamlessly integrate social network structure and node profile information into node representation. The experimental results on two real-world networks show that MPR-SNE outperforms the state-of-the-art baselines on node classification task and link prediction task."
On Embedding Uncertain Graphs,"Jiafeng Hu, Reynold Cheng, ZhipengHuang, Yixiang Fang, Siqiang Luo",ACM,,"Graph data are prevalent in communication networks, social media, and biological networks. These data, which are often noisy or inexact, can be represented by uncertain graphs, whose edges are associated with probabilities to indicate the chances that they exist. Recently, researchers have studied various algorithms (e.g., clustering, classification, and k-NN) for uncertain graphs. These solutions face two problems: (1) high dimensionality: uncertain graphs are often highly complex, which can affect the mining quality; and (2) low reusability, where an existing mining algorithm has to be redesigned to deal with uncertain graphs. To tackle these problems, we propose a solution called URGE, or UnceRtain Graph Embedding. Given an uncertain graph G, URGE generates G's embedding, or a set of low-dimensional vectors, which carry the proximity information of nodes in G. This embedding enables the dimensionality of G to be reduced, without destroying node proximity information. Due to its simplicity, existing mining solutions can be used on the embedding. We investigate two low- and high-order node proximity measures in the embedding generation process, and develop novel algorithms to enable fast evaluation. To our best knowledge, there is no prior study on the use of embedding for uncertain graphs. We have further performed extensive experiments for clustering, classification, and k-NN on several uncertain graph datasets. Our results show that URGE attains better effectiveness than current uncertain data mining algorithms, as well as state-of-the-art embedding solutions. The embedding and mining performance is also highly efficient in our experiments."
Hierarchical Attention Based Semi-supervised Network Representation Learning,"Jie Liu, Junyi Deng, Guanghui Xu,Zhicheng He",Natural Language Processing and Chinese Computing,"Network representation learning, Hierarchical attention network, Semi-supervised learning","Network Embedding is a process of learning low-dimensional representation vectors of nodes by comprehensively utilizing network characteristics. Besides structure properties, information networks also contain rich external information, such as texts and labels. However, most of the traditional learning methods do not consider this kind of information comprehensively, which leads to the lack of semantics of embeddings. In this paper, we propose a Semi-supervised Hierarchical Attention Network Embedding method, named as SHANE, which can incorporate external information in a semi-supervised manner. First, a hierarchical attention network is used to learn the text-based embeddings according to the content of nodes. Then, the text-based embeddings and the structure-based embeddings are integrated in a closed interaction way. After that, we further introduce the label information of nodes into the embedding learning, which can promote the nodes with the same label closed in the embedding space. Extensive experiments of link prediction and node classification are conducted on two real-world datasets, and the results demonstrate that our method outperforms other comparison methods in all cases."
Search Efficient Binary Network Embedding,"Daokun Zhang, Jie Yin, Xingquan Zhu,Chengqi Zhang",arXiv,"Network embedding, binary coding, search, efficiency","Traditional network embedding primarily focuses on learning a dense vector representation for each node, which encodes network structure and/or node content information, such that off-the-shelf machine learning algorithms can be easily applied to the vector-format node representations for network analysis. However, the learned dense vector representations are inefficient for large-scale similarity search, which requires to find the nearest neighbor measured by Euclidean distance in a continuous vector space. In this paper, we propose a search efficient binary network embedding algorithm called BinaryNE to learn a sparse binary code for each node, by simultaneously modeling node context relations and node attribute relations through a three-layer neural network. BinaryNE learns binary node representations efficiently through a stochastic gradient descent based online learning algorithm. The learned binary encoding not only reduces memory usage to represent each node, but also allows fast bit-wise comparisons to support much quicker network node search compared to Euclidean distance or other distance measures. Our experiments and comparisons show that BinaryNE not only delivers more than 23 times faster search speed, but also provides comparable or better search quality than traditional continuous vector based network embedding methods."
Graph Neighborhood Attentive Pooling,"Zekarias T. Kefato, SarunasGirdzijauskas",arXiv,,"Network representation learning (NRL) is a powerful technique for learning low-dimensional vector representation of high-dimensional and sparse graphs. Most studies explore the structure and metadata associated with the graph using random walks and employ an unsupervised or semi-supervised learning schemes. Learning in these methods is context-free, because only a single representation per node is learned. Recently studies have argued on the sufficiency of a single representation and proposed a context-sensitive approach that proved to be highly effective in applications such as link prediction and ranking. However, most of these methods rely on additional textual features that require RNNs or CNNs to capture high-level features or rely on a community detection algorithm to identify multiple contexts of a node. In this study, without requiring additional features nor a community detection algorithm, we propose a novel context-sensitive algorithm called GAP that learns to attend on different parts of a node's neighborhood using attentive pooling networks. We show the efficacy of GAP using three real-world datasets on link prediction and node clustering tasks and compare it against 10 popular and state-of-the-art (SOTA) baselines. GAP consistently outperforms them and achieves up to ~9% and ~20% gain over the best performing methods on link prediction and clustering tasks, respectively."
Semi-supervisedly Co-embedding Attributed Networks,"Z. Q. Meng, Shangsong Liang, JinyuanFang, Teng Xiao",arXiv,,"Deep generative models (DGMs) have achieved remarkable advances. Semi-supervised variational auto-encoders (SVAE) as a classical DGM offer a principled framework to effectively generalize from small labelled data to large unlabelled ones, but it is difficult to incorporate rich unstructured relationships within the multiple heterogeneous entities. In this paper, to deal with the problem, we present a semi-supervised co-embedding model for attributed networks (SCAN) based on the generalized SVAE for heterogeneous data, which collaboratively learns low-dimensional vector representations of both nodes and attributes for partially labelled attributed networks semi-supervisedly. The node and attribute embeddings obtained in a unified manner by our SCAN can benefit for capturing not only the proximities between nodes but also the affinities between nodes and attributes. Moreover, our model also trains a discriminative network to learn the label predictive distribution of nodes. Experimental results on real-world networks demonstrate that our model yields excellent performance in a number of applications such as attribute inference, user profiling and node classification compared to the state-of-the-art baselines."
Enhanced Network Embeddings via Exploiting Edge Labels,"Haochen Chen, Xiaofei Sun, YingtaoTian, Bryan Perozzi, Muhao Chen,Steven Skiena",arXiv,"network embeddings, network representation learning, social relation","Network embedding methods aim at learning low-dimensional latent representation of nodes in a network. While achieving competitive performance on a variety of network inference tasks such as node classification and link prediction, these methods treat the relations between nodes as a binary variable and ignore the rich semantics of edges. In this work, we attempt to learn network embeddings which simultaneously preserve network structure and relations between nodes. Experiments on several real-world networks illustrate that by considering different relations between different node pairs, our method is capable of producing node embeddings of higher quality than a number of state-of-the-art network embedding methods, as evaluated on a challenging multi-label node classification task."
Network Representation Learning Based on Community and Text Features,"Yu Zhu, Zhonglin Ye, Haixing Zhao, KeZhang",Chinese Computational Linguistics and Natural Language Processing Based on Naturally Annotated Big Data,"Network representation learning, Community and text features, Inductive matrix completion
","Network representation learning (NRL) aims at building a lowdimensional vector for each vertex in a network, which is also increasingly recognized as an important aspect for network analysis. Some current NRL methods only focus on learning representations using the network structure. However, vertices in lots of networks may contain community information or text contents, which could be good for relevant evaluation tasks, such as vertex classification, link prediction and so on. Since it has been proved that DeepWalk is actually equivalent to matrix factorization, we propose community and textenhanced DeepWalk (CTDW) based on the inductive matrix completion algorithm, which incorporates community features and text features of vertices into NRL under the framework of matrix factorization. In experiments, we evaluate the proposed CTDW compared with other state-of-the-art methods on vertex classification. The experimental results demonstrate that CTDW outperforms other baseline methods on three real-world datasets."
Dynamic Embedding on Textual Networks via a Gaussian Process.,"Pengyu Cheng, Yitong Li, Xin-yuanZhang, Liqun Cheng, David A. Carlson,Lawrence Carin",arXiv,,"Textual network embedding aims to learn low-dimensional representations of text-annotated nodes in a graph. Prior work in this area has typically focused on fixed graph structures; however, real-world networks are often dynamic. We address this challenge with a novel end-to-end node-embedding model, called Dynamic Embedding for Textual Networks with a Gaussian Process (DetGP). After training, DetGP can be applied efficiently to dynamic graphs without re-training or backpropagation. The learned representation of each node is a combination of textual and structural embeddings. Because the structure is allowed to be dynamic, our method uses the Gaussian process to take advantage of its non-parametric properties. To use both local and global graph structures, diffusion is used to model multiple hops between neighbors. The relative importance of global versus local structure for the embeddings is learned automatically. With the non-parametric nature of the Gaussian process, updating the embeddings for a changed graph structure requires only a forward pass through the learned model. Considering link prediction and node classification, experiments demonstrate the empirical effectiveness of our method compared to baseline approaches. We further show that DetGP can be straightforwardly and efficiently applied to dynamic textual networks."
Stochastic Training of Graph Convolutional Networks,"Jianfei Chen, Jun Zhu",arXiv,,"Graph convolutional networks (GCNs) are powerful deep neural networks for graph-structured data. However, GCN computes the representation of a node recursively from its neighbors, making the receptive field size grow exponentially with the number of layers. Previous attempts on reducing the receptive field size by subsampling neighbors do not have a convergence guarantee, and their receptive field size per node is still in the order of hundreds. In this paper, we develop control variate based algorithms which allow sampling an arbitrarily small neighbor size. Furthermore, we prove new theoretical guarantee for our algorithms to converge to a local optimum of GCN. Empirical results show that our algorithms enjoy a similar convergence with the exact algorithm using only two neighbors per node. The runtime of our algorithms on a large Reddit dataset is only one seventh of previous neighbor sampling algorithms."
SWAG: Item Recommendations using Convolutions on Weighted Graphs,"Amit Pande, Kai Ni, Venkataramani Kini",arXiv,"Learning, Data Mining, Graph Embeddings","Recent advancements in deep neural networks for graph-structured data have led to state-of-the-art performance on recommender system benchmarks. In this work, we present a Graph Convolutional Network (GCN) algorithm SWAG (Sample Weight and AGgregate), which combines efficient random walks and graph convolutions on weighted graphs to generate embeddings for nodes (items) that incorporate both graph structure as well as node feature information such as item-descriptions and item-images. The three important SWAG operations that enable us to efficiently generate node embeddings based on graph structures are (a) Sampling of graph to homogeneous structure, (b) Weighting the sampling, walks and convolution operations, and (c) using AGgregation functions for generating convolutions. The work is an adaptation of graphSAGE over weighted graphs. We deploy SWAG at Target and train it on a graph of more than 500K products sold online with over 50M edges. Offline and online evaluations reveal the benefit of using a graph-based approach and the benefits of weighing to produce high quality embeddings and product recommendations."
Jointly Learning Representations of Nodes and Attributes for Attributed Networks,"Zaiqiao Meng, Shangsong Liang,Xiangliang Zhang, Richard McCreadie,Iadh Ounis",ACM,"Attributed network, network embedding, dynamic embedding, variational auto-encoder","Previous embedding methods for attributed networks aim at learning low-dimensional vector representations only for nodes but not for both nodes and attributes, resulting in the fact that node embeddings cannot be directly used to recover the correlations between nodes and attributes. However, capturing such correlations by embeddings is of great importance for many real-world applications, such as attribute inference and user profiling. Moreover, in real-world scenarios, many attributed networks evolve over time, with their nodes, links, and attributes changing from time to time. In this article, we study the problem of jointly learning low-dimensional representations of both nodes and attributes for static and dynamic attributed networks. To address this problem, we propose a Co-embedding model for Static Attributed Networks (CSAN), which jointly learns low-dimensional representations of both attributes and nodes in the same semantic space such that their affinities can be effectively captured and measured, and a Co-embedding model for Dynamic Attributed Networks (CDAN) to dynamically track low-dimensional representations of nodes and attributes over time. To obtain effective embeddings, both our co-embedding models, CSAN and CDAN, embed each node and attribute with means and variances of Gaussian distributions via variational auto-encoders. Our CDAN model formulates the dynamic changes of a dynamic attributed network by aggregating perturbation features from the nodes’ local neighborhoods as well as attributes’ associations such that the evolving patterns of the given network can be tracked. Experimental results on real-world networks demonstrate that our proposed embedding models outperform state-of-the-art non-dynamic and dynamic embedding models."
Deep Recursive Network Embedding with Regular Equivalence,"Ke Tu, Peng Cui, Xiao Wang, Philip S.Yu, Wenwu Zhu",ACM,"network embedding, regular equivalence, recurrent neural network","Network embedding aims to preserve vertex similarity in an embedding space. Existing approaches usually define the similarity by direct links or common neighborhoods between nodes, i.e. structural equivalence. However, vertexes which reside in different parts of the network may have similar roles or positions, i.e. regular equivalence, which is largely ignored by the literature of network embedding. Regular equivalence is defined in a recursive way that two regularly equivalent vertexes have network neighbors which are also regularly equivalent. Accordingly, we propose a new approach named Deep Recursive Network Embedding (DRNE) to learn network embeddings with regular equivalence. More specifically, we propose a layer normalized LSTM to represent each node by aggregating the representations of their neighborhoods in a recursive way. We theoretically prove that some popular and typical centrality measures which are consistent with regular equivalence are optimal solutions of our model. This is also demonstrated by empirical results that the learned node representations can well predict the indexes of regular equivalence and related centrality scores. Furthermore, the learned node representations can be directly used for end applications like structural role classification in networks, and the experimental results show that our method can consistently outperform centrality-based methods and other state-of-the-art network embedding methods."
Dynamic Network Embeddings for Network Evolution Analysis,"Chuanchang Chen, Yubo Tao, Hai Lin",arXiv,"Dynamic networks, dynamic network embeddings, network structural analysis, temporal evolving nodes","Network embeddings learn to represent nodes as low-dimensional vectors to preserve the proximity between nodes and communities of the network for network analysis. The temporal edges (e.g., relationships, contacts, and emails) in dynamic networks are important for network evolution analysis, but few existing methods in network embeddings can capture the dynamic information from temporal edges. In this paper, we propose a novel dynamic network embedding method to analyze evolution patterns of dynamic networks effectively. Our method uses random walk to keep the proximity between nodes and applies dynamic Bernoulli embeddings to train discrete-time network embeddings in the same vector space without alignments to preserve the temporal continuity of stable nodes. We compare our method with several state-of-theart methods by link prediction and evolving node detection, and the experiments demonstrate that our method generally has better performance in these tasks. Our method is further verified by two real-world dynamic networks via detecting evolving nodes and visualizing their temporal trajectories in the embedded space."
GraphVite: A High-Performance CPU-GPU Hybrid System for Node Embedding,"Zhaocheng Zhu, Shizhen Xu, Meng Qu,Jian Tang",arXiv,"Unsupervised node embedding, parallel processing, scalability, graphics processing unit","Learning continuous representations of nodes is attracting growing interest in both academia and industry recently, due to their simplicity and effectiveness in a variety of applications. Most of existing node embedding algorithms and systems are capable of processing networks with hundreds of thousands or a few millions of nodes. However, how to scale them to networks that have tens of millions or even hundreds of millions of nodes remains a challenging problem. In this paper, we propose GraphVite, a high-performance CPU-GPU hybrid system for training node embeddings, by co-optimizing the algorithm and the system. On the CPU end, augmented edge samples are parallelly generated by random walks in an online fashion on the network, and serve as the training data. On the GPU end, a novel parallel negative sampling is proposed to leverage multiple GPUs to train node embeddings simultaneously, without much data transfer and synchronization. Moreover, an efficient collaboration strategy is proposed to further reduce the synchronization cost between CPUs and GPUs. Experiments on multiple real-world networks show that GraphVite is super efficient. It takes only about one minute for a network with 1 million nodes and 5 million edges on a single machine with 4 GPUs, and takes around 20 hours for a network with 66 million nodes and 1.8 billion edges. Compared to the current fastest system, GraphVite is about 50 times faster without any sacrifice on performance."
Feature Hashing for Network Representation Learning,"Qixiang Wang, Shanfeng Wang,Maoguo Gong, Yue Wu",IJCAI,,"The goal of network representation learning is to embed nodes so as to encode the proximity structures of a graph into a continuous low-dimensional feature space. In this paper, we propose a novel algorithm called node2hash based on feature hashing for generating node embeddings. This approach follows the encoder-decoder framework. There are two main mapping functions in this framework. The first is an encoder to map each node into high-dimensional vectors. The second is a decoder to hash these vectors into a lower dimensional feature space. More specifically, we firstly derive a proximity measurement called expected distance as target which combines position distribution and co-occurrence statistics of nodes over random walks so as to build a proximity matrix, then introduce a set of T different hash functions into feature hashing to generate uniformly distributed vector representations of nodes from the proximity matrix. Compared with the existing state-ofthe-art network representation learning approaches, node2hash shows a competitive performance on multi-class node classification and link prediction tasks on three real-world networks from various domains."
On Applying Meta-path for Network Embedding in Mining Heterogeneous DBLPNetwork,"Akash Anil, Uppinder Chugh, SanasamRanbir Singh",arXiv,"Heterogeneous Network, Meta-path, Network Embedding, DBLP, Co-authorship, Classification","In recent time, applications of network embedding in mining real-world information network have been widely reported in the literature. Majority of the information networks are heterogeneous in nature. Meta-path is one of the popularly used approaches for generating embedding in heterogeneous networks. As meta-path guides the models towards a specific sub-structure, it tends to lose some hetero- geneous characteristics inherently present in the underlying network. In this paper, we systematically study the effects of different meta-paths using different state-of-art network embedding methods (Metapath2vec, Node2vec, and VERSE) over DBLP bibliographic network and evaluate the performance of embeddings using two applications (co-authorship prediction and authors research area classification tasks). From various experimental observations, it is evident that embedding using different meta-paths perform differently over different tasks. It shows that meta- paths are task-dependent and can not be generalized for different tasks. We further observe that embedding obtained after considering all the node and relation types in bibliographic network outperforms its meta- path based counterparts."
RaRE: Social Rank Regulated Large-scale Network Embedding,"Yupeng Gu, Yizhou Sun, Yanen Li, YangYang",IW3C2,"Network embedding, social rank, representation learning","Network embedding algorithms that map nodes in a network into a low-dimensional vector space are prevalent in recent years, due to their superior performance in many network-based tasks, such as clustering, classification, and link prediction. The main assumption of existing algorithms is that the learned latent representation for nodes should preserve the structure of the network, in terms of firstorder or higher-order connectivity. In other words, nodes that are more similar will have higher probability to connect to each other. This phenomena is typically explained as homophily in network science. However, there is another factor usually neglected by the existing embedding algorithms, which is the popularity of a node. For example, celebrities in a social network usually receive numerous followers, which cannot be fully explained by the similarity of the two users. We denote this factor with the terminology “social rank”. We then propose a network embedding model that considers both of the two factors in link generation, and learn proximity-based embedding and social rank-based embedding separately. Rather than simply treating these two factors independent with each other, a carefully designed link generation model is proposed, which explicitly models the interdependency between these two types of embeddings. Experiments on several real-world datasets across different domains demonstrate the superiority of our novel network embedding model over the state-of-the-art methods."
Dynamic Network Embedding: AnExtended Approach for Skip-gram based Network Embedding,"Lun Du, Yun Wang, Guojie Song,Zhicong Lu, Junshan Wang",IJCAI,,"Network embedding, as an approach to learn lowdimensional representations of vertices, has been proved extremely useful in many applications. Lots of state-of-the-art network embedding methods based on Skip-gram framework are efficient and effective. However, these methods mainly focus on the static network embedding and cannot naturally generalize to the dynamic environment. In this paper, we propose a stable dynamic embedding framework with high efficiency. It is an extension for the Skip-gram based network embedding methods, which can keep the optimality of the objective in the Skip-gram based methods in theory. Our model can not only generalize to the new vertex representation, but also update the most affected original vertex representations during the evolvement of the network. Multi-class classification on three real-world networks demonstrates that, our model can update the vertex representations efficiently and achieve the performance of retraining simultaneously. Besides, the visualization experimental result illustrates that, our model is capable of avoiding the embedding space drifting."
dyngraph2vec: Capturing Network Dynamics using Dynamic Graph Representation Learning,"Palash Goyal, Sujit Rokka Chhetri,Arquimedes Canedo",arXiv,"Graph embedding techniques, Graph embedding applications, Python Graph Embedding Methods GEM Library","Learning graph representations is a fundamental task aimed at capturing various properties of graphs in vector space. The most recent methods learn such representations for static networks. However, real world networks evolve over time and have varying dynamics. Capturing such evolution is key to predicting the properties of unseen networks. To understand how the network dynamics affect the prediction performance, we propose an embedding approach which learns the structure of evolution in dynamic graphs and can predict unseen links with higher precision. Our model, dyngraph2vec, learns the temporal transitions in the network using a deep architecture composed of dense and recurrent layers. We motivate the need of capturing dynamics for prediction on a toy data set created using stochastic block models. We then demonstrate the efficacy of dyngraph2vec over existing state-of-the-art methods on two real world data sets. We observe that learning dynamics can improve the quality of embedding and yield better performance in link prediction."
On representation power of neural network-based graph embedding and beyond,"Akifumi Okuno, Hidetoshi Shimodaira",arXiv,,"We consider the representation power of siamese-style similarity functions used in neural network-based graph embedding. The inner product similarity (IPS) with feature vectors computed via neural networks is commonly used for representing the strength of association between two nodes. However, only a little work has been done on the representation capability of IPS. A very recent work shed light on the nature of IPS and reveals that IPS has the capability of approximating any positive definite (PD) similarities. However, a simple example demonstrates the fundamental limitation of IPS to approximate non-PD similarities. We then propose a novel model named Shifted IPS (SIPS) that approximates any Conditionally PD (CPD) similarities arbitrary well. CPD is a generalization of PD with many examples such as negative Poincaré distance and negative Wasserstein distance, thus SIPS has a potential impact to significantly improve the applicability of graph embedding without taking great care in configuring the similarity function. Our numerical experiments demonstrate the SIPS's superiority over IPS. In theory, we further extend SIPS beyond CPD by considering the inner product in Minkowski space so that it approximates more general similarities."
Dynamic Joint Variational Graph Autoencoders,"Sedigheh Mahdavi, Shima Khoshraftar,Aijun An",arXiv,"Graph Representation, Network Embedding, Generative Model, Dynamic Networks, Variational Autoencoder","Learning network representations is a fundamental task for many graph applications such as link prediction, node classification, graph clustering, and graph visualization. Many real-world networks are interpreted as dynamic networks and evolve over time. Most existing graph embedding algorithms were developed for static graphs mainly and cannot capture the evolution of a large dynamic network. In this paper, we propose Dynamic joint Variational Graph Autoencoders (Dyn-VGAE) that can learn both local structures and temporal evolutionary patterns in a dynamic network. Dyn-VGAE provides a joint learning framework for computing temporal representations of all graph snapshots simultaneously. Each auto-encoder embeds a graph snapshot based on its local structure and can also learn temporal dependencies by collaborating with other autoencoders. We conduct experimental studies on dynamic real-world graph datasets and the results demonstrate the effectiveness of the proposed method."
Learning Graph Representation: A Comparative Study,"Wael al Etaiwi, Arafat Awajan",IEEE,"graph representation learning, graph embedding, random walk","Graphs are ubiquitous and allow us to model entities and the relationships between them. Graph data is often observed directly in the natural world (e.g., telecommunication or social networks), and the success of many machine learning tasks such as classification, link prediction, and many others, depends mainly on learning a useful feature representation from graph. This study investigates several research studies that have been conducted in the field of graph representation learning. The growing attention in graph representation learning and graph embedding in recent years raise the need for comparing the existing methods in terms of methodology and techniques. This paper summarizes the recent techniques and methods used for graph representation learning, and compare them together"
Non-link Preserving Network Embedding using Subspace Learning for Network Reconstruction,"Pradumn Kumar Pandey, SourangshuBhattacharya, Niloy Ganguly",ACM,"Network Representation Learning, Link Prediction, Network reconstruction","Learning meaningful vector representations of nodes of a network has been a subject of intense study in the past few years, with various objectives such as node or link labeling, preserving higher order structures, etc. In this paper, we focus on reconstruction of adjacency matrix, which also leads to preservation of higher order structures, through spectral distance. Methodologically, existing techniques focus on construction of various neighborhoods based on the link-structure, but do not explicitly give importance to nonlinks. Our method, called the subspace learning method (SLM), is based on a simple observation that in addition to representations of neighbors sharing a common subspace, representations of non-neighbors should lie in each others’ null-space. We devise an efficient, negative sampling based algorithm for learning the node representations. Experimental results on many real world benchmark networks show surprising improvement in both reconstruction error and spectral distance over state of the art methods. Moreover, we show that the representations given by SLM perform better than state of the art representations on the tasks of community detection and link prediction."
"Graph Embedding on Biomedical Networks: Methods, Applications, and Evaluations","Xiang Yue, Zhen Wang, Jingong Huang,Srinivasan Parthasarathy, SoheilMoosavinasab, Yungui Huang, SimonM. Lin, Wen Zhang, Ping Zhang, HuanSun",arXiv,,"Graph embedding learning that aims to automatically learn low-dimensional node representations, has drawn increasing attention in recent years. To date, most recent graph embedding methods are evaluated on social and information networks and are not comprehensively studied on biomedical networks under systematic experiments and analyses. On the other hand, for a variety of biomedical network analysis tasks, traditional techniques such as matrix factorization (which can be seen as a type of graph embedding methods) have shown promising results, and hence there is a need to systematically evaluate the more recent graph embedding methods (e.g. random walk-based and neural network-based) in terms of their usability and potential to further the state-of-the-art. We select 11 representative graph embedding methods and conduct a systematic comparison on 3 important biomedical link prediction tasks: drug-disease association (DDA) prediction, drug-drug interaction (DDI) prediction, protein-protein interaction (PPI) prediction; and 2 node classification tasks: medical term semantic type classification, protein function prediction. Our experimental results demonstrate that the recent graph embedding methods achieve promising results and deserve more attention in the future biomedical graph analysis. Compared with three state-of-the-art methods for DDAs, DDIs and protein function predictions, the recent graph embedding methods achieve competitive performance without using any biological features and the learned embeddings can be treated as complementary representations for the biological features. By summarizing the experimental results, we provide general guidelines for properly selecting graph embedding methods and setting their hyper-parameters for different biomedical tasks."
Label Aware Graph Convolutional Network- Not All Edges Deserve Your Attention,"Hao Chen, Lei Wang, Senzhang Wang,Dijun Luo, Wenbing Huang, Zhoujun Li",arXiv,,"Graph classification is practically important in many domains. To solve this problem, one usually calculates a low-dimensional representation for each node in the graph with supervised or unsupervised approaches. Most existing approaches consider all the edges between nodes while overlooking whether the edge will brings positive or negative influence to the node representation learning. In many real-world applications, however, some connections among the nodes can be noisy for graph convolution, and not all the edges deserve your attention. In this work, we distinguish the positive and negative impacts of the neighbors to the node in graph node classification, and propose to enhance the graph convolutional network by considering the labels between the neighbor edges. We present a novel GCN framework, called Label-aware Graph Convolutional Network (LAGCN), which incorporates the supervised and unsupervised learning by introducing the edge label predictor. As a general model, LAGCN can be easily adapted in various previous GCN and enhance their performance with some theoretical guarantees. Experimental results on multiple real-world datasets show that LAGCN is competitive against various state-of-the-art methods in graph classification."
A Method for Learning Representations of Signed Networks,Inzamam Rahaman,ACM,"Network Embeddings, Latent Representations, Feature Learning, Signed Networks","Recently there has been significant interest in low dimensional representations of graphs that can then be exploited by machine learning and data mining techniques. The geometric relationships within these learned representations should reflect those between nodes in the original graph. Most work has concentrated on unsigned graphs, which only model positive relationships. However, such techniques can be inadequate for signed graphs, which model both positive and negative relationships. In this work in progress paper, we present a method - StEM (Signed neTwork Embedding Model) - for learning representations of signed networks that achieves improved performance on tasks such as visualization, node classification and signed link prediction."
Multi-granularity Network Representation Learning Based on Game Theory,"Hang Shu, Qun Liu, Shuyin Xia",IEEE,"feature learning, structural identity, homophily, multi-granularity, game theory","The study of embedding large information networks into low-dimensional vector spaces has been going on for several years. However, current feature learning methods are not sufficient to simultaneously capture the structural identity and homophily of nodes in the network. We propose Multi-granularity Network Representation Learning (MGNRL), a novel and flexible framework to learn the latent representations of nodes. Firstly, nodes are divided into different granular layers according to their importance by MGNRL, and the neighborhood structures of nodes are considered to encode their similarities. Then a random walk procedure is designed to explore nodes on different granularity layers, and the public goods game theory is introduced to adjust the probability of random walk continuously. MGNRL overcomes the limitations of existing methods by simultaneously capturing the structural identity and homophily of network nodes. Experiments show that MGNRL performs well in many tasks such as visualization, node classification and link prediction."
An Optimized Network Representation Learning Algorithm Using Multi-Relational Data,"Zhonglin Ye, Haixing Zhao, Ke Zhang,Yu Zhu, Zhaoyang Wang",Mathematics,"network representation, network embedding, representation learning, knowledge representation, joint learning","Representation learning aims to encode the relationships of research objects into lowdimensional, compressible, and distributed representation vectors. The purpose of network representation learning is to learn the structural relationships between network vertices. Knowledge representation learning is oriented to model the entities and relationships in knowledge bases. In this paper, we first introduce the idea of knowledge representation learning into network representation learning, namely, we propose a new approach to model the vertex triplet relationships based on DeepWalk without TransE. Consequently, we propose an optimized network representation learning algorithm using multi-relational data, MRNR, which introduces the multi-relational data between vertices into the procedures of network representation learning. Importantly, we adopted a kind of higher order transformation strategy to optimize the learnt network representation vectors. The purpose of MRNR is that multi-relational data (triplets) can effectively guide and constrain the procedures of network representation learning. The experimental results demonstrate that the proposed MRNR can learn the discriminative network representations, which show better performance on network classification, visualization, and case study tasks compared to the proposed baseline algorithms in this paper."
A Meta-Strategy Enhancement for Network Embedding,"Hengliang Wang, Yuan Li, ChenFeiZhao, Yanwu Zhang, Kedian Mu",IEEE,"Network data, Network Embedding, Meta Learning ","Network embedding, which learns continuous lowdimension representations of nodes, provides an effective way for many network analysis tasks, such as node classification and link prediction. Most existing models are time-consuming and cannot be applied to dynamic networks. To alleviate these issues, we apply Arora’s sentence2vec model to network embedding to enhance the performance of existing network embedding methods. Under the same framework of the sentence2vec, we name the network embedding method MNE2, which allows us to leverage the latent representation obtained from a given embedding approach to learn enhanced node embeddings in a network. Taking into account interactions between nodes in the network, the enhanced network embedding can be viewed as the latent factors for generating embedding representations of neighbor nodes. Then, PCA is applied to modify the embedding results to make the enhanced embeddings more expressive. We evaluate MNE2 on three real-world social network datasets for node classification and link prediction tasks. The results show that MNE2 can outperform state-of-the-art network embedding learning methods in both tasks."
PRUNE: Preserving Proximity and Global Ranking for Network Embedding,"Yi-An Lai, Chin-Chi Hsu, Wen-Hao Chen,Mi-Yen Yeh, Shou-de Lin",NIPS,,"We investigate an unsupervised generative approach for network embedding. A multi-task Siamese neural network structure is formulated to connect embedding vectors and our objective to preserve the global node ranking and local proximity of nodes. We provide deeper analysis to connect the proposed proximity objective to link prediction and community detection in the network. We show our model can satisfy the following design properties: scalability, asymmetry, unity and simplicity. Experiment results not only verify the above design properties but also demonstrate the superior performance in learning-to-rank, classification, regression, and link prediction tasks."
EsiNet: Enhanced Network Representation via Further Learning the Semantic Information of Edges,"Anqing Zheng, Chong Feng, Fang Yang,Hui Bin Zhang",IEEE,"network representation learning, social relation extraction, multi-label classification","Network representation learning (NRL) is a crucial method to learn low-dimensional vertex representations to capture network information. However, conventional NRL models only regard each edge as a binary or continuous value while neglecting the rich semantic information on edges. To enhance network representation for Social Relation Extraction (SRE) task, we present a novel deep neural network based model, EsiNet, by learning the structure and semantic information of edges simultaneously. Compared with previous work, EsiNet focuses on further learning the interactions between vertices and capturing the correlations between labels. By jointly optimizing the objective function of these two components, EsiNet can preserve both the semantic and structural information of edges. Extensive experiments on several public datasets demonstrate that EsiNet outperforms other baselines significantly, by around 3% to 5% on hits@10 absolutely."
Vertex-Context Sampling for Weighted Network Embedding,"Chih-Ming Chen, Yi-Hsuan Yang, YianChen, Ming-Feng Tsai",arXiv,"Vertex Sampling, Network Embedding","In recent years, network embedding methods have garnered increasing attention because of their effectiveness in various information retrieval tasks. The goal is to learn low-dimensional representations of vertexes in an information network and simultaneously capture and preserve the network structure. Critical to the performance of a network embedding method is how the edges/vertexes of the network is sampled for the learning process. Many existing methods adopt a uniform sampling method to reduce learning complexity, but when the network is non-uniform (i.e. a weighted network) such uniform sampling incurs information loss. The goal of this paper is to present a generalized vertex sampling framework that works seamlessly with most existing network embedding methods to support weighted instead of uniform vertex/edge sampling. For efficiency, we propose a delicate sequential vertex-to-context graph data structure, such that sampling a training pair for learning takes only constant time. For scalability and memory efficiency, we design the graph data structure in a way that keeps space consumption low without requiring additional space. In addition to implementing existing network embedding methods, the proposed framework can be used to implement extensions that feature high-order proximity modeling and weighted relation modeling. Experiments conducted on three datasets, including a commercial large-scale one, verify the effectiveness and efficiency of the proposed weighted network embedding methods on a variety of tasks, including word similarity search, multi-label classification, and item recommendation."
Learning Item Embedding with Heterogeneous Information for Collaborative Filtering,"Xiusi Chen, Xiaoyu Li, Chang Zhou,Xiaofei Liu, Jun Gao",,,"Item-based collaborative filtering captures the itemitem similarities via user-item interactions. However, in online platforms with tens of millions items, it is hard to precisely model the similarities since user behavior is very sparse w.r.t large number of items. Items associated with little user behavior are usually not sufficiently modeled. In fact, the similarities between items could be affected by many facts such as their properties like title and description. In this paper, we propose a representation learning based approach that utilizes the heterogeneous information of users, items, and user-item interactions, to bridge the user behavior and item content. The produced representation models the item similarity from multi-aspects, alleviating the problems above. We evaluate on several tasks, deploy our framework onto a real-world recommender system, and run A/B tests on one of the online recommendation services in Alibaba Group, proving our method to be effective and scalable."
Representation Learning for Heterogeneous Information Networks via Embedding Events,"Guoji Fu, Bo Yuan, Qiqi Duan, Xin Yao",arXiv,"Heterogeneous information networks, network representation learning, feature learning","Network representation learning (NRL) has been widely used to help analyze large-scale networks through mapping original networks into a low-dimensional vector space. However, existing NRL methods ignore the impact of properties of relations on the object relevance in heterogeneous information networks (HINs). To tackle this issue, this paper proposes a new NRL framework, called Event2vec, for HINs to consider both quantities and properties of relations during the representation learning process. Specifically, an event (i.e., a complete semantic unit) is used to represent the relation among multiple objects, and both event-driven first-order and second-order proximities are defined to measure the object relevance according to the quantities and properties of relations. We theoretically prove how event-driven proximities can be preserved in the embedding space by Event2vec, which utilizes event embeddings to facilitate learning the object embeddings. Experimental studies demonstrate the advantages of Event2vec over state-of-the-art algorithms on four real-world datasets and three network analysis tasks (including network reconstruction, link prediction, and node classification)."
TransNet: Translation-Based Network Representation Learning for Social Relation Extraction,"Cunchao Tu, Zhengyan Zhang, ZhiyuanLiu, Maosong Sun",IJCAI,,"Conventional network representation learning (NRL) models learn low-dimensional vertex representations by simply regarding each edge as a binary or continuous value. However, there exists rich semantic information on edges and the interactions between vertices usually preserve distinct meanings, which are largely neglected by most existing NRL models. In this work, we present a novel Translation-based NRL model, TransNet, by regarding the interactions between vertices as a translation operation. Moreover, we formalize the task of Social Relation Extraction (SRE) to evaluate the capability of NRL methods on modeling the relations between vertices. Experimental results on SRE demonstrate that TransNet significantly outperforms other baseline methods by 10% to 20% on hits@1."
Learning Multiple Temporal Relational Network Embeddings via Graph Convolutional Network,"Kecheng Xiao, Pengyu Zhao, YuanxingZhang, Yanzhou Li, Kaigui Bian, WeiYan",IEEE,"Network embedding, multiple temporal relations, graph convolutional network","In the era of big data, information on relationships changes along with time, and the graphs of relationships captured at consecutive timestamps form the multiple temporal relational (MTR) network. To identify the relations in the network while preserving the network structure, a common solution is to learn the network representations through network embedding methods, and then build the relations upon the similarity among these representations. However, the existing network embedding methods either focus on a single relation or ignore the correlation between the heterogeneous and homogeneous relations, and thus it is difficult to investigate the multiple temporal features in the network. In this paper, we propose a novel network embedding method, named Homo-Hetero Network Embedding (HHNE), for the MTR networks. The HHNE utilizes the Graph Convolutional Network (GCN) to extract homogeneous features from each temporal relational network and then generates the homo-hetero network embeddings by fusing the single temporal relational features through a Multi-Layer Perceptron (MLP). Therefore, HHNE could capture the multi-dimensional characteristics in the network, including both intra-relation information and interrelation information. To show the efficiency of HHNE, we conduct experiments in a real-world dataset on predicting new relations in the MTR networks. The result reveals that our method could outperform several legacy network embedding methods and stateof-the-art multi-relational network embedding methods in the task of relation prediction, demonstrating that the proposed embedding method is more suitable for the MTR network."
Network Embedding based on External Word Vectors,"Xiaokun Zhang, Yan Liu, Jing Chen",IEEE,"network embedding, content information network, auto-encoder, external word vectors","Network embedding, which preserves network’s sophisticated features, aims to effectively learn the lowdimensional embedding of vertices to lower the computing and storage costs. Content information network like Twitter is defined as network with rich text information. Most research about content information network are based on the information of the network itself. By introducing external word vectors into the modeling process, we can make use of the external syntactic and semantic features. In this paper, we propose NE-EWV(Network Embedding based on External Word Vectors), which preserves the feature fusion representation from both semantic feature space as well as structural feature space. Experiments are conducted in three real-world content information network datasets. In link predict task, the AUC increases 7% to 19% compared with the models which only considering the structural features, increases 1% to 12% compared with the model considering structural and text features in most cases."
LHONE: Label Homophily Oriented Network Embedding,"Le Zhang, Xiang Li, Ji Xiang, Ying Qi",IEEE,,"Network embedding is to learn effective lowdimensional vector representations for nodes in a network and has attracted considerable attention in recent years. To date, existing methods mainly focus on network structure information and cannot leverage abundant label information, which is potentially valuable in learning better vector representations. Due to the noise and incompleteness of label information, it is intractable to integrate label information into the vector representations in a partially labeled network. To address this issue, we investigate the effects of label information based on the label homophily. Briefly, label homophily can not only drive nodes sharing similar labels to be connected to each other, but also produce a division of a network into densely-connected, homogeneous parts that are weakly connected to each other. Furthermore, we propose a novel Label Homophily Oriented Network Embedding (LHONE) model to make the best of label homophily by converting a partially labeled network to two bipartite networks, and learning vector representations combined with a Gaussian mixture model (GMM). Extensive experiments on two real-world networks demonstrate the effectiveness of LHONE compared to state-ofthe-art network embedding approaches."
Document Network Projection in Pretrained Word Embedding Space,"Antoine Gourru, Adrien Guille, JulienVelcin, Julien Jacques",arXiv,"Document Network Embedding, Representation Learning","We present Regularized Linear Embedding (RLE), a novel method that projects a collection of linked documents (e.g. citation network) into a pretrained word embedding space. In addition to the textual content, we leverage a matrix of pairwise similarities providing complementary information (e.g., the network proximity of two documents in a citation graph). We first build a simple word vector average for each document, and we use the similarities to alter this average representation. The document representations can help to solve many information retrieval tasks, such as recommendation, classification and clustering. We demonstrate that our approach outperforms or matches existing document network embedding methods on node classification and link prediction tasks. Furthermore, we show that it helps identifying relevant keywords to describe document classes."
Link Prediction with Mutual Attention for Text-Attributed Networks,"Robin Brochier, Adrien Guille, JulienVelcin",arXiv,"representation learning, link prediction, attributed network, natural language processing","In this extended abstract, we present an algorithm that learns a similarity measure between documents from the network topology of a structured corpus. We leverage the Scaled Dot-Product Attention, a recently proposed attention mechanism, to design a mutual attention mechanism between pairs of documents. To train its parameters, we use the network links as supervision. We provide preliminary experiment results with a citation dataset on two prediction tasks, demonstrating the capacity of our model to learn a meaningful textual similarity."
"Representation Learning on Networks: Theories, Algorithms, and Applications","Jie Tang, Yuxiao Dong",IW3C2,"Network Embedding, Representation Learning, Graph Neural Networks, Feature Learning, Graph Mining, Network Science","Network representation learning offers a revolutionary paradigm for mining and learning with network data. In this tutorial, we will give a systematic introduction for representation learning on networks. We will start the tutorial with industry examples from Alibaba, AMiner, Microsoft Academic, WeChat, and XueTangX to explain how network analysis and graph mining on the Web are benefiting from representation learning. Then we will comprehensively introduce both the history and recent advances on network representation learning, such as network embedding and graph neural networks. Uniquely, this tutorial aims to provide the audience with the underlying theories in network representation learning, as well as our experience in translating this line of research into real-world applications on the Web. Finally, we will release public datasets and benchmarks for open and reproducible network representation learning research."
Network Sampling Using k-hop Random Walks for Heterogeneous Network Embedding,"Akash Anil, Ajay Ladhar, SandeepSingh, Uppinder Chugh, SanasamRanbir Singh",arXiv,"Heterogeneous Network, Random Walk, Network Embedding, DBLP, Co-authorship, Network Sampling","Sampling a network is an important prerequisite for unsupervised network embedding. Further, random walk has widely been used for sampling in previous studies. Since random walk based sampling tends to traverse adjacent neighbors, it may not be suitable for heterogeneous network because in heterogeneous networks two adjacent nodes often belong to different types. Therefore, this paper proposes a K-hop random walk based sampling approach which includes a node in the sample list only if it is separated by K hops from the source node. We exploit the samples generated using K-hop random walker for network embedding using skip-gram model (word2vec). Thereafter, the performance of network embedding is evaluated on co-authorship prediction task in heterogeneous DBLP network. We compare the efficacy of network embedding exploiting proposed sampling approach with recently proposed best performing network embedding models namely, Metapath2vec and Node2vec. It is evident that the proposed sampling approach yields better quality of embeddings and out-performs baselines in majority of the cases."
Learning Embeddings of Intersections on Road Networks,"Meng-xiang Wang, Wang-Chien Lee,Tao-Yang Fu, Ge Yu",ACM,"Road network, Representation learning, Neural network, Intelligent transportation systems","Road network is a basic component of intelligent transportation systems (ITS) in smart city. Informative representation of road networks is important as it is essential to a wide variety of ITS applications. In this paper, we propose a neural network representation learning model, namely Intersection of Road Network to Vector (IRN2Vec), to learn embeddings of road intersections that encode rich information in a road network by exploring geo-locality and intrinsic properties of intersections and moving behaviors of road users. In addition to model design, several issues unique to IRN2Vec, including data preparation for model training and various relationships among intersections, are examined. We evaluate the learned embeddings via extensive experiments on three real-world datasets using three downstream test cases, including prediction of traffic signals and crossings on intersections and travel time estimation. Experimental results show that the proposed IRN2Vec outperforms three existing methods, DeepWalk, LINE and Node2vec, in terms of F1-score in predicting traffic signals (22.21% to 23.84%) and crossings (8.65% to 11.65%), and mean absolute error (MAE) in travel time estimation (9.87% to 19.28%)."
A Structure-Enriched Neural Network for network embedding,"Lisheng Qiao, Hongke Zhao, XiaohuiHuang, Kai Li, Enhong Chen",Expert Systems with Applications,,"Recent years have witnessed the importance of network embedding in many fields, as well as increased attention in academia. Although a number of algorithms have been proposed in this area, most existing models which only utilize the structure topology information of networks often suffer performance losses because of their insufficiency with regard to selecting structure similar patterns, handling noise data, and/or capturing non-linear or high-order structure information. To address these challenges, in this paper, we present a novel Structure-Enriched Neural Network (SENN) for network embedding. Specifically, SENN can not only capture the complex structure similar patterns observed in networks by introducing direction adjustment parameters of the transition probability, but also introduce a stacked denoise autoencoder to perform the dimension reduction for each order matrix independently. Therefore, SENN can preserve more useful structure information and make the embeddings more robust. Moreover, SENN can effectively integrate the multi-order structure information by the combining layer with attention mechanism. Finally, to compare with other state-of-the-art methods, we conduct extensive experiments with both synthetic and real-world datasets on various tasks (e.g.,node classification, visualization). The experimental results clearly demonstrate the effectiveness of our proposed model for network embedding."
Impact of the Query Set on the Evaluation of Expert Finding Systems,"Robin Brochier, Adrien Guille, BenjaminRothan, Julien Velcin",arXiv,"expert finding, recommender system, evaluation","Expertise is a loosely defined concept that is hard to formalize. Much research has focused on designing efficient algorithms for expert finding in large databases in various application domains. The evaluation of such recommender systems lies most of the time on human-annotated sets of experts associated with topics. The protocol of evaluation consists in using the namings or short descriptions of these topics as raw queries in order to rank the available set of candidates. Several measures taken from the field of information retrieval are then applied to rate the rankings of candidates against the ground truth set of experts. In this paper, we apply this topic-query evaluation methodology with the AMiner data and explore a new document-query methodology to evaluate experts retrieval from a set of queries sampled directly from the experts documents. Specifically, we describe two datasets extracted from AMiner, three baseline algorithms from the literature based on several document representations and provide experiment results to show that using a wide range of more realistic queries provides different evaluation results to the usual topic-queries."
New Datasets and a Benchmark of Document Network Embedding Methods for Scientific Expert Finding,"Robin Brochier, Antoine Gourru, AdrienGuille, Julien Velcin",arXiv,,"The scientific literature is growing faster than ever. Finding an expert in a particular scientific domain has never been as hard as today because of the increasing amount of publications and because of the ever growing diversity of expertise fields. To tackle this challenge, automatic expert finding algorithms rely on the vast scientific heterogeneous network to match textual queries with potential expert candidates. In this direction, document network embedding methods seem to be an ideal choice for building representations of the scientific literature. Citation and authorship links contain major complementary information to the textual content of the publications. In this paper, we propose a benchmark for expert finding in document networks by leveraging data extracted from a scientific citation network and three scientific question & answer websites. We compare the performances of several algorithms on these different sources of data and further study the applicability of embedding methods on an expert finding task."
User Tagging in MOOCs Through Network Embedding,"Chaoyang Li, Zhengyang Song, JieTang",IEEE,"Massive open online courses, Network embedding, Heterogeneous network, Tag recommendation","Tags are used everywhere nowadays in popular systems and play very important role due to the semantic meanings they provide. For example, people use hash tags in Twitter to group relevant topics together. XuetangX, which is one of the largest MOOC platforms in China, also assign tags to the available courses to illustrate their disciplinary affiliations. Data analysis shows that users tend to enroll in courses under the same tag group as their previous enrollments. In this work, we research the problem of user tagging employing the usercourse-tag heterogeneous network from XuetangX, where the tags are course categories. We employ multiple network embedding models to learn vector representations of users, courses and tags, from the network user-course-tag, and find that representations learned by node2vec performs best. Offline experiments show that the resulting personalized tag recommendation can further help other tasks like course recommendation. This function has also been deployed online to XuetangX, and promising results have been observed."
Discrete Network Embedding,"Xiaobo Shen, Shirui Pan, Weiwei Liu,Yew-Soon Ong, Quan-Sen Sun",IJCAI,,"Network embedding aims to seek low-dimensional vector representations for network nodes, by preserving the network structure. The network embedding is typically represented in continuous vector, which imposes formidable challenges in storage and computation costs, particularly in largescale applications. To address the issue, this paper proposes a novel discrete network embedding (DNE) for more compact representations. In particular, DNE learns short binary codes to represent each node. The Hamming similarity between two binary embeddings is then employed to well approximate the ground-truth similarity. A novel discrete multi-class classifier is also developed to expedite classification. Moreover, we propose to jointly learn the discrete embedding and classifier within a unified framework to improve the compactness and discrimination of network embedding. Extensive experiments on node classification consistently demonstrate that DNE exhibits lower storage and computational complexity than state-ofthe-art network embedding methods, while obtains competitive classification results."
Document Network Embedding: Coping for Missing Content and Missing Links,"Jean Dupuy, Adrien Guille, JulienJacques",arXiv,"Document network, Document representation, Node representation, Translation","Searching through networks of documents is an important task. A promising path to improve the performance of information retrieval systems in this context is to leverage dense node and content representations learned with embedding techniques. However, these techniques cannot learn representations for documents that are either isolated or whose content is missing. To tackle this issue, assuming that the topology of the network and the content of the documents correlate, we propose to estimate the missing node representations from the available content representations, and conversely. Inspired by recent advances in machine translation, we detail in this paper how to learn a linear transformation from a set of aligned content and node representations. The projection matrix is efficiently calculated in terms of the singular value decomposition. The usefulness of the proposed method is highlighted by the improved ability to predict the neighborhood of nodes whose links are unobserved based on the projected content representations, and to retrieve similar documents when content is missing, based on the projected node representations."
Semantic Proximity Search on Heterogeneous Graph by Proximity Embedding,"Zemin Liu, Vincent Wenchen Zheng,Zhou Zhao, Fanwei Zhu, Kevin Chen-Chuan Chang, Minghui Wu, Jing Ying",AAAI,"semantic proximity search, heterogeneous graph, proximity embedding","Many real-world networks have a rich collection of objects. The semantics of these objects allows us to capture different classes of proximities, thus enabling an important task of semantic proximity search. As the core of semantic proximity search, we have to measure the proximity on a heterogeneous graph, whose nodes are various types of objects. Most of the existing methods rely on engineering features about the graph structure between two nodes to measure their proximity. With recent development on graph embedding, we see a good chance to avoid feature engineering for semantic proximity search. There is very little work on using graph embedding for semantic proximity search. We also observe that graph embedding methods typically focus on embedding nodes, which is an ""indirect'' approach to learn the proximity. Thus, we introduce a new concept of proximity embedding, which directly embeds the network structure between two possibly distant nodes. We also design our proximity embedding, so as to flexibly support both symmetric and asymmetric proximities. Based on the proximity embedding, we can easily estimate the proximity score between two nodes and enable search on the graph. We evaluate our proximity embedding method on three real-world public data sets, and show it outperforms the state-of-the-art baselines."
Topological Deep Network Embedding,"Mohammadreza Radmanesh, AhmadAsgharian Rezaei, Nameer Al Khafaf,Mahdi Jalili",IEEE,"Graph embedding, network analysis, topological deep network embedding, deep learning","Graph mining methods have been used to analyze complex network systems. However, with the increase in the complexity and dimensions of these networks, it is often required to have access to high computational processing to extract insights from networks. As such, it becomes vital to map complex graph into low dimensional vector space. Network embedding has been used to generate representation of graph in feature vector form. This brings many challenges as to what the dimension of the vector space should be, and which structure of the network has to be preserved. In this paper, we propose a semi-supervised deep learning model to generate network representation by preserving local and global structural properties of the network. We test the deep learning model on three datasets and compare it with state-of-the-art embedding methods. The results reveal effectiveness of the proposed method."
DeepDirect: Learning Directions of Social Ties with Edge-Based Network Embedding,"Changping Wang, Changping Wang,Zhen Wang, Xiaojun Ye, Jeffrey Xu Yu,Biwu Wang",IEEE,"Tie direction learning, network embedding, social networks, social ties","There is a lot of research work on social ties, few of which is about the directionality of social ties. However, the directionality is actually a basic but important attribute of social ties. In this paper, we present a supervised learning problem, the tie direction learning (TDL) problem, which aims to learn the directionality function of directed social networks. Two ways are introduced to solve the TDL problem: one is based on hand-crafted features and the other, named DeepDirect, learns the social tie representation through the topological information of the network. In DeepDirect, a novel network embedding approach, which directly maps the social ties to low-dimensional embedding vectors by deep learning techniques, is proposed. DeepDirect embeds the network considering three different aspects: preserving network topology, utilizing labeled data, and generating pseudo-labels based on observed directionality patterns. Two novel applications are proposed for the learned directionality function, i.e., direction discovery on undirected ties and direction quantification on bidirectional ties. Experiments are conducted on five different real-world data sets about these two tasks. The experimental results demonstrate our methods, especially DeepDirect, are effective and promising."
A Comparative Study of Link Prediction Algorithms For Social Networks of Varying Sizes,"Mukund Sood, Srinivas Shekar,Vaishnavi Rao, Bhaskarjyoti Das",IEEE,"link prediction, node embeddings, representation learning, random walk, Node2Vec, DeepWalk","Link prediction in social networks enables us to predict future links in an evolving social network as new nodes get added through the passage of time. It can also help to detect missing edges in the social graph. A successful link prediction method substantially reduces the experimental effort required to establish the topology of a network and can accelerate the mutually beneficial interactions that takes much longer to form by chance. In this work, the various state of art link prediction methods are analyzed while also looking at the kind of networks the algorithms work best with. Different social graph data sets are chosen based on their sizes and sparsity. Subsequently link prediction task on each of these data sets were done using various machine learning algorithms to understand the performance of several random walk based node embedding methods as compared with the performance of several classical approaches. It is found that the sparsity and size of the graph are important factors that determine the performance of random walk based node embedding methods."
On Network Embedding for Machine Learning on Road Networks: A Case Study on the Danish Road Network,"Tobias Skovgaard Jepsen, Christian S.Jensen, Thomas D. Nielsen, KristianTorp",arXiv,"road network, machine learning, feature learning, network embedding","Road networks are a type of spatial network, where edges may be associated with qualitative information such as road type and speed limit. Unfortunately, such information is often incomplete; for instance, OpenStreetMap only has speed limits for 13% of all Danish road segments. This is problematic for analysis tasks that rely on such information for machine learning. To enable machine learning in such circumstances, one may consider the application of network embedding methods to extract structural information from the network. However, these methods have so far mostly been used in the context of social networks, which differ significantly from road networks in terms of, e.g., node degree and level of homophily (which are key to the performance of many network embedding methods). We analyze the use of network embedding methods, specifically node2vec, for learning road segment embeddings in road networks. Due to the often limited availability of information on other relevant road characteristics, the analysis focuses on leveraging the spatial network structure. Our results suggest that network embedding methods can indeed be used for deriving relevant network features (that may, e.g, be used for predicting speed limits), but that the qualities of the embeddings differ from embeddings for social networks."
Network Embedding and Change Modeling in Dynamic Heterogeneous Networks,"Ranran Bian, Yun Sing Koh, GillianDobbie, Anna Divoli",ACM,"Dynamic Heterogeneous Networks, Vectors, Change Modeling","Network embedding learns the vector representations of nodes. Most real world networks are heterogeneous and evolve over time. There are, however, no network embedding approaches designed for dynamic heterogeneous networks so far. Addressing this research gap is beneficial for analyzing and mining real world networks. We develop a novel representation learning method, change2vec, which considers a dynamic heterogeneous network as snapshots of networks with different time stamps. Instead of processing the whole network at each time stamp, change2vec models changes between two consecutive static networks by capturing newly-added and deleted nodes with their neighbour nodes as well as newly-formed or deleted edges that caused core structural changes known as triad closure or open processes. Change2vec leverages metapath based node embedding and change modeling to preserve both heterogeneous and dynamic features of a network. Experimental results show that change2vec outperforms two state-of-the-art methods in terms of clustering performance and efficiency."
Attributed Network Representation Learning Approaches for Link Prediction,"Farzan Masrour, Pang-Ning Tan, Abdol-Hossein Esfahanian, CourtlandVanDam",IEEE,,"Network representation learning algorithms seek to embed the nodes of a network into a lower-dimensional feature space such that nodes that are in close proximity to each other share a similar representation. In this paper, we investigate the effectiveness of using network representation learning algorithms for link prediction problems. Specifically, we demonstrate the limitations of existing algorithms in terms of their ability to accurately predict links between nodes that are in the same or different communities and nodes that have low degrees. We also show that incorporating node attribute information can help alleviate this problem and compare three different approaches to integrate this information with network representation learning for link prediction problems. Using five real-world network datasets, we demonstrate the efficacy of one such approach, called SPIN, that can effectively combine the link structure with node attribute information and predict links between nodes in the same and different communities without favoring high degree nodes."
GEMSEC: Graph Embedding with Self Clustering,"Benedek Rozemberczki, Ryan Davies,Rik Sarkar, Charles A. Sutton",arXiv,"community detection, clustering, node embedding, network embedding, feature extraction","Modern graph embedding procedures can efficiently process graphs with millions of nodes. In this paper, we propose GEMSEC -- a graph embedding algorithm which learns a clustering of the nodes simultaneously with computing their embedding. GEMSEC is a general extension of earlier work in the domain of sequence-based graph embedding. GEMSEC places nodes in an abstract feature space where the vertex features minimize the negative log-likelihood of preserving sampled vertex neighborhoods, and it incorporates known social network properties through a machine learning regularization. We present two new social network datasets and show that by simultaneously considering the embedding and clustering problems with respect to social properties, GEMSEC extracts high-quality clusters competitive with or superior to other community detection algorithms. In experiments, the method is found to be computationally efficient and robust to the choice of hyperparameters."
Learning Network Embedding with Community Structural Information,"Yinping Li, Ying Wang, Tingting Zhang,Jiawei Zhang, Yi Chang",IJCAI,,"Network embedding is an effective approach to learn the low-dimensional representations of vertices in networks, aiming to capture and preserve the structure and inherent properties of networks. The vast majority of existing network embedding methods exclusively focus on vertex proximity of networks, while ignoring the network internal community structure. However, the homophily principle indicates that vertices within the same community are more similar to each other than those from different communities, thus vertices within the same community should have similar vertex representations. Motivated by this, we propose a novel network embedding framework NECS to learn the Network Embedding with Community Structural information, which preserves the highorder proximity and incorporates the community structure in vertex representation learning. We formulate the problem into a principled optimization framework and provide an effective alternating algorithm to solve it. Extensive experimental results on several benchmark network datasets demonstrate the effectiveness of the proposed framework in various network analysis tasks including network reconstruction, link prediction and vertex classification."
Finding Multi-granularity Community Structures in Social Networks Based on Significance of Community Partition,"Chenxu Gong, Guoyin Wang, Jun Hu,Ming Liu, Li Liu, Zihe Yang",IEEE,"multiple granularity, social network analysis, community detection, network embedding, granular computing","Community structure detection is an important and valuable task in social network studies as it is the base for many social network applications such as link prediction, recommendation, etc. Most social networks have an inherent multi-granular structure, which leads to different community structures at different granularities. However, few studies pay attention to such multi-granular characteristics of social networks. In this paper, a method called MGCD (Multi-Granularity Community Detection) is proposed for finding multi-granularity community structures of social networks. At first, a network embedding method is used to obtain the low-dimensional vector representation for each node. Then, an effective embedding-based strategy for weakening the detected community structures is proposed. Finally, a joint learning framework, which combines network embedding and community structure weakening is developed for identifying the multi-granularity community structures of social networks. Experimental results on real-world networks show that MGCD outperforms the state-of-the-art benchmark methods on finding multi-granularity community structure tasks."
N2VSCDNNR: A Local Recommender System Based on Node2vec and Rich Information Network,"Jinyin Chen, Yangyang Wu, Lu Fan,Xiang Lin, Haibin Zheng, Shanqing Yu,Qi Xuan",arXiv,"Spectral Clustering, Node2vec, Recommender System, Bipartite Network, Projection Network","Recommender systems are becoming more and more important in our daily lives. However, traditional recommendation methods are challenged by data sparsity and efficiency, as the numbers of users, items, and interactions between the two in many real-world applications increase fast. In this work, we propose a novel clustering recommender system based on node2vec technology and rich information network, namely N2VSCDNNR, to solve these challenges. In particular, we use a bipartite network to construct the user-item network, and represent the interactions among users (or items) by the corresponding one-mode projection network. In order to alleviate the data sparsity problem, we enrich the network structure according to user and item categories, and construct the one-mode projection category network. Then, considering the data sparsity problem in the network, we employ node2vec to capture the complex latent relationships among users (or items) from the corresponding one-mode projection category network. Moreover, considering the dependency on parameter settings and information loss problem in clustering methods, we use a novel spectral clustering method, which is based on dynamic nearest-neighbors (DNN) and a novel automatically determining cluster number (ADCN) method that determines the cluster centers based on the normal distribution method, to cluster the users and items separately. After clustering, we propose the two-phase personalized recommendation to realize the personalized recommendation of items for each user. A series of experiments validate the outstanding performance of our N2VSCDNNR over several advanced embedding and side information based recommendation algorithms. Meanwhile, N2VSCDNNR seems to have lower time complexity than the baseline methods in online recommendations, indicating its potential to be widely applied in large-scale systems."
Multipath2vec: Predicting Pathogenic Genes via Heterogeneous Network Embedding,"Bo Xu, Yu Liu, Shuo Yu, Lei Wang, LeiLiu, Hongfei Lin, Zhihao Yang, JianWang, Feng Xia",IEEE,"Prediction of pathogenic genes, heterogeneous network embedding, disease-causing genes, PPI","Phenotypically similar diseases have been verified to be in connection with specific genes. Predicting disease genes is important in disease prevention, diagnosis, and treatment. In this work, we focus on this significant issue and propose a diseasecausing genes prediction method called Multipath2vec. First, we generate an heterogeneous network called GP−network, which is constructed based on three kinds of relationships between genes and phenotypes, including interactions between genes, correlations between phenotypes, and known gene-phenotype pairs. Then, we propose the multi-path, which is used to guide random walk in GP−network in order to better embedding the network. Finally, we use the achieved vector representation of each protein and phenotype to calculate and rank the similarities between candidate genes and the target phenotype. We implement Multipath2vec as well as two baseline approaches (i.e., CATAPULT, and PRINCE) on whole gene-phenotype data, single-gene genephenotype data, and many-genes gene-phenotype data. According to leave-one-out cross validation, Multipath2vec achieves better results than baseline approaches. To our best knowledge, this is the first attempt to use heterogeneous network embedding method in handling pathogenic genes. The outperformed experimental results of Multipath2vec shed light on the possibility of applying network representation methods in the disease-causing genes prediction."
Learning Graph Representation via Frequent Subgraphs,"Dang Nguyen, Wei Luo, Tu DinhNguyen, Svetha Venkatesh, Dinh Q.Phung",SIAM,,"We propose a novel approach to learn distributed representation for graph data. Our idea is to combine a recently introduced neural document embedding model with a traditional pattern mining technique, by treating a graph as a document and frequent subgraphs as atomic units for the embedding process. Compared to the latest graph embedding methods, our proposed method offers three key advantages: fully unsupervised learning, entire-graph embedding, and edge label leveraging. We demonstrate our method on several datasets in comparison with a comprehensive list of up-to-date stateof-the-art baselines where we show its advantages for both classification and clustering tasks."
A network embedding model for pathogenic genes prediction by multi-path random walking on heterogeneous network,"Bo Xu, Youfang Liu, Shuo Yu, Lei Wang,Jie Dong, Hongfei Lin, Zhihao Yang,Jiajun Wang, Fan Xia",IEEE,"Prediction of pathogenic genes, Heterogeneous network embedding, Disease-causing genes","Prediction of pathogenic genes is crucial for disease prevention, diagnosis, and treatment. But traditional genetic localization methods are often technique-difficulty and time-consuming. With the development of computer science, computational biology has gradually become one of the main methods for finding candidate pathogenic genes. We propose a pathogenic genes prediction method based on network embedding which is called Multipath2vec. Firstly, we construct an heterogeneous network which is called GP−network. It is constructed based on three kinds of relationships between genes and phenotypes, including correlations between phenotypes, interactions between genes and known gene-phenotype pairs. Then in order to embedding the network better, we design the multi-path to guide random walk in GP−network. The multi-path includes multiple paths between genes and phenotypes which can capture complex structural information of heterogeneous network. Finally, we use the learned vector representation of each phenotype and protein to calculate the similarities and rank according to the similarities between candidate genes and the target phenotype. We implemented Multipath2vec and four baseline approaches (i.e., CATAPULT, PRINCE, Deepwalk and Metapath2vec) on many-genes gene-phenotype data, single-gene gene-phenotype data and whole gene-phenotype data. Experimental results show that Multipath2vec outperformed the state-of-the-art baselines in pathogenic genes prediction task. We propose Multipath2vec that can be utilized to predict pathogenic genes and experimental results show the higher accuracy of pathogenic genes prediction."
RL4HIN: Representation Learning for Heterogeneous Information Networks,"Chunfeng Liu, Jian Yu, Ying Liu, Mei Yu,Ruiguo Yu, Xuewei Li, Mankun Zhao,Tianyi Xu, Hongwei Liu, Linying Xu",IEEE,"Network representation learning, heterogeneous information networks, bidirectional recurrent neural network, skip-dependence","Effectively analyzing and mining large-scale heterogeneous information networks (HINs) by adopting network representation learning (NRL) approaches have received increasing attention. The abundant semantic and structural information contained in HINs not only facilitates network analysis and downstream tasks, but also poses special challenges to well capture that rich information. With the intention to preserve such rich yet potential information during HIN embedding, we first discuss the latent dependence existed in indirect neighbors, then study the different abilities of forward layer and backward layer of bidirectional recurrent neural network to remain semantic of HINs. And finally, we propose a novel representation learning model for HIN, namely RL4HIN. RL4HIN utilizes a skipdependence strategy for enhancing the latent dependence between farther neighbors, and then develops a proposed weighted loss function in order to balance such difference between forward and backward layer. Extensive experiments, including node classification and visualization, have been conducted on two large-scale and real-world HINs. The experimental results show that RL4HIN significantly outperforms several state-of-the-art NRL approaches."
"Meta-Graph Based HIN Spectral Embedding: Methods, Analyses, and Insights","Carl Yang, Yichen Feng, Pan Li, Yu Shi,Jiawei Han",arXiv,,"In this work, we propose to study the utility of different meta-graphs, as well as how to simultaneously leverage multiple meta-graphs for HIN embedding in an unsupervised manner. Motivated by prolific research on homogeneous networks, especially spectral graph theory, we firstly conduct a systematic empirical study on the spectrum and embedding quality of different meta-graphs on multiple HINs, which leads to an efficient method of meta-graph assessment. It also helps us to gain valuable insight into the higher-order organization of HINs and indicates a practical way of selecting useful embedding dimensions. Further, we explore the challenges of combining multiple meta-graphs to capture the multi-dimensional semantics in HIN through reasoning from mathematical geometry and arrive at an embedding compression method of autoencoder with ℓ2,1-loss, which finds the most informative meta-graphs and embeddings in an end-to-end unsupervised manner. Finally, empirical analysis suggests a unified workflow to close the gap between our meta-graph assessment and combination methods. To the best of our knowledge, this is the first research effort to provide rich theoretical and empirical analyses on the utility of meta-graphs and their combinations, especially regarding HIN embedding. Extensive experimental comparisons with various state-of-the-art neural network based embedding methods on multiple real-world HINs demonstrate the effectiveness and efficiency of our framework in finding useful meta-graphs and generating high-quality HIN embeddings."
PME: Projected Metric Embedding on Heterogeneous Networks for Link Prediction,"Hongxu Chen, Hongzhi Yin, WeiqingWang, Hao Wang, Quoc Viet HungNguyen, Xue Li",ACM,"Heterogenous Network Embedding, Link Prediction","Heterogenous information network embedding aims to embed heterogenous information networks (HINs) into low dimensional spaces, in which each vertex is represented as a low-dimensional vector, and both global and local network structures in the original space are preserved. However, most of existing heterogenous information network embedding models adopt the dot product to measure the proximity in the low dimensional space, and thus they can only preserve the first-order proximity and are insufficient to capture the global structure. Compared with homogenous information networks, there are multiple types of links (i.e., multiple relations) in HINs, and the link distribution w.r.t relations is highly skewed. To address the above challenging issues, we propose a novel heterogenous information network embedding model PME based on the metric learning to capture both first-order and second-order proximities in a unified way. To alleviate the potential geometrical inflexibility of existing metric learning approaches, we propose to build object and relation embeddings in separate object space and relation spaces rather than in a common space. Afterwards, we learn embeddings by firstly projecting vertices from object space to corresponding relation space and then calculate the proximity between projected vertices. To overcome the heavy skewness of the link distribution w.r.t relations and avoid “over-sampling” or “under-sampling” for each relation, we propose a novel loss-aware adaptive sampling approach for the model optimization. Extensive experiments have been conducted on a large-scale HIN dataset, and the experimental results show superiority of our proposed PME model in terms of prediction accuracy and scalability."
WMGCN: Weighted Meta-Graph Based Graph Convolutional Networks for Representation Learning in Heterogeneous Networks,"Jinli Zhang, Zongli Jiang, Zheng Chen,Xiaohua Hu",IEEE,"Heterogeneous network, weighted meta-graph, graph convolutional network, representation learning","Network embedding has been an effective tool to analyze heterogeneous networks (HNs) by representing nodes in a low-dimensional space. Although many recent methods have been proposed for representation learning of HNs, there is still much room for improvement. Random walks based methods are currently popular methods to learn network embedding; however, they are random and limited by the length of sampled walks, and have difficulty capturing network structural information. Some recent researches proposed using meta paths to express the sample relationship in HNs. Another popular graph learning model, the graph convolutional network (GCN) is known to be capable of better exploitation of network topology, but the current design of GCN is intended for homogenous networks. This paper proposes a novel combination of meta-graph and graph convolution, the meta-graph based graph convolutional networks (MGCN). To fully capture the complex long semantic information, MGCN utilizes different meta-graphs in HNs. As different meta-graphs express different semantic relationships, MGCN learns the weights of different meta-graphs to make up for the loss of semantics when applying GCN. In addition, we improve the current convolution design by adding node self-significance. To validate our model in learning feature representation, we present comprehensive experiments on four real-world datasets and two representation tasks: classification and link prediction. WMGCN’s representations can improve accuracy scores by up to around 10% in comparison to other popular representation learning models. What’s more, WMGCN’feature learning outperforms other popular baselines. The experimental results clearly show our model is superior over other state-of-the-art representation learning algorithms."
Task-Guided Pair Embedding in Heterogeneous Network,"Chanyoung Park, Donghyun Kim, QiZhu, Jiawei Han, Hwanjo Yu",arXiv,"Heterogeneous Network, Author Identification, Representation Learning, Deep Learning","Many real-world tasks solved by heterogeneous network embedding methods can be cast as modeling the likelihood of pairwise relationship between two nodes. For example, the goal of author identification task is to model the likelihood of a paper being written by an author (paper-author pairwise relationship). Existing task-guided embedding methods are node-centric in that they simply measure the similarity between the node embeddings to compute the likelihood of a pairwise relationship between two nodes. However, we claim that for task-guided embeddings, it is crucial to focus on directly modeling the pairwise relationship. In this paper, we propose a novel task-guided pair embedding framework in heterogeneous network, called TaPEm, that directly models the relationship between a pair of nodes that are related to a specific task (e.g., paper-author relationship in author identification). To this end, we 1) propose to learn a pair embedding under the guidance of its associated context path, i.e., a sequence of nodes between the pair, and 2) devise the pair validity classifier to distinguish whether the pair is valid with respect to the specific task at hand. By introducing pair embeddings that capture the semantics behind the pairwise relationships, we are able to learn the fine-grained pairwise relationship between two nodes, which is paramount for task-guided embedding methods. Extensive experiments on author identification task demonstrate that TaPEm outperforms the state-of-the-art methods, especially for authors with few publication records."
HAHE: Hierarchical Attentive Heterogeneous Information Network Embedding,"Sheng Zhou, Jiajun Bu, Xin Wang,Jiawei Chen, Bingbing Hu, DefangChen, Can Wang",arXiv,"Heterogeneous Information Network, Embedding, Aention","Heterogeneous information network (HIN) embedding has recently aracted much aention due to its effectiveness in dealing with the complex heterogeneous data. Meta path, which connects different object types with various semantic meanings, is widely used by existing HIN embedding works. However, several challenges have not been addressed so far. First, different meta paths convey different semantic meanings, while existing works assume that all nodes share same weights for meta paths and ignore the personalized preferences of different nodes on different meta paths. Second, given a meta path, nodes in HIN are connected by path instances while existing works fail to fully explore the differences between path instances that reflect nodes’ preferences in the semantic space. rTo tackle the above challenges, we propose a Hierarchical Aentive Heterogeneous information network Embedding (HAHE) model to capture the personalized preferences on meta paths and path instances in each semantic space. As path instances are based on a particular meta path, a hierarchical aention mechanism is naturally utilized to model the personalized preference on meta paths and path instances. Extensive experiments on several real-world datasets show that our proposed HAHEmodel significantly outperforms the state-of-the-art methods in terms of various data mining tasks."
ICSD: An Automatic System for Insecure Code Snippet Detection in Stack Overflow over Heterogeneous Information Network,"Yanfang Ye, Shifu Hou, Lingwei Chen,Xin Li, Liang Zhao, Shouhuai Xu, JiabinWang, Qi Xiong",ACM,"Social Coding, Code Security, Heterogeneous Information Network, Network Representation Learning, Multi-view Fusio","As the popularity of modern social coding paradigm such as Stack Overflow grows, its potential security risks increase as well (e.g., insecure codes could be easily embedded and distributed). To address this largely overlooked issue, in this paper, we bring an important new insight to exploit social coding properties in addition to code content for automatic detection of insecure code snippets in Stack Overflow. To determine if the given code snippets are insecure, we not only analyze the code content, but also utilize various kinds of relations among users, badges, questions, answers, code snippets and keywords in Stack Overflow. To model the rich semantic relationships, we first introduce a structured heterogeneous information network (HIN) for representation and then use meta-path based approach to incorporate higher-level semantics to build up relatedness over code snippets. Later, we propose a novel network embedding model named snippet2vec for representation learning in HIN where both the HIN structures and semantics are maximally preserved. After that, a multi-view fusion classifier is constructed for insecure code snippet detection. To the best of our knowledge, this is the first work utilizing both code content and social coding properties to address the code security issues in modern software coding platforms. Comprehensive experiments on the data collections from Stack Overflow are conducted to validate the effectiveness of the developed system ICSD which integrates our proposed method in insecure code snippet detection by comparisons with alternative approaches"
Spread-gram: A spreading-activation schema of network structural learning,"Jie Bai, Linjing Li, Daniel Dajun Zeng",arXiv,"representation learning, network analysis, Spreading Activation, cognitive psychology, node embeddings","Network representation learning has exploded recently. However, existing studies usually reconstruct networks as sequences or matrices, which may cause information bias or sparsity problem during model training. Inspired by a cognitive model of human memory, we propose a network representation learning scheme. In this scheme, we learn node embeddings by adjusting the proximity of nodes traversing the spreading structure of the network. Our proposed method shows a significant improvement in multiple analysis tasks based on various real-world networks, ranging from semantic networks to protein interaction networks, international trade networks, human behavior networks, etc. In particular, our model can effectively discover the hierarchical structures in networks. The well-organized model training speeds up the convergence to only a small number of iterations, and the training time is linear with respect to the edge numbers."
Temporal Network Embedding with Micro-and Macro-dynamics,"Yuanfu Lu, Xiao Wang, Chuan Shi, PhilipS. Yu, Yanfang Ye",arXiv,"Network Embedding, Temporal Network, Social Dynamics Analysis, Temporal Point Process","Network embedding aims to embed nodes into a low-dimensional space, while capturing the network structures and properties. Although quite a few promising network embedding methods have been proposed, most of them focus on static networks. In fact, temporal networks, which usually evolve over time in terms of microscopic and macroscopic dynamics, are ubiquitous. The micro-dynamics describe the formation process of network structures in a detailed manner, while the macro-dynamics refer to the evolution pattern of the network scale. Both micro- and macro-dynamics are the key factors to network evolution; however, how to elegantly capture both of them for temporal network embedding, especially macro-dynamics, has not yet been well studied. In this paper, we propose a novel temporal network embedding method with micro- and macro-dynamics, named M2DNE. Specifically, for micro-dynamics, we regard the establishments of edges as the occurrences of chronological events and propose a temporal attention point process to capture the formation process of network structures in a fine-grained manner. For macro-dynamics, we define a general dynamics equation parameterized with network embeddings to capture the inherent evolution pattern and impose constraints in a higher structural level on network embeddings. Mutual evolutions of micro- and macro-dynamics in a temporal network alternately affect the process of learning node embeddings. Extensive experiments on three real-world temporal networks demonstrate that M2DNE significantly outperforms the state-of-the-arts not only in traditional tasks, e.g., network reconstruction, but also in temporal tendency-related tasks, e.g., scale prediction."
"Heterogeneous Network Representation Learning: Survey, Benchmark, Evaluation, and Beyond","Carl Yang, Yuxin Xiao, Yu Zhang, YizhouSun, Jiawei Han",arXiv,"heterogeneous network, representation learning, survey, benchmark","Since real-world objects and their interactions are often multi-modal and multi-typed, heterogeneous networks have been widely used as a more powerful, realistic, and generic superclass of traditional homogeneous networks (graphs). Meanwhile, representation learning (a.k.a. embedding) has recently been intensively studied and shown effective for various network mining and analytical tasks. In this work, we aim to provide a unified framework to deeply summarize and evaluate existing research on heterogeneous network embedding (HNE), which includes but goes beyond a normal survey. Since there has already been a broad body of HNE algorithms, as the first contribution of this work, we provide a generic paradigm for the systematic categorization and analysis over the merits of various existing HNE algorithms. Moreover, existing HNE algorithms, though mostly claimed generic, are often evaluated on different datasets. Understandable due to the application favor of HNE, such indirect comparisons largely hinder the proper attribution of improved task performance towards effective data preprocessing and novel technical design, especially considering the various ways possible to construct a heterogeneous network from real-world application data. Therefore, as the second contribution, we create four benchmark datasets with various properties regarding scale, structure, attribute/label availability, and etc. from different sources, towards handy and fair evaluations of HNE algorithms. As the third contribution, we carefully refactor and amend the implementations and create friendly interfaces for eleven popular HNE algorithms, and provide all-around comparisons among them over multiple tasks and experimental settings. By putting all existing HNE algorithms under a unified framework, we aim to provide a universal reference and guideline for the understanding and development of HNE algorithms. Meanwhile, by open-sourcing all data and code, we envision to serve the community with an ready-to-use benchmark platform to test and compare the performance of existing and future HNE algorithms"
Adversarial Learning on Heterogeneous Information Networks,"Binbin Hu, Yuan Fang, Chuan Shi",ACM,"Heterogeneous Information Network, Network Embedding, Generative Adversarial Network","Network embedding, which aims to represent network data in a low-dimensional space, has been commonly adopted for analyzing heterogeneous information networks (HIN). Although exiting HIN embedding methods have achieved performance improvement to some extent, they still face a few major weaknesses. Most importantly, they usually adopt negative sampling to randomly select nodes from the network, and they do not learn the underlying distribution for more robust embedding. Inspired by generative adversarial networks (GAN), we develop a novel framework HeGAN for HIN embedding, which trains both a discriminator and a generator in a minimax game. Compared to existing HIN embedding methods, our generator would learn the node distribution to generate better negative samples. Compared to GANs on homogeneous networks, our discriminator and generator are designed to be relation-aware in order to capture the rich semantics on HINs. Furthermore, towards more effective and efficient sampling, we propose a generalized generator, which samples “latent” nodes directly from a continuous distribution, not confined to the nodes in the original network as existing methods are. Finally, we conduct extensive experiments on four real-world datasets. Results show that we consistently and significantly outperform state-of-the-art baselines across all datasets and tasks."
Embedding Learning with Events in Heterogeneous Information Networks,"Huan Gui, Jialu Liu, Fangbo Tao, MengJiang, Brandon Norick, Lance M.Kaplan, Jiawei Han",IEEE,"Heterogeneous information networks, event, object embedding, large scale, noise pairwise ranking","In real-world applications, objects of multiple types are interconnected, forming Heterogeneous Information Networks. In such heterogeneous information networks, we make the key observation that many interactions happen due to some event and the objects in each event form a complete semantic unit. By taking advantage of such a property, we propose a generic framework called HyperEdge-Based Embedding (HEBE) to learn object embeddings with events in heterogeneous information networks, where a hyperedge encompasses the objects participating in one event. The HEBE framework models the proximity among objects in each event with two methods: (1) predicting a target object given other participating objects in the event, and (2) predicting if the event can be observed given all the participating objects. Since each hyperedge encapsulates more information of a given event, HEBE is robust to data sparseness and noise. In addition, HEBE is scalable when the data size spirals. Extensive experiments on large-scale real-world datasets show the efficacy and robustness of the proposed framework."
Performance Bounds of Decentralized Search in Expert Networks for Query Answering,"Liang Ma, Mudhakar Srivatsa, DeryaCansever, Xifeng Yan, Sue E. Kase,Michelle T. Vanni",ACM,"Expert networks, query answering, decentralized search, performance bounds, theory","Expert networks are formed by a group of expert-professionals with different specialties to collaboratively resolve specific queries posted to the network. In such networks, when a query reaches an expert who does not have sufficient expertise, this query needs to be routed to other experts for further processing until it is completely solved; therefore, query answering efficiency is sensitive to the underlying query routing mechanism being used. Among all possible query routing mechanisms, decentralized search, operating purely on each expert’s local information without any knowledge of network global structure, represents the most basic and scalable routing mechanism, which is applicable to any network scenarios even in dynamic networks. However, there is still a lack of fundamental understanding of the efficiency of decentralized search in expert networks. In this regard, we investigate decentralized search by quantifying its performance under a variety of network settings. Our key findings reveal the existence of network conditions, under which decentralized search can achieve significantly short query routing paths (i.e., between O(logn) and O(log2 n) hops, n: total number of experts in the network). Based on such theoretical foundation, we further study how the unique properties of decentralized search in expert networks are related to the anecdotal small-world phenomenon. In addition, we demonstrate that decentralized search is robust against estimation errors introduced by misinterpreting the required expertise levels. The developed performance bounds, confirmed by real datasets, are able to assist in predicting network performance and designing complex expert networks."
Query Answering Efficiency in Expert Networks Under Decentralized Search,"Liang Ma, Mudhakar Srivatsa, DeryaCansever, Xifeng Yan, Sue Kase,Michelle Vanni",ACM,"Expert Networks, Query Answering, Decentralized Search, Performance Bounds","Expert networks are formed by a group of expert-professionals with different specialties to collaboratively resolve specific queries. In such networks, when a query reaches an expert who does not have sufficient expertise, this query needs to be routed to other experts for further processing until it is completely solved; therefore, query answering efficiency is sensitive to the underlying query routing mechanism being used. Among all possible query routing mechanisms, decentralized search, operating purely on each expert’s local information without any knowledge of network global structure, represents the most basic and scalable routing mechanism. However, there is still a lack of fundamental understanding of the efficiency of decentralized search in expert networks. In this regard, we investigate decentralized search by quantifying its performance under a variety of network settings. Our key findings reveal the existence of network conditions, under which decentralized search can achieve significantly short query routing paths (i.e., between O(log n) and O(log2 n) hops, n: total number of experts in the network). Based on such theoretical foundation, we then study how the unique properties of decentralized search in expert networks is related to the anecdotal small-world phenomenon. To the best of our knowledge, this is the first work studying fundamental behaviors of decentralized search in expert networks. The developed performance bounds, confirmed by real datasets, can assist in predicting network performance and designing complex expert networks."
Role action embeddings: scalable representation of network positions,George Berry,arXiv,,"We consider the question of embedding nodes with similar local neighborhoods together in embedding space, commonly referred to as “role embeddings.” We propose RAE, an unsupervised framework that learns role embeddings. It combines a within-node loss function and a graph neural network (GNN) architecture to place nodes with similar local neighborhoods close in embedding space. We also propose a faster way of generating negative examples called neighbor shuffling, which quickly creates negative examples directly within batches. These techniques can be easily combined with existing GNN methods to create unsupervised role embeddings at scale. We then explore role action embeddings, which summarize the non-structural features in a node’s neighborhood, leading to better performance on node classification tasks. We find that the model architecture proposed here provides strong performance on both graph and node classification tasks, in some cases competitive with semi-supervised methods."
Outlier Aware Network Embedding for Attributed Networks,"Sambaran Bandyopadhyay, N. Lokesh,M. Narasimha Murty",arXiv,,"Attributed network embedding has received much interest from the research community as most of the networks come with some content in each node, which is also known as node attributes. Existing attributed network approaches work well when the network is consistent in structure and attributes, and nodes behave as expected. But real world networks often have anomalous nodes. Typically these outliers, being relatively unexplainable, affect the embeddings of other nodes in the network. Thus all the downstream network mining tasks fail miserably in the presence of such outliers. Hence an integrated approach to detect anomalies and reduce their overall effect on the network embedding is required. Towards this end, we propose an unsupervised outlier aware network embedding algorithm (ONE) for attributed networks, which minimizes the effect of the outlier nodes, and hence generates robust network embeddings. We align and jointly optimize the loss functions coming from structure and attributes of the network. To the best of our knowledge, this is the first generic network embedding approach which incorporates the effect of outliers for an attributed network without any supervision. We experimented on publicly available real networks and manually planted different types of outliers to check the performance of the proposed algorithm. Results demonstrate the superiority of our approach to detect the network outliers compared to the state-of-the-art approaches. We also consider different downstream machine learning applications on networks to show the efficiency of ONE as a generic network embedding technique."
Decentralized search in expert networks: Generic models and performance bounds,"Liang Ma, Mudhakar Srivatsa, DeryaCansever, Xifeng Yan, Sue Kase,Michelle Vanni",IEEE,,"We investigate the problem of query answering in expert networks, which are composed of inter-connected experts with various specialties. Upon receiving a query, the expert network is tasked to route this query to experts with sufficient expertise in a timely and reliable manner. However, the efficiency of query answering depends on the underlying query routing protocol being used. Among all possible query routing protocols, decentralized search, operating purely on each expert’s local information without any network global knowledge, represents the most basic and scalable routing protocol. However, there is still a lack of fundamental understanding on the efficiency of decentralized search in different expert networks. In this regard, we establish a generic model that can abstract diversified social and structural attributes in various expert networks into a common framework, thus applicable to a wide range of network scenarios. On top of such generic network model, we then study decentralized search by quantifying its performance under a variety of network parameters. Our key findings reveal the existence of network conditions, under which decentralized search can achieve significantly short query routing paths (i.e., between O(log n) and O(log2 n) hops, n: total number of experts in the network). To the best of our knowledge, this is the first work studying fundamental behaviors of decentralized search without relying on strict underlying network structures in expert networks. Experiments in both synthetic and real expert networks confirm the efficacy of the developed performance bounds in understanding and reasoning the network performance."
Answering via Decentralized Search,Liang Ma,,,"Expert networks are formed by a group of expert-professionals with different specialties to collaboratively resolve specific queries posted to the network. In such networks, when a query reaches an expert who does not have sufficient expertise, this query needs to be routed to other experts for further processing until it is completely solved; therefore, query answering efficiency is sensitive to the underlying query routing mechanism being used. Among all possible query routing mechanisms, decentralized search, operating purely on each expert’s local information without any knowledge of network global structure, represents the most basic and scalable routing mechanism, which is applicable to any network scenarios even in dynamic networks. However, there is still a lack of fundamental understanding of the efficiency of decentralized search in expert networks. In this regard, we investigate decentralized search by quantifying its performance under a variety of network settings. Our key findings reveal the existence of network conditions, under which decentralized search can achieve significantly short query routing paths (i.e., between O(log n) and O(log2 n) hops, n: total number of experts in the network). Based on such theoretical foundation, we further study how the unique properties of decentralized search in expert networks is related to the anecdotal small-world phenomenon. In addition, we demonstrate that decentralized search is robust against estimation errors introduced by misinterpreting the required expertise levels. To the best of our knowledge, this is the first work studying fundamental behaviors of decentralized search in expert networks. The developed performance bounds, confirmed by real datasets, are able to assist in predicting network performance and designing complex expert networks."
Towards a Spectrum of Graph Convolutional Networks,"Mathias Niepert, Alberto García-Durán",arXiv,"graph convolutional networks, graph partition, convolutions","We present our ongoing work on understanding the limitations of graph convolutional networks (GCNs) as well as our work on generalizations of graph convolutions for representing more complex node attribute dependencies. Based on an analysis of GCNs with the help of the corresponding computation graphs, we propose a generalization of existing GCNs where the aggregation operations are (a) determined by structural properties of the local neighborhood graphs and (b) not restricted to weighted averages. We show that the proposed approach is strictly more expressive while requiring only a modest increase in the number of parameters and computations. We also show that the proposed generalization is identical to standard convolutional layers when applied to regular grid graphs."
Dataset Recommendation via Variational Graph Autoencoder,"Basmah Altaf, Uchenna Akujuobi, LuYu, Xiangliang Zhang",IEEE,"dataset recommendation, query-based recommendation, heterogeneous variational graph autoencoder","This paper targets on designing a query-based dataset recommendation system, which accepts a query denoting a user’s research interest as a set of research papers and returns a list of recommended datasets that are ranked by the potential usefulness for the user’s research need. The motivation of building such a system is to save users from spending time on heavy literature review work to find usable datasets. We start by constructing a two-layer network: one layer of citation network, and the other layer of datasets, connected to the firstlayer papers in which they were used. A query highlights a set of papers in the citation layer. However, answering the query as a naive retrieval of datasets linked with these highlighted papers excludes other semantically relevant datasets, which widely exist several hops away from the queried papers. We propose to learn representations of research papers and datasets in the two-layer network using heterogeneous variational graph autoencoder, and then compute the relevance of the query to the dataset candidates based on the learned representations. Our ranked datasets shown in extensive evaluation results are validated to be more truly relevant than those obtained by naive retrieval methods and adoptions of existing related solutions."
Deep Inductive Graph Representation Learning,"Ryan A. Rossi, Rong Zhou, NesreenAhmed",IEEE,"Graph representation learning, inductive representation learning, relational function learning, transfer learning, graph-based feature learning, higher-order structures","This paper presents a general inductive graph representation learning framework called DeepGL for learning deep node and edge features that generalize across-networks. In particular, DeepGL begins by deriving a set of base features from the graph (e.g., graphlet features) and automatically learns a multi-layered hierarchical graph representation where each successive layer leverages the output from the previous layer to learn features of a higher-order. Contrary to previous work, DeepGL learns relational functions (each representing a feature) that naturally generalize across-networks and are therefore useful for graphbased transfer learning tasks. Moreover, DeepGL naturally supports attributed graphs, learns interpretable inductive graph representations, and is space-efficient (by learning sparse feature vectors). In addition, DeepGL is expressive, flexible with many interchangeable components, efficient with a time complexity of OðjEjÞ, and scalable for large networks via an efficient parallel implementation. Compared with recent methods, DeepGL is (1) effective for across-network transfer learning tasks and large (attributed) graphs, (2) space-efficient requiring up to 6x less memory, (3) fast with up to 106x speedup in runtime performance, and (4) accurate with an average improvement in AUC of 20 percent or more on many learning tasks and across a wide variety of networks."
A Scalable Vector Symbolic Architecture Approach for Decentralized Workflows,"Christopher Simpkin, Ian Taylor,Graham A. Bent, Geeth de Mel, RaghuK. Ganti","The Eighth International Conference on Advanced Collaborative Networks, Systems and Applications COLLA 2018","vector symbolic architectures, decentralized workflows, semantics, associative memory models","Vectors Symbolic Architectures (VSAs) are distributed representations that combine random patterns, representing atomic symbols across a hyper-dimensional vector space, into new symbolic vector representations that semantically represent the component vectors and their relationships. In this paper, we extend the VSA approach and apply it to decentralized workflows, capable of executing distributed compute nodes and their interdependencies. To achieve this goal, services must be discovered and orchestrated in a decentralized way with the minimum communication overhead whilst providing detailed information about the workflow - tasks, dependencies, location, metadata, and so on. To this end, we extended VSAs using a hierarchical vector chunking scheme that enables semantic matching at each level and provides scaling up to tens of thousands of services. We then show how VSAs can be used to encode complex workflows by building primitives that represent sequences (pipelines) and then extend this to support full Directed Acyclic Graphs (DAGs) and apply this to five well-known Pegasus scientific workflows to demonstrate the approach."
"Node, Motif and Subgraph: Leveraging Network Functional Blocks Through Structural Convolution","Carl Yang, Mengxiong Liu, VincentWenchen Zheng, Jiawei Han",IEEE,,"Networks or graphs provide a natural and generic way for modeling rich structured data. Recent research on graph analysis has been focused on representation learning, of which the goal is to encode the network structures into distributed embedding vectors, so as to enable various downstream applications through off-the-shelf machine learning. However, existing methods mostly focus on node-level embedding, which is insufficient for subgraph analysis. Moreover, their leverage of network structures through path sampling or neighborhood preserving is implicit and coarse. Network motifs allow graph analysis in a finer granularity, but existing methods based on motif matching are limited to enumerated simple motifs and do not leverage node labels and supervision. In this paper, we develop NEST, a novel hierarchical network embedding method combining motif filtering and convolutional neural networks. Motif-based filtering enables NEST to capture exact small structures within networks, and convolution over the filtered embedding allows it to fully explore complex substructures and their combinations. NEST can be trivially applied to any domain and provide insight into particular network functional blocks. Extensive experiments on protein function prediction, drug toxicity prediction and social network community identification have demonstrated its effectiveness and efficiency."
Graph Node-Feature Convolution for Representation Learning,"Li Zhang, Heda Song, Haiping Lu",arXiv,,"Graph convolutional network (GCN) is an emerging neural network approach. It learns new representation of a node by aggregating feature vectors of all neighbors in the aggregation process without considering whether the neighbors or features are useful or not. Recent methods have improved solutions by sampling a fixed size set of neighbors, or assigning different weights to different neighbors in the aggregation process, but features within a feature vector are still treated equally in the aggregation process. In this paper, we introduce a new convolution operation on regular size feature maps constructed from features of a fixed node bandwidth via sampling to get the first-level node representation, which is then passed to a standard GCN to learn the secondlevel node representation. Experiments show that our method outperforms competing methods in semi-supervised node classification tasks. Furthermore, our method opens new doors for exploring new GCN architectures, particularly deeper GCN models."
GraphNet: Recommendation system based on language and network structure,Rex Ying,,,"Recommendation systems are widely used in many popular online services, however, present algorithms use either network structure or language features only. In this paper, we present a scalable and efficient recommendation system that combines both language content and complex social network structure. Given a dataset consisting of objects created and commented on by users, the system predicts other content that the user may be interested in. We demonstrate the efficacy of our system through the task of recommending posts to reddit users based on their previous posts and comments. We extract the language feature using GloVe vectors and sequential model, and use attention mechanism, multi-layer perceptron and max pooling to learn hidden representations for users and posts. We show in experiments that our method is able to achieve the state-of-the-art performance."
Virtual-Link Representation for Link Prediction,"Can Yao, Hai Rong Huang, LongxuanMa, Ze Yang, Lefei Zhang",IEEE,"Link prediction, Embedding, Virtual link, Feature learning","Link prediction predicts the likelihood of a future association between two nodes in a network. It plays an important role in mining and analyzing the evolution of networks and it is the fundament of many applications, including bioinformatics, e-commerce, security domain and co-authorship networks. The past few decades has witnessed the development of link prediction. In this paper, we propose a link prediction method VirtualLink2vec, which learns features of target link by concatenating representations from two different aspects as the link’s full representation. Comprehensive experiments are conducted on six networks. Compared with heuristics and latent feature methods, our results show that VirtualLink2vec has the ability to reserve rich information related to positive link and negative link with less consumption of time and computing resources. In the meantime, our method consistently performs well across networks with different structures and characteristics."
Embedding Networks with Edge Attributes,"Palash Goyal, Homa Hosseinmardi,Emilio Ferrara, Aram Galstyan",ACM,"Graph Embedding, Deep Learning, Network Representation","Predicting links in information networks requires deep understanding and careful modeling of network structure. Network embedding, which aims to learn low-dimensional representations of nodes, has been used successfully for the task of link prediction in the past few decades. Existing methods utilize the observed edges in the network to model the interactions between nodes and learn representations which explain the behavior. In addition to the presence of edges, networks often have information which can be used to improve the embedding. For example, in author collaboration networks, the bag of words representing the abstract of co-authored paper can be used as edge attributes. In this paper, we propose a novel approach, which uses the edges and their associated labels to learn node embeddings. Our model jointly optimizes higher order node neighborhood, social roles and edge attributes reconstruction error using deep architecture which can model highly non-linear interactions. We demonstrate the efficacy of our model over existing state-of-the-art methods on two real world data sets. We observe that such attributes can improve the quality of embedding and yield better performance in link prediction."
GEM: A Python package for graph embedding methods,"Palash Goyal, Emilio Ferrara",JOSS,,"Many physical systems in the world involve interactions between different entities and can be represented as graphs. Understanding the structure and analyzing properties of graphs are hence paramount to developing insights into the physical systems. Graph embedding, which aims to represent a graph in a low dimensional vector space, takes a step in this direction. The embeddings can be used for various tasks on graphs such as visualization, clustering, classification and prediction. GEM is a Python package which offers a general framework for graph embedding methods. It implements many state-of-the-art embedding techniques including Locally Linear Embedding (Roweis & Saul, 2000), Laplacian Eigenmaps (Belkin & Niyogi, 2003), Graph Factorization (Ahmed, Shervashidze, Narayanamurthy, Josifovski, & Smola, 2013), HOPE (Ou, Cui, Pei, Zhang, & Zhu, 2016), SDNE (Wang, Cui, & Zhu, 2016) and node2vec (Grover & Leskovec, 2016). It is formatted such that new methods can be easily added for comparison. Furthermore, the framework implements several functions to evaluate the quality of obtained embedding including graph reconstruction, link prediction, visualization and node classification. It supports many edge reconstruction metrics including cosine similarity, euclidean distance and decoder based. For node classification, it defaults to one-vs-rest logistic regression classifier and supports other classifiers. For faster execution, C++ backend is integrated using Boost for supported methods. GEM was designed to be used by researchers studying graphs. It has already been used in a number of scientific publications to compare novel methods against the state-ofthe-art and general evaluation (Salehi Rizi, Granitzer, & Ziegler, 2017, Lyu, Zhang, & Zhang (2017)). A paper showcasing the results using GEM on various real world datasets can be accessed (Goyal & Ferrara, 2018). The source code of GEM is made available at https://github.com/palash1992/GEM. Bug reports and feedback can be directed to the Github issues page (https://github.com/palash1992/GEM/issues)."
DynGEM: Deep Embedding Method for Dynamic Graphs,"Palash Goyal, Nitin Kamra, Xinran He,Yan Liu",arXiv,,"Embedding large graphs in low dimensional spaces has recently attracted significant interest due to its wide applications such as graph visualization, link prediction and node classification. Existing methods focus on computing the embedding for static graphs. However, many graphs in practical applications are dynamic and evolve constantly over time. Naively applying existing embedding algorithms to each snapshot of dynamic graphs independently usually leads to unsatisfactory performance in terms of stability, flexibility and efficiency. In this work, we present an efficient algorithm DynGEM based on recent advances in deep autoencoders for graph embeddings, to address this problem. The major advantages of DynGEM include: (1) the embedding is stable over time, (2) it can handle growing dynamic graphs, and (3) it has better running time than using static embedding methods on each snapshot of a dynamic graph. We test DynGEM on a variety of tasks including graph visualization, graph reconstruction, link prediction and anomaly detection (on both synthetic and real datasets). Experimental results demonstrate the superior stability and scalability of our approach."
Geometric Laplacian Eigenmap Embedding,"Leo Torres, Kevin S. Chan, Tina Eliassi-Rad",arXiv,"Graph embedding, graph Laplacian, simplex geometry.","Graph embedding seeks to build a low-dimensional representation of a graph G. This low-dimensional representation is then used for various downstream tasks. One popular approach is Laplacian Eigenmaps, which constructs a graph embedding based on the spectral properties of the Laplacian matrix of G. The intuition behind it, and many other embedding techniques, is that the embedding of a graph must respect node similarity: similar nodes must have embeddings that are close to one another. Here, we dispose of this distance-minimization assumption. Instead, we use the Laplacian matrix to find an embedding with geometric properties instead of spectral ones, by leveraging the so-called simplex geometry of G. We introduce a new approach, Geometric Laplacian Eigenmap Embedding (or GLEE for short), and demonstrate that it outperforms various other techniques (including Laplacian Eigenmaps) in the tasks of graph reconstruction and link prediction. Graph embedding, graph Laplacian, simplex geometry."
Integrating Dual User Network Embedding with Matrix Factorization for Social Recommender Systems∗,"Liying Chen, Hong‐lei Zhang, JingjingWu",IEEE,,"To address the data sparsity problem faced by recommender systems, social network among users is often utilized to complement rating data for improving the recommendation performance. One of current trends is to combine the idea of matrix factorization (MF) for predicting ratings with the idea of graph embedding (GE) for analyzing social network towards recommendation tasks. Despite enjoying many advantages, the existing integrated models have two critical limitations. First, such models are designed to work with either explicit or implicit social network, but little is known in taking both into account. Second, the users’ embeddings learned by GE are fed to the downstream MF, but not reverse, which is sub-optimal because rating information is not considered for learning the users’ embeddings. In this paper, we propose a novel social recommendation algorithm which exploits both explicit and implicit social networks towards the task of rating prediction. In Particular, we seamlessly integrate MF model and GE model within a unified optimization framework, in which MF and GE tasks can be reinforced each other during the learning process. Our encouraging experimental results on three real-world benchmarks validate the superiority of the proposed approach to state-of-the-art social recommendation methods."
EvalNE: A Framework for Evaluating Network Embeddings on Link Prediction,"Alexandru Mara, Jefrey Lijffijt, Tijl DeBie",arXiv,"Network Embedding, Link Prediction, Evaluation, Edge Sampling, Graphs","In this paper we present EvalNE, a Python toolbox for evaluating network embedding methods on link prediction tasks. Link prediction is one of the most popular choices for evaluating the quality of network embeddings. However, the complexity of this task requires a carefully designed evaluation pipeline in order to provide consistent, reproducible and comparable results. EvalNE simplifies this process by providing automation and abstraction of tasks such as hyper-parameter tuning and model validation, edge sampling and negative edge sampling, computation of edge embeddings from node embeddings, and evaluation metrics. The toolbox allows for the evaluation of any off-the-shelf embedding method without the need to write extra code. Moreover, it can also be used for evaluating any other link prediction method, and integrates several link prediction heuristics as baselines."
Tensor Decomposition-based Node Embedding,"Shah Muhammad Hamdi, SoukainaFilali Boubrahimi, Rafal A. Angryk",ACM,"Node embedding, Tensor decomposition, Interpretability of feature space, Network reconstruction","In recent years, node embedding algorithms, which learn low dimensional vector representations for nodes in a graph, have been one of the key research interests of the graph mining community. The existing algorithms either rely on computationally expensive eigendecomposition of the large matrices, or require tuning of the word embedding-based hyperparameters as a result of representing the graph as a node sequence similar to the sentences in a document. Moreover, the latent features produced by these algorithms are hard to interpret. In this paper, we present Tensor Decomposition-based Node Embedding (TDNE), a novel model for learning node representations for arbitrary types of graphs: undirected, directed, and/or weighted. Our model preserves the local and global structural properties of a graph by constructing a third-order tensor using the k-step transition probability matrices and decomposing the tensor through CANDECOMP/PARAFAC (CP) decomposition in order to produce an interpretable, low dimensional vector space for the nodes. Our experimental evaluation using two well-known social network datasets proves TDNE to be interpretable with respect to the understandability of the feature space, and precise with respect to the network reconstruction."
Learning Permutation Invariant Representations using Memory Networks,"Shivam Kalra, Mohammed MuqeetAdnan, Graham W. Taylor, Hamid R.Tizhoosh",arXiv,"Permutation Invariant Models, Multi Instance Learning, Whole Slide Image Classification, Medical Images","Many real world tasks such as classification of digital histopathological images and 3D object detection involve learning from a set of instances. In these cases, only a group of instances or a set, collectively, contains meaningful information and therefore only the sets have labels, and not individual data instances. In this work, we present a permutation invariant neural network called Memory-based Exchangeable Model (MEM) for learning universal set functions. The MEM model consists of memory units which embed an input sequence to high-level features enabling it to learn inter-dependencies among instances through a selfattention mechanism. We evaluated the learning ability of MEM on various toy datasets, point cloud classification, and classification of whole slide images (WSIs) into two subtypes of lung cancer—Lung Adenocarcinoma, and Lung Squamous Cell Carcinoma. We systematically extracted patches from WSIs of lung, downloaded from The Cancer Genome Atlas (TCGA) dataset, the largest public repository of WSIs, achieving a competitive accuracy of 84.84% for classification of two sub-types of lung cancer. The results on other datasets are promising as well, and demonstrate the efficacy of our model."
Cross-GCN: Enhancing Graph Convolutional Network with k-Order Feature Interactions,"Fuli Feng, Xiangnan He, HanwangZhang, Tat-Seng Chua",arXiv,"Cross-Feature, Graph-based Learning, Graph Neural Networks","Graph Convolutional Network (GCN) is an emerging technique that performs learning and reasoning on graph data. It operates feature learning on the graph structure, through aggregating the features of the neighbor nodes to obtain the embedding of each target node. Owing to the strong representation power, recent research shows that GCN achieves state-of-the-art performance on several tasks such as recommendation and linked document classification. Despite its effectiveness, we argue that existing designs of GCN forgo modeling cross features, making GCN less effective for tasks or data where cross features are important. Although neural network can approximate any continuous function, including the multiplication operator for modeling feature crosses, it can be rather inefficient to do so (i.e., wasting many parameters at the risk of overfitting) if there is no explicit design. To this end, we design a new operator named Cross-feature Graph Convolution, which explicitly models the arbitrary-order cross features with complexity linear to feature dimension and order size. We term our proposed architecture as Cross-GCN, and conduct experiments on three graphs to validate its effectiveness. Extensive analysis validates the utility of explicitly modeling cross features in GCN, especially for feature learning at lower layers."
Community Preserving Network Embedding,"Xiao Wang, Peng Cui, Jing Wang, JianPei, Wenwu Zhu, Shiqiang Yang",AAAI,,"Network embedding, aiming to learn the low-dimensional representations of nodes in networks, is of paramount importance in many real applications. One basic requirement of network embedding is to preserve the structure and inherent properties of the networks. While previous network embedding methods primarily preserve the microscopic structure, such as the first- and second-order proximities of nodes, the mesoscopic community structure, which is one of the most prominent feature of networks, is largely ignored. In this paper, we propose a novel Modularized Nonnegative Matrix Factorization (M-NMF) model to incorporate the community structure into network embedding. We exploit the consensus relationship between the representations of nodes and community structure, and then jointly optimize NMF based representation learning model and modularity based community detection model in a unified framework, which enables the learned representations of nodes to preserve both of the microscopic and community structures. We also provide efficient updating rules to infer the parameters of our model, together with the correctness and convergence guarantees. Extensive experimental results on a variety of real-world networks show the superior performance of the proposed method over the state-of-the-arts."
HINE: Heterogeneous Information Network Embedding,"Yuxin Chen, Chenguang Wang",Database Systems for Advanced Applications,"Heterogeneous information network, Network embedding, Semantic embedding","Network embedding has shown its effectiveness in embedding homogeneous networks. Compared with homogeneous networks, heterogeneous information networks (HINs) contain semantic information from multi-typed entities and relations, and are shown to be a more effective model for real world data. The existing network embedding methods fail to explicitly capture the semantics in HINs. In this paper, we propose an HIN embedding model (HINE), which consists of local and global semantic embedding. Local semantic embedding aims to incorporate entity type information via embedding the local structures and types of the entities in a supervised way. Global semantic embedding leverages multihop relation types among entities to propagate the global semantics via a Markov Random Field (MRF) to impact the embedding vectors. By doing so, HINE is capable to capture both local and global semantic information in the embedding vectors. Experimental results show that HINE significantly outperforms state-of-the-art methods."
Deep Structure Learning for Fraud Detection,"Haibo Wang, Chuan Zhou, Jia Wu,Weizhen Dang, Xingquan Zhu, JilongWang",IEEE,"Fraud Detection, Density Block, Graph Structure Learning, Behavior Similarity","Fraud detection is of great importance because fraudulent behaviors may mislead consumers or bring huge losses to enterprises. Due to the lockstep feature of fraudulent behaviors, fraud detection problem can be viewed as finding suspicious dense blocks in the attributed bipartite graph. In reality, existing attribute-based methods are not adversarially robust, because fraudsters can take some camouflage actions to cover their behavior attributes as normal. More importantly, existing structural information based methods only consider shallow topology structure, making their effectiveness sensitive to the density of suspicious blocks. In this paper, we propose a novel deep structure learning model named DeepFD to differentiate normal users and suspicious users. DeepFD can preserve the non-linear graph structure and user behavior information simultaneously. Experimental results on different types of datasets demonstrate that DeepFD outperforms the state-of-the-art baselines."
GraRep: Learning Graph Representations with Global Structural Information,"Shaosheng Cao, Wei Lu, Qiongkai Xu",ACM,"Graph Representation, Matrix Factorization, Feature Learning, Dimension Reduction","In this paper, we present GraRep, a novel model for learning vertex representations of weighted graphs. This model learns low dimensional vectors to represent vertices appearing in a graph and, unlike existing work, integrates global structural information of the graph into the learning process. We also formally analyze the connections between our work and several previous research efforts, including the DeepWalk model of Perozzi et al. [20] as well as the skip-gram model with negative sampling of Mikolov et al. [18] We conduct experiments on a language network, a social network as well as a citation network and show that our learned global representations can be effectively used as features in tasks such as clustering, classification and visualization. Empirical results demonstrate that our representation significantly outperforms other state-of-the-art methods in such tasks."
Scalable Graph Embedding Enhanced by Content-Preserving Locality Sensitive Hashing,"Xiusi Chen, Xiaoyu Li, Chang Zhou, Jun Gao",AAAI,,"Recent years have seen a massive research on representation learning of information networks, a.k.a, graph embedding. Graph embedding techniques aim at learning distributed representation that captures the semantic role of each vertex in a network, and can be applied to a variety of successor tasks such as natural language processing, image processing, recommender systems, and speech processing, etc. Most previous work on graph embedding only focuses on the structural properties of the graph. The insight behind these work is that the role of each node can be represented by its neighbors. For the high-degree nodes, the representation can be sufficiently trained due to the surrounding dense structure. For many real-world information networks, however, the degree distribution is likely to be subject to the Power Law, meaning that a large proportion of vertices are low-degree vertices. Due to the structural sparsity, merely learning the representation through the proximity to the neighbors could lead to poor quality of these low-degree nodes. To address this problem, we incorporate the content information to represent graph nodes and make the embedding generalizes well. We propose a model based on Locality Sensitive Hashing (LSH) to incorporate content features of vertices by preserving the content similarity between high-degree nodes and low-degree nodes. In this way, we improve the quality of the representation of the low-degree nodes by associating them to the high-degree ones with similar content via shared hashing outputs. We reformulate the representation of each vertex based on its output of hash functions, and then utilize graph structure to learn the representation. The hashing trick in our method can also reduce the redundant space consumption caused by contenthomogenous vertices so that it can be scaled up to data of industrial volume. We conduct extensive offline experiments on public datasets, and deploy our model onto the online recommendation system in Alibaba Group. The results show that our method is both effective and highly scalable."
Label Informed Attributed Network Embedding,"Xiao Huang, Jundong Li, Xia Hu",ACM,,"Attributed network embedding aims to seek low-dimensional vector representations for nodes in a network, such that original network topological structure and node attribute proximity can be preserved in the vectors. These learned representations have been demonstrated to be helpful in many learning tasks such as network clustering and link prediction. While existing algorithms follow an unsupervised manner, nodes in many real-world attributed networks are often associated with abundant label information, which is potentially valuable in seeking more effective joint vector representations. In this paper, we investigate how labels can be modeled and incorporated to improve attributed network embedding. This is a challenging task since label information could be noisy and incomplete. In addition, labels are completely distinct with the geometrical structure and node attributes. The bewildering combination of heterogeneous information makes the joint vector representation learning more difficult. To address these issues, we propose a novel Label informed Attributed Network Embedding (LANE) framework. It can smoothly incorporate label information into the attributed network embedding while preserving their correlations. Experiments on real-world datasets demonstrate that the proposed framework achieves significantly better performance compared with the state-of-the-art embedding algorithms."
Network Embedding via Community Based Variational Autoencoder,"Wei Shi, Ling Huang, Chang-DongWang, Juan-Hui Li, Yong Tang,Chengzhou Fu",IEEE,"Network embedding, community detection, variational autoencoder","In recent years, network embedding has attracted more and more attention due to its effectiveness and convenience to compress the network structured data. In this paper, we propose a communitybased variational autoencoder (ComVAE) model to learn network embedding, which consists of a community detection module and a deep learning module. In the proposed model, both community information and deep learning techniques are utilized to learn low-dimensional vertex representations. First, community information reveals an implicit relationship between vertices from a global view, which can be a supplement to local information and help to improve the embedding quality. To obtain the community information, community detection algorithms are utilized as a module and the modularization design makes the model more flexible. Second, deep learning techniques can not only integrate and preserve the information from both local and global views efficiently but also strengthen the robustness of vertex representations. To demonstrate the performance of our model, extensive experiments are conducted in four downstream tasks, namely, network reconstruction, node classification, link prediction, and visualization. The experimental results show that our model outperforms the state-of-the-art approaches to real-world datasets."
Deep Thinking: What Mathematics Can Teach Us About The Mind,William Byers,World Scientific Publishing,,"There is more than one way to think. Most people are familiar with the systematic, rule-based thinking that one finds in a mathematical proof or a computer program. But such thinking does not produce breakthroughs in mathematics and science nor is it the kind of thinking that results in significant learning. Deep thinking is a different and more basic way of using the mind. It results in the discontinuous ""aha!"" experience, which is the essence of creativity. It is at the heart of every paradigm shift or reframing of a problematic situation. The identification of deep thinking as the default state of the mind has the potential to reframe our current approach to technological change, education, and the nature of mathematics and science. For example, there is an unbridgeable gap between deep thinking and computer simulations of thinking. Many people suspect that such a gap exists, but find it difficult to make this intuition precise. This book identifies the way in which the authentic intelligence of deep thinking differs from the artificial intelligence of ""big data"" and ""analytics"". Deep thinking is the essential ingredient in every significant learning experience, which leads to a new way to think about education. It is also essential to the construction of conceptual systems that are at the heart of mathematics and science, and of the technologies that shape the modern world. Deep thinking can be found whenever one conceptual system morphs into another. The sources of this study include the cognitive development of numbers in children, neuropsychology, the study of creativity, and the historical development of mathematics and science. The approach is unusual and original. It comes out of the author’s lengthy experience as a mathematician, teacher, and writer of books about mathematics and science, such as How Mathematicians Think: Using Ambiguity, Contradiction, and Paradox to Create Mathematics and The Blind Spot: Science and the Crisis of Uncertainty."
Belief Network Analysis: A Relational Approach to Understanding the Structure of Attitudes1,"Andrei Boutyline, Stephen Vaisey",American Journal of Sociology,,"Many accounts of political belief systems conceive of them as networks of interrelated opinions, in which some beliefs are central and others peripheral. We formally show how such structural features can be used to construct direct measures of belief centrality in a network of correlations. We apply this method to the 2000 ANES data, which have been used to argue that political beliefs are organized around parenting schemas. Our structural approach instead yields results consistent with the central role of political identity, which individuals may use as the organizing heuristic to filter information from the political field. We search for population heterogeneity in this organizing logic first by comparing 44 demographic subpopulations, and then with inductive techniques. Contra recent accounts of belief system heterogeneity, we find that belief systems of different groups vary in the amount of organization, but not in the logic which organizes them."
Making Data Visual,"Danyel Fisher, Miriah D. Meyer",O'Reilly Media ,,"You have a mound of data front of you and a suite of computation tools at your disposal. Which parts of the data actually matter? Where is the insight hiding? If you’re a data scientist trying to navigate the murky space between data and insight, this practical book shows you how to make sense of your data through high-level questions, well-defined data analysis tasks, and visualizations to clarify understanding and gain insights along the way. When incorporated into the process early and often, iterative visualization can help you refine the questions you ask of your data. Authors Danyel Fisher and Miriah Meyer provide detailed case studies that demonstrate how this process can evolve in the real world. You’ll learn: The data counseling process for moving from general to more precise questions about your data, and arriving at a working visualization, The role that visual representations play in data discovery, Common visualization types by the tasks they fulfill and the data they use, Visualization techniques that use multiple views and interaction to support analysis of large, complex data sets."
"The (Protestant) Bible, the (printed) sermon, and the word(s): The semantic structure of the Conformist and Dissenting Bible, 1660–1780","M A Hoffman, Jean-Phillippe Cointet,Philipp Brandt, Newton E. Key, PeterShawn Bearman",Poetics,"Bible, Sermons, Network, Contention, Dissent, Text analysis, Structure","Using co-occurrence methods for identifying semantic structure in texts, we first describe the structure of the Protestant Bible, focusing on the ways in which contents of the Bible are organized in both the New and Old Testaments. We introduce a strategy for capturing the co-occurrence of nouns and verbs in windows defined by verses that progressively move across the text, from start to finish in a manner similar to reading. We then consider how Dissenters and Conformists used the Bible by locating Biblical verse in sermons printed in England during the period from 1660 to 1780. We describe how chapters are linked by themes over time, by dissenting and conformist religious communities, and map Dissenter and Conformist uses of the Bible onto its semantic structure. We show that it is possible to induce a semantic network image of the Bible, that this structure serves as a skeletal frame for interpretation, thereby highlighting different contents as central to denominations’ religious inspirations and concerns."
The impact of centrality on cooperative processes,"Sandro M. Reia, Sebastian Herrmann,José F. Fontanari",Physical Review E,,"The solution of today's complex problems requires the grouping of task forces whose members are usually connected remotely over long physical distances and different time zones. Hence, understanding the effects of imposed communication patterns (i.e., who can communicate with whom) on group performance is important. Here we use an agent-based model to explore the influence of the betweenness centrality of the nodes on the time the group requires to find the global maxima of NK-fitness landscapes. The agents cooperate by broadcasting messages, informing on their fitness to their neighbors, and use this information to copy the more successful agents in their neighborhood. We find that for easy tasks (smooth landscapes), the topology of the communication network has no effect on the performance of the group, and that the more central nodes are the most likely to find the global maximum first. For difficult tasks (rugged landscapes), however, we find a positive correlation between the variance of the betweenness among the network nodes and the group performance. For these tasks, the performances of individual nodes are strongly influenced by the agents' dispositions to cooperate and by the particular realizations of the rugged landscapes."
"Lexical shifts, substantive changes, and continuity in State of the Union discourse,1790-2014.","Alix Rule, Jean-Philippe Cointet, PeterShawn Bearman",PNAS,"State of the Union, text analysis, networks, natural language processing, American history","This study reveals that the entry into World War I in 1917 indexed the decisive transition to the modern period in American political consciousness, ushering in new objects of political discourse, a more rapid pace of change of those objects, and a fundamental reframing of the main tasks of governance. We develop a strategy for identifying meaningful categories in textual corpora that span long historic durées, where terms, concepts, and language use changes. Our approach is able to account for the fluidity of discursive categories over time, and to analyze their continuity by identifying the discursive stream as the object of interest."
Juniper: A Tree+Table Approach to Multivariate Graph Visualization,"Carolina Nobre, Marc Streit, AlexanderLex",arXiv,"Multivariate graphs, networks, tree-based graph visualization, adjacency matrix, spanning trees, visualization","Analyzing large, multivariate graphs is an important problem in many domains, yet such graphs are challenging to visualize. In this paper, we introduce a novel, scalable, tree+table multivariate graph visualization technique, which makes many tasks related to multivariate graph analysis easier to achieve. The core principle we follow is to selectively query for nodes or subgraphs of interest and visualize these subgraphs as a spanning tree of the graph. The tree is laid out linearly, which enables us to juxtapose the nodes with a table visualization where diverse attributes can be shown. We also use this table as an adjacency matrix, so that the resulting technique is a hybrid node-link/adjacency matrix technique. We implement this concept in Juniper and complement it with a set of interaction techniques that enable analysts to dynamically grow, restructure, and aggregate the tree, as well as change the layout or show paths between nodes. We demonstrate the utility of our tool in usage scenarios for different multivariate networks: a bipartite network of scholars, papers, and citation metrics and a multitype network of story characters, places, books, etc."
Graphiti: Interactive Specification of Attribute-Based Edges for Network Modeling and Visualization,"Arjun Srinivasan, Hyunwoo Park, AlexEndert, Rahul C. Basole",IEEE,"Network modeling, visual analytics, user interaction","Network visualizations, often in the form of node-link diagrams, are an effective means to understand relationships between entities, discover entities with interesting characteristics, and to identify clusters. While several existing tools allow users to visualize pre-defined networks, creating these networks from raw data remains a challenging task, often requiring users to program custom scripts or write complex SQL commands. Some existing tools also allow users to both visualize and model networks. Interaction techniques adopted by these tools often assume users know the exact conditions for defining edges in the resulting networks. This assumption may not always hold true, however. In cases where users do not know much about attributes in the dataset or when there are several attributes to choose from, users may not know which attributes they could use to formulate linking conditions. We propose an alternate interaction technique to model networks that allows users to demonstrate to the system a subset of nodes and links they wish to see in the resulting network. The system, in response, recommends conditions that can be used to model networks based on the specified nodes and links. In this paper, we show how such a demonstration-based interaction technique can be used to model networks by employing it in a prototype tool, Graphiti. Through multiple usage scenarios, we show how Graphiti not only allows users to model networks from a tabular dataset but also facilitates updating a pre-defined network with additional edge types."
Tempo and mode of performance evolution across multiple independent origins of adhesive toe pads in lizards.,"Travis J Hagey, Josef C. Uyeda, KristenE Crandell, Jorn A Cheney, KellarAutumn, Luke J. Harmon",Evolution,"Anole, Brownian motion, gecko, Ornstein–Uhlenbeck, toe detachment angle","Understanding macroevolutionary dynamics of trait evolution is an important endeavor in evolutionary biology. Ecological opportunity can liberate a trait as it diversifies through trait space, while genetic and selective constraints can limit diversification. While many studies have examined the dynamics of morphological traits, diverse morphological traits may yield the same or similar performance and as performance is often more proximately the target of selection, examining only morphology may give an incomplete understanding of evolutionary dynamics. Here, we ask whether convergent evolution of pad‐bearing lizards has followed similar evolutionary dynamics, or whether independent origins are accompanied by unique constraints and selective pressures over macroevolutionary time. We hypothesized that geckos and anoles each have unique evolutionary tempos and modes. Using performance data from 59 species, we modified Brownian motion (BM) and Ornstein–Uhlenbeck (OU) models to account for repeated origins estimated using Bayesian ancestral state reconstructions. We discovered that adhesive performance in geckos evolved in a fashion consistent with Brownian motion with a trend, whereas anoles evolved in bounded performance space consistent with more constrained evolution (an Ornstein–Uhlenbeck model). Our results suggest that convergent phenotypes can have quite distinctive evolutionary patterns, likely as a result of idiosyncratic constraints or ecological opportunities."
When more of the same is better,José F. Fontanari,arXiv,,"Problem solving (e.g., drug design, traffic engineering, software development) by task forces represents a substantial portion of the economy of developed countries. Here we use an agent-based model of cooperative problem-solving systems to study the influence of diversity on the performance of a task force. We assume that agents cooperate by exchanging information on their partial success and use that information to imitate the more successful agent in the system —the model. The agents differ only in their propensities to copy the model. We find that, for easy tasks, the optimal organization is a homogeneous system composed of agents with the highest possible copy propensities. For difficult tasks, we find that diversity can prevent the system from being trapped in sub-optimal solutions. However, when the system size is adjusted to maximize the performance the homogeneous systems outperform the heterogeneous systems, i.e., for optimal performance, sameness should be preferred to diversity."
A Club Is a Nation in Miniature,Carolyn Eastman,Chicago Scholarship Online,"Calliopean Society, young men, debating society, New-York Magazine, speeches, writing, oratory, public engagement","This chapter focuses on the Calliopean Society, a young men's debating society formed to support its middling, upwardly mobile members at a formative period in their lives by helping them hone their skills in speech and social engagement and providing the social connections necessary to succeed in business. It examines how this group of young men underwent transformation in their collective understanding of themselves as members of the public. These men worked as writers and editors of a column for a literary magazine, the New-York Magazine, and patterned their literary styles after those of cultural elites to assert themselves as worthy commentators and mediators to the public. The chapter shows how their understanding of themselves and their self-portrayals in print were transformed by the particular events of the 1790s. It also demonstrates how elocutionary ideas about speech, writing, and public engagement extended beyond one's school years. When members of the Calliopean Society engaged in debate or oratory and criticized each other's writings, they relied on elocutionary theories and sometimes even drew their speeches or themes from schoolbooks."
The Merchants' national bank of the city of New York,Philip Gengembre Hubert,New York Merchants' National Bank,,
Republic of Intellect,Bryan Waterman,Johns Hopkins University Press,,"In the 1790s, a single conversational circle—the Friendly Club—united New York City's most ambitious young writers, and in Republic of Intellect, Bryan Waterman uses an innovative blend of literary criticism and historical narrative to re-create the club's intellectual culture. The story of the Friendly Club reveals the mutually informing conditions of authorship, literary association, print culture, and production of knowledge in a specific time and place—the tumultuous, tenuous world of post-revolutionary New York City. More than any similar group in the early American republic, the Friendly Club occupied a crossroads—geographical, professional, and otherwise—of American literary and intellectual culture. Waterman argues that the relationships among club members' novels, plays, poetry, diaries, legal writing, and medical essays lead to important first examples of a distinctively American literature and also illuminate the local, national, and transatlantic circuits of influence and information that club members called ""the republic of intellect."" He addresses topics ranging from political conspiracy in the gothic novels of Charles Brockden Brown to the opening of William Dunlap's Park Theatre, from early American debates on gendered conversation to the publication of the first American medical journal. Voluntary association and print culture helped these young New Yorkers, Waterman concludes, to produce a broader and more diverse post-revolutionary public sphere than scholars have yet recognized."
Lineage: Visualizing Multivariate Clinical Data in Genealogy Graphs,"Carolina Nobre, Nils Gehlenborg, HilaryCoon, Alexander Lex",IEEE,"Multivariate networks, biology visualization, genealogies, hereditary genetics, multifactorial diseases","The majority of diseases that are a significant challenge for public and individual heath are caused by a combination of hereditary and environmental factors. In this paper we introduce Lineage, a novel visual analysis tool designed to support domain experts who study such multifactorial diseases in the context of genealogies. Incorporating familial relationships between cases with other data can provide insights into shared genomic variants and shared environmental exposures that may be implicated in such diseases. We introduce a data and task abstraction, and argue that the problem of analyzing such diseases based on genealogical, clinical, and genetic data can be mapped to a multivariate graph visualization problem. The main contribution of our design study is a novel visual representation for tree-like, multivariate graphs, which we apply to genealogies and clinical data about the individuals in these families. We introduce data-driven aggregation methods to scale to multiple families. By designing the genealogy graph layout to align with a tabular view, we are able to incorporate extensive, multivariate attributes in the analysis of the genealogy without cluttering the graph. We validate our designs by conducting case studies with our domain collaborators."
Policies for allocation of information in task-oriented groups: elitism and egalitarianism outperform welfarism,"Paulo F. Gomes, Sandro M. Reia, JoséF. Fontanari",arXiv,,"Communication or influence networks are probably the most controllable of all factors that are known to impact on the problem-solving capability of task-forces. In the case connections are costly, it is necessary to implement a policy to allocate them to the individuals. Here we use an agent-based model to study how distinct allocation policies affect the performance of a group of agents whose task is to find the global maxima of NK fitness landscapes. Agents cooperate by broadcasting messages informing on their fitness and use this information to imitate the fittest agent in their influence neighborhoods. The larger the influence neighborhood of an agent, the more links, and hence information, the agent receives. We find that the elitist policy in which agents with above-average fitness have their influence neighborhoods amplified, whereas agents with below-average fitness have theirs deflated, is optimal for smooth landscapes, provided the group size is not too small. For rugged landscapes, however, the elitist policy can perform very poorly for certain group sizes. In addition, we find that the egalitarian policy, in which the size of the influence neighborhood is the same for all agents, is optimal for both smooth and rugged landscapes in the case of small groups. The welfarist policy, in which the actions of the elitist policy are reversed, is always suboptimal, i.e., depending on the group size it is outperformed by either the elitist or the egalitarian policies."
The surprising little effectiveness of cooperative algorithms in parallel problem solving,"Sandro M. Reia, Larissa F. Aquino, JoséF. Fontanari",arXiv,,"Biological and cultural inspired optimization algorithms are nowadays part of the basic toolkit of a great many research domains. By mimicking processes in nature and animal societies, these general-purpose search algorithms promise to deliver optimal or near-optimal solutions using hardly any information on the optimization problems they are set to tackle. Here we study the performances of a cultural-inspired algorithm – the imitative learning search – as well as of asexual and sexual variants of evolutionary algorithms in finding the global maxima of NK-fitness landscapes. The main performance measure is the total number of agent updates required by the algorithms to find those global maxima and the baseline performance, which establishes the effectiveness of the cooperative algorithms, is set by the blind search in which the agents explore the problem space (binary strings) by flipping bits at random. We find that even for smooth landscapes that exhibit a single maximum, the evolutionary algorithms do not perform much better than the blind search due to the stochastic effects of the genetic roulette. The imitative learning is immune to this effect thanks to the deterministic choice of the fittest string in the population, which is used as a model for imitation. The tradeoff is that for rugged landscapes the imitative learning search is more prone to be trapped in local maxima than the evolutionary algorithms. In fact, in the case of rugged landscapes with a mild density of local maxima, the blind search either beats or matches the cooperative algorithms regardless of whether the task is to find the global maximum or to find the fittest state within a given runtime."
Agent-based models of collective intelligence,"Sandro M. Reia, André C. Amado, JoséF. Fontanari",arXiv,,"Collective or group intelligence is manifested in the fact that a team of cooperating agents can solve problems more efficiently than when those agents work in isolation. Although cooperation is, in general, a successful problem solving strategy, it is not clear whether it merely speeds up the time to find the solution, or whether it alters qualitatively the statistical signature of the search for the solution. Here we review and offer insights on two agent-based models of distributed cooperative problem-solving systems, whose task is to solve a cryptarithmetic puzzle. The first model is the imitative learning search in which the agents exchange information on the quality of their partial solutions to the puzzle and imitate the most successful agent in the group. This scenario predicts a very poor performance in the case imitation is too frequent or the group is too large, a phenomenon akin to Groupthink of social psychology. The second model is the blackboard organization in which agents read and post hints on a public blackboard. This brainstorming scenario performs the best when there is a stringent limit to the amount of information that is exhibited on the board. Both cooperative scenarios produce a substantial speed up of the time to solve the puzzle as compared with the situation where the agents work in isolation. The statistical signature of the search, however, is the same as that of the independent search."
Effect of group organization on the performance of cooperative processes,"Sandro M. Reia, José F. Fontanari",arXiv,,"Problem-solving competence at group level is influenced by the structure of the social networks and so it may shed light on the organization patterns of gregarious animals. Here we use an agent-based model to investigate whether the ubiquity of hierarchical networks in nature could be explained as the result of a selection pressure favoring problem-solving efficiency. The task of the agents is to find the global maxima of NK fitness landscapes and the agents cooperate by broadcasting messages informing on their fitness to the group. This information is then used to imitate, with a certain probability, the fittest agent in their influence networks. For rugged landscapes, we find that the modular organization of the hierarchical network with its high degree of clustering eases the escape from the local maxima, resulting in a superior performance as compared with the scale-free and the random networks. The optimal performance in a rugged landscape is achieved by letting the main hub to be only slightly more propense to imitate the other agents than vice versa. The performance is greatly harmed when the main hub carries out the search independently of the rest of the group as well as when it compulsively imitates the other agents."
Influence of network topology on cooperative problem-solving systems,"José F. Fontanari, Francisco AparecidoRodrigues",arXiv,,"The idea of a collective intelligence behind the complex natural structures built by organisms suggests that the organization of social networks is selected so as to optimize problem-solving competence at the group-level. Here we study the influence of the social network topology on the performance of a group of agents whose task is to locate the global maxima of NK fitness landscapes. Agents cooperate by broadcasting messages informing on their fitness and use this information to imitate the fittest agent in their influence networks. In the case those messages convey accurate information on the proximity of the solution (i.e., for smooth fitness landscapes) we find that high connectivity as well as centralization boost the group performance. For rugged landscapes, however, these characteristics are beneficial for small groups only. For large groups, it is advantageous to slow down the information transmission through the network to avoid local maximum traps. Long-range links and modularity have marginal effects on the performance of the group, except for a very narrow region of the model parameters."
Exploring NK fitness landscapes using imitative learning,José F. Fontanari,arXiv,,"The idea that a group of cooperating agents can solve problems more efficiently than when those agents work independently is hardly controversial, despite our obliviousness of the conditions that make cooperation a successful problem solving strategy. Here we investigate the performance of a group of agents in locating the global maxima of NK fitness landscapes with varying degrees of ruggedness. Cooperation is taken into account through imitative learning and the broadcasting of messages informing on the fitness of each agent. We find a trade-off between the group size and the frequency of imitation: for rugged landscapes, too much imitation or too large a group yield a performance poorer than that of independent agents. By decreasing the diversity of the group, imitative learning may lead to duplication of work and hence to a decrease of its effective size. However, when the parameters are set to optimal values the cooperative group substantially outperforms the independent agents."
Imitative Learning as a Connector of Collective Brains,José F. Fontanari,arXiv,,"The notion that cooperation can aid a group of agents to solve problems more efficiently than if those agents worked in isolation is prevalent, despite the little quantitative groundwork to support it. Here we consider a primordial form of cooperation – imitative learning – that allows an effective exchange of information between agents, which are viewed as the processing units of a social intelligence system or collective brain. In particular, we use agent-based simulations to study the performance of a group of agents in solving a cryptarithmetic problem. An agent can either perform local random moves to explore the solution space of the problem or imitate a model agent – the best performing agent in its influence network. There is a complex trade-off between the number of agents N and the imitation probability p, and for the optimal balance between these parameters we observe a thirtyfold diminution in the computational cost to find the solution of the cryptarithmetic problem as compared with the independent search. If those parameters are chosen far from the optimal setting, however, then imitative learning can impair greatly the performance of the group. The observed maladaptation of imitative learning for large N offers an alternative explanation for the group size of social animals."
Exploring NK Fitness Landscapes Using an Imitative Learning Search,José F. Fontanari,arXiv,,"The idea that a group of cooperating agents can solve problems more efficiently than when those agents work independently is hardly controversial, despite our obliviousness of the conditions that make cooperation a successful problem solving strategy. Here we investigate the performance of a group of agents in locating the global maxima of NK fitness landscapes with varying degrees of ruggedness. Cooperation is taken into account through imitative learning and the broadcasting of messages informing on the fitness of each agent. We find a trade-off between the group size and the frequency of imitation: for rugged landscapes, too much imitation or too large a group yield a performance poorer than that of independent agents. By decreasing the diversity of the group, imitative learning may lead to duplication of work and hence to a decrease of its effective size. However, when the parameters are set to optimal values the cooperative group substantially outperforms the independent agents."
The Logic of Opportunity: A Formal Analysis of the University of California's Outreach and Diversity Discourse.Research & Occasional Paper Series:CSHE.9.04.,"John W. Mohr, Michael Bourgeois,Vincent Duquenne","University of California, Berkeley",,"Since 1995, the University of California has been prohibited from employing affirmative action principles in student admissions. In response to this constraint, the UC has sought to pursue a number of other avenues for promoting the selection and retention of a diverse student body. In this paper we look at how officials and staff within the UC system have sought to develop an alternative rationale for managing the categorical problem of identifying types and classes of applicants along with strategies of action that stay within legally allowable frameworks. We argue that a new framework for organizational action has emerged (a cultural logic) which is made up of a dually ordered system of identity categories and institutional activity categories. We use Galois lattices as a way of unpacking the dynamic emergence of this new organizational logic."
Graffinity: Visualizing Connectivity In Large Graphs,"Ethan Kerzner, Alexander Lex, CrystalLynn Sigulinsky, Timothy Urness, BryanW. Jones, Robert Marc, Miriah D. Meyer",ACM,,"Multivariate graphs are prolific across many fields, including transportation and neuroscience. A key task in graph analysis is the exploration of connectivity, to, for example, analyze how signals flow through neurons, or to explore how well different cities are connected by flights. While standard node-link diagrams are helpful in judging connectivity, they do not scale to large networks. Adjacency matrices also do not scale to large networks and are only suitable to judge connectivity of adjacent nodes. A key approach to realize scalable graph visualization are queries: instead of displaying the whole network, only a relevant subset is shown. Query-based techniques for analyzing connectivity in graphs, however, can also easily suffer from cluttering if the query result is big enough. To remedy this, we introduce techniques that provide an overview of the connectivity and reveal details on demand. We have two main contributions: (1) two novel visualization techniques that work in concert for summarizing graph connectivity; and (2) Graffinity, an open-source implementation of these visualizations supplemented by detail views to enable a complete analysis workflow. Graffinity was designed in a close collaboration with neuroscientists and is optimized for connectomics data analysis, yet the technique is applicable across domains. We validate the connectivity overview and our open-source tool with illustrative examples using flight and connectomics data."
The Materiality of Ideology: Cultural Consumption and Political Thought after the American Revolution 1,M A Hoffman,American Journal of Sociology,,"Political polarization in America dates to the turn of the 19th century, when divisions over finance and the ideal structure of governance led to bitter battles between the first political parties. These party affiliations have traditionally been treated as emerging from either material interests or ideological commitments, a dispute that has proved unresolvable on empirical grounds. The dichotomy between materiality and ideology, however, is false: for ideas to have life, they require referent. For most of the early modern period, books, newspapers, letters and magazines were the material referents of ideas, furnishing the intellectual resources for the assemblage of ideologies. This paper uses reading patterns of America’s earliest political and economic elites, including a significant portion of the founding fathers, who checked out books from the New York Society Library (NYSL), to evaluate the extent of political polarization in the years between the ratification of the Constitution and the War of 1812. The reading data come from two charging ledgers spanning two periods –1789 to 1792, and 1799 to 1806 – during which a new country was built, relations with foreign nations defined, and contestation over the character of a new democracy was intense. Using novel combinations of text and network analysis, I explore the political nature of reading and the extent to which social, economic, and political positions overlapped with what people read. In the process, I identify the key intellectual dimensions on which New York, and by extension, American, elite society was politically stratified in its early years."
Predictability of the imitative learning trajectories,"Paulo R. A. Campos, José F. Fontanari",arXiv,,"The fitness landscape metaphor plays a central role on the modeling of optimizing principles in many research fields, ranging from evolutionary biology, where it was first introduced, to management research. Here we consider the ensemble of trajectories of the imitative learning search, in which agents exchange information on their fitness and imitate the fittest agent in the population aiming at reaching the global maximum of the fitness landscape. We assess the degree to which the starting and ending points determine the learning trajectories using two measures, namely, the predictability that yields the probability that two randomly chosen trajectories are the same, and the mean path divergence that gauges the dissimilarity between two learning trajectories. We find that the predictability is greater in rugged landscapes than in smooth ones. The mean path divergence, however, is strongly affected by the search parameters – population size and imitation propensity – that obliterate the influence of the underlying landscape. The learning trajectories become more deterministic, in the sense that there are fewer distinct trajectories and those trajectories are more similar to each other, with increasing population size and imitation propensity. In addition, we find that the roughness of the learning trajectories, which measures the deviation from additivity of the fitness function, is always greater than the roughness estimated over the entire fitness landscape."
Awareness improves problem-solving performance,José F. Fontanari,arXiv,,"The brain’s self-monitoring of activities, including internal activities – a functionality that we refer to as awareness – has been suggested as a key element of consciousness. Here we investigate whether the presence of an inner-eye-like process (monitor) that supervises the activities of a number of subsystems (operative agents) engaged in the solution of a problem can improve the problemsolving efficiency of the system. The problem is to find the global maximum of a NK fitness landscape and the performance is measured by the time required to find that maximum. The operative agents explore blindly the fitness landscape and the monitor provides them with feedback on the quality (fitness) of the proposed solutions. This feedback is then used by the operative agents to bias their searches towards the fittest regions of the landscape. We find that a weak feedback between the monitor and the operative agents improves the performance of the system, regardless of the difficulty of the problem, which is gauged by the number of local maxima in the landscape. For easy problems (i.e., landscapes without local maxima), the performance improves monotonically as the feedback strength increases, but for difficult problems, there is an optimal value of the feedback strength beyond which the system performance degrades very rapidly."
"Ploceus: Modeling, visualizing, and analyzing tabular data as networks","Zhicheng Liu, Shamkant B. Navathe,John T. Stasko",Information Visualization,"Data transformations, graph and network visualization, multivariate data, interaction design, exploratory data analysis","Tabular data are pervasive. Although tables often describe multivariate data without explicit definitions of a network, it may be advantageous to explore the data by modeling it as a graph or network for analysis. Even when a given table design specifies a network structure, analysts may want to look at multiple networks from different perspectives, at different levels of abstraction, and with different edge semantics. We present a system called Ploceus that offers a general approach for performing multidimensional and multilevel network–based visual analysis on multivariate tabular data. Powered by an underlying relational algebraic framework, Ploceus supports flexible construction and transformation of networks through a direct manipulation interface and integrates dynamic network manipulation with visual exploration through immediate feedback mechanisms. We report our findings on the learnability and usability of Ploceus and propose a model of user actions in visualization construction using Ploceus."
The old merchants of New York city,Walter Barrett,Andesite Press,,
Pathfinder: Visual Analysis of Paths in Graphs,"Christian Partl, Samuel Gratzl, MarcStreit, Anne Mai Wassermann,Hanspeter Pfister, Dieter Schmalstieg,Alexander Lex",Eurographics Conference on Visualization (EuroVis) 2016,,"The analysis of paths in graphs is highly relevant in many domains. Typically, path-related tasks are performed in node-link layouts. Unfortunately, graph layouts often do not scale to the size of many real world networks. Also, many networks are multivariate, i.e., contain rich attribute sets associated with the nodes and edges. These attributes are often critical in judging paths, but directly visualizing attributes in a graph layout exacerbates the scalability problem. In this paper, we present visual analysis solutions dedicated to path-related tasks in large and highly multivariate graphs. We show that by focusing on paths, we can address the scalability problem of multivariate graph visualization, equipping analysts with a powerful tool to explore large graphs. We introduce Pathfinder, a technique that provides visual methods to query paths, while considering various constraints. The resulting set of paths is visualized in both a ranked list and as a node-link diagram. For the paths in the list, we display rich attribute data associated with nodes and edges, and the node-link diagram provides topological context. The paths can be ranked based on topological properties, such as path length or average node degree, and scores derived from attribute data. Pathfinder is designed to scale to graphs with tens of thousands of nodes and edges by employing strategies such as incremental query results. We demonstrate Pathfinder’s fitness for use in scenarios with data from a coauthor network and biological pathways."
Jeffersonian democracy in New England,William Albert Robinson,Wentworth Press,,
"History of the Bank of New York and Trust Company, 1784 to 1934",Allan Nevins,Arno Pr,,
enRoute: Dynamic path extraction from biological pathway maps for in-depth experimental data analysis,"Christian Partl, Denis Kalkofen,Alexander Lex, Karl Kashofer, MarcStreit, Dieter Schmalstieg",BMC Bioinformatics,,"Jointly analyzing biological pathway maps and experimental data is critical for understanding how biological processes work in different conditions and why different samples exhibit certain characteristics. This joint analysis, however, poses a significant challenge for visualization. Current techniques are either well suited to visualize large amounts of pathway node attributes, or to represent the topology of the pathway well, but do not accomplish both at the same time. To address this we introduce enRoute, a technique that enables analysts to specify a path of interest in a pathway, extract this path into a separate, linked view, and show detailed experimental data associated with the nodes of this extracted path right next to it. This juxtaposition of the extracted path and the experimental data allows analysts to simultaneously investigate large amounts of potentially heterogeneous data, thereby solving the problem of joint analysis of topology and node attributes. As this approach does not modify the layout of pathway maps, it is compatible with arbitrary graph layouts, including those of hand-crafted, imagebased pathway maps. We demonstrate the technique in context of pathways from the KEGG and the Wikipathways databases. We apply experimental data from two public databases, the Cancer Cell Line Encyclopedia (CCLE) and The Cancer Genome Atlas (TCGA) that both contain a wide variety of genomic datasets for a large number of samples. In addition, we make use of a smaller dataset of hepatocellular carcinoma and common xenograft models. To verify the utility of enRoute, domain experts conducted two case studies where they explore data from the CCLE and the hepatocellular carcinoma datasets in the context of relevant pathways."
Periodical publics: Magazines and literary networks in post-Revolutionary America,Robb K. Haberman,University of Connecticut ,,"Periodical Publics investigates the twenty American magazines produced between 1783 to 1792. Using the magazine medium as a window, this study seeks to expand our understanding of American society and culture in the post-Revolutionary era. Focusing on networks, I identify the different and overlapping connections that formed as authors, publishers, printers, and editors took part in acts of textual presentation, periodical publication, literary collaboration, and learned investigation. My study also examines the close ties linking magazines with such other sites of cultural production as literary societies, museums, and the theater. Magazines contributed to a rich world of intellectual and social exchanges by fostering local and regional cultures. Thus, unlike the scholarship that views magazines from the perspective of nation formation, I foreground smaller spaces of textual exchange. Magazine proprietors and editors in New York, Philadelphia, and Boston may have used nationalist rhetoric in their publications, but this ""provincial nationalism"" worked on the ground to promote not one republic but multiple publics. My dissertation therefore challenges those who view the 1780s and 1790s from an exceptionalist standpoint and judge culture by its capacity to create uniquely American subjectivities"
Social learning strategies modify the effect of network structure on group performance,"Daniel Barkoczi, Mirta Galesic",Nature Communications,,"The structure of communication networks is an important determinant of the capacity of teams, organizations and societies to solve policy, business and science problems. Yet, previous studies reached contradictory results about the relationship between network structure and performance, finding support for the superiority of both well-connected efficient and poorly connected inefficient network structures. Here we argue that understanding how communication networks affect group performance requires taking into consideration the social learning strategies of individual team members. We show that efficient networks outperform inefficient networks when individuals rely on conformity by copying the most frequent solution among their contacts. However, inefficient networks are superior when individuals follow the best member by copying the group member with the highest payoff. In addition, groups relying on conformity based on a small sample of others excel at complex tasks, while groups following the best member achieve greatest performance for simple tasks. Our findings reconcile contradictory results in the literature and have broad implications for the study of social learning across disciplines."
Social learning strategies reconcile the relationship between network structure and collective problem solving,"Daniel Barkoczi, Mirta Galesic",Santa Fe Institute ,,"We study how different social learning strategies, composed of cognitively plausible rules that guide information search, stopping search and decision making, affect population-level performance in a collective problem-solving task. We show that different social learning strategies lead to remarkably different outcomes and demonstrate how these outcomes are affected by the communication networks agents are embedded in. We argue that understanding how communication networks affect collective performance requires taking into consideration the individual strategies used by agents. To illustrate this point we show how our findings can reconcile contradictory results in the literature on network structure and collective problem solving."
On the Expected Performance of Systems with Complex Interactions Among Components,"Daniel Solow, Apostolos Burnetas,Ming-Chi Tsai, Neil S. Greenspan",Complex Systems ,,"A class of combinatorial optimization models is presented for studying certain systems that arise in biology, physics, business, and elsewhere. These systems consist of a finite number of parts. For each part, it is necessary to choose one of several interchangeable components so as to maximize a performance measure of the resulting system that depends on how the chosen parts interact with each other. Probabilistic analysis and computer simulations provide insight into some factors that affect the expected performance of such systems. These models provide the ability to control the interactions among the components and to study the effect of replacing a single component in the system."
enRoute: dynamic path extraction from biological pathway maps for exploring heterogeneous experimental datasets,"Christian Partl, Alexander Lex, MarcStreit, Denis Kalkofen, Karl Kashofer,Dieter Schmalstieg",BMC Bioinformatics,,"Jointly analyzing biological pathway maps and experimental data is critical for understanding how biological processes work in different conditions and why different samples exhibit certain characteristics. This joint analysis, however, poses a significant challenge for visualization. Current techniques are either well suited to visualize large amounts of pathway node attributes, or to represent the topology of the pathway well, but do not accomplish both at the same time. To address this we introduce enRoute, a technique that enables analysts to specify a path of interest in a pathway, extract this path into a separate, linked view, and show detailed experimental data associated with the nodes of this extracted path right next to it. This juxtaposition of the extracted path and the experimental data allows analysts to simultaneously investigate large amounts of potentially heterogeneous data, thereby solving the problem of joint analysis of topology and node attributes. As this approach does not modify the layout of pathway maps, it is compatible with arbitrary graph layouts, including those of hand-crafted, imagebased pathway maps. We demonstrate the technique in context of pathways from the KEGG and the Wikipathways databases. We apply experimental data from two public databases, the Cancer Cell Line Encyclopedia (CCLE) and The Cancer Genome Atlas (TCGA) that both contain a wide variety of genomic datasets for a large number of samples. In addition, we make use of a smaller dataset of hepatocellular carcinoma and common xenograft models. To verify the utility of enRoute, domain experts conducted two case studies where they explore data from the CCLE and the hepatocellular carcinoma datasets in the context of relevant pathways."
"Social learning strategies, network structure and the exploration-exploitation tradeoff","Daniel Barkoczi, Mirta Galesic",Nature Communications,"social learning, NK model, exploration-exploitation, social network","In this paper we study how different social learning strategies composed of three cognitive building blocks (i.e., rules that guide information search, stopping search and decision making) affect populationlevel performance in a collective problem-solving task. We show that different social learning strategies lead to remarkably different outcomes and demonstrate how these outcomes are affected by the communication networks agents are embedded in. We argue that understanding how communication networks affect collective performance requires taking into consideration the individual strategies used by agents. To illustrate this point we show how our findings can reconcile contradictory results in the literature on network structure and collective problem-solving."
Collaborative learning in networks.,"Winter A. Mason, Duncan J. Watts",PNAS,"collaboration, diffusion, exploration-exploitation trade off","Complex problems in science, business, and engineering typically require some tradeoff between exploitation of known solutions and exploration for novel ones, where, in many cases, information about known solutions can also disseminate among individual problem solvers through formal or informal networks. Prior research on complex problem solving by collectives has found the counterintuitive result that inefficient networks, meaning networks that disseminate information relatively slowly, can perform better than efficient networks for problems that require extended exploration. In this paper, we report on a series of 256 Web-based experiments in which groups of 16 individuals collectively solved a complex problem and shared information through different communication networks. As expected, we found that collective exploration improved average success over independent exploration because good solutions could diffuse through the network. In contrast to prior work, however, we found that efficient networks outperformed inefficient networks, even in a problem space with qualitative properties thought to favor inefficient networks. We explain this result in terms of individual-level explore-exploit decisions, which we find were influenced by the network structure as well as by strategic considerations and the relative payoff between maxima. We conclude by discussing implications for realworld problem solving and possible extensions."
Detecting Changes in Suicide Content Manifested in Social Media Following Celebrity Suicides,"Mrinal Kumar, Mark Dredze, GlenCoppersmith, Munmun De Choudhury",ACM,"social media, suicide, Werther effect, mental health, Reddit","The Werther effect describes the increased rate of completed or attempted suicides following the depiction of an individual’s suicide in the media, typically a celebrity. We present findings on the prevalence of this effect in an online platform: r/SuicideWatch on Reddit. We examine both the posting activity and post content after the death of ten high-profile suicides. Posting activity increases following reports of celebrity suicides, and post content exhibits considerable changes that indicate increased suicidal ideation. Specifically, we observe that post-celebrity suicide content is more likely to be inward focused, manifest decreased social concerns, and laden with greater anxiety, anger, and negative emotion. Topic model analysis further reveals content in this period to switch to a more derogatory tone that bears evidence of self-harm and suicidal tendencies. We discuss the implications of our findings in enabling better community support to psychologically vulnerable populations, and the potential of building suicide prevention interventions following high-profile suicides."
Predicting Depression via Social Media,"Munmun De Choudhury, MichaelGamon, Scott Counts, Eric Horvitz",AAAI,,"Major depression constitutes a serious challenge in personal and public health. Tens of millions of people each year suffer from depression and only a fraction receives adequate treatment. We explore the potential to use social media to detect and diagnose major depressive disorder in individuals. We first employ crowdsourcing to compile a set of Twitter users who report being diagnosed with clinical depression, based on a standard psychometric instrument. Through their social media postings over a year preceding the onset of depression, we measure behavioral attributes relating to social engagement, emotion, language and linguistic styles, ego network, and mentions of antidepressant medications. We leverage these behavioral cues, to build a statistical classifier that provides estimates of the risk of depression, before the reported onset. We find that social media contains useful signals for characterizing the onset of depression in individuals, as measured through decrease in social activity, raised negative affect, highly clustered egonetworks, heightened relational and medicinal concerns, and greater expression of religious involvement. We believe our findings and methods may be useful in developing tools for identifying the onset of major depression, for use by healthcare agencies; or on behalf of individuals, enabling those suffering from depression to be more proactive about their mental health."
Quantifying Mental Health Signals in Twitter,"Glen Coppersmith, Mark Dredze, CraigHarman",ACL,,"The ubiquity of social media provides a rich opportunity to enhance the data available to mental health clinicians and researchers, enabling a better-informed and better-equipped mental health field. We present analysis of mental health phenomena in publicly available Twitter data, demonstrating how rigorous application of simple natural language processing methods can yield insight into specific disorders as well as mental health writ large, along with evidence that as-of-yet undiscovered linguistic signals relevant to mental health exist in social media. We present a novel method for gathering data for a range of mental illnesses quickly and cheaply, then focus on analysis of four in particular: post-traumatic stress disorder (PTSD), depression, bipolar disorder, and seasonal affective disorder (SAD). We intend for these proof-of-concept results to inform the necessary ethical discussion regarding the balance between the utility of such data and the privacy"
Quantifying and Predicting Mental Illness Severity in Online Pro-Eating Disorder Communities,"Stevie Chancellor, Zhiyuan Lin, Erica L.Goodman, Stephanie Zerwas, MunmunDe Choudhury",ACM,"Instagram, social media, mental health, mental illness, selfinjury, eating disorder","Social media sites have struggled with the presence of emotional and physical self-injury content. Individuals who share such content are often challenged with severe mental illnesses like eating disorders. We present the first study quantifying levels of mental illness severity (MIS) in social media. We examine a set of users on Instagram who post content on pro-eating disorder tags (26M posts from 100K users). Our novel statistical methodology combines topic modeling and novice/clinician annotations to infer MIS in a user’s content. Alarmingly, we find that proportion of users whose content expresses high MIS have been on the rise since 2012 (13%/year increase). Previous MIS in a user’s content over seven months can predict future risk with ∼81% accuracy. Our model can also forecast MIS levels up to eight months in the future with performance better than baseline. We discuss the health outcomes and design implications as well as ethical considerations of this line of research."
Measuring Post Traumatic Stress Disorder in Twitter,"Glen Coppersmith, Craig Harman, MarkDredze",AAAI,,"Traditional mental health studies rely on information primarily collected through personal contact with a health care professional. Recent work has shown the utility of social media data for studying depression, but there have been limited evaluations of other mental health conditions. We consider post traumatic stress disorder (PTSD), a serious condition that affects millions worldwide, with especially high rates in military veterans. We also present a novel method to obtain a PTSD classifier for social media using simple searches of available Twitter data, a significant reduction in training data cost compared to previous work. We demonstrate its utility by examining differences in language use between PTSD and random individuals, building classifiers to separate these two groups and by detecting elevated rates of PTSD at and around U.S. military bases using our classifiers."
Characterizing and predicting postpartum depression from shared facebook data,"Munmun De Choudhury, Scott Counts,Eric Horvitz, Aaron Hoff",ACM,"childbirth, emotion, health, language, postpartum, social media, Twitter, wellness","The birth of a child is a major milestone in the life of parents. We leverage Facebook data shared voluntarily by 165 new mothers as streams of evidence for characterizing their postnatal experiences. We consider multiple measures including activity, social capital, emotion, and linguistic style in participants’ Facebook data in pre- and postnatal periods. Our study includes detecting and predicting onset of post-partum depression (PPD). The work complements recent work on detecting and predicting significant postpartum changes in behavior, language, and affect from Twitter data. In contrast to prior studies, we gain access to ground truth on postpartum experiences via self-reports and a common psychometric instrument used to evaluate PPD. We develop a series of statistical models to predict, from data available before childbirth, a mother’s likelihood of PPD. We corroborate our quantitative findings through interviews with mothers experiencing PPD. We find that increased social isolation and lowered availability of social capital on Facebook, are the best predictors of PPD in mothers."
"Mental Health Discourse on reddit: Self-Disclosure, Social Support, and Anonymity","Munmun De Choudhury, Sushovan De",AAAI,,"Social media is continually emerging as a platform of information exchange around health challenges. We study mental health discourse on the popular social media: reddit. Building on findings about health information seeking and sharing practices in online forums, and social media like Twitter, we address three research challenges. First, we present a characterization of self-disclosure in mental illness communities on reddit. We observe individuals discussing a variety of concerns ranging from the daily grind to specific queries about diagnosis and treatment. Second, we build a statistical model to examine the factors that drive social support on mental health reddit communities. We also develop language models to characterize mental health social support, which are observed to bear emotional, informational, instrumental, and prescriptive information. Finally, we study disinhibition in the light of the dissociative anonymity that reddit’s throwaway accounts provide. Apart from promoting open conversations, such anonymity surprisingly is found to gather feedback that is more involving and emotionally engaging. Our findings reveal, for the first time, the kind of unique information needs that a social media like reddit might be fulfilling when it comes to a stigmatic illness. They also expand our understanding of the role of the social web in behavioral therapy."
From ADHD to SAD: Analyzing the Language of Mental Health on Twitter through Self-Reported Diagnoses,"Glen Coppersmith, Mark Dredze, CraigHarman, Kristy Hollingshead",ACL,,"Many significant challenges exist for the mental health field, but one in particular is a lack of data available to guide research. Language provides a natural lens for studying mental health – much existing work and therapy have strong linguistic components, so the creation of a large, varied, language-centric dataset could provide significant grist for the field of mental health research. We examine a broad range of mental health conditions in Twitter data by identifying self-reported statements of diagnosis. We systematically explore language differences between ten conditions with respect to the general population, and to each other. Our aim is to provide guidance and a roadmap for where deeper exploration is likely to be fruitful."
Exploratory Analysis of Social Media Prior to a Suicide Attempt,"Glen Coppersmith, Kim Ngo, RyanLeary, Anthony Wood",ACL,,"Tragically, an estimated 42,000 Americans died by suicide in 2015, each one deeply affecting friends and family. Very little data and information is available about people who attempt to take their life, and thus scientific exploration has been hampered. We examine data from Twitter users who have attempted to take their life and provide an exploratory analysis of patterns in language and emotions around their attempt. We also show differences between those who have attempted to take their life and matched controls. We find quantifiable signals of suicide attempts in the language of social media data and estimate performance of a simple machine learning classifier with these signals as a non-invasive analysis in a screening process."
Social media as a measurement tool of depression in populations,"Munmun De Choudhury, Scott Counts,Eric Horvitz",ACM,"behavior, depression, emotion, health, language, social media, mental health, public health, Twitter, wellness","Depression is a serious and widespread public health challenge. We examine the potential for leveraging social media postings as a new type of lens in understanding depression in populations. Information gleaned from social media bears potential to complement traditional survey techniques in its ability to provide finer grained measurements over time while radically expanding population sample sizes. We present work on using a crowdsourcing methodology to build a large corpus of postings on Twitter that have been shared by individuals diagnosed with clinical depression. Next, we develop a probabilistic model trained on this corpus to determine if posts could indicate depression. The model leverages signals of social activity, emotion, and language manifested on Twitter. Using the model, we introduce a social media depression index that may serve to characterize levels of depression in populations. Geographical, demographic and seasonal patterns of depression given by the measure confirm psychiatric findings and correlate highly with depression statistics reported by the Centers for Disease Control and Prevention (CDC)."
Quantifying Suicidal Ideation via Language Usage on Social Media,"Glen Coppersmith, Ryan Leary, EricWhyne",JSM 2015,"Mental Health, Social Media, Suicidal Ideation, Suicide","Suicide is a large and growing problem, yet relevant data to draw informed decisions and assess intervention strategies is sorely lacking, and often at least two years out of date. We analyze publicly available data to assess the viability of using it to provide more timely information. We examine quantifiable signals related to suicide attempts and suicidal ideation in the language of social media data. Our data consists of Twitter users who have attempted suicide and age- and gender-matched neurotypical controls and similarly matched clinically depressed users. We apply simple language modeling techniques to separate those users automatically, and examine what quantifiable signals allow them to function, tying them back to psychometrically validated concepts related to suicide. We then use these scalable classifiers with public social media data and open government data to suggest some direction for future epidemiological research. All this research is done with public data, though we take great care to protect the privacy of the users."
Role of social media in tackling challenges in mental health,Munmun De Choudhury,ACM,"behavior, depression, emotion, health, language, multimedia, social media, mental health, public health, Twitter, wellness","Mental illness is a serious and widespread health challenge in our society today. Tens of millions of people each year suffer from depression and only a fraction receives adequate treatment. This position paper highlights some recent attempts examining the potential for leveraging social media postings as a new type of lens in understanding mental illness in individuals and populations. Information gleaned from social media bears potential to complement traditional survey techniques in its ability to provide finer grained measurements of behavior over time while radically expanding population sample sizes. We conclude highlighting how this research direction may be useful in developing tools for identifying the onset of depressive disorders in individuals, for use by healthcare agencies; or on behalf of individuals, enabling those suffering from mental illness to be more proactive about their mental health."
#thyghgapp: Instagram Content Moderation and Lexical Variation in Pro-Eating Disorder Communities,"Stevie Chancellor, Jessica Pater,Trustin Clear, Eric Gilbert, Munmun DeChoudhury",ACM,"Instagram, social media, lexical variation, eating disorder","Pro-eating disorder (pro-ED) communities on social media encourage the adoption and maintenance of disordered eating habits as acceptable alternative lifestyles rather than threats to health. In particular, the social networking site Instagram has reacted by banning searches on several proED tags and issuing content advisories on others. We present the first large-scale quantitative study investigating pro-ED communities on Instagram in the aftermath of moderation – our dataset contains 2.5M posts between 2011 and 2014. We find that the pro-ED community has adopted nonstandard lexical variations of moderated tags to circumvent these restrictions. In fact, increasingly complex lexical variants have emerged over time. Communities that use lexical variants show increased participation and support of proED (15-30%). Finally, the tags associated with content on these variants express more toxic, self-harm, and vulnerable content. Despite Instagram’s moderation strategies, pro-ED communities are active and thriving. We discuss the effectiveness of content moderation as an intervention for communities of deviant behavior."
The Language of Social Support in Social Media and Its Effect on Suicidal Ideation Risk,"Munmun De Choudhury, Emre Kiciman",AAAI,,"Online social support is known to play a significant role in mental well-being. However, current research is limited in its ability to quantify this link. Challenges exist due to the paucity of longitudinal, pre- and post mental illness risk data, and reliable methods that can examine causality between past availability of support and future risk. In this paper, we propose a method to measure how the language of comments in Reddit mental health communities influences risk to suicidal ideation in the future. Incorporating human assessments in a stratified propensity score analysis based framework, we identify comparable subpopulations of individuals and measure the effect of online social support language. We interpret these linguistic cues with an established theoretical model of social support, and find that esteem and network support play a more prominent role in reducing forthcoming risk. We discuss the implications of our work for designing tools that can improve support provisions in online communities."
Triaging content severity in online mental health forums,"Arman Cohan, Sydney Young, AndrewYates, Nazli Goharian",arXiv,,"Mental health forums are online communities where people express their issues and seek help from moderators and other users. In such forums, there are often posts with severe content indicating that the user is in acute distress and there is a risk of attempted self-harm. Moderators need to respond to these severe posts in a timely manner to prevent potential selfharm. However, the large volume of daily posted content makes it difficult for the moderators to locate and respond to these critical posts. We present a framework for triaging user content into four severity categories which are defined based on indications of self-harm ideation. Our models are based on a feature-rich classification framework which includes lexical, psycholinguistic, contextual and topic modeling features. Our approaches improve the state of the art in triaging the content severity in mental health forums by large margins (up to 17% improvement over the F-1 scores). Using the proposed model, we analyze the mental state of users and we show that overall, long-term users of the forum demonstrate a decreased severity of risk over time. Our analysis on the interaction of the moderators with the users further indicates that without an automatic way to identify critical content, it is indeed challenging for the moderators to provide timely response to the users in need."
Recovery Amid Pro-Anorexia: Analysis of Recovery in Social Media,"Stevie Chancellor, Tanushree Mitra,Munmun De Choudhury",ACM,"Tumblr, social media, anorexia, proana, recovery","Online communities can promote illness recovery and improve well-being in the cases of many kinds of illnesses. However, for challenging mental health condition like anorexia, social media harbor both recovery communities as well as those that encourage dangerous behaviors. The effectiveness of such platforms in promoting recovery despite housing both communities is underexplored. Our work begins to fill this gap by developing a statistical framework using survival analysis and situating our results within the cognitive behavioral theory of anorexia. This model identifies content and participation measures that predict the likelihood of recovery. From our dataset of over 68M posts and 10K users that self-identify with anorexia, we find that recovery on Tumblr is protracted - only half of the population is estimated to exhibit signs of recovery after four years. We discuss the effectiveness of social media in improving well-being around anorexia, a unique health challenge, and emergent questions from this line of work."
Recognizing Depression from Twitter Activity,"Sho Tsugawa, Yusuke Kikuchi, FumioKishino, Kosuke Nakajima, Yuichi Itoh,Hiroyuki Ohsaki",ACM,"Social media, Depression, Twitter, Machine learning","In this paper, we extensively evaluate the effectiveness of using a user’s social media activities for estimating degree of depression. As ground truth data, we use the results of a web-based questionnaire for measuring degree of depression of Twitter users. We extract several features from the activity histories of Twitter users. By leveraging these features, we construct models for estimating the presence of active depression. Through experiments, we show that (1) features obtained from user activities can be used to predict depression of users with an accuracy of 69%, (2) topics of tweets estimated with a topic model are useful features, (3) approximately two months of observation data are necessary for recognizing depression, and longer observation periods do not contribute to improving the accuracy of estimation for current depression; sometimes, longer periods worsen the accuracy."
Predicting postpartum changes in emotion and behavior via social media,"Munmun De Choudhury, Scott Counts,Eric Horvitz",ACM,"behavioral health, childbirth, depression, emotion, health, language, postpartum, PPD, social media, Twitter, wellness","We consider social media as a promising tool for public health, focusing on the use of Twitter posts to build predictive models about the influence of childbirth on the forthcoming behavior and mood of new mothers. Using Twitter posts, we quantify postpartum changes in 376 mothers along dimensions of social engagement, emotion, social network, and linguistic style. We then construct statistical models from a training set of observations of these measures before and after the reported childbirth, to forecast significant postpartum changes in mothers. The predictive models can classify mothers who will change significantly following childbirth with an accuracy of 71%, using observations about their prenatal behavior, and as accurately as 80-83% when additionally leveraging the initial 2-3 weeks of postnatal data. The study is motivated by the opportunity to use social media to identify mothers at risk of postpartum depression, an underreported health concern among large populations, and to inform the design of low-cost, privacy-sensitive early-warning systems and intervention programs aimed at promoting wellness postpartum."
Gender and Cross-Cultural Differences in Social Media Disclosures of Mental Illness,"Munmun De Choudhury, Sanket S.Sharma, Tomaz Logar, Wouter Eekhout,René Clausen Nielsen",ACM,"social media, twitter, reddit, mental health, depression, suicide, health, gender, culture","Cultural and gender norms shape how mental illness and therapy are perceived. However, there is a paucity of adequate empirical evidence around gender and cultural dimensions of mental illness. In this paper we situate social media as a “lens” to examine these dimensions. We focus on a large dataset of individuals who self-disclose to have an underlying mental health concern on Twitter. Having identified genuine disclosures in this data via semi-supervised learning, we examine differences in their posts, as measured via linguistic attributes and topic models. Our findings reveal significant differences between the content shared by female and male users, and by users from two western and two majority world countries. Males express higher negativity and lower desire for social support, whereas majority world users demonstrate more inhibition in their expression. We discuss the implications of our work in providing insights into the relationship of gender and culture with mental health, and in the design of gender and culture-aware health interventions."
Anorexia on Tumblr: A Characterization Study,Munmun De Choudhury,ACM,"anorexia, eating disorder, health, social media, tumblr","Eating disorders, such as anorexia nervosa are a major health concern affecting many young individuals. Given the extensive adoption of social media technologies in the anorexia affected demographic, we study behavioral characteristics of this population focusing on the social media Tumblr. Aligned with observations in prior literature, we find the presence of two prominent anorexia related communities on Tumblr — pro-anorexia and pro-recovery. Empirical analyses on several thousand Tumblr posts show use of the site as a media-rich platform replete with triggering content for enacting anorexia as a lifestyle choice. Through use of common pro-anorexia tags, the prorecovery community however attempts to “permeate” into the pro-anorexia community to educate them of the health risks of anorexia. Further, the communities exhibit distinctive affective, social, cognitive, and linguistic style markers. Compared with recovering anorexics, pro-anorexics express greater negative affect, higher cognitive impairment, and greater feelings of social isolation and selfharm. We also observe that these characteristics may be used in a predictive setting to detect anorexia content with ∼80% accuracy. Based on our findings, clinical implications of detecting anorexia related content on social media are discussed."
Depression and Self-Harm Risk Assessment in Online Forums,"Andrew Yates, Arman Cohan, NazliGoharian",ACL,,"Users suffering from mental health conditions often turn to online resources for support, including specialized online support communities or general communities such as Twitter and Reddit. In this work, we present a framework for supporting and studying users in both types of communities. We propose methods for identifying posts in support communities that may indicate a risk of self-harm, and demonstrate that our approach outperforms strong previously proposed methods for identifying such posts. Self-harm is closely related to depression, which makes identifying depressed users on general forums a crucial related task. We introduce a largescale general forum dataset consisting of users with self-reported depression diagnoses matched with control users. We show how our method can be applied to effectively identify depressed users from their use of language alone. We demonstrate that our method outperforms strong baselines on this general forum dataset."
Quantifying the Language of Schizophrenia in Social Media,"Margaret Mitchell, Kristy Hollingshead,Glen Coppersmith",ACL,,"Analyzing symptoms of schizophrenia has traditionally been challenging given the low prevalence of the condition, affecting around 1% of the U.S. population. We explore potential linguistic markers of schizophrenia using the tweets1 of self-identified schizophrenia sufferers, and describe several natural language processing (NLP) methods to analyze the language of schizophrenia. We examine how these signals compare with the widelyused LIWC categories for understanding mental health (Pennebaker et al., 2007), and provide preliminary evidence of additional linguistic signals that may aid in identifying and getting help to people suffering from schizophrenia."
CLPsych 2015 Shared Task: Depression and PTSD on Twitter,"Glen Coppersmith, Mark Dredze, CraigHarman, Kristy Hollingshead, MargaretMitchell",ACL,,"This paper presents a summary of the Computational Linguistics and Clinical Psychology (CLPsych) 2015 shared and unshared tasks. These tasks aimed to provide apples-to-apples comparisons of various approaches to modeling language relevant to mental health from social media. The data used for these tasks is from Twitter users who state a diagnosis of depression or post traumatic stress disorder (PTSD) and demographically-matched community controls. The unshared task was a hackathon held at Johns Hopkins University in November 2014 to explore the data, and the shared task was conducted remotely, with each participating team submitted scores for a held-back test set of users. The shared task consisted of three binary classification experiments: (1) depression versus control, (2) PTSD versus control, and (3) depression versus PTSD. Classifiers were compared primarily via their average precision, though a number of other metrics are used along with this to allow a more nuanced interpretation of the performance measures."
Language Signals Preceding Suicide Attempts,Anthony Wood,PMC,"Suicide, suicide screening, suicide prevention, social media, data science, natural language processing","Suicide is among the 10 most common causes of death, as assessed by the World Health Organization. For every death by suicide, an estimated 138 people’s lives are meaningfully affected, and almost any other statistic around suicide deaths is equally alarming. The pervasiveness of social media—and the near-ubiquity of mobile devices used to access social media networks—offers new types of data for understanding the behavior of those who (attempt to) take their own lives and suggests new possibilities for preventive intervention. We demonstrate the feasibility of using social media data to detect those at risk for suicide. Specifically, we use natural language processing and machine learning (specifically deep learning) techniques to detect quantifiable signals around suicide attempts, and describe designs for an automated system for estimating suicide risk, usable by those without specialized mental health training (eg, a primary care doctor). We also discuss the ethical use of such technology and examine privacy implications. Currently, this technology is only used for intervention for individuals who have “opted in” for the analysis and intervention, but the technology enables scalable screening for suicide risk, potentially identifying many people who are at risk preventively and prior to any engagement with a health care system. This raises a significant cultural question about the trade-off between privacy and prevention—we have potentially life-saving technology that is currently reaching only a fraction of the possible people at risk because of respect for their privacy. Is the current trade-off between privacy and prevention the right one?"
"The role of personality, age, and gender in tweeting about mental illness","Daniel Preotiuc-Pietro, Johannes C.Eichstaedt, Gregory J. Park, MaartenSap, Laura Smith, Victoria Tobolsky, H.Andrew Schwartz, Lyle H. Ungar",ACL,,"Mental illnesses, such as depression and post traumatic stress disorder (PTSD), are highly underdiagnosed globally. Populations sharing similar demographics and personality traits are known to be more at risk than others. In this study, we characterise the language use of users disclosing their mental illness on Twitter. Language-derived personality and demographic estimates show surprisingly strong performance in distinguishing users that tweet a diagnosis of depression or PTSD from random controls, reaching an area under the receiveroperating characteristic curve – AUC – of around .8 in all our binary classification tasks. In fact, when distinguishing users disclosing depression from those disclosing PTSD, the single feature of estimated age shows nearly as strong performance (AUC = .806) as using thousands of topics (AUC = .819) or tens of thousands of n-grams (AUC = .812). We also find that differential language analyses, controlled for demographics, recover many symptoms associated with the mental illnesses in the clinical literature."
Quantifying and Understanding Gender and Cross-Cultural Differences in Mental Health Expression via Social Media,"Munmun De Choudhury, Sanket S.Sharma, Tomaz Logar, Wouter Eekhout,René Ernst Nielsen, Georgia Tech",,,"For a long time, mental illness was treated as a gender and culture-neutral problem. However recent research shows that several social and psychological characteristics are unique to women [6], and hence there is a need to investigate in depth the causes and antecedents of emotional distress in women [49]. In developing countries, socio-political and economic issues such as poverty, inequalities in the workplace, societal and cultural expectations of women are often known to heighten women’s risk to distress and mental illness [54]. However, the gender and cultural dimensions of mental health, especially in countries of the majority world, are less understood1 . The United Nations’ Millennium Development Goals2 , established in 2000, notes that the majority of data we have on global burden of mental illnesses comes from massive data aggregation exercises conducted only once every few years [38]. This data often does not include gender information; and often different countries have different policies and practices in place in terms of how mental illnesses are assessed [48]. Overlooking gender or culture based differences can have drastic consequences. This includes, misdiagnosis, misappropriation of interventions, constrained help-seeking along stereotypical lines, and a “one-size-fits-all” approach to extend help to those who may have unique needs [49, 48]. With the lack of an adequate global surveillance system, and with the accelerating pace of economic and cultural change, more frequently updated information on mental disorders for different gender and cultural subgroups is needed [39, 41], especially from subgroups who may not necessarily appear in formal statistical surveys of health and well-being. In recent years, a new research direction has established social media data as a way to understand mental health challenges in people [16, 14, 26]. It has been found that these approaches can greatly supplement and complement traditional mental health assessments, such as the Behavioral Risk Factor Surveillance System (BFRSS) survey conducted by the Centers for Disease Control and Prevention (CDC) in the US [13, 12, 10, 18]. However, cultural and gendered expression of different subgroups may differ markedly from the “typical”, largely western populations, on which these current social media investigations of mental health are based [16, 14]. Per the perspective laid out by postcolonial computing, rarely are analytical insights and intervention mechanisms able to be transplanted without modification from one subgroup to another, and still provide the same value [29]. Therefore, identifying gender based and cross-cultural context is critical in the use of such passively sensed big data for making sense of mental health and well-being."
Towards Assessing Changes in Degree of Depression through Facebook,"H. Andrew Schwartz, Johannes C.Eichstaedt, Margaret L. Kern, Gregory J.Park, Maarten Sap, David Stillwell,Michal Kosinski, Lyle H. Ungar",ACL,,"Depression is typically diagnosed as being present or absent. However, depression severity is believed to be continuously distributed rather than dichotomous. Severity may vary for a given patient daily and seasonally as a function of many variables ranging from life events to environmental factors. Repeated population-scale assessment of depression through questionnaires is expensive. In this paper we use survey responses and status updates from 28,749 Facebook users to develop a regression model that predicts users’ degree of depression based on their Facebook status updates. Our user-level predictive accuracy is modest, significantly outperforming a baseline of average user sentiment. We use our model to estimate user changes in depression across seasons, and find, consistent with literature, users’ degree of depression most often increases from summer to winter. We then show the potential to study factors driving individuals’ level of depression by looking at its most highly correlated language features."
Detecting and Characterizing Eating-Disorder Communities on Social Media,"Tao Wang, Markus Brede, AntonellaIanni, Emmanouil Mentzakis",ACM,,"Eating disorders are complex mental disorders and responsible for the highest mortality rate among mental illnesses. Recent studies reveal that user-generated content on social media provides useful information in understanding these disorders. Most previous studies focus on studying communities of people who discuss eating disorders on social media, while few studies have explored community structures and interactions among individuals who suffer from this disease over social media. In this paper, we first develop a snowball sampling method to automatically gather individuals who self-identify as eating disordered in their profile descriptions, as well as their social network connections with one another on Twitter. Then, we verify the effectiveness of our sampling method by: 1. quantifying differences between the sampled eating disordered users and two sets of reference data collected for non-disordered users in social status, behavioral patterns and psychometric properties; 2. building predictive models to classify eating disordered and non-disordered users. Finally, leveraging the data of social connections between eating disordered individuals on Twitter, we present the first homophily study among eating-disorder communities on social media. Our findings shed new light on how an eating-disorder community develops on social media."
A Social Media Based Index of Mental Well-Being in College Campuses,"Shrey Bagroy, PonnurangamKumaraguru, Munmun De Choudhury",PMC,"college mental health, Reddit, social media, transfer learning","Psychological distress in the form of depression, anxiety and other mental health challenges among college students is a growing health concern. Dearth of accurate, continuous, and multicampus data on mental well-being presents significant challenges to intervention and mitigation efforts in college campuses. We examine the potential of social media as a new “barometer” for quantifying the mental well-being of college populations. Utilizing student-contributed data in Reddit communities of over 100 universities, we first build and evaluate a transfer learning based classification approach that can detect mental health expressions with 97% accuracy. Thereafter, we propose a robust campus-specific Mental Well-being Index: MWI. We find that MWI is able to reveal meaningful temporal patterns of mental well-being in campuses, and to assess how their expressions relate to university attributes like size, academic prestige, and student demographics. We discuss the implications of our work for improving counselor efforts, and in the design of tools that can enable better assessment of the mental health climate of college campuses."
Identity Management and Mental Health Discourse in Social Media,"Umashanthi Pavalanathan, Munmun DeChoudhury",PMC,"health, identity, mental health, reddit, social media, throwaways","Social media is increasingly being adopted in health discourse. We examine the role played by identity in supporting discourse on socially stigmatized conditions. Specifically, we focus on mental health communities on reddit. We investigate the characteristics of mental health discourse manifested through reddit's characteristic ‘throwaway’ accounts, which are used as proxies of anonymity. For the purpose, we propose affective, cognitive, social, and linguistic style measures, drawing from literature in psychology. We observe that mental health discourse from throwaways is considerably disinhibiting and exhibits increased negativity, cognitive bias and self-attentional focus, and lowered self-esteem. Throwaways also seem to be six times more prevalent as an identity choice on mental health forums, compared to other reddit communities. We discuss the implications of our work in guiding mental health interventions, and in the design of online communities that can better cater to the needs of vulnerable populations. We conclude with thoughts on the role of identity manifestation on social media in behavioral therapy."
LAXARY: A Trustworthy Explainable Twitter Analysis Model for Post-Traumatic Stress Disorder Assessment,"Mohammad Arif Ul Alam, DhawalKapadia",arXiv,"Post Traumatic Stress Disorder, Twitter Analysis, Explainable AI, Trustworthy AI","Veteran mental health is a significant national problem as large number of veterans are returning from the recent war in Iraq and continued military presence in Afghanistan. While significant existing works have investigated twitter postsbased Post Traumatic Stress Disorder (PTSD) assessment using blackbox machine learning techniques, these frameworks cannot be trusted by the clinicians due to the lack of clinical explainability. To obtain the trust of clinicians, we explore the big question, can twitter posts provide enough information to fill up clinical PTSD assessment surveys that have been traditionally trusted by clinicians? To answer the above question, we propose, LAXARY (Linguistic Analysis-based Exaplainable Inquiry) model, a novel Explainable Artificial Intelligent (XAI) model to detect and represent PTSD assessment of twitter users using a modified Linguistic Inquiry and Word Count (LIWC) analysis. First, we employ clinically validated survey tools for collecting clinical PTSD assessment data from real twitter users and develop a PTSD Linguistic Dictionary using the PTSD assessment survey results. Then, we use the PTSD Linguistic Dictionary along with machine learning model to fill up the survey tools towards detecting PTSD status and its intensity of corresponding twitter users. Our experimental evaluation on 210 clinically validated veteran twitter users provides promising accuracies of both PTSD classification and its intensity estimation. We also evaluate our developed PTSD Linguistic Dictionary’s reliability and validity."
Text-Based Detection and Understanding of Changes in Mental Health,"Yaoyiran Li, Rada Mihalcea, Steven R.Wilson",Social Informatics,"Natural language processing, Mental health, Social media","Previous work has investigated the identification of mental health issues in social media users, yet the way that users’ mental states and related behavior change over time remains relatively understudied. This paper focuses on online mental health communities and studies how users’ contributions to these communities change over one year. We define a metric called the Mental Health Contribution Index (MHCI), which we use to measure the degree to which users’ contributions to mental health topics change over a one-year period. In this work, we study the relationship between MHCI scores and the online expression of mental health symptoms by extracting relevant linguistic features from user-generated content and conducting statistical analyses. Additionally, we build a classifier to predict whether or not a user’s contributions to mental health subreddits will increase or decrease. Finally, we employ propensity score matching to identify factors that correlate with an increase or a decrease in mental health forum contributions. Our work provides some of the first insights into detecting and understanding social media users’ changes in mental health states over time."
Triaging Mental Health Forum Posts,"Arman Cohan, Sydney Young, NazliGoharian",ACL,,"Online mental health forums provide users with an anonymous support platform that is facilitated by moderators responsible for finding and addressing critical posts, especially those related to self-harm. Given the seriousness of these posts, it is important that the moderators are able to locate these critical posts quickly in order to respond with timely support. We approached the task of automatically triaging forum posts as a multiclass classification problem. Our model uses a supervised classifier with various features including lexical, psycholinguistic, and topic modeling features. On a dataset of mental forum posts from ReachOut.com1 , our approach identified critical cases with a F-score of over 80%, showing the effectiveness of the model. Among 16 participating teams and 60 total runs, our best run achieved macro-average F1-score of 41% for the critical categories (The best score among all the runs was 42%)."
Scalable mental health analysis in the clinical whitespace via natural language processing,"Glen A. Coppersmith, Casey Hilland,Ophir Frieder, Ryan Leary",IEEE,,"Our increasingly digital life provides a wealth of data about our behavior, beliefs, mood, and well-being. This data provides some insight into the lives of patients outside the healthcare setting, and in aggregate can be insightful for the person’s mental health and emotional crisis. Here, we introduce this community to some of the recent advancement in using natural language processing and machine learning to provide insight into mental health of both individuals and populations. We advocate using these linguistic signals as a supplement to those that are collected in the health care system, filling in some of the so-called “whitespace” between visits."
Small but Mighty: Affective Micropatterns for Quantifying Mental Health from Social Media Language,"Kate Loveys, Patrick Crutchley, EmilyWyatt, Glen Coppersmith",ACL,,"Many psychological phenomena occur in small time windows, measured in minutes or hours. However, most computational linguistic techniques look at data on the order of weeks, months, or years. We explore micropatterns in sequences of messages occurring over a short time window for their prevalence and power for quantifying psychological phenomena, specifically, patterns in affect. We examine affective micropatterns in social media posts from users with anxiety, eating disorders, panic attacks, schizophrenia, suicidality, and matched controls."
Detecting suicidality on Twitter,"Bridianne O'Dea, Stephen Wan, Philip J.Batterham, Alison L. Calear, CécileParis, Helen E. Christensen",Internet Interventions ,"Twitter, Suicide, Social media, Machine learning, Prevention, Big data, Online","Twitter is increasingly investigated as a means of detecting mental health status, including depression and suicidality, in the population. However, validated and reliable methods are not yet fully established. This study aimed to examine whether the level of concern for a suicide-related post on Twitter could be determined based solely on the content of the post, as judged by human coders and then replicated by machine learning. From 18th February 2014 to 23rd April 2014, Twitter was monitored for a series of suicide-related phrases and terms using the public Application Program Interface (API). Matching tweets were stored in a data annotation tool developed by the Commonwealth Scientific and Industrial Research Organisation (CSIRO). During this time, 14,701 suicide-related tweets were collected: 14% were randomly (n = 2000) selected and divided into two equal sets (Set A and B) for coding by human researchers. Overall, 14% of suicide-related tweets were classified as ‘strongly concerning’, with the majority coded as ‘possibly concerning’ (56%) and the remainder (29%) considered ‘safe to ignore’. The overall agreement rate among the human coders was 76% (average κ = 0.55). Machine learning processes were subsequently applied to assess whether a ‘strongly concerning’ tweet could be identified automatically. The computer classifier correctly identified 80% of ‘strongly concerning’ tweets and showed increasing gains in accuracy; however, future improvements are necessary as a plateau was not reached as the amount of data increased. The current study demonstrated that it is possible to distinguish the level of concern among suicide-related tweets, using both human coders and an automatic machine classifier. Importantly, the machine classifier replicated the accuracy of the human coders. The findings confirmed that Twitter is used by individuals to express suicidality and that such posts evoked a level of concern that warranted further investigation. However, the predictive power for actual suicidal behaviour is not yet known and the findings do not directly identify targets for intervention."
Major life changes and behavioral markers in social media: case of childbirth,"Munmun De Choudhury, Scott Counts,Eric Horvitz",ACM,"childbirth, emotion, health, language, postpartum, social media, Twitter, wellness","We explore the harnessing of social media as a window on changes around major life events in individuals and larger populations. We specifically examine patterns of activity, emotional, and linguistic correlates for childbirth and postnatal course. After identifying childbirth events on Twitter, we analyze daily posting patterns and language usage before and after birth by new mothers, and make inferences about the status and dynamics of changes in emotions expressed following childbirth. We find that childbirth is associated with some changes for most new mothers, but approximately 15% of new mothers show significant changes in their online activity and emotional expression postpartum. We observe that these mothers can be distinguished by linguistic changes captured by shifts in a relatively small number of words in their social media posts. We introduce a greedy differencing procedure to identify the type of language that characterizes significant changes in these mothers during postpartum. We conclude with a discussion about how such characterizations might be applied to recognizing and understanding health and well-being in women following childbirth."
"Sensitive Self-disclosures, Responses, and Social Support on Instagram: The Case of#Depression","Nazanin Andalibi, Pinar Öztürk, AndreaForte",ACM,"Self-disclosure, emotions, depression, mental illness, eating disorder, self-harm, suicide, stigma, content analysis, mixed methods, photo sharing, social media, Instagram","People can benefit from disclosing negative emotions or stigmatized facets of their identities, and psychologists have noted that imagery can be an effective medium for expressing difficult emotions. Social network sites like Instagram offer unprecedented opportunity for image-based sharing. In this paper, we investigate sensitive selfdisclosures on Instagram and the responses they attract. We use visual and textual qualitative content analysis and statistical methods to analyze self-disclosures, associated comments, and relationships between them. We find that people use Instagram to engage in social exchange and storytelling about difficult experiences. We find considerable evidence of social support, a sense of community, and little aggression or support for harmful or pro-disease behaviors. Finally, we report on factors that influence engagement and the type of comments these disclosures attract. Personal narratives, food and beverage, references to illness, and selfappearance concerns are more likely to attract positive social support. Posts seeking support attract significantly more comments. CAUTION: This paper includes some detailed examples of content about eating disorders and self-injury illnesses."
Understanding Social Media Disclosures of Sexual Abuse Through the Lenses of Support Seeking and Anonymity,"Nazanin Andalibi, Oliver L. Haimson,Munmun De Choudhury, Andrea Forte",ACM,"Identity, reddit, self-disclosure, sexual abuse, social media, well-being, social support, stigma, anonymity, throwaway","Support seeking in stigmatized contexts is useful when the discloser receives the desired response, but it also entails social risks. Thus, people do not always disclose or seek support when they need it. One such stigmatized context for support seeking is sexual abuse. In this paper, we use mixed methods to understand abuse-related posts on reddit. First, we take a qualitative approach to understand post content. Then we use quantitative methods to investigate the use of ""throwaway"" accounts, which provide greater anonymity, and report on factors associated with support seeking and first-time disclosures. In addition to significant linguistic differences between throwaway and identified accounts, we find that those using throwaway accounts are significantly more likely to engage in seeking support. We also find that men are significantly more likely to use throwaway accounts when posting about sexual abuse. Results suggest that subreddit moderators and members who wish to provide support pay attention to throwaway accounts, and we discuss the importance of context-specific anonymity in support seeking."
“Hunger Hurts but Starving Works”: Characterizing the Presentation of Eating Disorders Online,"Jessica Pater, Oliver L. Haimson,Nazanin Andalibi, Elizabeth D. Mynatt",ACM,"Anorexia nervosa, bulimia nervosa, eating disorder, ED, self-injury, self-harm; social media; online communities; content analysis; EDNOS; OSFED; behavioral health; social networking; Twitter; Tumblr; Instagram","Within the CSCW community, little has been done to systematically analyze online eating disorder (ED) user generated content. In this paper, we present the results of a cross-platform content analysis of ED-related posts. We analyze the way that hashtags are used in ad-hoc EDfocused networks and present a comprehensive corpus of ED-terminology that frequently accompanies ED activities online. We provide exemplars of the types of ED-related content found online. Through this characterization of activities, we draw attention to the increasingly important role that these platforms play and how they are used and misappropriated for negative health purposes. We also outline specific challenges associated with researching these types of networks online. CAUTION: This paper includes media that could potentially be a trigger to those dealing with an eating disorder or with other self-injury illnesses. Please use caution when reading, printing, or disseminating this paper."
Learning of Social Representations,Bryan Perozzi,,,
Discriminative Deep Random Walk for Network Classification,"Juzheng Li, Jun Zhu, Bo Zhang",ACL,,"Deep Random Walk (DeepWalk) can learn a latent space representation for describing the topological structure of a network. However, for relational network classification, DeepWalk can be suboptimal as it lacks a mechanism to optimize the objective of the target task. In this paper, we present Discriminative Deep Random Walk (DDRW), a novel method for relational network classification. By solving a joint optimization problem, DDRW can learn the latent space representations that well capture the topological structure and meanwhile are discriminative for the network classification task. Our experimental results on several real social networks demonstrate that DDRW significantly outperforms DeepWalk on multilabel network classification tasks, while retaining the topological structure in the latent space. DDRW is stable and consistently outperforms the baseline methods by various percentages of labeled data. DDRW is also an online method that is scalable and can be naturally parallelized."
Semi-Supervised Classification with Graph Convolutional Networks,"Thomas N. Kipf, Max Welling",arXiv,,We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.
PTE: Predictive Text Embedding through Large-scale Heterogeneous Text Networks,"Jian Tang, Meng Qu, Qiaozhu Mei",arXiv,"predictive text embedding, representation learning","Unsupervised text embedding methods, such as Skip-gram and Paragraph Vector, have been attracting increasing attention due to their simplicity, scalability, and effectiveness. However, comparing to sophisticated deep learning architectures such as convolutional neural networks, these methods usually yield inferior results when applied to particular machine learning tasks. One possible reason is that these text embedding methods learn the representation of text in a fully unsupervised way, without leveraging the labeled information available for the task. Although the low dimensional representations learned are applicable to many different tasks, they are not particularly tuned for any task. In this paper, we fill this gap by proposing a semi-supervised representation learning method for text data, which we call the predictive text embedding (PTE). Predictive text embedding utilizes both labeled and unlabeled data to learn the embedding of text. The labeled information and different levels of word co-occurrence information are first represented as a large-scale heterogeneous text network, which is then embedded into a low dimensional space through a principled and efficient algorithm. This low dimensional embedding not only preserves the semantic closeness of words and documents, but also has a strong predictive power for the particular task. Compared to recent supervised approaches based on convolutional neural networks, predictive text embedding is comparable or more effective, much more efficient, and has fewer parameters to tune."
Deep Neural Networks for Learning Graph Representations,"Shaosheng Cao, Wei Lu, Qiongkai Xu",AAAI,,"In this paper, we propose a novel model for learning graph representations, which generates a low-dimensional vector representation for each vertex by capturing the graph structural information. Different from other previous research efforts, we adopt a random surfing model to capture graph structural information directly, instead of using the sampling-based method for generating linear sequences proposed by Perozzi et al. (2014). The advantages of our approach will be illustrated from both theorical and empirical perspectives. We also give a new perspective for the matrix factorization method proposed by Levy and Goldberg (2014), in which the pointwise mutual information (PMI) matrix is considered as an analytical solution to the objective function of the skip-gram model with negative sampling proposed by Mikolov et al. (2013). Unlike their approach which involves the use of the SVD for finding the low-dimensitonal projections from the PMI matrix, however, the stacked denoising autoencoder is introduced in our model to extract complex features and model non-linearities. To demonstrate the effectiveness of our model, we conduct experiments on clustering and visualization tasks, employing the learned vertex representations as features. Empirical results on datasets of varying sizes show that our model outperforms other stat-of-the-art models in such tasks."
Local Modeling of Attributed Graphs: Algorithms and Applications,Bryan Perozzi,,,"It is increasingly common to encounter real-world graphs which have attributes associated with the nodes, in addition to their raw connectivity information. For example, social networks contain both the friendship relations as well as user attributes such as interests and demographics. A protein-protein interaction network may not only have the interaction relations but the expression levels associated with the proteins. Such information can be described by a graph in which nodes represent the objects, edges represent the relations between them, and feature vectors associated with the nodes represent the attributes. This graph data is often referred to as an attributed graph. This thesis focuses on developing scalable algorithms and models for attributed graphs. This data can be viewed as either discrete (set of edges), or continuous (distances between embedded nodes), and I examine the issue from both sides. Specifically, I present an online learning algorithm which utilizes recent advances in deep learning to create rich graph embeddings. The multiple scales of social relationships encoded by this novel approach are useful for multi-label classification and regression tasks in networks. I also present local algorithms for anomalous community scoring in discrete graphs. These algorithms discover subsets of the graph’s attributes which cause communities to form (e.g. shared interests on a social network). The scalability of all the methods in this thesis is ensured by building from a restricted set of graph primitives, such as ego-networks and truncated random walks, which exploit the local information around each vertex. In addition, limiting the scope of graph dependencies we consider enables my approaches to be trivially parallelized using commodity tools for big data processing, like MapReduce or Spark. The applications of this work are broad and far reaching across the fields of data mining and information retrieval, including user profiling/demographic inference, online advertising, and fraud detection.
"
Graph Attention Networks,"Petar Velickovic, Guillem Cucurull,Arantxa Casanova, Adriana Romero,Pietro Liò, Yoshua Bengio",arXiv,,"We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods’ features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-theart results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a proteinprotein interaction dataset (wherein test graphs remain unseen during training)."
Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering,"Michaël Defferrard, Xavier Bresson,Pierre Vandergheynst",arXiv,,"In this work, we are interested in generalizing convolutional neural networks (CNNs) from low-dimensional regular grids, where image, video and speech are represented, to high-dimensional irregular domains, such as social networks, brain connectomes or words’ embedding, represented by graphs. We present a formulation of CNNs in the context of spectral graph theory, which provides the necessary mathematical background and efficient numerical schemes to design fast localized convolutional filters on graphs. Importantly, the proposed technique offers the same linear computational complexity and constant learning complexity as classical CNNs, while being universal to any graph structure. Experiments on MNIST and 20NEWS demonstrate the ability of this novel deep learning system to learn local, stationary, and compositional features on graphs."
struc2vec: Learning Node Representations from Structural Identity,"Daniel R. Figueiredo, Leonardo FilipeRodrigues Ribeiro, Pedro H. P.Saverese",arXiv,feature learning; node embeddings; structural identity,"Structural identity is a concept of symmetry in which network nodes are identied according to the network structure and their relationship to other nodes. Structural identity has been studied in theory and practice over the past decades, but only recently has it been addressed with representational learning techniques. is work presents struc2vec, a novel and exible framework for learning latent representations for the structural identity of nodes. struc2vec uses a hierarchy to measure node similarity at dierent scales, and constructs a multilayer graph to encode structural similarities and generate structural context for nodes. Numerical experiments indicate that state-of-the-art techniques for learning node representations fail in capturing stronger notions of structural identity, while struc2vec exhibits much superior performance in this task, as it overcomes limitations of prior approaches. As a consequence, numerical experiments indicate that struc2vec improves performance on classication tasks that depend more on structural identity."
Heterogeneous Network Embedding via Deep Architectures,"Shiyu Chang, Wei Han, Jiliang Tang,Guo-Jun Qi, Charu C. Aggarwal,Thomas S. Huang",ACM,"Heterogeneous embedding, network embedding, feature learning, crossdomain knowledge propagation, deep learning, dimensionality reduction.","Data embedding is used in many machine learning applications to create low-dimensional feature representations, which preserves the structure of data points in their original space. In this paper, we examine the scenario of a heterogeneous network with nodes and content of various types. Such networks are notoriously difficult to mine because of the bewildering combination of heterogeneous contents and structures. The creation of a multidimensional embedding of such data opens the door to the use of a wide variety of off-the-shelf mining techniques for multidimensional data. Despite the importance of this problem, limited efforts have been made on embedding a network of scalable, dynamic and heterogeneous data. In such cases, both the content and linkage structure provide important cues for creating a unified feature representation of the underlying network. In this paper, we design a deep embedding algorithm for networked data. A highly nonlinear multilayered embedding function is used to capture the complex interactions between the heterogeneous data in a network. Our goal is to create a multi-resolution deep embedding function, that reflects both the local and global network structures, and makes the resulting embedding useful for a variety of data mining tasks. In particular, we demonstrate that the rich content and linkage information in a heterogeneous network can be captured by such an approach, so that similarities among cross-modal data can be measured directly in a common embedding space. Once this goal has been achieved, a wide variety of data mining problems can be solved by applying off-the-shelf algorithms designed for handling vector representations. Our experiments on real-world network datasets show the effectiveness and scalability of the proposed algorithm as compared to the state-of-the-art embedding methods."
Embedding through Large-scale Heterogeneous Text Networks,Jian Tang,,,
Revisiting Semi-Supervised Learning with Graph Embeddings,"Zhilin Yang, William W. Cohen, RuslanSalakhutdinov",arXiv,,"We present a semi-supervised learning framework based on graph embeddings. Given a graph between instances, we train an embedding for each instance to jointly predict the class label and the neighborhood context in the graph. We develop both transductive and inductive variants of our method. In the transductive variant of our method, the class labels are determined by both the learned embeddings and input feature vectors, while in the inductive variant, the embeddings are defined as a parametric function of the feature vectors, so predictions can be made on instances not seen during training. On a large and diverse set of benchmark tasks, including text classification, distantly supervised entity extraction, and entity classification, we show improved performance over many of the existing models."
Spectral Networks and Locally Connected Networks on Graphs,"Joan Bruna, Wojciech Zaremba, ArthurSzlam, Yann LeCun",arXiv,,"Convolutional Neural Networks are extremely efficient architectures in image and audio recognition tasks, thanks to their ability to exploit the local translational invariance of signal classes over their domain. In this paper we consider possible generalizations of CNNs to signals defined on more general domains without the action of a translation group. In particular, we propose two constructions, one based upon a hierarchical clustering of the domain, and another based on the spectrum of the graph Laplacian. We show through experiments that for lowdimensional graphs it is possible to learn convolutional layers with a number of parameters independent of the input size, resulting in efficient deep architectures."
Neural Message Passing for Quantum Chemistry,"Justin Gilmer, Samuel S. Schoenholz,Patrick F. Riley, Oriol Vinyals, George E.Dahl",arXiv,,"Supervised learning on molecules has incredible potential to be useful in chemistry, drug discovery, and materials science. Luckily, several promising and closely related neural network models invariant to molecular symmetries have already been described in the literature. These models learn a message passing algorithm and aggregation procedure to compute a function of their entire input graph. At this point, the next step is to find a particularly effective variant of this general approach and apply it to chemical prediction benchmarks until we either solve them or reach the limits of the approach. In this paper, we reformulate existing models into a single common framework we call Message Passing Neural Networks (MPNNs) and explore additional novel variations within this framework. Using MPNNs we demonstrate state of the art results on an important molecular property prediction benchmark; these results are strong enough that we believe future work should focus on datasets with larger molecules or more accurate ground truth labels."
SIGNet: Scalable Embeddings for Signed Networks,"Mohammad Raihanul Islam, B. AdityaPrakash, Naren Ramakrishnan",Advances in Knowledge Discovery and Data Mining,,"Recent successes in word embedding and document embedding have motivated researchers to explore similar representations for networks and to use such representations for tasks such as edge prediction, node label prediction, and community detection. Such network embedding methods are largely focused on finding distributed representations for unsigned networks and are unable to discover embeddings that respect polarities inherent in edges. We propose SIGNet, a fast scalable embedding method suitable for signed networks. Our proposed objective function aims to carefully model the social structure implicit in signed networks by reinforcing the principles of social balance theory. Our method builds upon the traditional word2vec family of embedding approaches and adds a new targeted node sampling strategy to maintain structural balance in higher-order neighborhoods. We demonstrate the superiority of SIGNet over state-of-the-art methods proposed for both signed and unsigned networks on several real world datasets from different domains. In particular, SIGNet offers an approach to generate a richer vocabulary of features of signed networks to support representation and reasoning."
Graph Convolutional Neural Networks for Web-Scale Recommender Systems,"Rex Ying, Ruining He, Kaifeng Chen,Pong Eksombatchai, William L.Hamilton, Jure Leskovec",arXiv,,"Recent advancements in deep neural networks for graph-structured data have led to state-of-the-art performance on recommender system benchmarks. However, making these methods practical and scalable to web-scale recommendation tasks with billions of items and hundreds of millions of users remains a challenge. Here we describe a large-scale deep recommendation engine that we developed and deployed at Pinterest. We develop a dataefficient Graph Convolutional Network (GCN) algorithm PinSage, which combines efficient random walks and graph convolutions to generate embeddings of nodes (i.e., items) that incorporate both graph structure as well as node feature information. Compared to prior GCN approaches, we develop a novel method based on highly efficient random walks to structure the convolutions and design a novel training strategy that relies on harder-and-harder training examples to improve robustness and convergence of the model. We deploy PinSage at Pinterest and train it on 7.5 billion examples on a graph with 3 billion nodes representing pins and boards, and 18 billion edges. According to offline metrics, user studies and A/B tests, PinSage generates higher-quality recommendations than comparable deep learning and graph-based alternatives. To our knowledge, this is the largest application of deep graph embeddings to date and paves the way for a new generation of web-scale recommender systems based on graph convolutional architectures."
How Powerful are Graph Neural Networks?,"Keyulu Xu, Weihua Hu, Jure Leskovec,Stefanie Jegelka",arXiv,,"Graph Neural Networks (GNNs) are an effective framework for representation learning of graphs. GNNs follow a neighborhood aggregation scheme, where the representation vector of a node is computed by recursively aggregating and transforming representation vectors of its neighboring nodes. Many GNN variants have been proposed and have achieved state-of-the-art results on both node and graph classification tasks. However, despite GNNs revolutionizing graph representation learning, there is limited understanding of their representational properties and limitations. Here, we present a theoretical framework for analyzing the expressive power of GNNs to capture different graph structures. Our results characterize the discriminative power of popular GNN variants, such as Graph Convolutional Networks and GraphSAGE, and show that they cannot learn to distinguish certain simple graph structures. We then develop a simple architecture that is provably the most expressive among the class of GNNs and is as powerful as the WeisfeilerLehman graph isomorphism test. We empirically validate our theoretical findings on a number of graph classification benchmarks, and demonstrate that our model achieves state-of-the-art performance."
HIN2Vec: Explore Meta-paths in Heterogeneous Information Networks for Representation Learning,"Tao-Yang Fu, Wang-Chien Lee, Zhen Lei",ACM,"representation learning, heterogeneous information network","In this paper, we propose a novel representation learning framework, namely HIN2Vec, for heterogeneous information networks (HINs). The core of the proposed framework is a neural network model, also called HIN2Vec, designed to capture the rich semantics embedded in HINs by exploiting different types of relationships among nodes. Given a set of relationships specified in forms of meta-paths in an HIN, HIN2Vec carries out multiple prediction training tasks jointly based on a target set of relationships to learn latent vectors of nodes and meta-paths in the HIN. In addition to model design, several issues unique to HIN2Vec, including regularization of meta-path vectors, node type selection in negative sampling, and cycles in random walks, are examined. To validate our ideas, we learn latent vectors of nodes using four large-scale real HIN datasets, including Blogcatalog, Yelp, DBLP and U.S. Patents, and use them as features for multi-label node classification and link prediction applications on those networks. Empirical results show that HIN2Vec soundly outperforms the state-of-the-art representation learning models for network data, including DeepWalk, LINE, node2vec, PTE, HINE and ESim, by 6.6% to 23.8% ofmicro-f1 in multi-label node classification and 5% to 70.8% of MAP in link prediction."
Geometric Deep Learning on Graphs and Manifolds Using Mixture Model CNNs,"Federico Monti, Davide Boscaini,Jonathan Masci, Emanuele Rodolà, JanSvoboda, Michael M. Bronstein",arXiv,,"Deep learning has achieved a remarkable performance breakthrough in several fields, most notably in speech recognition, natural language processing, and computer vision. In particular, convolutional neural network (CNN) architectures currently produce state-of-the-art performance on a variety of image analysis tasks such as object detection and recognition. Most of deep learning research has so far focused on dealing with 1D, 2D, or 3D Euclideanstructured data such as acoustic signals, images, or videos. Recently, there has been an increasing interest in geometric deep learning, attempting to generalize deep learning methods to non-Euclidean structured data such as graphs and manifolds, with a variety of applications from the domains of network analysis, computational social science, or computer graphics. In this paper, we propose a unified framework allowing to generalize CNN architectures to non-Euclidean domains (graphs and manifolds) and learn local, stationary, and compositional task-specific features. We show that various non-Euclidean CNN methods previously proposed in the literature can be considered as particular instances of our framework. We test the proposed method on standard tasks from the realms of image-, graphand 3D shape analysis and show that it consistently outperforms previous approaches."
Gated Graph Sequence Neural Networks,"Yujia Li, Daniel Tarlow, MarcBrockschmidt, Richard S. Zemel",arXiv,,"Graph-structured data appears frequently in domains including chemistry, natural language semantics, social networks, and knowledge bases. In this work, we study feature learning techniques for graph-structured inputs. Our starting point is previous work on Graph Neural Networks (Scarselli et al., 2009), which we modify to use gated recurrent units and modern optimization techniques and then extend to output sequences. The result is a flexible and broadly useful class of neural network models that has favorable inductive biases relative to purely sequence-based models (e.g., LSTMs) when the problem is graph-structured. We demonstrate the capabilities on some simple AI (bAbI) and graph algorithm learning tasks. We then show it achieves state-of-the-art performance on a problem from program verification, in which subgraphs need to be described as abstract data structures."
Tri-Party Deep Network Representation,"Shirui Pan, Jia Wu, Xingquan Zhu,Chengqi Zhang, Yang Wang",IJCAI,,"Information network mining often requires examination of linkage relationships between nodes for analysis. Recently, network representation has emerged to represent each node in a vector format, embedding network structure, so off-the-shelf machine learning methods can be directly applied for analysis. To date, existing methods only focus on one aspect of node information and cannot leverage node labels. In this paper, we propose TriDNR, a tri-party deep network representation model, using information from three parties: node structure, node content, and node labels (if available) to jointly learn optimal node representation. TriDNR is based on our new coupled deep natural language module, whose learning is enforced at three levels: (1) at the network structure level, TriDNR exploits inter-node relationship by maximizing the probability of observing surrounding nodes given a node in random walks; (2) at the node content level, TriDNR captures node-word correlation by maximizing the co-occurrence of word sequence given a node; and (3) at the node label level, TriDNR models label-word correspondence by maximizing the probability of word sequence given a class label. The tri-party information is jointly fed into the neural network model to mutually enhance each other to learn optimal representation, and results in up to 79% classification accuracy gain, compared to state-of-the-art methods."
An English Reading Tool as a NLP Showcase,"Mahmoud Azab, Ahmed Salama, KemalOflazer, Hideki Shima, Jun Araki,Teruko Mitamura",ACL,,"We introduce -SmartReader- an English reading tool for non-native English readers to overcome language related hindrances while reading a text. It makes extensive use of widely-available NLP tools and resources. SmartReader is a web-based application that can be accessed from standard browsers running on PCs or tablets. A user can choose a text document from the system’s library they want to read or can upload a new document of their own and the system will display an interactive version of such text, that provides the reader with an intelligent e-book functionality"
MUCK: A toolkit for extracting and visualizing semantic dimensions of large text collections,Rebecca Weiss,ACL,,"Users with large text collections are often faced with one of two problems; either they wish to retrieve a semanticallyrelevant subset of data from the collection for further scrutiny (needle-in-a-haystack) or they wish to glean a high-level understanding of how a subset compares to the parent corpus in the context of aforementioned semantic dimensions (forestfor-the-trees). In this paper, I describe MUCK1 , an open-source toolkit that addresses both of these problems through a distributed text processing engine with an interactive visualization interface."
sranjans: Semantic Textual Similarity using Maximal Weighted Bipartite Graph Matching,"Sumit Bhagwani, ShrutiranjanSatapathy, Harish Karnick",ACL,,"The paper aims to come up with a system that examines the degree of semantic equivalence between two sentences. At the core of the paper is the attempt to grade the similarity of two sentences by finding the maximal weighted bipartite match between the tokens of the two sentences. The tokens include single words, or multiwords in case of Named Entitites, adjectivally and numerically modified words. Two token similarity measures are used for the task - WordNet based similarity, and a statistical word similarity measure which overcomes the shortcomings of WordNet based similarity. As part of three systems created for the task, we explore a simple bag of words tokenization scheme, a more careful tokenization scheme which captures named entities, times, dates, monetary entities etc., and finally try to capture context around tokens using grammatical dependencies.
"
An NLP-based Reading Tool for Aiding Non-native English Readers,"Mahmoud Azab, Ahmed Salama, KemalOflazer, Hideki Shima, Jun Araki,Teruko Mitamura",ACL,,"This paper describes a text-reading tool that makes extensive use of widelyavailable NLP tools and resources to aid non-native English speakers overcome language related hindrances while reading a text. It is a web-based tool, that can be accessed from browsers running on PCs or tablets, and provides the reader with an intelligent e-book functionality."
NASTEA: Investigating Narrative Schemas through Annotated Entities,"Dan Simonson, Anthony R. Davis",ACL,,"In this paper, we investigate the distribution of narrative schemas (Chambers and Jurafsky, 2009) throughout different document categories and how the structure of narrative schemas is conditioned by document category, the converse of the relationship explored in Simonson and Davis (2015). We evaluate cross-category narrative differences by assessing the predictability of verbs in each category and the salience of arguments to events that narrative schemas highlight. For the former, we use the narrative cloze task employed in previous work on schemas. For the latter, we introduce a task that employs narrative schemas called narrative argument salience through entities annotated, or NASTEA. We compare the schemas induced from the entire corpus to those from the subcorpora for each topic using these two types of evaluation. Results of each evaluation vary by each topical subcorpus, in some cases showing improvement, but the NASTEA task additionally reveals that some the documents within some topics are significantly more rigid in their narrative structure, instantiating a limited number of schemas in a highly predictable fashion."
Question Answering System for Entrance Exams in QA4MRE,"Xinjian Li, Ran Tian, Ngan L. T. Nguyen,Yusuke Miyao, Akiko Aizawa",CLEF 2013,"Question Answering Systems, Coreference Resolution, Recognizing Textual Entailment","This paper describes our question answering system for Entrance Exams, which is a pilot task of the Question Answering for Machine Reading Evaluation at Conference and Labs of the Evaluation Forum (CLEF) 2013. We conducted experiments in which participants were provided with documents and multiple-choice questions. Their goals was to select one answer or leave it unanswered for each question. In our system, we developed a component to detect all story characters in the documents and tag all personal pronouns using coreference resolution. For each question, we extracted related sentences and combined them with candidate answers to create inputs for a Recognizing Textual Entailment (RTE) component. The answers were then selected based on the confidence scores from the Recognizing Textual Entailment component. We submitted five runs in the task and the run that ranked highest obtained a c@1 score of 0.35, which outperformed the baseline c@1 score of 0.25."
IXA pipeline: Efficient and Ready to Use Multilingual NLP tools,"Rodrigo Agerri, Josu Bermudez,German Rigau",ACL,"Multilingual NLP tools, parsing, semantics","IXA pipeline is a modular set of Natural Language Processing tools (or pipes) which provide easy access to NLP technology. It offers robust and efficient linguistic annotation to both researchers and non-NLP experts with the aim of lowering the barriers of using NLP technology either for research purposes or for small industrial developers and SMEs. IXA pipeline can be used “as is” or exploit its modularity to pick and change different components. Given its open-source nature, it can also be modified and extended for it to work with other languages. This paper describes the general data-centric architecture of IXA pipeline and presents competitive results in several NLP annotations for English and Spanish."
Interactions between Narrative Schemas and Document Categories,"Dan Simonson, Anthony R. Davis",ACL,,"The unsupervised extraction of narrative schemas—sets of events with associated argument chains—has been explored and evaluated from many angles (Chambers and Jurafsky, 2009; Jans et al. 2012; Balasubramanian et al., 2013; Pichotta and Mooney 2014). While the extraction process and evaluation of the products has been well-researched and debated, little insight has been garnered on properties of narrative schemas themselves. We examine how well extracted narrative schemas align with existing document categories using a novel procedure for retrieving candidate category alignments. This was tested against alternative baseline alignment procedures that disregard some of the complex information the schemas contain. We find that a classifier built with all available information in a schema is more precise than a classifier built with simpler subcomponents. Coreference information plays an crucial role in schematic knowledge."
A Tidy Data Model for Natural Language Processing using cleanNLP,Taylor Arnold,arXiv,,"Recent advances in natural language processing have produced libraries that extract lowlevel features from a collection of raw texts. These features, known as annotations, are usually stored internally in hierarchical, tree-based data structures. This paper proposes a data model to represent annotations as a collection of normalized relational data tables optimized for exploratory data analysis and predictive modeling. The R package cleanNLP, which calls one of two state of the art NLP libraries (CoreNLP or spaCy), is presented as an implementation of this data model. It takes raw text as an input and returns a list of normalized tables. Specific annotations provided include tokenization, part of speech tagging, named entity recognition, sentiment analysis, dependency parsing, coreference resolution, and word embeddings. The package currently supports input text in English, German, French, and Spanish."
Italy goes to Stanford: a collection of CoreNLP modules for Italian,"Alessio Palmero Aprosio, GiovanniMoretti",arXiv,,"In this we paper present Tint, an easy-to-use set of fast, accurate and extendable Natural Language Processing modules for Italian. It is based on Stanford CoreNLP and is freely available as a standalone software or a library that can be integrated in an existing project."
TUTA1 at the NTCIR-11 Temporalia Task,"Haitao Yu, Xin Kang, Fuji Ren",NTCIR 2014,"Temporal feature extraction, Semi-supervised learning, Learn to rank","This paper details our participation in the NTCIR-11 Temporalia task including Temporal Query Intent Classification (TQIC) and Temporal Information Retrieval (TIR). In the TQIC subtask, we explore the rich temporal information in the labeled and unlabeled search queries. Semi-supervised and supervised linear classifiers are learned to predict the temporal classes for each search query. In the TIR subtask, we perform temporal ranking based on the technique of learning-to-rank. Two classes of features are investigated for estimating the document relevance."
Narrative Schema Stability in News Text,"Dan Simonson, Anthony Davis",ACL,,"We investigate the stability of narrative schemas (Chambers & Jurafsky, 2009) automatically induced from a news corpus, representing recurring narratives in a corpus. If such techniques produce meaningful results, we should expect that small changes to the corpus will result in only small changes to the induced schemas. We describe experiments involving successive ablation of a corpus and cross-validation at each stage of ablation, on schemas generated by three different techniques over a general news corpus and topically-specific subcorpora. We also develop a method for evaluating the similarity between sets of narrative schemas, and thus the stability of the schema induction algorithms. This stability analysis affirms the heterogeneous/homogeneous document category hypothesis first presented in Simonson & Davis (2016), whose technique is problematically limited. Additionally, increased ablation leads to increasing stability, so the smaller the remaining corpus, the more stable schema generation appears to be. We surmise that as a corpus grows larger, novel and more varied narratives continue to appear and stability declines, though at some point this decline levels off as new additions to the corpus consist essentially of “more of the same.”"
NAIST at the CLEF 2013 QA4MRE Pilot Task,"Philip Arthur, Graham Neubig, SakrianiSakti, Tomoki Toda, Satoshi Nakamura",CLEF 2013,"discriminative learning, minimum error rate training, linear feature model, question answering, machine reading, inter-sentence features",This paper describes the Nara Institute of Science and Technology’s system for the entrance exam pilot task of CLEF 2013 QA4MRE. The core of the system is a similar to the system for the main task of CLEF 2013 QA4MRE. We use minimum error rate training (MERT) to train the weights of the model and also propose a novel method for MERT with the addition of a threshold that defines the certainty with which we must answer questions. The system received a score of 22% c@1.
"Multilingual, Efficient and Easy NLP Processing with IXA Pipeline","Rodrigo Agerri, Josu Bermudez,German Rigau",ACL,,IXA pipeline is a modular set of Natural Language Processing tools (or pipes) which provide easy access to NLP technology. It aims at lowering the barriers of using NLP technology both for research purposes and for small industrial developers and SMEs by offering robust and efficient linguistic annotation to both researchers and non-NLP experts. IXA pipeline can be used “as is” or exploit its modularity to pick and change different components. This paper describes the general data-centric architecture of IXA pipeline and presents competitive results in several NLP annotations for English and Spanish.
A New Image Captioning Approach for Visually Impaired People,"Burak Makav, Volkan Kılıç",IEEE,,"Automatic caption generation in natural language to describe the visual content of an image has attracted an increasing amount of attention in the last decade due to its potential applications. It is a challenging task to generate captions with proper linguistics properties as it requires an advanced level of image understanding that goes far beyond image classification and object detection. In this paper, we propose to use the Stanford CoreNLP model to generate a caption after images are trained using VGG16 deep learning architecture. The visual attributes of images are extracted with the VGG16, which conveys richer content, and then they are fed into the Stanford model for caption generation. Experimental results on the MSCOCO dataset show that the proposed model significantly outperforms the state-ofthe-art approaches consistently across different evaluation metrics."
Querying Linked Data Using Semantic Relatedness: A Vocabulary Independent Approach,"André Freitas, João Gabriel Oliveira,Seán O'Riain, Edward Curry, JoãoCarlos Pereira da Silva",Data & Knowledge Engineering ,"Natural Language Queries, Linked Data","Linked Data brings the promise of incorporating a new dimension to the Web where the availability of Web-scale data can determine a paradigmatic transformation of the Web and its applications. However, together with its opportunities, Linked Data brings inherent challenges in the way users and applications consume the available data. Users consuming Linked Data on the Web, or on corporate intranets, should be able to search and query data spread over potentially a large number of heterogeneous, complex and distributed datasets. Ideally, a query mechanism for Linked Data should abstract users from the representation of data. This work focuses on the investigation of a vocabulary independent natural language query mechanism for Linked Data, using an approach based on the combination of entity search, a Wikipediabased semantic relatedness measure and spreading activation. The combination of these three elements in a query mechanism for Linked Data is a new contribution in the space. Wikipedia-based relatedness measures address existing limitations of existing works which are based on similarity measures/term expansion based on WordNet. Experimental results using the query mechanism to answer 50 natural language queries over DBPedia achieved a mean reciprocal rank of 61.4%, an average precision of 48.7% and average recall of 57.2%, answering 70% of the queries."
Stop Clickbait: Detecting and preventing clickbaits in online news media,"Abhijnan Chakraborty, BhargaviParanjape, Sourya Kakarla, NiloyGanguly",IEEE,,"Most of the online news media outlets rely heavily on the revenues generated from the clicks made by their readers, and due to the presence of numerous such outlets, they need to compete with each other for reader attention. To attract the readers to click on an article and subsequently visit the media site, the outlets often come up with catchy headlines accompanying the article links, which lure the readers to click on the link. Such headlines are known as Clickbaits. While these baits may trick the readers into clicking, in the longrun, clickbaits usually don’t live up to the expectation of the readers, and leave them disappointed. In this work, we attempt to automatically detect clickbaits and then build a browser extension which warns the readers of different media sites about the possibility of being baited by such headlines. The extension also offers each reader an option to block clickbaits she doesn’t want to see. Then, using such reader choices, the extension automatically blocks similar clickbaits during her future visits. We run extensive offline and online experiments across multiple media sites and find that the proposed clickbait detection and the personalized blocking approaches perform very well achieving 93% accuracy in detecting and 89% accuracy in blocking clickbaits."
Multiple Choice Question (MCQ) Answering System for Entrance Examination,"Somnath Banerjee, Pinaki Bhaskar,Partha Pakray, Sivaji Bandyopadhyay,Alexander Gelbukh",CLEF 2013,"Question Answering technique, QA4MRE Data Sets, Named Entity, Textual Entailment.","The article presents the experiments carried out as part of the participation in the pilot task of QA4MRE@CLEF 2013. In the developed system, we have first generated answer pattern by combining the question and each answer option to form the Hypothesis (H). Stop words and interrogative word are removed from each H and query words are identified to retrieve the most relevant sentences from the associated document using Lucene. Relevant sentences are retrieved from the associated document based on the TF-IDF of the matching query words along with n-gram overlap of the sentence with the H. Each retrieved sentence defines the Text T. Each T-H pair is assigned a ranking score that works on textual entailment principle. A matching score is automatically assigned to each answer options based on the matching. A parallel procedure also generates the possible answer patterns from given questions and answer options. Each sentence in the associated document is assigned an inference score with respect to each answer pattern. Evaluated inference score for each answer option is added with the matching score. The answer option that receives the highest selection score is identified as the most relevant option and selected as the answer to the given question."
Discovering Implicit Discourse Relations Through Brown Cluster Pair Representation and Coreference Patterns,"Attapol Rutherford, Nianwen Xue",ACL,,"Sentences form coherent relations in a discourse without discourse connectives more frequently than with connectives. Senses of these implicit discourse relations that hold between a sentence pair, however, are challenging to infer. Here, we employ Brown cluster pairs to represent discourse relation and incorporate coreference patterns to identify senses of implicit discourse relations in naturally occurring text. Our system improves the baseline performance by as much as 25%. Feature analyses suggest that Brown cluster pairs and coreference patterns can reveal many key linguistic characteristics of each type of discourse relation."
Extractivism: Extracting Activists Events from News Articles Using Existing NLP Tools and Services,"Thomas Ploeger, Maxine Kruijt, LoraAroyo, Frank de Bakker, Iina Hellsten,Antske Fokkens, Jesper Hoeksema,Serge ter Braake",CEUR Workshop Proceedings,,"Activists have a significant role in shaping social views and opinions. Social scientists study the events activists are involved in order to find out how activists shape our views. Unfortunately, individual sources may present incomplete, incorrect, or biased event descriptions. We present a method where we automatically extract event mentions from different news sources that could complement, contradict, or verify each other. The method makes use of off-the-shelf NLP tools. It is therefore easy to setup and can also be applied to extract events that are not related to activism."
Context Aware Text Representation,"Soha A. Khazaeli, Gerald M. Knapp",IISE 2014,"Text Representation, Context, Graph, First-Order-Logic","In conversations, stories, news reporting, and other forms of natural language, when story line moves forward and additional facts become known or time and location of the scene changed, the first facts of the text may be supported, contradicted, or refined. In these cases, more than one context exists in the text. Different methods of text representation have been offered from a bag of unigram, bigram, etc. to the bag of the words accompanied with lexical, syntactical and semantic features, or graph representation of the text, or First-Order-Logic representation. But in all the representation method for different natural language understanding problems, context has not been considered. Thus text representations include contradiction or disorganization may cause fatal problems in understanding. This research develops a new method to develop context aware text representation. This representation keeps lexical, syntactical, and semantic aspect of the statement as well as keeping track of the contexts the events and state happens in it and changing from one context to another context. The method can offer both graph representation and FirstOrder-Logic representation of the text."
Big data for Natural Language Processing: A streaming approach,"Rodrigo Agerri, Xabier Artola, ZuhaitzBeloki, German Rigau, Aitor Soroa",Knowledge-Based Systems,"Natural Language Processing, Distributed NLP architectures, Big data, Storm, NLP tools","Requirements in computational power have grown dramatically in recent years. This is also the case in many language processing tasks, due to the overwhelming and ever increasing amount of textual information that must be processed in a reasonable time frame. This scenario has led to a paradigm shift in the computing architectures and large-scale data processing strategies used in the Natural Language Processing field. In this paper we present a new distributed architecture and technology for scaling up text analysis running a complete chain of linguistic processors on several virtual machines. Furthermore, we also describe a series of experiments carried out with the goal of analyzing the scaling capabilities of the language processing pipeline used in this setting. We explore the use of Storm in a new approach for scalable distributed language processing across multiple machines and evaluate its effectiveness and efficiency when processing documents on a medium and large scale. The experiments have shown that there is a big room for improvement regarding language processing performance when adopting parallel architectures, and that we might expect even better results with the use of large clusters with many processing nodes."
Summary generation approaches based on semantic analysis for news documents,"Shanmuga Vadivel Kogilavani, C. S.Kanimozhiselvi, Subramaniam Malliga",Journal of Information Science,Features; initial summary; latent semantic analysis; summarization; update summary,"With the exponential growth of the internet, a lot of online news reports are produced on the web every day. The news stream flows so rapidly that no one has the time to look at each and every item of information. In this situation, a person would naturally prefer to read updated information at certain time intervals. Document updating technique is very helpful for individuals to acquire new information or knowledge by eliminating out-of-date or redundant information. Existing summarization systems involve identifying the most relevant sentences from the text and putting them together to create a concise initial summary. In the process of identifying the important sentences, features influencing the relevance of sentences are determined. Based on these features the salience of the sentence is calculated and an initial summary is generated from highly important sentences at different compression rates. These types of initial summaries work on a batch of documents and do not consider the documents that may arrive at later time, so that corresponding summaries need to get updated. The update summarization system addresses this issue by taking into account the documents read by the user in the past and seeks to present only fresh or different information. The first step is to create an initial summary based on basic and additional features. The next step is to create an update summary based on the basic, additional and update features. In this paper, two approaches are proposed for generating initial and update summary from multiple documents about given news. The first approach performs semantic analysis by modifying the vector space model with dependency parse relations and applying latent semantic analysis on it to create a summary. The second approach applies sentence annotation based on aspects, prepositions and named entities to generate summary. Experimental results show that the proposed approaches generate better initial and update summaries compared with the existing systems."
"Table of Contents Storyline Detection and Tracking Using Dynamic Latent Dirichlet Allocation Richer Event Description:Integrating Event Coreference withTemporal, Causal and Bridging Annotation Workshop Program Bridging the Gap between Event Macro-structures and Event Micro-structures Storyline Det","Tommaso Caselli, Vrije Universiteit,Amsterdam Ben Miller, David J.Caswell, Alexandra Balahur, SabineBergler, Leon Derczynski, Mark A.Finlayson, Vivi Nastase, Silvia Pareti,Octavian Popescu, Ellen Riloff, XavierTannier, Daniel Bruggermann, YannikHermey, Carsten Orth, DariusSchneider, Stefan Selzer, Gerasi, Tim O'gorman, Kristin Wright-Bettner, MarthaPalmer, Ed Hovy, Gerasimos Spanakis,Dan Simonson, Anthony P Davis",,,
ResumeVis: A Visual Analytics System to Discover Semantic Information in Semi-structured Resume Data,"Chen Zhang, Hao Wang, Yingcai Wu",arXiv,Visual analytics; resume analysis; semantic information mining; text visualization,"Massive public resume data emerging on the WWW indicates individual-related characteristics in terms of profile and career experiences. Resume Analysis (RA) provides opportunities for many applications, such as talent seeking and evaluation. Existing RA studies based on statistical analyzing have primarily focused on talent recruitment by identifying explicit attributes. However, they failed to discover the implicit semantic information, i.e., individual career progress patterns and social-relations, which are vital to comprehensive understanding of career development. Besides, how to visualize them for better human cognition is also challenging. To tackle these issues, we propose a visual analytics system ResumeVis to mine and visualize resume data. Firstly, a text-mining based approach is presented to extract semantic information. Then, a set of visualizations are devised to represent the semantic information in multiple perspectives. By interactive exploration on ResumeVis performed by domain experts, the following tasks can be accomplished: to trace individual career evolving trajectory; to mine latent social-relations among individuals; and to hold the full picture of massive resumes’ collective mobility. Case studies with over 2500 online officer resumes demonstrate the effectiveness of our system. We provide a demonstration video"
Evaluating Machine Reading Systems through Comprehension Tests,"Anselmo Peñas, Eduard H. Hovy,Pamela Forner, Álvaro Rodrigo, RichardF. E. Sutcliffe, Corina Forascu, CarolineSporleder",ACL,"Question Answering, Machine Reading, Evaluation","This paper describes a methodology for testing and evaluating the performance of Machine Reading systems through Question Answering and Reading Comprehension Tests. The methodology is being used in QA4MRE (QA for Machine Reading Evaluation), one of the labs of CLEF. We report here the conclusions and lessons learned after the first campaign in 2011."
Multiple Choice Question (MCQ) Answering for Machine Reading Evaluation,"Pinaki Bhaskar, Somnath Banerjee,Partha Pakray, Samadrita Banerjee,Sivaji Bandyopadhyay, AlexanderGelbukh",CLEF 2013,"Question Answering technique, QA4MRE Data Sets, Named Entity, Textual Entailment, Machine Reading","The article presents the experiments carried out as part of the participation in the main task (English dataset) of QA4MRE@CLEF 2013. In the developed system, we first combine the question Q and each candidate answer option A to form (Q , A) pair. Each pair has been considered a Hypothesis (H). We have used Morphological Expansion to rebuild the H. Then, each H has been verified by assigning a matching score. Stop words and interrogative words are removed from each H and query words are identified to retrieve the most relevant sentences from the associated document using Lucene. Relevant sentences are retrieved from the associated document based on the TF-IDF of the matching query words along with n-gram overlap of the sentence with the H. Each retrieved sentence defines the Text T. Each T-H pair is assigned a ranking score that works on textual entailment principle. The inference weight i.e., matching score has automatically been assigned to each answer options based on their inference matching. Each sentence in the associated document has contributed an inference score to each H. The candidate answer option that receives the highest inference score has been identified as the most relevant option and selected as the answer to the given question."
Glove: Global Vectors for Word Representation,"Jeffrey Pennington, Richard Socher,Christopher D. Manning",ACL,,"Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition."
Recurrent Neural Nets and Long Short-Term Memory,"Karl Pichotta, Raymond J. Mooney",AAAI,,"Scripts encode knowledge of prototypical sequences of events. We describe a Recurrent Neural Network model for statistical script learning using Long Short-Term Memory, an architecture which has been demonstrated to work well on a range of Artificial Intelligence tasks. We evaluate our system on two tasks, inferring held-out events from text and inferring novel events from text, substantially outperforming prior approaches on both tasks."
Learning statistical scripts with LSTM Recurrent Neural Networks,"Karl Pichotta, Raymond J. Mooney",AAAI,,"Scripts encode knowledge of prototypical sequences of events. We describe a Recurrent Neural Network model for statistical script learning using Long Short-Term Memory, an architecture which has been demonstrated to work well on a range of Artificial Intelligence tasks. We evaluate our system on two tasks, inferring held-out events from text and inferring novel events from text, substantially outperforming prior approaches on both tasks."
Investigations of the Properties of Narrative Schemas,Daniel E. Simonson,Georgetown University ,computational linguistics; narrative; narrative analysis; narrative schemas; natural language processing; Linguistics; Computer science; Linguistics; Computer science;,"Narrative schemas are generalizations of frequently re-occurring sequences of events linked through co-referring entities in text (Chambers & Jurafsky, 2009). The use of such schemas in the unsupervised analysis of text promises to assist with the characterization, comparison, and analysis of large volumes of text. How-ever, problems exist prior to conducting such an analysis, particularly with respect to evaluation. Most work following Chambers & Jurafsky (2009) focuses on cloze task performance, which does not directly evaluate schemas. To this end, I devise techniques to directly measure properties of narrative schemas. I first define the distinction between score—what is evaluated on the cloze task—and germinator—how a score is used to generate schemas. I re-interpret Chambers & Jurafsky (2009)’ s technique for generating schemas in these terms and devise two novel schema germination techniques. These different germinators produce very different sets of schemas. To evaluate schemas directly, I create two new tasks. The first is the Narrative Argument Salience Through Entities Annotated task, where schemas are shown to generally perform better than a number of baselines. I also coin a pair of minimum description length inspired measures. I conduct a meta-evaluation of these measures on the OntoNotes corpus (Weischedel et al., 2013); they show an insignificant degradation in schema quality despite receiving higher quality data."
CoreNLP-it: A UD Pipeline for Italian based on Stanford Core NLP,"Alessandro Bondielli, Lucia C. Passaro,Alessandro Lenci",CLiC-it 2018,,"This paper describes a collection of modules for Italian language processing based on CoreNLP and Universal Dependencies (UD). The software will be freely available for download under the GNU General Public License (GNU GPL). Given the flexibility of the framework, it is easily adaptable to new languages provided with an UD Treebank."
"Building a French-speaking community around UIMA, gathering research, education and industrial partners, mainly in Natural Language Processing and Speech Recognizing domains","Nicolas Hernandez, Fabien Poulard,Matthieu Vernier, Jérôme Rocheteau",LREC 2010,,"We report on the efforts the UN-LINA has made to build a UIMA French-speaking community both in Natural Language Processing and Speech Recognizing domains that would bring together researchers, industrials and educational interests. The intentions of building this community are twofold: to encourage the French-speaking academic and industrial organizations which have not yet adopt a middleware solution to use UIMA as a common development framework and middleware architecture for their research and engineering projects; to improve the collaborative development of common UIMA-based NLP tools and components for processing French. We present the services we set up as well as the resources we distribute freely under open licences to accomplish this objective. Most of them are currently available on the uima-fr.org Web Portal. They consist of: A web portal to discuss and exchange information about UIMA; A bundle of scripts and resources for automatically installing the whole of the Apache UIMA SDK; A bundle of UIMA-based components including some French NLP preprocessing components, a type mapper and a semantic rule-based analyser; A bundle of UIMA tools including an Analysis Engine Apache Maven archetype and an advanced web rest server; Course and training materials."
Aspect based Sentiment Analysis using support vector machine classifier,"Raisa Varghese, Mahiya Ummer P.A.Jayasree",IEEE,"Sentiment Analysis, Aspect Selection, Machine Learning, Natural Language Processing","Sentiment Analysis involves the process of identifying the polarity of opinionated texts. Lots of social networking sites are being used for expressing thoughts and opinions by users to rate products. These user opinionated text is highly unstructured in nature and thus involves the application of various natural language processing techniques. In aspect based sentiment analysis, the various features of a product is identified through the training process. For e.g. the aspects of a camera are picture quality, size, resolution etc. The quantitative analysis of each aspect is done using support vector machine classifier. In most of the previous works, a product review is analysed as a whole rather than considering each aspect of it. Aspect based opinion mining is tedious since the identification of individual features is in itself a challenging task."
Statistical Script Learning with Recurrent Neural Networks,Karl Pichotta,ACL,,We describe some of our recent efforts in learning statistical models of co-occurring events from large text corpora using Recurrent Neural Networks.
Using Anaphora Resolution in a Question Answering System for Machine Reading Evaluation,"Adrian Iftene, Mihai Alex Moruz, EugenIgnat",CLEF 2013,"Question Answering for Machine Reading Evaluation, Information Retrieval, Textual Entailment, Anaphora Resolution","This paper describes UAIC1 ’s Question Answering for Machine Reading Evaluation systems participating in the QA4MRE 2013 evaluation task. We submitted two types of runs, both type of runs based on our system from 2012 edition of QA4MRE, and both used anaphora resolution system. Differences come from the fact the textual entailment component was used or not. The results offered by organizer showed that runs based on textual entailment component were better."
Using Sentence-Level LSTM Language Models for Script Inference,"Karl Pichotta, Raymond J. Mooney",arXiv,,"There is a small but growing body of research on statistical scripts, models of event sequences that allow probabilistic inference of implicit events from documents. These systems operate on structured verb-argument events produced by an NLP pipeline. We compare these systems with recent Recurrent Neural Net models that directly operate on raw tokens to predict sentences, finding the latter to be roughly comparable to the former in terms of predicting missing events in documents."
Script Induction as Language Modeling,"Rachel Rudinger, Pushpendre Rastogi,Francis Ferraro, Benjamin Van Durme",ACL,,"The narrative cloze is an evaluation metric commonly used for work on automatic script induction. While prior work in this area has focused on count-based methods from distributional semantics, such as pointwise mutual information, we argue that the narrative cloze can be productively reframed as a language modeling task. By training a discriminative language model for this task, we attain improvements of up to 27 percent over prior methods on standard narrative cloze metrics."
Automated Identification of Sensitive Data via Flexible User Requirements,"Ziqi Yang, Zhenkai Liang",Cybersecurity ,,"The sensitivity of information is dependent on the context of application and user preference. Protecting sensitive data in the cloud era requires identifying them in the first place. It typically needs intensive manual efforts. More importantly, users may specify sensitive information only through an implicit manner. Existing research efforts on identifying sensitive data from its descriptive texts focus on keyword/phrase searching. These approaches can have high false positives/negatives as they do not consider the semantics of the descriptions. In this paper, we propose S3, an automated approach to identify sensitive data based on users’ implicit specifications. Our approach considers semantic, syntactic and lexical information comprehensively, aiming to identify sensitive data by the semantics of its descriptive texts. We introduce the notion concept space to represent the user’s notion of privacy, by which our approach can support flexible user requirements in defining sensitive data. Our approach is able to learn users’ preferences from readable concepts initially provided by users, and automatically identify related sensitive data. We evaluate our approach on over 18,000 top popular applications from Google Play Store. S3 achieves an average precision of 89.2%, and average recall 95.8% in identifying sensitive data."
Finding Cross Genome Patterns in Annotation Graphs,"Joseph Benik, Caren Chang, LouiqaRaschid, Maria-Esther Vidal, GuillermoPalma, Andreas Thor",Data Integration in the Life Sciences,"Link Prediction, Distance Metrics, Gene CRY2, Annotation Graph, Graph Summary","Annotation graph datasets are a natural representation of scientific knowledge. They are common in the life sciences where concepts such as genes and proteins are annotated with controlled vocabulary terms from ontologies. Scientists are interested in analyzing or mining these annotations, in synergy with the literature, to discover patterns. Further, annotated datasets provide an avenue for scientists to explore shared annotations across genomes to support cross genome discovery. We present a tool, PAnG (Patterns in Annotation Graphs), that is based on a complementary methodology of graph summarization and dense subgraphs. The elements of a graph summary correspond to a pattern and its visualization can provide an explanation of the underlying knowledge. We present and analyze two distance metrics to identify related concepts in ontologies. We present preliminary results using groups of Arabidopsis and C. elegans genes to illustrate the potential benefits of cross genome pattern discovery."
Distributed Representations of Sentences and Documents,"Quoc Le, Shaobo He",arXiv,,"Many machine learning algorithms require the input to be represented as a fixed-length feature vector. When it comes to texts, one of the most common fixed-length features is bag-of-words. Despite their popularity, bag-of-words features have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words. For example, “powerful,” “strong” and “Paris” are equally distant. In this paper, we propose Paragraph Vector, an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents. Our algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-ofwords models. Empirical results show that Paragraph Vectors outperform bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks."
Efficient Estimation of Word Representations in Vector Space,"Shaobo He, Kai Chen, Gregory S.Corrado, Jeffrey Dean",arXiv,,"We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities."
Recursive Deep Models for Semantic Compositionality Over a SentimentTreebank,"Richard Socher, Alex Perelygin, JeanWu, Jason Chuang, Christopher D.Manning, Andrew Y. Ng, ChristopherPotts",ACL,,"Semantic word spaces have been very useful but cannot express the meaning of longer phrases in a principled way. Further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation resources and more powerful models of composition. To remedy this, we introduce a Sentiment Treebank. It includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality. To address them, we introduce the Recursive Neural Tensor Network. When trained on the new treebank, this model outperforms all previous methods on several metrics. It pushes the state of the art in single sentence positive/negative classification from 80% up to 85.4%. The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7%, an improvement of 9.7% over bag of features baselines. Lastly, it is the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases."
Exploiting Similarities among Languages for Machine Translation,"Shaobo He, Quoc V. Le, Ilya Sutskever",arXiv,,"Dictionaries and phrase tables are the basis of modern statistical machine translation systems. This paper develops a method that can automate the process of generating and extending dictionaries and phrase tables. Our method can translate missing word and phrase entries by learning language structures based on large monolingual data and mapping between languages from small bilingual data. It uses distributed representation of words and learns a linear mapping between vector spaces of languages. Despite its simplicity, our method is surprisingly effective: we can achieve almost 90% precision@5 for translation of words between English and Spanish. This method makes little assumption about the languages, so it can be used to extend and refine dictionaries and translation tables for any language pairs."
Phrase Type Sensitive Tensor Indexing Model for Semantic Composition,"Yu Zhao, Zhiyuan Liu, Maosong Sun",AAAI,,"Compositional semantic aims at constructing the meaning of phrases or sentences according to the compositionality of word meanings. In this paper, we propose to synchronously learn the representations of individual words and extracted high-frequency phrases. Representations of extracted phrases are considered as gold standard for constructing more general operations to compose the representation of unseen phrases. We propose a grammatical type specific model that improves the composition flexibility by adopting vector-tensorvector operations. Our model embodies the compositional characteristics of traditional additive and multiplicative model. Empirical result shows that our model outperforms state-of-the-art composition methods in the task of computing phrase similarities."
Multi-Document Extractive Summarization Using Window-Based Sentence Representation,"Yong Zhang, Meng Joo Er, Rui Zhao",IEEE,,"Multi-document summarization has gained popularity in many real world applications because significant information can be obtained within a short time. Extractive summarization aims to generate a summary of a document or a set of documents by ranking sentences and the ranking results rely heavily on the quality of sentence features. However, almost all previous algorithms require hand-crafted features for sentence representation. In this paper, we leverage on word embedding to represent sentences so as to avoid the intensive labor of feature engineering. We propose a new technique, namely window-based sentence representation (WSR), to obtain the features of sentences using pre-trained word vectors. The method is developed based on the Extreme Learning Machine (ELM). Our proposed framework does not require any prior knowledge and thus can be applied to various document summarization tasks with different languages, written styles and so on. We evaluate our proposed method on the DUC 2006 and 2007 datasets. This proposed method achieves superior performance compared with state-of-the-arts document summarization algorithms with significantly faster learning speed."
Hierarchical Tree Long Short-Term Memory for Sentence Representations,"Xiuying Wang, Changliang Li, Bo Xu",IEEE,Deep Learning; Hierarchical Tree Long Shortterm Memory; Sentence Representation; Sentiment Analysis,"A fixed-length feature vector is required for many machine learning algorithms in NLP field. Word embeddings have been very successful at learning lexical information. However, they can’t capture the compositional meaning of sentences, which prevents them from a deeper understanding of language. In this paper, we introduce a novel hierarchical tree long short-term memory (HTLSTM) model that learns vector representations for sentences of arbitrary syntactic type and length. We propose to split one sentence into three hierarchies: short phrase, long phrase and full sentence level. The HTLSTM model gives our algorithm the potential to fully consider the hierarchical information and longterm dependencies of language. We design the experiments on both English and Chinese corpus to evaluate our model on sentiment analysis task. And the results show that our model outperforms several existing state of the art approaches significantly."
Semantic Compositionality through Recursive Matrix-Vector Spaces,"Richard Socher, Brody Huval,Christopher D. Manning, Andrew Y. Ng",ACL,,"Single-word vector space models have been very successful at learning lexical information. However, they cannot capture the compositional meaning of longer phrases, preventing them from a deeper understanding of language. We introduce a recursive neural network (RNN) model that learns compositional vector representations for phrases and sentences of arbitrary syntactic type and length. Our model assigns a vector and a matrix to every node in a parse tree: the vector captures the inherent meaning of the constituent, while the matrix captures how it changes the meaning of neighboring words or phrases. This matrix-vector RNN can learn the meaning of operators in propositional logic and natural language. The model obtains state of the art performance on three different experiments: predicting fine-grained sentiment distributions of adverb-adjective pairs; classifying sentiment labels of movie reviews and classifying semantic relationships such as cause-effect or topic-message between nouns using the syntactic path between them."
Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks,"Kai Sheng Tai, Richard Socher,Christopher D. Manning",arXiv,,"Because of their superior ability to preserve sequence information over time, Long Short-Term Memory (LSTM) networks, a type of recurrent neural network with a more complex computational unit, have obtained strong results on a variety of sequence modeling tasks. The only underlying LSTM structure that has been explored so far is a linear chain. However, natural language exhibits syntactic properties that would naturally combine words to phrases. We introduce the Tree-LSTM, a generalization of LSTMs to tree-structured network topologies. TreeLSTMs outperform all existing systems and strong LSTM baselines on two tasks: predicting the semantic relatedness of two sentences (SemEval 2014, Task 1) and sentiment classification (Stanford Sentiment Treebank)."
A Unified Framework for Jointly Learning Distributed Representations of Word and Attributes,"Liqiang Niu, Xin-Yu Dai, Shujian Huang,Jiajun Chen",PMLR,"framework, learning, representation, word, topic, document","Distributed word representations have achieved great success in natural language processing (NLP) area. However, most distributed models focus on local context properties and learn task-specific representations individually, therefore lack the ability to fuse multi-attributes and learn jointly. In this paper, we propose a unified framework which jointly learns distributed representations of word and attributes: characteristics of word. In our models, we consider three types of attributes: topic, lemma and document. Besides learning distributed attribute representations, we find that using additional attributes is beneficial to improve word representations. Several experiments are conducted to evaluate the performance of the learned topic representations, document representations, and improved word representations, respectively. The experimental results show that our models achieve significant and competitive results."
Adaptation of SVM for MIL for inferring the polarity of movies and movie reviews,"Maria Joana Correia, Isabel Trancoso,Bhiksha Raj",IEEE,"sentiment analysis, Doc2Vec, multiple instance learning, SVM, IMDb","Polarity detection is a research topic of major interest, with many applications including detecting the polarity of product reviews. However, in some cases, the polarity of the product reviews might not be available while the polarity of the product itself might be, prohibiting the use of any form of fully supervised learning technique. This scenario, while different, is close to that of multiple instance learning (MIL). In this work we propose two new adaptations of support vector machines (SVM) for MIL, θ-MIL, to suit this new scenario, and infer the polarity of products and product reviews. We perform experiments on the proposed methods using the IMDb movie review corpus, and compare the performance of the proposed methods to the traditional SVM for MIL approach. Although we make weaker assumptions about the data, the proposed methods achieve a comparable performance to the SVM for MIL in accurately detecting the polarity of movies and movie reviews"
An Analysis on the Learning Rules of the Skip-Gram Model,"Canlin Zhang, Xiuwen Liu, Daniel Bis",arXiv,,"To improve the generalization of the representations for natural language processing tasks, words are commonly represented using vectors, where distances among the vectors are related to the similarity of the words. While word2vec, the state-of-the-art implementation of the skip-gram model, is widely used and improves the performance of many natural language processing tasks, its mechanism is not yet well understood. In this work, we derive the learning rules for the skipgram model and establish their close relationship to competitive learning. In addition, we provide the global optimal solution constraints for the skip-gram model and validate them by experimental results."
Comparing Semantic and Nutrient Value Similarities of Recipes,"Gordana Ispirova, Tome Eftimov,Barbara Korousic-Seljak",IEEE,"recipe data, macronutient values, word embeddings, paragraph embeddings, recipe similarity","Although food and nutrition have been studied for centuries, modern nutritional science is surprisingly young. Human knowledge about food and nutrition has evolved drastically with time, and it has especially expanded the last few decades, with information and data being mass produced and available everywhere and in any form it is really easy to get overwhelmed and confused when it comes to what is right and what is wrong. Macronutrient assessment is a crucial task for individuals suffering from various diseases, and also very relevant for professional athletes, and nowadays it is becoming part of everyday life for many people, because of health or fitness reasons. Assessing the nutritional components of food is very challenging and requires reliant source of data. In this paper, we introduce an idea of finding similar recipes with regard to their macronutrient values based on learned recipe vector representation. On a scientifically proven dataset of recipe data containing description and macronutrient values we introduce word and paragraph embeddings, learn concept representations for the textual descriptions, proceed with calculating similarity between the embeddings, and then compare with the similarity between nutrient values. The results show a strong correlation between these two similarities. This study is a promising beginning for continuing in this direction – introducing multi-label classification or regression for predicting nutrient content of food."
Skip-Thought Vectors,"Ryan Kiros, Yukun Zhu, RuslanSalakhutdinov, Richard S. Zemel,Raquel Urtasun, Antonio Torralba,Sanja Fidler",arXiv,,"We describe an approach for unsupervised learning of a generic, distributed sentence encoder. Using the continuity of text from books, we train an encoderdecoder model that tries to reconstruct the surrounding sentences of an encoded passage. Sentences that share semantic and syntactic properties are thus mapped to similar vector representations. We next introduce a simple vocabulary expansion method to encode words that were not seen as part of training, allowing us to expand our vocabulary to a million words. After training our model, we extract and evaluate our vectors with linear models on 8 tasks: semantic relatedness, paraphrase detection, image-sentence ranking, question-type classification and 4 benchmark sentiment and subjectivity datasets. The end result is an off-the-shelf encoder that can produce highly generic sentence representations that are robust and perform well in practice. We will make our encoder publicly available."
A Framework for Learning Knowledge-Powered Word Embedding,"Qing Cui, Bin Gao, Jiang Bian, Siyu Qiu,Tie-Yan Liu",,,
Learning distributed word representation with multi-contextual mixed embedding,"Jianqiang Li, Jing Li, Xianghua Fu, MdAbdul Masud, Joshua Zhexue Huang",Knowledge-Based Systems ,"Word embedding, Distributed word representation, Word2vec, Natural language processing","Learning distributed word representations has been a popular method for various natural language processing applications such as word analogy and similarity, document classification and sentiment analysis. However, most existing word embedding models only exploit a shallow slide window as the context to predict the target word. Because the semantic of each word is also influenced by its global context, as the distributional models usually induced the word representations from the global co-occurrence matrix, the window-based models are insufficient to capture semantic knowledge. In this paper, we propose a novel hybrid model called mixed word embedding (MWE) based on the well-known word2vec toolbox. Specifically, the proposed MWE model combines the two variants of word2vec, i.e., SKIP-GRAM and CBOW, in a seamless way via sharing a common encoding structure, which is able to capture the syntax information of words more accurately. Furthermore, it incorporates a global text vector into the CBOW variant so as to capture more semantic information. Our MWE preserves the same time complexity as the SKIP-GRAM. To evaluate our MWE model efficiently and adaptively, we study our model on linguistic and application perspectives with both English and Chinese dataset. For linguistics, we conduct empirical studies on word analogies and similarities. The learned latent representations on both document classification and sentiment analysis are considered for application point of view of this work. The experimental results show that our MWE model is very competitive in all tasks as compared with the state-of-the-art word embedding models such as CBOW, SKIP-GRAM, and GloVe."
Weighted word2vec based on the distance of words,"Chia-Yang Chang, Shie-Jue Lee, Chih-Chin Lai",IEEE,Word2vec; Natural language processing(NLP); Word embedding; Fuzzy,"Word2vec is a novel technique for the study and application of natural language processing(NLP). It trains a word embedding neural network model with a large training corpus. After the model is trained, each word is represented by a vector in the specified vector space. The vectors obtained possess many interesting and useful characteristics that are implicitly embedded with the original words. The idea of word2vec is that there are relations between the words if they appear in the neighborhood. These relations are employed by considering various context windows in training the network model. However, word2vec doesn’t consider the influence of distance between the words. It only considers whether or not the words appear in the same context window. We consider that word distances in the context bear certain semantic sense which can be exploited to better train the network model. To formalize the influence of different distances in the context, the fuzzy concept is adopted. Various experiments show that our proposed improvement can result in better language models than Word2Vec."
Copy detection for digital documents,"Pang-Ming Chu, Chia-Yang Chang, Shie-Jue Lee",ACM,,"In a digital library system, documents are available in digital form and therefore are more easily copied and their copyrights are more easily violated. This is a very serious problem, as it discourages owners of valuable information from sharing it with authorized users. There are two main philosophies for addressing this problem: prevention and detection. The former actually makes unauthorized use of documents difficult or impossible while the latter makes it easier to discover such activity.In this paper we propose a system for registering documents and then detecting copies, either complete copies or partial copies. We describe algorithms for such detection, and metrics required for evaluating detection mechanisms (covering accuracy, efficiency, and security). We also describe a working prototype, called COPS, describe implementation issues, and present experimental results that suggest the proper settings for copy detection parameters."
Learning word embeddings efficiently with noise-contrastive estimation,"Andriy Mnih, Koray Kavukcuoglu",NIPS,,"Continuous-valued word embeddings learned by neural language models have recently been shown to capture semantic and syntactic information about words very well, setting performance records on several word similarity tasks. The best results are obtained by learning high-dimensional embeddings from very large quantities of data, which makes scalability of the training method a critical factor. We propose a simple and scalable new approach to learning word embeddings based on training log-bilinear models with noise-contrastive estimation. Our approach is simpler, faster, and produces better results than the current state-of-theart method. We achieve results comparable to the best ones reported, which were obtained on a cluster, using four times less data and more than an order of magnitude less computing time. We also investigate several model types and find that the embeddings learned by the simpler models perform at least as well as those learned by the more complex ones."
Learning Effective Word Embedding using Morphological Word Similarity,"Qing Cui, Bin Gao, Jiang Bian, Siyu Qiu,Tie-Yan Liu",arXiv,,"Deep learning techniques aim at obtaining high-quality distributed representations of words, i.e., word embeddings, to address text mining and natural language processing tasks. Recently, efficient methods have been proposed to learn word embeddings from context that captures both semantic and syntactic relationships between words. However, it is challenging to handle unseen words or rare words with insufficient context. In this paper, inspired by the study on word recognition process in cognitive psychology, we propose to take advantage of seemingly less obvious but essentially important morphological word similarity to address these challenges. In particular, we introduce a novel neural network architecture that leverages both contextual information and morphological word similarity to learn word embeddings. Meanwhile, the learning architecture is also able to refine the pre-defined morphological knowledge and obtain more accurate word similarity. Experiments on an analogical reasoning task and a word similarity task both demonstrate that the proposed method can greatly enhance the effectiveness of word embeddings."
Improving Vector Space Word Representations Using Multilingual Correlation,"Manaal Faruqui, Chris Dyer",ACL ,,"The distributional hypothesis of Harris (1954), according to which the meaning of words is evidenced by the contexts they occur in, has motivated several effective techniques for obtaining vector space semantic representations of words using unannotated text corpora. This paper argues that lexico-semantic content should additionally be invariant across languages and proposes a simple technique based on canonical correlation analysis (CCA) for incorporating multilingual evidence into vectors generated monolingually. We evaluate the resulting word representations on standard lexical semantic evaluation tasks and show that our method produces substantially better semantic representations than monolingual techniques."
Learning word representations for Turkish,"Mehmet Umut Sen, Hakan Erdogan",IEEE,"Word embeddings, Natural Language Processing, Deep Learning","High-quality word representations have been very successful in recent years at improving performance across a variety of NLP tasks. These word representations are the mappings of each word in the vocabulary to a real vector in the Euclidean space. Besides high performance on specific tasks, learned word representations have been shown to perform well on establishing linear relationships among words. The recently introduced skipgram model improved performance on unsupervised learning of word embeddings that contains rich syntactic and semantic word relations both in terms of accuracy and speed. Word embeddings that have been used frequently on English language, is not applied to Turkish yet. In this paper, we apply the skip-gram model to a large Turkish text corpus and measured the performance of them quantitatively with the ""question"" sets that we generated. The learned word embeddings and the question sets are publicly available at our website."
Türkçe için Kelime Temsillerinin Ö˘ grenimiLearning Word Representations for Turkish,"Mehmet Umut Sen, Hakan Erdogan",IEEE,"Kelime temsilleri, Do ˘gal Dil ˙I¸sleme, Derin Ö ˘grenme","Son yıllarda yüksek kaliteli kelime temsillerinin, bir çok dogal dil i¸sleme problemlerinin çözümünde performansı artır- ˘ mada ba¸sarılı oldukları görülmü¸stür. Kelime temsilleri, sözcük haznesindeki her bir kelimenin Öklit uzayında gerçel bir vektöre e¸slemlenmesidir. Ögrenilen kelime temsillerinin özgül problem ˘ için faydalı olmasının yanında kelimeler arası dogrusal ili¸ski ˘ kurdukları da gözlemlenmi¸stir. Yeni tanıtılan atla-gram modeli, zengin anlamsal ve sözdizimsel kelime temsillerinin güdümsüz ögrenimini daha hızlı ve ba¸sarılı kılmı¸stır. ˘ ˙Ingilizce dili için sıklıkla kullanılmaya ba¸slanan kelime temsillerinin henüz Türkçe için bir uygulaması bulunmamaktadır. Bu bildiride, atla-gram modelini büyük miktardaki bir Türkçe veritabanına uyguladık ve olu¸sturdugumuz soru bankalarıyla bu temsillerin kelime ˘ anlamları arasında ili¸ski kurma ba¸sarısını nicel olarak ölçtük. Olu¸sturdugumuz kelime temsilleri ve soru bankaları web sitemiz ˘ üzerinden akademik kullanıma açılmı¸stır."
Co-learning of Word Representations and Morpheme Representations,"Siyu Qiu, Qing Cui, Jiang Bian, Bin Gao,Tie-Yan Liu",ACL ,,"The techniques of using neural networks to learn distributed word representations (i.e., word embeddings) have been used to solve a variety of natural language processing tasks. The recently proposed methods, such as CBOW and Skip-gram, have demonstrated their effectiveness in learning word embeddings based on context information such that the obtained word embeddings can capture both semantic and syntactic relationships between words. However, it is quite challenging to produce high-quality word representations for rare or unknown words due to their insufficient context information. In this paper, we propose to leverage morphological knowledge to address this problem. Particularly, we introduce the morphological knowledge as both additional input representation and auxiliary supervision to the neural network framework. As a result, beyond word representations, the proposed neural network model will produce morpheme representations, which can be further employed to infer the representations of rare or unknown words based on their morphological structure. Experiments on an analogical reasoning task and several word similarity tasks have demonstrated the effectiveness of our method in producing high-quality words embeddings compared with the state-of-the-art methods."
Knowledge-Powered Deep Learning for Word Embedding,"Jiang Bian, Bin Gao, Tie-Yan Liu",Machine Learning and Knowledge Discovery in Databases,,"The basis of applying deep learning to solve natural language processing tasks is to obtain high-quality distributed representations of words, i.e., word embeddings, from large amounts of text data. However, text itself usually contains incomplete and ambiguous information, which makes necessity to leverage extra knowledge to understand it. Fortunately, text itself already contains well-defined morphological and syntactic knowledge; moreover, the large amount of texts on the Web enable the extraction of plenty of semantic knowledge. Therefore, it makes sense to design novel deep learning algorithms and systems in order to leverage the above knowledge to compute more effective word embeddings. In this paper, we conduct an empirical study on the capacity of leveraging morphological, syntactic, and semantic knowledge to achieve high-quality word embeddings. Our study explores these types of knowledge to define new basis for word representation, provide additional input information, and serve as auxiliary supervision in deep learning, respectively. Experiments on an analogical reasoning task, a word similarity task, and a word completion task have all demonstrated that knowledge-powered deep learning can enhance the effectiveness of word embedding."
A Convolutional Neural Network for Modelling Sentences,"Nal Kalchbrenner, Edward Grefenstette,Phil Blunsom",arXiv,,"The ability to accurately represent sentences is central to language understanding. We describe a convolutional architecture dubbed the Dynamic Convolutional Neural Network (DCNN) that we adopt for the semantic modelling of sentences. The network uses Dynamic k-Max Pooling, a global pooling operation over linear sequences. The network handles input sentences of varying length and induces a feature graph over the sentence that is capable of explicitly capturing short and long-range relations. The network does not rely on a parse tree and is easily applicable to any language. We test the DCNN in four experiments: small scale binary and multi-class sentiment prediction, six-way question classification and Twitter sentiment prediction by distant supervision. The network achieves excellent performance in the first three tasks and a greater than 25% error reduction in the last task with respect to the strongest baseline."
Topic2Vec: Learning distributed representations of topics,"Liqiang Niu, Xin-Yu Dai, Jianbing Zhang,Jiajun Chen",arXiv,,"Latent Dirichlet Allocation (LDA) mining thematic structure of documents plays an important role in nature language processing and machine learning areas. However, the probability distribution from LDA only describes the statistical relationship of occurrences in the corpus and usually in practice, probability is not the best choice for feature representations. Recently, embedding methods have been proposed to represent words and documents by learning essential concepts and representations, such as Word2Vec and Doc2Vec. The embedded representations have shown more effectiveness than LDA-style representations in many tasks. In this paper, we propose the Topic2Vec approach which can learn topic representations in the same semantic vector space with words, as an alternative to probability. The experimental results show that Topic2Vec achieves interesting and meaningful results."
Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions,"Richard Socher, Jeffrey Pennington,Eric H. Huang, Andrew Y. Ng,Christopher D. Manning",ACL ,,"We introduce a novel machine learning framework based on recursive autoencoders for sentence-level prediction of sentiment label distributions. Our method learns vector space representations for multi-word phrases. In sentiment prediction tasks these representations outperform other state-of-the-art approaches on commonly used datasets, such as movie reviews, without using any pre-defined sentiment lexica or polarity shifting rules. We also evaluate the model’s ability to predict sentiment distributions on a new dataset based on confessions from the experience project. The dataset consists of personal user stories annotated with multiple labels which, when aggregated, form a multinomial distribution that captures emotional reactions. Our algorithm can more accurately predict distributions over such labels compared to several competitive baselines."
Deep Guessing: Generating Meaningful Personalized Quizzes on Historical Topics by Introducing Wikicategories in Doc2Vec,"Borja Varela-Brea, Martín López Nores,Yolanda Blanco-Fernández, José JuanPazos-Arias, Alberto Gil-Solla, ManuelRamos Cabrer",IEEE,,"Neural language models are being increasingly used for unsupervised text classification and clustering tasks, with proposals that learn vector representations from word- to documentlevel. We have adapted one of the latter to discover Wikipedia articles which are relevant to selected historical topics, and also to a given question and its correct answer, by exploiting not only the knowledge captured in the writing of the articles themselves, but also in their classification in wikicategories. Our goal is to automate the generation of personalized multiple-choice quizzes, with wrong alternatives to the correct answer tailored to the level of knowledge of the target user on the selected topics. The approach is shown to provide diverse and meaningful alternatives, in a way that even the absurd ones –which are included mainly for fun– do have some interesting connections to the right answers."
Text clustering using VSM with feature clusters,"Qimin Cao, Qiao Guo, Yongliang Wang,Xianghua Wu",Neural Computing and Applications,"Text clustering, Feature clusters, Distributed representation, FC-VSM, Non-contiguous phrases","Representation of documents is the basis of clustering systems. In addition, non-contiguous phrases appear more and more frequent in the text in the Web 2.0 age, and these phrases can affect the result of text clustering. In order to improve the quality of text clustering, this paper proposed a feature cluster-based vector space model (FC-VSM) which used the text feature clusters cooccurrence matrix to represent document and proposed to identify non-contiguous phrases in the text preprocessing stage. Our method can reduce dimension of features compared with the traditional VSM-based model. It identified non-contiguous phrases, used distributed representation of features, and implements feature clusters. Despite their simplicity, our methods are surprisingly effective and can improve the accuracy of clustering significantly which is shown in experimental results."
Normalized Word Embedding and Orthogonal Transform for Bilingual Word Translation,"Chao Xing, Dong Wang, Chao Liu, YiyeLin",ACL ,,"Word embedding has been found to be highly powerful to translate words from one language to another by a simple linear transform. However, we found some inconsistence among the objective functions of the embedding and the transform learning, as well as the distance measurement. This paper proposes a solution which normalizes the word vectors on a hypersphere and constrains the linear transform as an orthogonal transform. The experimental results confirmed that the proposed solution can offer better performance on a word similarity task and an English-toSpanish word translation task."
Topic Modeling Using Distributed Word Embeddings,"Ramandeep S. Randhawa, Parag Jain,Gagan Madan",arXiv,,"We propose a new algorithm for topic modeling, Vec2Topic, that identifies the main topics in a corpus using semantic information captured via high-dimensional distributed word embeddings. Our technique is unsupervised and generates a list of topics ranked with respect to importance. We find that it works better than existing topic modeling techniques such as Latent Dirichlet Allocation for identifying key topics in user-generated content, such as emails, chats, etc., where topics are diffused across the corpus. We also find that Vec2Topic works equally well for non-user generated content, such as papers, reports, etc., and for small corpora such as a single-document."
Embedding Semantic Relations into Word Representations,"Danushka Bollegala, Takanori Maehara,Ken-ichi Kawarabayashi",arXiv,,"Learning representations for semantic relations is important for various tasks such as analogy detection, relational search, and relation classification. Although there have been several proposals for learning representations for individual words, learning word representations that explicitly capture the semantic relations between words remains under developed. We propose an unsupervised method for learning vector representations for words such that the learnt representations are sensitive to the semantic relations that exist between two words. First, we extract lexical patterns from the co-occurrence contexts of two words in a corpus to represent the semantic relations that exist between those two words. Second, we represent a lexical pattern as the weighted sum of the representations of the words that co-occur with that lexical pattern. Third, we train a binary classifier to detect relationally similar vs. non-similar lexical pattern pairs. The proposed method is unsupervised in the sense that the lexical pattern pairs we use as train data are automatically sampled from a corpus, without requiring any manual intervention. Our proposed method statistically significantly outperforms the current state-of-the-art word representations on three benchmark datasets for proportional analogy detection, demonstrating its ability to accurately capture the semantic relations among words."
A Factorized Recurrent Neural Network Based Architecture for Medium to Large Vocabulary Language Modelling,Anantharaman Palacode Narayana Iyer,IEEE,Recurrent Neural Networks; Language Models; hierarchical softmax; class based prediction,"Statistical language models are central to many applications that use semantics. Recurrent Neural Networks (RNN) are known to produce state of the art results for language modelling, outperforming their traditional n-gram counterparts in many cases. To generate a probability distribution across a vocabulary, these models require a softmax output layer that linearly increases in size with the size of the vocabulary. Large vocabularies need a commensurately large softmax layer and training them on typical laptops/PCs requires significant time and machine resources. In this paper we present a new technique for implementing RNN based large vocabulary language models that substantially speeds up computation while optimally using the limited memory resources. Our technique, while building on the notion of factorizing the output layer by having multiple output layers, improves on the earlier work by substantially optimizing on the individual output layer size and also eliminating the need for a multistep prediction process."
A Study on the CBOW Model's Overfitting and Stability,"Qun Luo, Weiran Xu, Jun Guo",ACM,Word representations; Continuous Bag-of-Words Model; regularization; inverse word frequency; semantic; syntactic,"Word vectors are distributed representations of word features. Continuous Bag-of-Words Model(CBOW) is a state-of-the-art model for learning word vectors, yet can be ameliorated for learning better word vectors because we find that CBOW is vulnerable to be overfitted and unstable. We use two methods to solve these two problems so that CBOW can learn better word vectors. In this study, we add the regularized structure risk summation to the objective function of the CBOW model and propose inverse word frequency encoding for the CBOW model. Our proposed methods substantially improve the quality of word vectors, boosting r from 0.638 to 0.696 for word relatedness and total accuracy from 30.80% to 38.43% for word pairs relationship relatedness regarding to 52 million training words with 200 dimensionality."
"Don't count, predict! A systematic comparison of context-counting vs. context-predicting semantic vectors","Marco Baroni, Georgiana Dinu, GermánKruszewski",ACL ,,"Context-predicting models (more commonly known as embeddings or neural language models) are the new kids on the distributional semantics block. Despite the buzz surrounding these models, the literature is still lacking a systematic comparison of the predictive models with classic, count-vector-based distributional semantic approaches. In this paper, we perform such an extensive evaluation, on a wide range of lexical semantics tasks and across many parameter settings. The results, to our own surprise, show that the buzz is fully justified, as the context-predicting models obtain a thorough and resounding victory against their count-based counterparts."
KNET: A General Framework for Learning Word Embedding Using Morphological Knowledge,"Qing Cui, Bin Gao, Jiang Bian, Siyu Qiu,Hanjun Dai, Tie-Yan Liu",arXiv,,"Neural network techniques are widely applied to obtain high-quality distributed representations of words, i.e., word embeddings, to address text mining, information retrieval, and natural language processing tasks. Recently, efficient methods have been proposed to learn word embeddings from context that captures both semantic and syntactic relationships between words. However, it is challenging to handle unseen words or rare words with insufficient context. In this paper, inspired by the study on word recognition process in cognitive psychology, we propose to take advantage of seemingly less obvious but essentially important morphological knowledge to address these challenges. In particular, we introduce a novel neural network architecture called KNET that leverages both contextual information and morphological word similarity built based on morphological knowledge to learn word embeddings. Meanwhile, the learning architecture is also able to refine the predefined morphological knowledge and obtain more accurate word similarity. Experiments on an analogical reasoning task and a word similarity task both demonstrate that the proposed KNET framework can greatly enhance the effectiveness of word embeddings."
Linguistic Regularities in Continuous Space Word Representations,"Tomas Mikolov, Wen-tau Yih, GeoffreyZweig",ACL ,,"Continuous space language models have recently demonstrated outstanding results across a variety of tasks. In this paper, we examine the vector-space word representations that are implicitly learned by the input-layer weights. We find that these representations are surprisingly good at capturing syntactic and semantic regularities in language, and that each relationship is characterized by a relation-specific vector offset. This allows vector-oriented reasoning based on the offsets between words. For example, the male/female relationship is automatically learned, and with the induced vector representations, “King - Man + Woman” results in a vector very close to “Queen.” We demonstrate that the word vectors capture syntactic regularities by means of syntactic analogy questions (provided with this paper), and are able to correctly answer almost 40% of the questions. We demonstrate that the word vectors capture semantic regularities by using the vector offset method to answer SemEval-2012 Task 2 questions. Remarkably, this method outperforms the best previous systems."
Learning Word Representation Considering Proximity and Ambiguity,"Lin Qiu, Yong Cao, Zaiqing Nie, YongYu, Yong Rui",AAAI,Word Representation; Neural Networks,"Distributed representations of words (aka word embedding) have proven helpful in solving natural language processing (NLP) tasks. Training distributed representations of words with neural networks has lately been a major focus of researchers in the field. Recent work on word embedding, the Continuous Bag-of-Words (CBOW) model and the Continuous Skip-gram (Skip-gram) model, have produced particularly impressive results, significantly speeding up the training process to enable word representation learning from large-scale data. However, both CBOW and Skip-gram do not pay enough attention to word proximity in terms of model or word ambiguity in terms of linguistics. In this paper, we propose Proximity-Ambiguity Sensitive (PAS) models (i.e. PAS CBOW and PAS Skip-gram) to produce high quality distributed representations of words considering both word proximity and ambiguity. From the model perspective, we introduce proximity weights as parameters to be learned in PAS CBOW and used in PAS Skip-gram. By better modeling word proximity, we reveal the strength of pooling-structured neural networks in word representation learning. The proximity-sensitive pooling layer can also be applied to other neural network applications that employ pooling layers. From the linguistics perspective, we train multiple representation vectors per word. Each representation vector corresponds to a particular group of POS tags of the word. By using PAS models, we achieved a 16.9% increase in accuracy over state-of-the-art models."
Practice in Synonym Extraction at Large Scale,"Liangliang Cao, Chang Wang",arXiv,,"Synonym extraction is an important task in natural language processing and often used as a submodule in query expansion, question answering and other applications. Automatic synonym extractor is highly preferred for large scale applications. Previous studies in synonym extraction are most limited to small scale datasets. In this paper, we build a large dataset with 3.4 million synonym/non-synonym pairs to capture the challenges in real world scenarios. We proposed (1) a new cost function to accommodate the unbalanced learning problem, and (2) a feature learning based deep neural network to model the complicated relationships in synonym pairs. We compare several different approaches based on SVMs and neural networks, and find out a novel feature learning based neural network outperforms the methods with hand-assigned features. Specifically, the best performance of our model surpasses the SVM baseline with a significant 97\% relative improvement."
Learning Patient Similarity Using Joint Distributed Embeddings of Treatment and Diagnoses,"Christopher J Ormandy, Zina M.Ibrahim, Richard J. B. Dobson",CEUR Workshop Proceedings,,"We propose the use of vector-based word embedding models to learn a cross-conceptual representation of medical vocabulary. The learned model is dense and encodes useful knowledge from the training concepts. Applying the embedding to the concepts of diagnoses and medications, we then show that they can then be used to measure similarities among patient prescriptions, leading to the discovery of in- formative and intuitive relationships between patients."
A Word Vector Based Review Vector Method for Sentiment Analysis of Movie Reviews Exploring the Applicability of the Movie Reviews,"Fulian Yin, Yanyan Wang, Xingyi Pan,Pei Dong Su",IEEE,sentiment analysis; word embedding; text mining; natural language processing; machine learning,"Based on word embedding method, this paper presents a word vector based review vector method for sentiment analysis of movie reviews. As a result, it is achieved that 86.18% classification accuracy using the method. Meanwhile, the method is applicable to multiple languages such as Chinese and English, and it is extensible for larger scale contents as well. What’s more, the influence of word vector dimensions on the sentiment analysis accuracy and the method’s applicability on sentences of varied lengths are also discussed in this paper. The experimental result proved that the word vector based review method for sentiment analysis is not only an efficient and simple way to analyze emotional expression, but also has extensibility and applicability for comments in varied lengths and multiple languages."
A fast and simple algorithm for training neural probabilistic language models,"Andriy Mnih, Yee Whye Teh",arXiv,,"In spite of their superior performance, neural probabilistic language models (NPLMs) remain far less widely used than n-gram models due to their notoriously long training times, which are measured in weeks even for moderately-sized datasets. Training NPLMs is computationally expensive because they are explicitly normalized, which leads to having to consider all words in the vocabulary when computing the log-likelihood gradients. We propose a fast and simple algorithm for training NPLMs based on noise-contrastive estimation, a newly introduced procedure for estimating unnormalized continuous distributions. We investigate the behaviour of the algorithm on the Penn Treebank corpus and show that it reduces the training times by more than an order of magnitude without affecting the quality of the resulting models. The algorithm is also more efficient and much more stable than importance sampling because it requires far fewer noise samples to perform well. We demonstrate the scalability of the proposed approach by training several neural language models on a 47M-word corpus with a 80K-word vocabulary, obtaining state-of-the-art results on the Microsoft Research Sentence Completion Challenge dataset."
Better Word Representations with Recursive Neural Networks for Morphology,"Thang Luong, Richard Socher,Christopher D. Manning",ACL ,,"Vector-space word representations have been very successful in recent years at improving performance across a variety of NLP tasks. However, common to most existing work, words are regarded as independent entities without any explicit relationship among morphologically related words being modeled. As a result, rare and complex words are often poorly estimated, and all unknown words are represented in a rather crude way using only one or a few vectors. This paper addresses this shortcoming by proposing a novel model that is capable of building representations for morphologically complex words from their morphemes. We combine recursive neural networks (RNNs), where each morpheme is a basic unit, with neural language models (NLMs) to consider contextual information in learning morphologicallyaware word representations. Our learned models outperform existing word representations by a good margin on word similarity tasks across many datasets, including a new dataset we introduce focused on rare words to complement existing ones in an interesting way."
RC-NET: A General Framework for Incorporating Knowledge into Word Representations,"Chang Xu, Yalong Bai, Jiang Bian, BinGao, Gang Wang, Xiaoguang Liu, Tie-Yan Liu",ACM,"Distributed word representations, deep learning, knowledge graph","Representing words into vectors in continuous space can form up a potentially powerful basis to generate high-quality textual features for many text mining and natural language processing tasks. Some recent efforts, such as the skip-gram model, have attempted to learn word representations that can capture both syntactic and semantic information among text corpus. However, they still lack the capability of encoding the properties of words and the complex relationships among words very well, since text itself often contains incomplete and ambiguous information. Fortunately, knowledge graphs provide a golden mine for enhancing the quality of learned word representations. In particular, a knowledge graph, usually composed by entities (words, phrases, etc.), relations between entities, and some corresponding meta information, can supply invaluable relational knowledge that encodes the relationship between entities as well as categorical knowledge that encodes the attributes or properties of entities. Hence, in this paper, we introduce a novel framework called RC-NET to leverage both the relational and categorical knowledge to produce word representations of higher quality. Specifically, we build the relational knowledge and the categorical knowledge into two separate regularization functions, and combine both of them with the original objective function of the skip-gram model. By solving this combined optimization problem using back propagation neural networks, we can obtain word representations enhanced by the knowledge graph. Experiments on popular text mining and natural language processing tasks, including analogical reasoning, word similarity, and topic prediction, have all demonstrated that our model can significantly improve the quality of word representations.
"
Bilingual Word Representations with Monolingual Quality in Mind,"Thang Luong, Hieu Pham, ChristopherD. Manning",ACL ,,"Recent work in learning bilingual representations tend to tailor towards achieving good performance on bilingual tasks, most often the crosslingual document classification (CLDC) evaluation, but to the detriment of preserving clustering structures of word representations monolingually. In this work, we propose a joint model to learn word representations from scratch that utilizes both the context coocurrence information through the monolingual component and the meaning equivalent signals from the bilingual constraint. Specifically, we extend the recently popular skipgram model to learn high quality bilingual representations efficiently. Our learned embeddings achieve a new state-of-the-art accuracy of 80.3 for the German to English CLDC task and a highly competitive performance of 90.7 for the other classification direction. At the same time, our models outperform best embeddings from past bilingual representation work by a large margin in the monolingual word similarity evaluation.1"
Variable-Length Word Encodings for Neural Translation Models,"Rohan Chitnis, John DeNero",ACL ,,"Recent work in neural machine translation has shown promising performance, but the most effective architectures do not scale naturally to large vocabulary sizes. We propose and compare three variable-length encoding schemes that represent a large vocabulary corpus using a much smaller vocabulary with no loss in information. Common words are unaffected by our encoding, but rare words are encoded using a sequence of two pseudo-words. Our method is simple and effective: it requires no complete dictionaries, learning procedures, increased training time, changes to the model, or new parameters. Compared to a baseline that replaces all rare words with an unknown word symbol, our best variable-length encoding strategy improves WMT English-French translation performance by up to 1.7 BLEU."
Empirically combining unnormalized NNLMand back-off N-gram for fast N-best rescoring in speech recognition,"Yongzhe Shi, Wei-Qiang Zhang, MengCai, Jia Liu","EURASIP Journal on Audio, Speech and Music Processing",Neural network language model; N-best rescoring; Speech recognition,"Neural network language models (NNLM) have been proved to be quite powerful for sequence modeling, including feed-forward NNLM (FNNLM), recurrent NNLM (RNNLM), etc. One main issue concerned for NNLM is the heavy computational burden of the output layer, where the output needs to be probabilistically normalized and the normalizing factors require lots of computation. How to fast rescore the N-best list or lattice with NNLM attracts much attention for large-scale applications. In this paper, the statistic characteristics of normalizing factors are investigated on the N-best list. Based on the statistic observations, we propose to approximate the normalizing factors for each hypothesis as a constant proportional to the number of words in the hypothesis. Then, the unnormalized NNLM is investigated and combined with back-off N-gram for fast rescoring, which can be computed very fast without the normalization in the output layer, with the complexity reduced significantly. We apply our proposed method to a well-tuned context-dependent deep neural network hidden Markov model (CD-DNN-HMM) speech recognition system on the English-Switchboard phone-call speech-to-text task, where both FNNLM and RNNLM are trained to demonstrate our method. Experimental results show that unnormalized probability of NNLM is quite complementary to that of back-off N-gram, and combining the unnormalized NNLM and back-off N-gram can further reduce the word error rate with little computational consideration."
Compositional Morphology for Word Representations and Language Modelling,"Jan A. Botha, Phil Blunsom",arXiv,,"This paper presents a scalable method for integrating compositional morphological representations into a vector-based probabilistic language model. Our approach is evaluated in the context of log-bilinear language models, rendered suitably efficient for implementation inside a machine translation decoder by factoring the vocabulary. We perform both intrinsic and extrinsic evaluations, presenting results on a range of languages which demonstrate that our model learns morphological representations that both perform well on word similarity tasks and lead to substantial reductions in perplexity. When used for translation into morphologically rich languages with large vocabularies, our models obtain improvements of up to 1.2 BLEU points relative to a baseline system using back-off n-gram models."
Bilingual Word Embeddings for Phrase-Based Machine Translation,"Will Y. Zou, Richard Socher, Daniel M.Cer, Christopher D. Manning",ACL ,,"We introduce bilingual word embeddings: semantic embeddings associated across two languages in the context of neural language models. We propose a method to learn bilingual embeddings from a large unlabeled corpus, while utilizing MT word alignments to constrain translational equivalence. The new embeddings significantly out-perform baselines in word semantic similarity. A single semantic similarity feature induced with bilingual embeddings adds near half a BLEU point to the results of NIST08 Chinese-English machine translation task."
Unsupervised and Efficient Vocabulary Expansion for Recurrent Neural Network Language Models in ASR,"Yerbolat Khassanov, Chng Eng Siong",arXiv,,"In automatic speech recognition (ASR) systems, recurrent neural network language models (RNNLM) are used to rescore a word lattice or N-best hypotheses list. Due to the expensive training, the RNNLM's vocabulary set accommodates only small shortlist of most frequent words. This leads to suboptimal performance if an input speech contains many out-of-shortlist (OOS) words. An effective solution is to increase the shortlist size and retrain the entire network which is highly inefficient. Therefore, we propose an efficient method to expand the shortlist set of a pretrained RNNLM without incurring expensive retraining and using additional training data. Our method exploits the structure of RNNLM which can be decoupled into three parts: input projection layer, middle layers, and output projection layer. Specifically, our method expands the word embedding matrices in projection layers and keeps the middle layers unchanged. In this approach, the functionality of the pretrained RNNLM will be correctly maintained as long as OOS words are properly modeled in two embedding spaces. We propose to model the OOS words by borrowing linguistic knowledge from appropriate in-shortlist words. Additionally, we propose to generate the list of OOS words to expand vocabulary in unsupervised manner by automatically extracting them from ASR output."
Neural Word Embedding as Implicit Matrix Factorization,"Omer Levy, Yoav Goldberg",NIPS,,"We analyze skip-gram with negative-sampling (SGNS), a word embedding method introduced by Mikolov et al., and show that it is implicitly factorizing a word-context matrix, whose cells are the pointwise mutual information (PMI) of the respective word and context pairs, shifted by a global constant. We find that another embedding method, NCE, is implicitly factorizing a similar matrix, where each cell is the (shifted) log conditional probability of a word given its context. We show that using a sparse Shifted Positive PMI word-context matrix to represent words improves results on two word similarity tasks and one of two analogy tasks. When dense low-dimensional vectors are preferred, exact factorization with SVD can achieve solutions that are at least as good as SGNS’s solutions for word similarity tasks. On analogy questions SGNS remains superior to SVD. We conjecture that this stems from the weighted nature of SGNS’s factorization."
Linguistic Regularities in Sparse and Explicit Word Representations,"Omer Levy, Yoav Goldberg",ACL ,,"Recent work has shown that neuralembedded word representations capture many relational similarities, which can be recovered by means of vector arithmetic in the embedded space. We show that Mikolov et al.’s method of first adding and subtracting word vectors, and then searching for a word similar to the result, is equivalent to searching for a word that maximizes a linear combination of three pairwise word similarities. Based on this observation, we suggest an improved method of recovering relational similarities, improving the state-of-the-art results on two recent word-analogy datasets. Moreover, we demonstrate that analogy recovery is not restricted to neural word embeddings, and that a similar amount of relational similarities can be recovered from traditional distributional word representations."
WordRep: A Benchmark for Research on Learning Word Representations,"Bin Gao, Jiang Bian, Tie-Yan Liu",arXiv,,"WordRep is a benchmark collection for the research on learning distributed word representations (or word embeddings), released by Microsoft Research. In this paper, we describe the details of the WordRep collection and show how to use it in different types of machine learning research related to word embedding. Specifically, we describe how the evaluation tasks in WordRep are selected, how the data are sampled, and how the evaluation tool is built. We then compare several state-of-the-art word representations on WordRep, report their evaluation performance, and make discussions on the results. After that, we discuss new potential research topics that can be supported by WordRep, in addition to algorithm comparison. We hope that this paper can help people gain deeper understanding of WordRep, and enable more interesting research on learning distributed word representations and related topics."
Category Enhanced Word Embedding,"Chunting Zhou, Chonglin Sun, ZhiyuanLiu, Francis C. M. Lau",arXiv,,"Distributed word representations have been demonstrated to be effective in capturing semantic and syntactic regularities. Unsupervised representation learning from large unlabeled corpora can learn similar representations for those words that present similar cooccurrence statistics. Besides local occurrence statistics, global topical information is also important knowledge that may help discriminate a word from another. In this paper, we incorporate category information of documents in the learning of word representations and to learn the proposed models in a documentwise manner. Our models outperform several state-of-the-art models in word analogy and word similarity tasks. Moreover, we evaluate the learned word vectors on sentiment analysis and text classification tasks, which shows the superiority of our learned word vectors. We also learn high-quality category embeddings that reflect topical meanings."
Dependency-Based Word Embeddings,"Omer Levy, Yoav Goldberg",ACL ,,"While continuous word embeddings are gaining popularity, current models are based solely on linear contexts. In this work, we generalize the skip-gram model with negative sampling introduced by Mikolov et al. to include arbitrary contexts. In particular, we perform experiments with dependency-based contexts, and show that they produce markedly different embeddings. The dependencybased embeddings are less topical and exhibit more functional similarity than the original skip-gram embeddings."
Improving Prediction of Suicide and Accidental Death After Discharge From General Hospitals With Natural Language Processing.,"Thomas H. McCoy, Victor M Castro,Ashlee M Roberson, Leslie A Snapper,Roy H. Perlis",JAMA Psychiatry,,"Suicide represents the 10th leading cause of death across age groups in the United States (12.6 cases per 100 000) and remains challenging to predict. While many individuals who die by suicide are seen by physicians before their attempt, they may not seek psychiatric care. To determine the extent to which incorporating natural language processing of narrative discharge notes improves stratification of risk for death by suicide after medical or surgical hospital discharge. In this retrospective health care use study, clinical data were analyzed from individuals with discharges from 2 large academic medical centers between January 1, 2005, and December 31, 2013. The primary outcome was suicide as a reported cause of death based on Massachusetts Department of Public Health records. Regression models for prediction of death by suicide or accidental death were compared relying solely on coded clinical data and those using natural language processing of hospital discharge notes. There were 845 417 hospital discharges represented in the cohort, including 458 053 unique individuals. Overall, all-cause mortality was 18% during 9 years, and the median follow-up was 5.2 years. The cohort included 235 (0.1%) who died by suicide during 2.4 million patient-years of follow-up. Positive valence reflected in narrative notes was associated with a 30% reduction in risk for suicide in models adjusted for coded sociodemographic and clinical features (hazard ratio, 0.70; 95% CI, 0.58-0.85; P < .001) and improved model fit (χ22 = 14.843, P < .001 by log-likelihood test). The C statistic was 0.741 (95% CI, 0.738-0.744) for models of suicide with or without inclusion of accidental death. Multiple clinical features available at hospital discharge identified a cohort of individuals at substantially increased risk for suicide. Greater positive valence expressed in narrative discharge summaries was associated with substantially diminished risk. Automated tools to aid clinicians in evaluating these risks may assist in identifying high-risk individuals."
Using electronic medical records to enable large-scale studies in psychiatry: treatment resistant depression as a model.,"Roy H. Perlis, Dan V. Iosifescu, Victor MCastro, Shawn N. Murphy, Vivian S.Gainer, Jessica Minnier, Tianxi Cai,Sergey Goryachev, Qingsong Zeng, PaulJ. Gallagher, Maurizio Fava, JeffreyWeilburg, Susanne E. Churchill, Isaac S.Kohane, Jordan W. Smoller",Psychological Medicine ,,"Electronic medical records (EMR) provide a unique opportunity for efficient, large-scale clinical investigation in psychiatry. However, such studies will require development of tools to define treatment outcome. Natural language processing (NLP) was applied to classify notes from 127 504 patients with a billing diagnosis of major depressive disorder, drawn from out-patient psychiatry practices affiliated with multiple, large New England hospitals. Classifications were compared with results using billing data (ICD-9 codes) alone and to a clinical gold standard based on chart review by a panel of senior clinicians. These cross-sectional classifications were then used to define longitudinal treatment outcomes, which were compared with a clinician-rated gold standard. Models incorporating NLP were superior to those relying on billing data alone for classifying current mood state (area under receiver operating characteristic curve of 0.85-0.88 v. 0.54-0.55). When these cross-sectional visits were integrated to define longitudinal outcomes and incorporate treatment data, 15% of the cohort remitted with a single antidepressant treatment, while 13% were identified as failing to remit despite at least two antidepressant trials. Non-remitting patients were more likely to be non-Caucasian (p<0.001). The application of bioinformatics tools such as NLP should enable accurate and efficient determination of longitudinal outcomes, enabling existing EMR data to be applied to clinical research, including biomarker investigations. Continued development will be required to better address moderators of outcome such as adherence and co-morbidity."
Electronic Medical Records for Discovery Research in Rheumatoid Arthritis Citation,"Katherine P. Liao, Tianxi Cai, Vivian S.Gainer, Sergey Goryachev, Qing Zeng-Treitler, Soumya Raychaudhuri, PSzolovits, Susanne E. Churchill, ShawnN. Murphy, Isaac S. Kohane, ElizabethW. Karlson, Robert M. Plenge",Arthritis Care & Research,,"Electronic medical records (EMRs) are a rich data source for discovery research but are underutilized due to the difficulty of extracting highly accurate clinical data. We assessed whether a classification algorithm incorporating narrative EMR data (typed physician notes), more accurately classifies subjects with rheumatoid arthritis (RA) compared to an algorithm using codified EMR data alone. Subjects with ≥1 ICD9 RA code (714.xx) or who had anti-CCP checked in the EMR of two large academic centers were included into an ‘RA Mart’ (n=29,432). For all 29,432 subjects, we extracted narrative (using natural language processing) and codified RA clinical information. In a training set of 96 RA and 404 non-RA cases from the RA Mart classified by medical record review, we used narrative and codified data to develop classification algorithms using logistic regression. These algorithms were applied to the entire RA Mart. We calculated and compared the positive predictive value (PPV) of these algorithms by reviewing records of an additional 400 subjects classified as RA by the algorithms. A complete algorithm (narrative and codified data) classified RA subjects with a significantly higher PPV of 94%, than an algorithm with codified data alone (PPV 88%). Characteristics of the RA cohort identified by the complete algorithm were comparable to existing RA cohorts (80% female, 63% anti-CCP+, 59% erosion+). We demonstrate the ability to utilize complete EMR data to define an RA cohort with a PPV of 94%, which was superior to an algorithm using codified data alone."
Electronic medical records for discovery research in rheumatoid arthritis.,"Katherine P. Liao, Tianxi Cai, Vivian S.Gainer, Sergey Goryachev, Qing Zeng-Treitler, Soumya Raychaudhuri, PeterSzolovits, Susanne E. Churchill, ShawnMurphy, Isaac S. Kohane, Elizabeth W.Karlson, Robert M. Plenge",Arthritis Care & Research,,"Electronic medical records (EMRs) are a rich data source for discovery research but are underutilized due to the difficulty of extracting highly accurate clinical data. We assessed whether a classification algorithm incorporating narrative EMR data (typed physician notes) more accurately classifies subjects with rheumatoid arthritis (RA) compared with an algorithm using codified EMR data alone. Subjects with > or =1 International Classification of Diseases, Ninth Revision RA code (714.xx) or who had anti-cyclic citrullinated peptide (anti-CCP) checked in the EMR of 2 large academic centers were included in an ""RA Mart"" (n = 29,432). For all 29,432 subjects, we extracted narrative (using natural language processing) and codified RA clinical information. In a training set of 96 RA and 404 non-RA cases from the RA Mart classified by medical record review, we used narrative and codified data to develop classification algorithms using logistic regression. These algorithms were applied to the entire RA Mart. We calculated and compared the positive predictive value (PPV) of these algorithms by reviewing the records of an additional 400 subjects classified as having RA by the algorithms. A complete algorithm (narrative and codified data) classified RA subjects with a significantly higher PPV of 94% than an algorithm with codified data alone (PPV of 88%). Characteristics of the RA cohort identified by the complete algorithm were comparable to existing RA cohorts (80% women, 63% anti-CCP positive, and 59% positive for erosions). We demonstrate the ability to utilize complete EMR data to define an RA cohort with a PPV of 94%, which was superior to an algorithm using codified data alone."
Portability of an algorithm to identify rheumatoid arthritis in electronic health records,"Robert J. Carroll, William K. Thompson,Anne E. Eyler, Arthur M. Mandelin,Tianxi Cai, Raquel M. Zink, Jennifer A.Pacheco, Chad S. Boomershine,Thomas A. Lasko, Hua Xu, Elizabeth W.Karlson, Raul G. Perez, Vivian S. Gainer,Shawn N. Murphy, Eric M. Ruderman,Richard M. Pope, Robert M. Plenge,Abel N. Kho, Katherine P. Liao, JoshuaC. Denny",JAMIA,,"Electronic health records (EHR) can allow for the generation of large cohorts of individuals with given diseases for clinical and genomic research. A rate-limiting step is the development of electronic phenotype selection algorithms to find such cohorts. This study evaluated the portability of a published phenotype algorithm to identify rheumatoid arthritis (RA) patients from EHR records at three institutions with different EHR systems. Physicians reviewed charts from three institutions to identify patients with RA. Each institution compiled attributes from various sources in the EHR, including codified data and clinical narratives, which were searched using one of two natural language processing (NLP) systems. The performance of the published model was compared with locally retrained models. Applying the previously published model from Partners Healthcare to datasets from Northwestern and Vanderbilt Universities, the area under the receiver operating characteristic curve was found to be 92% for Northwestern and 95% for Vanderbilt, compared with 97% at Partners. Retraining the model improved the average sensitivity at a specificity of 97% to 72% from the original 65%. Both the original logistic regression models and locally retrained models were superior to simple billing code count thresholds. These results show that a previously published algorithm for RA is portable to two external hospitals using different EHR systems, different NLP systems, and different target NLP vocabularies. Retraining the algorithm primarily increased the sensitivity at each site. Electronic phenotype algorithms allow rapid identification of case populations in multiple sites with little retraining."
Predicting Suicidal Behavior From Longitudinal Electronic Health Records.,"Yuval Barak-Corren, Victor M Castro,Solomon Javitt, Alison G Hoffnagle,Yael Dai, Roy H. Perlis, Matthew K.Nock, Jordan W. Smoller, Ben Y. Reis",The American Journal of Psychiatry,Diagnosis And Classification; Suicide,"The purpose of this article was to determine whether longitudinal historical data, commonly available in electronic health record (EHR) systems, can be used to predict patients' future risk of suicidal behavior. Bayesian models were developed using a retrospective cohort approach. EHR data from a large health care database spanning 15 years (1998-2012) of inpatient and outpatient visits were used to predict future documented suicidal behavior (i.e., suicide attempt or death). Patients with three or more visits (N=1,728,549) were included. ICD-9-based case definition for suicidal behavior was derived by expert clinician consensus review of 2,700 narrative EHR notes (from 520 patients), supplemented by state death certificates. Model performance was evaluated retrospectively using an independent testing set. Among the study population, 1.2% (N=20,246) met the case definition for suicidal behavior. The model achieved sensitive (33%-45% sensitivity), specific (90%-95% specificity), and early (3-4 years in advance on average) prediction of patients' future suicidal behavior. The strongest predictors identified by the model included both well-known (e.g., substance abuse and psychiatric disorders) and less conventional (e.g., certain injuries and chronic conditions) risk factors, indicating that a data-driven approach can yield more comprehensive risk profiles. Longitudinal EHR data, commonly available in clinical settings, can be useful for predicting future risk of suicidal behavior. This modeling approach could serve as an early warning system to help clinicians identify high-risk patients for further screening. By analyzing the full phenotypic breadth of the EHR, computerized risk screening approaches may enhance prediction beyond what is feasible for individual clinicians."
A Controlled Trial Using Natural Language Processing to Examine the Language of Suicidal Adolescents in the Emergency Department.,"John P. Pestian, Jacqueline Grupp-Phelan, Kevin Bretonnel Cohen, GabrielMeyers, Linda A Richey, PawelMatykiewicz, Michael T. Sorter",The Official Journal of the American Association of Suicidology,,"What adolescents say when they think about or attempt suicide influences the medical care they receive. Mental health professionals use teenagers' words, actions, and gestures to gain insight into their emotional state and to prescribe what they believe to be optimal care. This prescription is often inconsistent among caregivers, however, and leads to varying outcomes. This variation could be reduced by applying machine learning as an aid in clinical decision support. We designed a prospective clinical trial to test the hypothesis that machine learning methods can discriminate between the conversation of suicidal and nonsuicidal individuals. Using semisupervised machine learning methods, the conversations of 30 suicidal adolescents and 30 matched controls were recorded and analyzed. The results show that the machines accurately distinguished between suicidal and nonsuicidal teenagers."
Efficient Development of Electronic Health Record Based Algorithms to Identify Rheumatoid Arthritis,R. William Carroll,Arthritis Care & Research,,
Improving case definition of Crohn's disease and ulcerative colitis in electronic medical records using natural language processing: a novel informatics approach.,"Ashwin N. Ananthakrishnan, Tianxi Cai,Guergana K. Savova, Su-Chun Cheng,Pei Jun Chen, Raul G. Perez, Vivian S.Gainer, Shawn N. Murphy, PeterSzolovits, Zongqi Xia, Stanley Y. Shaw,Susanne E. Churchill, Elizabeth W.Karlson, Isaac S. Kohane, Robert M.Plenge, Katherine P. Liao",Inflammatory Bowel Diseases ,,"Previous studies identifying patients with inflammatory bowel disease using administrative codes have yielded inconsistent results. Our objective was to develop a robust electronic medical record-based model for classification of inflammatory bowel disease leveraging the combination of codified data and information from clinical text notes using natural language processing. Using the electronic medical records of 2 large academic centers, we created data marts for Crohn's disease (CD) and ulcerative colitis (UC) comprising patients with ≥1 International Classification of Diseases, 9th edition, code for each disease. We used codified (i.e., International Classification of Diseases, 9th edition codes, electronic prescriptions) and narrative data from clinical notes to develop our classification model. Model development and validation was performed in a training set of 600 randomly selected patients for each disease with medical record review as the gold standard. Logistic regression with the adaptive LASSO penalty was used to select informative variables. We confirmed 399 CD cases (67%) in the CD training set and 378 UC cases (63%) in the UC training set. For both, a combined model including narrative and codified data had better accuracy (area under the curve for CD 0.95; UC 0.94) than models using only disease International Classification of Diseases, 9th edition codes (area under the curve 0.89 for CD; 0.86 for UC). Addition of natural language processing narrative terms to our final model resulted in classification of 6% to 12% more subjects with the same accuracy. Inclusion of narrative concepts identified using natural language processing improves the accuracy of electronic medical records case definition for CD and UC while simultaneously identifying more subjects compared with models using codified data alone."
Methods for Identifying Suicide or Suicidal Ideation in EHRs,"Krystl Haerian, Hojjat Salmasian, CarolFriedman",AMIA Annual Symposium Proceedings ,,"Electronic health records contain important data elements for detection of novel adverse drug reactions, genotype/phenotype identification and psychosocial factor analysis, and the role of each of these as risk factors for suicidality warrants further investigation. Suicide and suicidal ideation are documented in clinical narratives. The specific purpose of this study was to define an algorithm for automated detection of this serious event. We found that ICD-9 E-Codes had the lowest positive predictive value: 0.55 (90% CI: 0.42-0.67), while combining ICD-9 and NLP had the best PPV: 0.97 (90% CI: 0.92-0.99). A qualitative analysis and classification of the types of errors by ICD-9 and NLP automated coding compared to manual review are also discussed."
Genetic basis of autoantibody positive and negative rheumatoid arthritis risk in a multi-ethnic cohort derived from electronic health records.,"Fina A. S. Kurreeman, Katherine P. Liao,Lori B Chibnik, Brendan Hickey, Eli AStahl, Vivian S. Gainer, Gang Li, LynnBry, Scott Mahan, Kristin G Ardlie, BrianThomson, Peter Szolovits, Susanne E.Churchill, Shawn N. Murphy, Tianxi Cai,Soumya Raychaudhuri, Isaac S.Kohane, Elizabeth W. Karlson, RobertM. Plenge",The American Journal of Human Genetics,,"Discovering and following up on genetic associations with complex phenotypes require large patient cohorts. This is particularly true for patient cohorts of diverse ancestry and clinically relevant subsets of disease. The ability to mine the electronic health records (EHRs) of patients followed as part of routine clinical care provides a potential opportunity to efficiently identify affected cases and unaffected controls for appropriate-sized genetic studies. Here, we demonstrate proof-of-concept that it is possible to use EHR data linked with biospecimens to establish a multi-ethnic case-control cohort for genetic research of a complex disease, rheumatoid arthritis (RA). In 1,515 EHR-derived RA cases and 1,480 controls matched for both genetic ancestry and disease-specific autoantibodies (anti-citrullinated protein antibodies [ACPA]), we demonstrate that the odds ratios and aggregate genetic risk score (GRS) of known RA risk alleles measured in individuals of European ancestry within our EHR cohort are nearly identical to those derived from a genome-wide association study (GWAS) of 5,539 autoantibody-positive RA cases and 20,169 controls. We extend this approach to other ethnic groups and identify a large overlap in the GRS among individuals of European, African, East Asian, and Hispanic ancestry. We also demonstrate that the distribution of a GRS based on 28 non-HLA risk alleles in ACPAþ cases partially overlaps with ACPA- subgroup of RA cases. Our study demonstrates that the genetic basis of rheumatoid arthritis risk is similar among cases of diverse ancestry divided into subsets based on ACPA status and emphasizes the utility of linking EHR clinical data with biospecimens for genetic studies."
A Machine Learning Approach to Identifying the Thought Markers of Suicidal Subjects: A Prospective Multicenter Trial,"John P. Pestian, Michael T. Sorter,Brian Connolly, Kevin Bretonnel Cohen,Cheryl B Mccullumsmith, Jeffry T Gee,Louis-Philippe Morency, Stefan Scherer,Lesley Rohlfs",The Official Journal of the American Association of Suicidology,,"Death by suicide demonstrates profound personal suffering and societal failure. While basic sciences provide the opportunity to understand biological markers related to suicide, computer science provides opportunities to understand suicide thought markers. In this novel prospective, multimodal, multicenter, mixed demographic study, we used machine learning to measure and fuse two classes of suicidal thought markers: verbal and nonverbal. Machine learning algorithms were used with the subjects' words and vocal characteristics to classify 379 subjects recruited from two academic medical centers and a rural community hospital into one of three groups: suicidal, mentally ill but not suicidal, or controls. By combining linguistic and acoustic characteristics, subjects could be classified into one of the three groups with up to 85% accuracy. The results provide insight into how advanced technology can be used for suicide assessment and prevention."
Validation of electronic health record phenotyping of bipolar disorder cases and controls.,"Victor M Castro, Jessica Minnier,Shawn N. Murphy, Isaac S. Kohane,Susanne E. Churchill, Vivian S. Gainer,Tianxi Cai, Alison G Hoffnagle, Yael Dai,Stefanie R. Block, Sydney Weill, MireyaF Nadal-Vicens, Alisha R. Pollastri, J.Niels Rosenquist, Sergey Goryachev,Dost Ongur, Pamela Sklar, Roy H.Perlis, Jordan W. Smoller",The American Journal of Psychiatry,,"The study was designed to validate use of electronic health records (EHRs) for diagnosing bipolar disorder and classifying control subjects. EHR data were obtained from a health care system of more than 4.6 million patients spanning more than 20 years. Experienced clinicians reviewed charts to identify text features and coded data consistent or inconsistent with a diagnosis of bipolar disorder. Natural language processing was used to train a diagnostic algorithm with 95% specificity for classifying bipolar disorder. Filtered coded data were used to derive three additional classification rules for case subjects and one for control subjects. The positive predictive value (PPV) of EHR-based bipolar disorder and subphenotype diagnoses was calculated against diagnoses from direct semistructured interviews of 190 patients by trained clinicians blind to EHR diagnosis. The PPV of bipolar disorder defined by natural language processing was 0.85. Coded classification based on strict filtering achieved a value of 0.79, but classifications based on less stringent criteria performed less well. No EHR-classified control subject received a diagnosis of bipolar disorder on the basis of direct interview (PPV=1.0). For most subphenotypes, values exceeded 0.80. The EHR-based classifications were used to accrue 4,500 bipolar disorder cases and 5,000 controls for genetic analyses. Semiautomated mining of EHRs can be used to ascertain bipolar disorder patients and control subjects with high specificity and predictive value compared with diagnostic interviews. EHRs provide a powerful resource for high-throughput phenotyping for genetic and clinical research."
Validation of electronic medical record-based phenotyping algorithms: results and lessons learned from the eMERGE network.,"Katherine M. Newton, Peggy L. Peissig,Abel N. Kho, Suzette J. Bielinski,Richard L. Berg, Vidhu Choudhary,Melissa Basford, Christopher G. Chute,Iftikhar J. Kullo, Rongling Li, Jennifer A.Pacheco, Luke V. Rasmussen, LeslieSpangler, Joshua C. Denny",JAMIA ,electronic health record; electronic medical record; genomics; phenotype; validation studies.,"Genetic studies require precise phenotype definitions, but electronic medical record (EMR) phenotype data are recorded inconsistently and in a variety of formats. To present lessons learned about validation of EMR-based phenotypes from the Electronic Medical Records and Genomics (eMERGE) studies. The eMERGE network created and validated 13 EMR-derived phenotype algorithms. Network sites are Group Health, Marshfield Clinic, Mayo Clinic, Northwestern University, and Vanderbilt University. By validating EMR-derived phenotypes we learned that: (1) multisite validation improves phenotype algorithm accuracy; (2) targets for validation should be carefully considered and defined; (3) specifying time frames for review of variables eases validation time and improves accuracy; (4) using repeated measures requires defining the relevant time period and specifying the most meaningful value to be studied; (5) patient movement in and out of the health plan (transience) can result in incomplete or fragmented data; (6) the review scope should be defined carefully; (7) particular care is required in combining EMR and research data; (8) medication data can be assessed using claims, medications dispensed, or medications prescribed; (9) algorithm development and validation work best as an iterative process; and (10) validation by content experts or structured chart review can provide accurate results. Despite the diverse structure of the five EMRs of the eMERGE sites, we developed, validated, and successfully deployed 13 electronic phenotype algorithms. Validation is a worthwhile process that not only measures phenotype performance but also strengthens phenotype algorithm definitions and enhances their inter-institutional sharing."
Electronic medical records for genetic research: results of the eMERGE consortium.,"Abel N. Kho, Jennifer A. Pacheco,Peggy L. Peissig, Luke V. Rasmussen,Katherine M. Newton, Noah Weston,Paul K Crane, Jyotishman Pathak,Christopher G. Chute, Suzette J.Bielinski, Iftikhar J. Kullo, Rongling Li,Teri A Manolio, Rex L. Chisholm,Joshua C. Denny",Science Translational Medicine,,"Clinical data in Electronic Medical Records (EMRs) is a potential source of longitudinal clinical data for research. The Electronic Medical Records and Genomics Network or eMERGE investigates whether data captured through routine clinical care using EMRs can identify disease phenotypes with sufficient positive and negative predictive values for use in genome wide association studies (GWAS). Using data from five different sets of EMRs, we have identified five disease phenotypes with positive predictive values of 73–98% and negative predictive values of 98–100%. A majority of EMRs captured key information (diagnoses, medications, laboratory tests) used to define phenotypes in a structured format. We identified natural language processing as an important tool to improve case identification rates. Efforts and incentives to increase the implementation of interoperable EMRs will markedly improve the availability of clinical data for genomics research."
Modeling Disease Severity in Multiple Sclerosis Using Electronic Health Records,"Zongqi Xia, Elizabeth Secor, Lori BChibnik, Riley M Bove, Suchun Cheng,Tanuja Chitnis, Andrew Cagan, Vivian S.Gainer, Pei Jun Chen, Katherine P. Liao,Stanley Y. Shaw, Ashwin N.Ananthakrishnan, Peter Szolovits,Howard L Weiner, Elizabeth W. Karlson,Shawn N. Murphy, Guergana K. Savova,Tianxi Cai, Susanne E. Churchill, RobertM. Plenge, Isaac S. Kohane, Philip L. DeJager",Plos One,,"To optimally leverage the scalability and unique features of the electronic health records (EHR) for research that would ultimately improve patient care, we need to accurately identify patients and extract clinically meaningful measures. Using multiple sclerosis (MS) as a proof of principle, we showcased how to leverage routinely collected EHR data to identify patients with a complex neurological disorder and derive an important surrogate measure of disease severity heretofore only available in research settings. In a cross-sectional observational study, 5,495 MS patients were identified from the EHR systems of two major referral hospitals using an algorithm that includes codified and narrative information extracted using natural language processing. In the subset of patients who receive neurological care at a MS Center where disease measures have been collected, we used routinely collected EHR data to extract two aggregate indicators of MS severity of clinical relevance multiple sclerosis severity score (MSSS) and brain parenchymal fraction (BPF, a measure of whole brain volume). The EHR algorithm that identifies MS patients has an area under the curve of 0.958, 83% sensitivity, 92% positive predictive value, and 89% negative predictive value when a 95% specificity threshold is used. The correlation between EHR-derived and true MSSS has a mean R(2) = 0.38±0.05, and that between EHR-derived and true BPF has a mean R(2) = 0.22±0.08. To illustrate its clinical relevance, derived MSSS captures the expected difference in disease severity between relapsing-remitting and progressive MS patients after adjusting for sex, age of symptom onset and disease duration (p = 1.56×10(-12)). Incorporation of sophisticated codified and narrative EHR data accurately identifies MS patients and provides estimation of a well-accepted indicator of MS severity that is widely used in research settings but not part of the routine medical records. Similar approaches could be applied to other complex neurological disorders."
"Associations of autoantibodies, autoimmune risk alleles, and clinical diagnoses from the electronic medical records in rheumatoid arthritis cases and non-rheumatoid arthritis controls.","Katherine P. Liao, Fina A. S. Kurreeman,Gang Li, Grant E Duclos, ShawnMurphy, Raúl Guzmán, Tianxi Cai,Namrata Gupta, Vivian S. Gainer, PeterH. Schur, Jing Cui, Joshua C. Denny,Peter Szolovits, Susanne E. Churchill,Isaac S. Kohane, Elizabeth W. Karlson,Robert M. Plenge",Arthritis & Rheumatology,,"The significance of non-rheumatoid arthritis (RA) autoantibodies in patients with RA is unclear. The aim of this study was to assess associations of autoantibodies with autoimmune risk alleles and with clinical diagnoses from the electronic medical records (EMRs) among RA cases and non-RA controls. Data on 1,290 RA cases and 1,236 non-RA controls of European genetic ancestry were obtained from the EMRs of 2 large academic centers. The levels of anti-citrullinated protein antibodies (ACPAs), antinuclear antibodies (ANAs), anti-tissue transglutaminase antibodies (AGTAs), and anti-thyroid peroxidase (anti-TPO) antibodies were measured. All subjects were genotyped for autoimmune risk alleles, and the association between number of autoimmune risk alleles present and number of types of autoantibodies present was studied. A phenome-wide association study (PheWAS) was conducted to study potential associations between autoantibodies and clinical diagnoses among RA cases and non-RA controls. The mean ages were 60.7 years in RA cases and 64.6 years in non-RA controls. The proportion of female subjects was 79% in each group. The prevalence of ACPAs and ANAs was higher in RA cases compared to controls (each P < 0.0001); there were no differences in the prevalence of anti-TPO antibodies and AGTAs. Carriage of higher numbers of autoimmune risk alleles was associated with increasing numbers of autoantibody types in RA cases (P = 2.1 × 10(-5)) and non-RA controls (P = 5.0 × 10(-3)). From the PheWAS, the presence of ANAs was significantly associated with a diagnosis of Sjögren's/sicca syndrome in RA cases. The increased frequency of autoantibodies in RA cases and non-RA controls was associated with the number of autoimmune risk alleles carried by an individual. PheWAS of EMR data, with linkage to laboratory data obtained from blood samples, provide a novel method to test for the clinical significance of biomarkers in disease."
Use of diverse electronic medical to identify genetic risk for type 2 diabetes within a genome-wide association study,"Abel N. Kho, M. Geoffrey Hayes, LauraJ Rasmussen-Torvik, Jennifer A.Pacheco, William K. Thompson, LorenL. Armstrong, Joshua C. Denny, PeggyL. Peissig, Aaron W. Miller, Wei-Qi Wei,Suzette J. Bielinski, Christopher G.Chute, Cynthia L. Leibson, Gail P.Jarvik, David R. Crosslin, Christopher S.Carlson, Katherine M. Newton, WendyA. Wolf, Rex L. Chisholm, William L.Lowe",JAMIA,,"Genome-wide association studies (GWAS) require high specificity and large numbers of subjects to identify genotype-phenotype correlations accurately. The aim of this study was to identify type 2 diabetes (T2D) cases and controls for a GWAS, using data captured through routine clinical care across five institutions using different electronic medical record (EMR) systems. An algorithm was developed to identify T2D cases and controls based on a combination of diagnoses, medications, and laboratory results. The performance of the algorithm was validated at three of the five participating institutions compared against clinician review. A GWAS was subsequently performed using cases and controls identified by the algorithm, with samples pooled across all five institutions. The algorithm achieved 98% and 100% positive predictive values for the identification of diabetic cases and controls, respectively, as compared against clinician review. By standardizing and applying the algorithm across institutions, 3353 cases and 3352 controls were identified. Subsequent GWAS using data from five institutions replicated the TCF7L2 gene variant (rs7903146) previously associated with T2D. By applying stringent criteria to EMR data collected through routine clinical care, cases and controls for a GWAS were identified that subsequently replicated a known genetic variant. The use of standard terminologies to define data elements enabled pooling of subjects and data across five different institutions to achieve the robust numbers required for GWAS. An algorithm using commonly available data from five different EMR can accurately identify T2D cases and controls for genetic study across multiple institutions."
Using electronic health records to drive discovery in disease genomics,Isaac S. Kohane,Nature Reviews Genetics ,,"If genomic studies are to be a clinically relevant and timely reflection of the relationship between genetics and health status — whether for common or rare variants — cost-effective ways must be found to measure both the genetic variation and the phenotypic characteristics of large populations, including the comprehensive and up-to-date record of their medical treatment. The adoption of electronic health records, used by clinicians to document clinical care, is becoming widespread and recent studies demonstrate that they can be effectively employed for genetic studies using the informational and biological 'by-products' of health-care delivery while maintaining patient privacy."
Naïve Electronic Health Record phenotype identification for Rheumatoid arthritis.,"Robert J. Carroll, Anne E. Eyler, JoshuaC. Denny",AMIA Annual Symposium Proceedings ,,"Electronic Health Records (EHRs) provide a real-world patient cohort for clinical and genomic research. Phenotype identification using informatics algorithms has been shown to replicate known genetic associations found in clinical trials and observational cohorts. However, development of accurate phenotype identification methods can be challenging, requiring significant time and effort. We applied Support Vector Machines (SVMs) to both naïve (i.e., non-curated) and expert-defined collections of EHR features to identify Rheumatoid Arthritis cases using billing codes, medication exposures, and natural language processing-derived concepts. SVMs trained on naïve and expert-defined data outperformed an existing deterministic algorithm; the best performing naïve system had precision of 0.94 and recall of 0.87, compared to precision of 0.75 and recall of 0.51 for the deterministic algorithm. We show that with an expert defined feature set as few as 50-100 training samples are required. This study demonstrates that SVMs operating on non-curated sets of attributes can accurately identify cases from an EHR."
Development of phenotype algorithms using electronic medical records and incorporating natural language processing,"Katherine P. Liao, Tianxi Cai, GuerganaK. Savova, Shawn N. Murphy, ElizabethW. Karlson, Ashwin N.Ananthakrishnan, Vivian S. Gainer,Stanley Y. Shaw, Zongqi Xia, PeterSzolovits, Susanne E. Churchill, Isaac S.Kohane",BMJ,,"Electronic medical records are emerging as a major source of data for clinical and translational research studies, although phenotypes of interest need to be accurately defined first. This article provides an overview of how to develop a phenotype algorithm from electronic medical records, incorporating modern informatics and biostatistics methods"
Predicting Risk of Suicide Attempts Over Time Through Machine Learning,"Colin G. Walsh, Jessica D. Ribeiro,Joseph C. Franklin",Clinical Psychological Science ,"suicide prevention, prediction, prevention, classification","Traditional approaches to the prediction of suicide attempts have limited the accuracy and scale of risk detection for these dangerous behaviors. We sought to overcome these limitations by applying machine learning to electronic health records within a large medical database. Participants were 5,167 adult patients with a claim code for self-injury (i.e., ICD-9, E95x); expert review of records determined that 3,250 patients made a suicide attempt (i.e., cases), and 1,917 patients engaged in self-injury that was nonsuicidal, accidental, or nonverifiable (i.e., controls). We developed machine learning algorithms that accurately predicted future suicide attempts (AUC = 0.84, precision = 0.79, recall = 0.95, Brier score = 0.14). Moreover, accuracy improved from 720 days to 7 days before the suicide attempt, and predictor importance shifted across time. These findings represent a step toward accurate and scalable risk detection and provide insight into how suicide attempt risk shifts over time."
PheWAS: demonstrating the feasibility of a phenome-wide scan to discover gene–disease associations,"Joshua C. Denny, Marylyn DeRiggiRitchie, Melissa A. Basford, Jill M.Pulley, Lisa Bastarache, Kristin Brown-Gentry, Deede Wang, Daniel R. Masys,Dan M. Roden, Dana C. Crawford",Bioinformatics ,,"Emergence of genetic data coupled to longitudinal electronic medical records (EMRs) offers the possibility of phenome-wide association scans (PheWAS) for disease–gene associations. We propose a novel method to scan phenomic data for genetic associations using International Classification of Disease (ICD9) billing codes, which are available in most EMR systems. We have developed a code translation table to automatically define 776 different disease populations and their controls using prevalent ICD9 codes derived from EMR data. As a proof of concept of this algorithm, we genotyped the first 6005 European–Americans accrued into BioVU, Vanderbilt's DNA biobank, at five single nucleotide polymorphisms (SNPs) with previously reported disease associations: atrial fibrillation, Crohn's disease, carotid artery stenosis, coronary artery disease, multiple sclerosis, systemic lupus erythematosus and rheumatoid arthritis. The PheWAS software generated cases and control populations across all ICD9 code groups for each of these five SNPs, and disease-SNP associations were analyzed. The primary outcome of this study was replication of seven previously known SNP–disease associations for these SNPs. Four of seven known SNP–disease associations using the PheWAS algorithm were replicated with P-values between 2.8 × 10−6 and 0.011. The PheWAS algorithm also identified 19 previously unknown statistical associations between these SNPs and diseases at P < 0.01. This study indicates that PheWAS analysis is a feasible method to investigate SNP–disease associations. Further evaluation is needed to determine the validity of these associations and the appropriate statistical thresholds for clinical significance."
Importance of multi-modal approaches to effectively identify cataract cases from electronic health records,"Peggy L. Peissig, Luke V. Rasmussen,Richard L. Berg, James G. Linneman,Catherine A. McCarty, Carol Waudby,Lin Chen, Joshua C. Denny, Russell A.Wilke, Jyotishman Pathak, DavidCarrell, Abel N. Kho, Justin Starren",JAMIA,,"There is increasing interest in using electronic health records (EHRs) to identify subjects for genomic association studies, due in part to the availability of large amounts of clinical data and the expected cost efficiencies of subject identification. We describe the construction and validation of an EHR-based algorithm to identify subjects with age-related cataracts. We used a multi-modal strategy consisting of structured database querying, natural language processing on free-text documents, and optical character recognition on scanned clinical images to identify cataract subjects and related cataract attributes. Extensive validation on 3657 subjects compared the multi-modal results to manual chart review. The algorithm was also implemented at participating electronic MEdical Records and GEnomics (eMERGE) institutions. An EHR-based cataract phenotyping algorithm was successfully developed and validated, resulting in positive predictive values (PPVs) >95%. The multi-modal approach increased the identification of cataract subject attributes by a factor of three compared to single-mode approaches while maintaining high PPV. Components of the cataract algorithm were successfully deployed at three other institutions with similar accuracy. A multi-modal strategy incorporating optical character recognition and natural language processing may increase the number of cases identified while maintaining similar PPVs. Such algorithms, however, require that the needed information be embedded within clinical documents.We have demonstrated that algorithms to identify and characterize cataracts can be developed utilizing data collected via the EHR. These algorithms provide a high level of accuracy even when implemented across multiple EHRs and institutional boundaries."
Ten-year prediction of suicide death using Cox regression and machine learning in a nationwide retrospective cohort study in South Korea.,"Soo Beom Choi, Wanhyung Lee, Jin-haYoon, Jong Uk Won, Deok Won Kim",Journal of Effective Disorders,Cox regression; Deep learning; Suicide prediction; Support vector machine.,"Death by suicide is a preventable public health concern worldwide. The aim of this study is to investigate the probability of suicide death using baseline characteristics and simple medical facility visit history data using Cox regression, support vector machines (SVMs), and deep neural networks (DNNs). This study included 819,951 subjects in the National Health Insurance Service (NHIS)-Cohort Sample Database from 2004 to 2013. The dataset was divided randomly into two independent training and validation groups. To improve the performance of predicting suicide death, we applied SVM and DNN to the same training set as the Cox regression model. Among the study population, 2546 people died by intentional self-harm during the follow-up time. Sex, age, type of insurance, household income, disability, and medical records of eight ICD-10 codes (including mental and behavioural disorders) were selected by a Cox regression model with backward stepwise elimination. The area of under the curve (AUC) of Cox regression (0.688), SVM (0.687), and DNN (0.683) were approximately the same. The group with top .5% of predicted probability had hazard ratio of 26.21 compared to that with the lowest 10% of predicted probability. This study is limited by the lack of information on suicidal ideation and attempts, other potential covariates such as information of medication and subcategory ICD-10 codes. Moreover, predictors from the prior 12-24 months of the date of death could be expected to show better performances than predictors from up to 10 years ago. We suggest a 10-year probability prediction model for suicide death using general characteristics and simple insurance data, which are annually conducted by the Korean government. Suicide death prevention might be enhanced by our prediction model."
Robust replication of genotype-phenotype associations across multiple diseases in an electronic medical record.,"Marylyn DeRiggi Ritchie, Joshua C.Denny, Dana C. Crawford, Andrea H.Ramirez, Justin B Weiner, Jill M. Pulley,Melissa A. Basford, Kristin Brown-Gentry, Jeffrey R. Balser, Daniel R.Masys, Jonathan L. Haines, Dan M.Roden",The American Journal of Human Genetics,,"Large-scale DNA databanks linked to electronic medical record (EMR) systems have been proposed as an approach for rapidly generating large, diverse cohorts for discovery and replication of genotype-phenotype associations. However, the extent to which such resources are capable of delivering on this promise is unknown. We studied whether an EMR-linked DNA biorepository can be used to detect known genotype-phenotype associations for five diseases. Twenty-one SNPs previously implicated as common variants predisposing to atrial fibrillation, Crohn disease, multiple sclerosis, rheumatoid arthritis, or type 2 diabetes were successfully genotyped in 9483 samples accrued over 4 mo into BioVU, the Vanderbilt University Medical Center DNA biobank. Previously reported odds ratios (OR(PR)) ranged from 1.14 to 2.36. For each phenotype, natural language processing techniques and billing-code queries were used to identify cases (n = 70-698) and controls (n = 808-3818) from deidentified health records. Each of the 21 tests of association yielded point estimates in the expected direction. Previous genotype-phenotype associations were replicated (p < 0.05) in 8/14 cases when the OR(PR) was > 1.25, and in 0/7 with lower OR(PR). Statistically significant associations were detected in all analyses that were adequately powered. In each of the five diseases studied, at least one previously reported association was replicated. These data demonstrate that phenotypes representing clinical diagnoses can be extracted from EMR systems, and they support the use of DNA resources coupled to EMR systems as tools for rapid generation of large data sets required for replication of associations found in research cohorts and for discovery in genome science."
Monitoring suicidal patients in primary care using electronic health records.,"Heather D. Anderson, Wilson D. Pace,Elias Brandt, Rodney D. Nielsen,Richard Read Allen, Anne M. Libby,David R. West, Robert J. Valuck",Journal of the American Board of Family Medicine,Attempted; Electronic Health Records; Natural Language Processing; Suicidal Ideation; Suicide.,"Patients at risk for suicide often come into contact with primary care providers, many of whom use electronic health records (EHRs) for charting. It is not known, however, how often suicide ideation or attempts are documented in EHRs. We used retrospective analyses of de-identified EHR data from a distributed health network of primary care organizations to estimate the frequency of using diagnostic codes to record suicidal ideation and attempts. Data came from 3 sources: a clinician notes field processed using natural language processing; a suicidal ideation item on a patient-reported depression severity instrument (9-item Patient Health Questionnaire [PHQ-9]); and diagnostic codes from the EHR. Only 3% of patients with an indication of suicidal ideation in the notes field had a corresponding International Classification of Diseases, 9th Revision (ICD-9), code (κ = 0.036). Agreement between an indication of suicidal ideation from item 9 of the PHQ-9 and an ICD-9 code was slightly higher (κ = 0.068). Suicide attempt indicated in the notes field was more likely to be recorded using an ICD-9 code (19%; κ = 0.18). Few cases of suicidal ideation and attempt were documented in patients' EHRs using diagnostic codes. Increased documentation of suicidal ideation and behaviors in patients' EHRs may improve their monitoring in the health care system."
A review of approaches to identifying patient phenotype cohorts using electronic health records,"Chaitanya P. Shivade, PreethiRaghavan, Eric Fosler-Lussier, Peter J.Embi, Noémie Elhadad, Stephen B.Johnson, Albert M. Lai",JAMIA,"Review, Electronic Health Records, Cohort Identification, Phenotyping","Objective was to summarize literature describing approaches aimed at automatically identifying patients with a common phenotype. We performed a review of studies describing systems or reporting techniques developed for identifying cohorts of patients with specific phenotypes. Every full text article published in (1) Journal of American Medical Informatics Association, (2) Journal of Biomedical Informatics, (3) Proceedings of the Annual American Medical Informatics Association Symposium, and (4) Proceedings of Clinical Research Informatics Conference within the past 3 years was assessed for inclusion in the review. Only articles using automated techniques were included. Ninety-seven articles met our inclusion criteria. Forty-six used natural language processing (NLP)-based techniques, 24 described rule-based systems, 41 used statistical analyses, data mining, or machine learning techniques, while 22 described hybrid systems. Nine articles described the architecture of large-scale systems developed for determining cohort eligibility of patients. We observe that there is a rise in the number of studies associated with cohort identification using electronic medical records. Statistical analyses or machine learning, followed by NLP techniques, are gaining popularity over the years in comparison with rule-based systems. There are a variety of approaches for classifying patients into a particular phenotype. Different techniques and data sources are used, and good performance is reported on datasets at respective institutions. However, no system makes comprehensive use of electronic medical records addressing all of their known weaknesses."
Variants near FOXE1 are associated with hypothyroidism and other thyroid conditions: using electronic medical records for genome- and phenome-wide studies.,"Joshua C. Denny, Dana C. Crawford,Marylyn DeRiggi Ritchie, Suzette J.Bielinski, Melissa A. Basford, YukiBradford, High Seng Chai, LisaBastarache, Rebecca L. Zuvich, PeggyL. Peissig, David S. Carrell, Andrea H.Ramirez, Jyotishman Pathak, Russell A.Wilke, Luke V. Rasmussen, XiaomingWang, Jennifer A. Pacheco, Abel N.Kho, M. Geoffrey Hayes, Noah Weston,Martha Matsumoto, Peter AndreasKopp, Katherine M. Newton, Gail P.Jarvik, Rongling Li, Teri A Manolio,Iftikhar J. Kullo, Christopher G. Chute,Rex L. Chisholm, Eric B. Larson,Catherine A. McCarty, Daniel R. Masys,Dan M. Roden, Mariza de Andrade",The American Journal of Human Genetics,,"We repurposed existing genotypes in DNA biobanks across the Electronic Medical Records and Genomics network to perform a genome-wide association study for primary hypothyroidism, the most common thyroid disease. Electronic selection algorithms incorporating billing codes, laboratory values, text queries, and medication records identified 1317 cases and 5053 controls of European ancestry within five electronic medical records (EMRs); the algorithms' positive predictive values were 92.4% and 98.5% for cases and controls, respectively. Four single-nucleotide polymorphisms (SNPs) in linkage disequilibrium at 9q22 near FOXE1 were associated with hypothyroidism at genome-wide significance, the strongest being rs7850258 (odds ratio [OR] 0.74, p = 3.96 × 10(-9)). This association was replicated in a set of 263 cases and 1616 controls (OR = 0.60, p = 5.7 × 10(-6)). A phenome-wide association study (PheWAS) that was performed on this locus with 13,617 individuals and more than 200,000 patient-years of billing data identified associations with additional phenotypes: thyroiditis (OR = 0.58, p = 1.4 × 10(-5)), nodular (OR = 0.76, p = 3.1 × 10(-5)) and multinodular (OR = 0.69, p = 3.9 × 10(-5)) goiters, and thyrotoxicosis (OR = 0.76, p = 1.5 × 10(-3)), but not Graves disease (OR = 1.03, p = 0.82). Thyroid cancer, previously associated with this locus, was not significantly associated in the PheWAS (OR = 1.29, p = 0.09). The strongest association in the PheWAS was hypothyroidism (OR = 0.76, p = 2.7 × 10(-13)), which had an odds ratio that was nearly identical to that of the curated case-control population in the primary analysis, providing further validation of the PheWAS method. Our findings indicate that EMR-linked genomic data could allow discovery of genes associated with many diseases without additional genotyping cost."
A translational engine at the national scale: informatics for integrating biology and the bedside,"Isaac S. Kohane, Susanne E. Churchill,Shawn N. Murphy",JAMIA,,Informatics for integrating biology and the bedside (i2b2) seeks to provide the instrumentation for using the informational by-products of health care and the biological materials accumulated through the delivery of health care to conduct discovery research and to study the healthcare system in vivo. This complements existing efforts such as prospective cohort studies or trials outside the delivery of routine health care. i2b2 has been used to generate genome-wide studies at less than one tenth the cost and one tenth the time of conventionally performed studies as well as to identify important risk from commonly used medications. i2b2 has been adopted by over 60 academic health centers internationally.
The eMERGE Network: A consortium of biorepositories linked to electronic medical records data for conducting genomic studies,"Catherine A. McCarty, Rex L. Chisholm,Christopher G. Chute, Iftikhar J. Kullo,Gail P. Jarvik, Eric B. Larson, RonglingLi, Daniel R. Masys, Marylyn DeRiggiRitchie, Dan M. Roden, Jeffery P.Struewing, Wendy A. Wolf",BMC Medical Genomics,,"The eMERGE (electronic MEdical Records and GEnomics) Network is an NHGRI-supported consortium of five institutions to explore the utility of DNA repositories coupled to Electronic Medical Record (EMR) systems for advancing discovery in genome science. eMERGE also includes a special emphasis on the ethical, legal and social issues related to these endeavors. The five sites are supported by an Administrative Coordinating Center. Setting of network goals is initiated by working groups: (1) Genomics, (2) Informatics, and (3) Consent & Community Consultation, which also includes active participation by investigators outside the eMERGE funded sites, and (4) Return of Results Oversight Committee. The Steering Committee, comprised of site PIs and representatives and NHGRI staff, meet three times per year, once per year with the External Scientific Panel. The primary site-specific phenotypes for which samples have undergone genome-wide association study (GWAS) genotyping are cataract and HDL, dementia, electrocardiographic QRS duration, peripheral arterial disease, and type 2 diabetes. A GWAS is also being undertaken for resistant hypertension in ≈ 2,000 additional samples identified across the network sites, to be added to data available for samples already genotyped. Funded by ARRA supplements, secondary phenotypes have been added at all sites to leverage the genotyping data, and hypothyroidism is being analyzed as a cross-network phenotype. Results are being posted in dbGaP. Other key eMERGE activities include evaluation of the issues associated with cross-site deployment of common algorithms to identify cases and controls in EMRs, data privacy of genomic and clinically-derived data, developing approaches for large-scale meta-analysis of GWAS data across five sites, and a community consultation and consent initiative at each site. Plans are underway to expand the network in diversity of populations and incorporation of GWAS findings into clinical care. By combining advanced clinical informatics, genome science, and community consultation, eMERGE represents a first step in the development of data-driven approaches to incorporate genomic information into routine healthcare delivery."
"Extracting principal diagnosis, co-morbidity and smoking status for asthma research: evaluation of a natural language processing system","Qing Zeng-Treitler, Sergey Goryachev,Scott T. Weiss, Margarita Sordo, ShawnN. Murphy, Ross Lazarus",BMC Medical Informatics and Decision Making,,"The text descriptions in electronic medical records are a rich source of information. We have developed a Health Information Text Extraction (HITEx) tool and used it to extract key findings for a research study on airways disease. The principal diagnosis, co-morbidity and smoking status extracted by HITEx from a set of 150 discharge summaries were compared to an expert-generated gold standard. The accuracy of HITEx was 82% for principal diagnosis, 87% for co-morbidity, and 90% for smoking status extraction, when cases labeled ""Insufficient Data"" by the gold standard were excluded. We consider the results promising, given the complexity of the discharge summaries and the extraction tasks."
Identification of rheumatoid arthritis patients using an administrative database: a Veterans Affairs study.,"Bernard S. Ng, Fawad Aslam, Nancy J.Petersen, Hong-Jen Yu, Maria E Suarez-Almazor",Arthritis Care & Research,,The accuracy of the diagnosis is vital when administrative databases are used for pharmacoepidemiologic and outcome studies. Data pertaining to the utility of databases for rheumatoid arthritis (RA) are sparse and variable. We assessed the utility of various diagnostic algorithms to identify RA patients within the Veterans Health Administration (VHA) databases.
Validation of rheumatoid arthritis diagnoses in health care utilization data,"Seo Young Kim, Amber D Servi,Jennifer M. Polinski, Helen Mogun,Michael E. Weinblatt, Jeffrey N. Katz,Daniel H. Solomon",Arthritis Research & Therapy ,,"Health care utilization databases have been increasingly used for studies of rheumatoid arthritis (RA). However, the accuracy of RA diagnoses in these data has been inconsistent. Using medical records and a standardized abstraction form, we examined the positive predictive value (PPV) of several algorithms to define RA diagnosis using claims data: A) at least two visits coded for RA (ICD-9, 714); B) at least three visits coded for RA; and C) at least two visits to a rheumatologist for RA. We also calculated the PPVs for the subgroups identified by these algorithms combined with pharmacy claims data for at least one disease-modifying anti-rheumatic drug (DMARD) prescription. We invited 9,482 Medicare beneficiaries with pharmacy benefits in Pennsylvania to participate; 2% responded and consented for review of their medical records. There was no difference in characteristics between respondents and non-respondents. Using 'RA diagnosis per rheumatologists' as the gold standard, the PPVs were 55.7% for at least two claims coded for RA, 65.5% for at least three claims for RA, and 66.7% for at least two rheumatology claims for RA. The PPVs of these algorithms in patients with at least one DMARD prescription increased to 86.2%-88.9%. When fulfillment of 4 or more of the ACR RA criteria was used as the gold standard, the PPVs of the algorithms combined with at least one DMARD prescriptions were 55.6%-60.7%. To accurately identify RA patients in health care utilization databases, algorithms that include both diagnosis codes and DMARD prescriptions are recommended."
Predicting suicides after psychiatric hospitalization in US Army soldiers: the Army Study To Assess Risk and rEsilience in Service members (Army STARRS).,"Ronald C. Kessler, Christopher H.Warner, Christopher G Ivany, MariaVladimirovna Petukhova, Sherri Rose,Evelyn J. Bromet, Millard Brown, TianxiCai, Lisa J. Colpe, Kenneth L. Cox, CarolS. Fullerton, Stephen E. Gilman, MichaelJ Gruber, Steven G. Heeringa, LisaLewandowski‐Romps, Junlong Li, AmyMillikan-Bell, James A Naifeh, MatthewK. Nock, Anthony J Rosellini, Nancy A.Sampson, Michael L Schoenbaum,Murray B. Stein, Simon Wessely, Alan MZaslavsky, Robert J. Ursano",JAMA Psychiatry,,"The US Army experienced a sharp increase in soldier suicides beginning in 2004. Administrative data reveal that among those at highest risk are soldiers in the 12 months after inpatient treatment of a psychiatric disorder. To develop an actuarial risk algorithm predicting suicide in the 12 months after US Army soldier inpatient treatment of a psychiatric disorder to target expanded posthospitalization care. There were 53,769 hospitalizations of active duty soldiers from January 1, 2004, through December 31, 2009, with International Classification of Diseases, Ninth Revision, Clinical Modification psychiatric admission diagnoses. Administrative data available before hospital discharge abstracted from a wide range of data systems (sociodemographic, US Army career, criminal justice, and medical or pharmacy) were used to predict suicides in the subsequent 12 months using machine learning methods (regression trees and penalized regressions) designed to evaluate cross-validated linear, nonlinear, and interactive predictive associations. Suicides of soldiers hospitalized with psychiatric disorders in the 12 months after hospital discharge. Sixty-eight soldiers died by suicide within 12 months of hospital discharge (12.0% of all US Army suicides), equivalent to 263.9 suicides per 100,000 person-years compared with 18.5 suicides per 100,000 person-years in the total US Army. The strongest predictors included sociodemographics (male sex [odds ratio (OR), 7.9; 95% CI, 1.9-32.6] and late age of enlistment [OR, 1.9; 95% CI, 1.0-3.5]), criminal offenses (verbal violence [OR, 2.2; 95% CI, 1.2-4.0] and weapons possession [OR, 5.6; 95% CI, 1.7-18.3]), prior suicidality [OR, 2.9; 95% CI, 1.7-4.9], aspects of prior psychiatric inpatient and outpatient treatment (eg, number of antidepressant prescriptions filled in the past 12 months [OR, 1.3; 95% CI, 1.1-1.7]), and disorders diagnosed during the focal hospitalizations (eg, nonaffective psychosis [OR, 2.9; 95% CI, 1.2-7.0]). A total of 52.9% of posthospitalization suicides occurred after the 5% of hospitalizations with highest predicted suicide risk (3824.1 suicides per 100,000 person-years). These highest-risk hospitalizations also accounted for significantly elevated proportions of several other adverse posthospitalization outcomes (unintentional injury deaths, suicide attempts, and subsequent hospitalizations). The high concentration of risk of suicide and other adverse outcomes might justify targeting expanded posthospitalization interventions to soldiers classified as having highest posthospitalization suicide risk, although final determination requires careful consideration of intervention costs, comparative effectiveness, and possible adverse effects."
Improving the power of genetic association tests with imperfect phenotype derived from electronic medical records,"Jennifer A. Sinnott, Wei Dai, KatherineP. Liao, Stanley Y. Shaw, Ashwin N.Ananthakrishnan, Vivian S. Gainer,Elizabeth W. Karlson, Susanne E.Churchill, Peter Szolovits, Shawn N.Murphy, Isaac S. Kohane, Robert M.Plenge, Tianxi Cai",Human Genetics,,"To reduce costs and improve clinical relevance of genetic studies, there has been increasing interest in performing such studies in hospital-based cohorts by linking phenotypes extracted from electronic medical records (EMRs) to genotypes assessed in routinely collected medical samples. A fundamental difficulty in implementing such studies is extracting accurate information about disease outcomes and important clinical covariates from large numbers of EMRs. Recently, numerous algorithms have been developed to infer phenotypes by combining information from multiple structured and unstructured variables extracted from EMRs. Although these algorithms are quite accurate, they typically do not provide perfect classification due to the difficulty in inferring meaning from the text. Some algorithms can produce for each patient a probability that the patient is a disease case. This probability can be thresholded to define case-control status, and this estimated case-control status has been used to replicate known genetic associations in EMR-based studies. However, using the estimated disease status in place of true disease status results in outcome misclassification, which can diminish test power and bias odds ratio estimates. We propose to instead directly model the algorithm-derived probability of being a case. We demonstrate how our approach improves test power and effect estimation in simulation studies, and we describe its performance in a study of rheumatoid arthritis. Our work provides an easily implemented solution to a major practical challenge that arises in the use of EMR data, which can facilitate the use of EMR infrastructure for more powerful, cost-effective, and diverse genetic studies."
Toward high-throughput phenotyping: unbiased automated feature extraction and selection from knowledge sources,"Sheng Yu, Katherine P. Liao, Stanley Y.Shaw, Vivian S. Gainer, Susanne E.Churchill, Peter Szolovits, Shawn N.Murphy, Isaac S. Kohane, Tianxi Cai",JAMIA,,"Analysis of narrative (text) data from electronic health records (EHRs) can improve population-scale phenotyping for clinical and genetic research. Currently, selection of text features for phenotyping algorithms is slow and laborious, requiring extensive and iterative involvement by domain experts. This paper introduces a method to develop phenotyping algorithms in an unbiased manner by automatically extracting and selecting informative features, which can be comparable to expert-curated ones in classification accuracy. Comprehensive medical concepts were collected from publicly available knowledge sources in an automated, unbiased fashion. Natural language processing (NLP) revealed the occurrence patterns of these concepts in EHR narrative notes, which enabled selection of informative features for phenotype classification. When combined with additional codified features, a penalized logistic regression model was trained to classify the target phenotype. The authors applied our method to develop algorithms to identify patients with rheumatoid arthritis and coronary artery disease cases among those with rheumatoid arthritis from a large multi-institutional EHR. The area under the receiver operating characteristic curves (AUC) for classifying RA and CAD using models trained with automated features were 0.951 and 0.929, respectively, compared to the AUCs of 0.938 and 0.929 by models trained with expert-curated features. Models trained with NLP text features selected through an unbiased, automated procedure achieved comparable or slightly higher accuracy than those trained with expert-curated features. The majority of the selected model features were interpretable. The proposed automated feature extraction method, generating highly accurate phenotyping algorithms with improved efficiency, is a significant step toward high-throughput phenotyping."
Systematic comparison of phenome-wide association study of electronic medical record data and genome-wide association study data,"Joshua C. Denny, Lisa Bastarache,Marylyn DeRiggi Ritchie, Robert J.Carroll, Raquel M. Zink, Jonathan D.Mosley, Julie R. Field, Jill M. Pulley,Andrea H. Ramirez, Erica A. Bowton,Melissa A. Basford, David S. Carrell,Peggy L. Peissig, Abel N. Kho, JenniferA. Pacheco, Luke V. Rasmussen, DavidR. Crosslin, Paul K Crane, JyotishmanPathak, Suzette J. Bielinski, Sarah A.Pendergrass, Hua Tong Xu, Lucia A.Hindorff, Rongling Li, Teri A Manolio,Christopher G. Chute, Rex L. Chisholm,Eric B. Larson, Gail P. Jarvik, Murray H.Brilliant, Catherine A. McCarty, IftikharJ. Kullo, Jonathan L. Haines, Dana C.Crawford, Daniel R. Masys, Dan M.Roden",Nature Biotechnology,,"Candidate gene and genome-wide association studies (GWAS) have identified genetic variants that modulate risk for human disease; many of these associations require further study to replicate the results. Here we report the first large-scale application of the phenome-wide association study (PheWAS) paradigm within electronic medical records (EMRs), an unbiased approach to replication and discovery that interrogates relationships between targeted genotypes and multiple phenotypes. We scanned for associations between 3,144 single-nucleotide polymorphisms (previously implicated by GWAS as mediators of human traits) and 1,358 EMR-derived phenotypes in 13,835 individuals of European ancestry. This PheWAS replicated 66% (51/77) of sufficiently powered prior GWAS associations and revealed 63 potentially pleiotropic associations with P < 4.6 × 10−6 (false discovery rate < 0.1); the strongest of these novel associations were replicated in an independent cohort (n = 7,406). These findings validate PheWAS as a tool to allow unbiased interrogation across multiple phenotypes in EMR-based cohorts and to enhance analysis of the genomic basis of human disease."
Leveraging informatics for genetic studies: use of the electronic medical record to enable a genome-wide association study of peripheral arterial disease,"Iftikhar J. Kullo, Jin Fan, JyotishmanPathak, Guergana K. Savova, ZeenatAli, Christopher G. Chute",JAMIA,,"There is significant interest in leveraging the electronic medical record (EMR) to conduct genome-wide association studies (GWAS). A biorepository of DNA and plasma was created by recruiting patients referred for non-invasive lower extremity arterial evaluation or stress ECG. Peripheral arterial disease (PAD) was defined as a resting/post-exercise ankle-brachial index (ABI) less than or equal to 0.9, a history of lower extremity revascularization, or having poorly compressible leg arteries. Controls were patients without evidence of PAD. Demographic data and laboratory values were extracted from the EMR. Medication use and smoking status were established by natural language processing of clinical notes. Other risk factors and comorbidities were ascertained based on ICD-9-CM codes, medication use and laboratory data. Of 1802 patients with an abnormal ABI, 115 had non-atherosclerotic vascular disease such as vasculitis, Buerger's disease, trauma and embolism (phenocopies) based on ICD-9-CM diagnosis codes and were excluded. The PAD cases (66+/-11 years, 64% men) were older than controls (61+/-8 years, 60% men) but had similar geographical distribution and ethnic composition. Among PAD cases, 1444 (85.6%) had an abnormal ABI, 233 (13.8%) had poorly compressible arteries and 10 (0.6%) had a history of lower extremity revascularization. In a random sample of 95 cases and 100 controls, risk factors and comorbidities ascertained from EMR-based algorithms had good concordance compared with manual record review; the precision ranged from 67% to 100% and recall from 84% to 100%. This study demonstrates use of the EMR to ascertain phenocopies, phenotype heterogeneity and relevant covariates to enable a GWAS of PAD. Biorepositories linked to EMR may provide a relatively efficient means of conducting GWAS."
Instrumenting the health care enterprise for discovery research in the genomic era.,"Shawn N. Murphy, Susanne E. Churchill,L. Bry, Henry C. Chueh, Scott Weiss,Ross Lazarus, Qing Tian Zeng, Anil KDubey, Vivian S. Gainer, MichaelMendis, John Glaser, Isaac S. Kohane",Genome Research,,"Tens of thousands of subjects may be required to obtain reliable evidence relating disease characteristics to the weak effects typically reported from common genetic variants. The costs of assembling, phenotyping, and studying these large populations are substantial, recently estimated at three billion dollars for 500,000 individuals. They are also decade-long efforts. We hypothesized that automation and analytic tools can repurpose the informational byproducts of routine clinical care, bringing sample acquisition and phenotyping to the same high-throughput pace and commodity price-point as is currently true of genome-wide genotyping. Described here is a demonstration of the capability to acquire samples and data from densely phenotyped and genotyped individuals in the tens of thousands for common diseases (e.g., in a 1-yr period: N = 15,798 for rheumatoid arthritis; N = 42,238 for asthma; N = 34,535 for major depressive disorder) in one academic health center at an order of magnitude lower cost. Even for rare diseases caused by rare, highly penetrant mutations such as Huntington disease (N = 102) and autism (N = 756), these capabilities are also of interest."
"Mental illness stigma: concepts, consequences, and initiatives to reduce stigma.","Nicolas Rüsch, Matthias C.Angermeyer, Patrick W Corrigan",European Psychiatry,,"Persons with mental illness frequently encounter public stigma and may suffer from self-stigma. This review aims to clarify the concept of mental illness stigma and discuss consequences for individuals with mental illness. After a conceptual overview of stigma we discuss two leading concepts of mental illness stigma and consequences of stigma, focussing on self-stigma/empowerment and fear of stigma as a barrier to using health services. Finally, we discuss three main strategies to reduce stigma -- protest, education, and contact -- and give examples of current anti-stigma campaigns. Well-designed anti-stigma initiatives will help to diminish negative consequences of mental illness stigma."
How stigma interferes with mental healthcare.,Patrick M. Corrigan,American Psychologist,,"Many people who would benefit from mental health services opt not to pursue them or fail to fully participate once they have begun. One of the reasons for this disconnect is stigma; namely, to avoid the label of mental illness and the harm it brings, people decide not to seek or fully participate in care. Stigma yields 2 kinds of harm that may impede treatment participation: It diminishes self-esteem and robs people of social opportunities. Given the existing literature in this area, recommendations are reviewed for ongoing research that will more comprehensively expand understanding of the stigma-care seeking link. Implications for the development of antistigma programs that might promote care seeking and participation are also reviewed."
The Paradox of Self‐Stigma and Mental Illness,"Patrick W Corrigan, A. Clinton Watson",Clinical Psychology: Science and Practice,"stigmatization, mental illness, self esteem, self-efficacy","Published narratives by persons with serious mental illness eloquently describe the harmful effects of stigma on self-esteem and self-efficacy. However, a more careful review of the research literature suggests a paradox; namely, personal reactions to the stigma of mental illness may result in significant loss in self-esteem for some, while others are energized by prejudice and express righteous anger. Added to this complexity is a third group: persons who neither lose self-esteem nor become righteously angry at stigma, instead seemingly ignoring the effects of public prejudice altogether. This article draws on research from social psychologists on self-stigma in other minority groups to explain this apparent paradox. We describe a situational model of the personal response to mental illness stigma based on the collective representations that are primed in that situation, the person’s perception of the legitimacy of stigma in the situation, and the person’s identification with the larger group of individuals with mental illness. Implications for a research program on the personal response to mental illness stigma are discussed."
Mental health stigma as social attribution: Implications for research methods and attitude change.,Patrick W Corrigan,Clinical Psychology: Science and Practice,"mental illness stigma, attributions, controllability, stability","The course and outcomes of mental illness are hampered by stigma and discrimination. Research on controllability attributions has mapped the relationships between signaling events, mediating stigma, emotional reactions, and discriminating behavior. In this article, I describe how an attribution model advances research questions related to mental health stigma in three areas. (1) Stigma research needs to examine signaling events related to psychiatric stigma including the label of mental illness, behaviors associated with psychiatric symptoms, and physical appearance. (2) Research into mediating knowledge structures needs to bridge information about controllability attributions with public attitudes about dangerousness and self‐care. (3) Ways in which these knowledge structures lead to emotional reactions (pity, anger, and fear) as well as behavioral responses (helping and punishing behaviors) need to be examined. The attribution model has significant implications for social change strategies that seek to decrease mental illness stigma and discrimination."
Acerca del estigma de la enfermedadmental y las adicciones,"Mario Souza y Machorro, Lenin CruzMoreno",,"Stigma, mental illness, addictions","Misinformation and misrepresentation of facts frequently overlaps in Psychiatry, in addition to the erratic vision of the complex issues it handles. In large part, this occurs with the help and participation of the technical process, which is often not considered as an educational matter for patients and their families, permitting the persistence of doubts, reflections and inadequate conclusions regarding professional procedures. The professional activity must consider, health education for patients with as a benchmark that would guide to the handling of some of their health problems, the healthy functioning of their body in order to help to reach a good care of the social health of the community. The word vice and its moral connotations, having already permeated social education on health, is threatening and requires prompt and forced solution to avoid that the patient mentally ill and/or abuser addicted be considered as a bad person and no longer a patient: it is then a vicious person, not worthy of respect and attention, but worthy of punishment. In parallel, the underlying resistance becomes now the best condition, justifying the fears and apprehensions on behalf of a rational defense."
An attribution model of public discrimination towards persons with mental illness.,"Patrick W Corrigan, Fred E. Markowitz,A. Clinton Watson, David Rowan, MaryAnn Kubiak",Journal of Health and Social Behavior,,"In this study, we build on previous work by developing and estimating a model of the relationships between causal attributions (e.g., controllability, responsibility), familiarity with mental illness, dangerousness, emotional responses (e.g., pity, anger, fear), and helping and rejecting responses. Using survey data containing responses to hypothetical vignettes, we examine these relationships in a sample of 518 community college students. Consistent with attribution theory, causal attributions affect beliefs about persons' responsibility for causing their condition, beliefs which in turn lead to affective reactions, resulting in rejecting responses such as avoidance, coercion, segregation, and withholding help. However, consistent with a danger appraisal hypothesis, the effects of perceptions of dangerousness on helping and rejecting responses are unmediated by responsibility beliefs. Much of the dangerousness effects operate by increasing fear, a particularly strong predictor of support for coercive treatment. The results from this study also suggest that familiarity with mental illness reduces discriminatory responses."
Challenging two mental illness stigmas: personal responsibility and dangerousness.,"Patrick W Corrigan, David J. Rowan,Amy Elizabeth Green, Rickard Lundin,Philip River, Kyle Uphoff-Wasowski, K.White, Mary Anne Kubiak",Schizophrenia Bulletin,,"Two stigmatizing attitudes related to dangerousness and personal responsibility may undermine the opportunities of persons with serious mental illness. This study set out to examine path models that explain how these attitudes lead to discriminatory behavior and to assess the impact of antistigma programs on components of personal responsibility and dangerousness models. Two hundred thirteen persons were randomly assigned to one of five antistigma conditions: education on personal responsibility, education on dangerousness, contact with a person with serious mental illness where personal responsibility is discussed, contact where dangerousness is discussed, or no change. Persons completed an attribution questionnaire (AQ) representing personal responsibility and dangerousness path models at pretest, posttest, and 1-week followup. They also completed tasks that represented helping behavior. Goodness of fit indexes from linear structural modeling were mixed for both models but suggested that fear of dangerousness was a key attitude leading to discriminatory behavior. Results also showed that subjects who had contact with persons with serious mental illness experienced greater changes than subjects in the education or control groups did on measures of attribution and helping behavior."
Demonstrating Translational Research for Mental Health Services: An Example from Stigma Research,"Patrick W Corrigan, GalenBodenhausen, Fred A. Markowitz,Leonard J. Newman, Kenneth A.Rasinski, Amy Watson",Mental Health Services Research,translational research; mental health services research; employment discrimination; housing discrimination; mental illness; stigma,"In seeking to understand how the goal of providing efficient and effective mental health services can best be attained, services researchers have developed principles and methods that distinguish it from other research approaches. In 2000, the National Institute of Mental Health called for translational research paradigms that seek to expand the conceptual and methodological base of mental health services with knowledge gained from basic behavioral sciences such as cognitive, developmental, and social psychology. The goal of this paper is to enter the discussion of what is translational research by illustrating a services research program of the Chicago Consortium for Stigma Research on mental illness stigma. Our research strives to explain the prejudice and discrimination that some landlords and employers show toward people with mental illness in terms of basic research from social psychology and contextual sociology. We end the paper with a discussion of the implications of this research approach for the very practical issues of trying to change mental illness stigma."
Three programs that use mass approaches to challenge the stigma of mental illness.,"Patrick W Corrigan, Betsy D. Gelb",Psychiatric Services,,"Stigma impedes the life opportunities of people with mental illness. Research suggests that stigma may be reduced by three approaches: protest, education, and contact. Three programs that adapt these approaches for mass audiences are described: StigmaBusters, which is a form of protest; Elimination of Barriers Initiative, which involves education or social marketing; and In Our Own Voice, which relies on direct contact between people with mental illness and the public. The authors review preliminary research that offers initial support for the feasibility and impact of these programs, with a particular focus on how the components of social marketing (problem identification, description of target audiences, development of the change technology, and process and outcome evaluation) can be adapted to antistigma campaigns."
How clinical diagnosis might exacerbate the stigma of mental illness.,Patrick W Corrigan,Social Work ,diagnosis; DSM; empathy; stigma,"Stigma can greatly exacerbate the experience of mental illness. Diagnostic classification frequently used by clinical social workers may intensify this stigma by enhancing the public's sense of ""groupness"" and ""differentness"" when perceiving people with mental illness. The homogeneity assumed by stereotypes may lead mental health professionals and the public to view individuals in terms of their diagnostic labels. The stability of stereotypes may exacerbate notions that people with mental illness do not recover. Several strategies may diminish the unintended effects of diagnosis. Dimensional approaches to diagnosis may not augment stigma in the same manner as classification. Moreover, regular interaction with people with mental illness and focusing on recovery may diminish the stigmatizing effects of diagnosis."
Target-specific stigma change: a strategy for impacting mental illness stigma.,Patrick W Corrigan,Psychiatric Rehabilitation Journal,,"In the past decade, mental health advocates and researchers have sought to better understand stigma so that the harm it causes can be erased. In this paper, we propose a target-specific stigma change model to organize the diversity of information into a cogent framework. ""Target"" here has a double meaning: the power groups that have some authority over the life goals of people with mental illness and specific discriminatory behaviors which power groups might produce that interfere with these goals. Key power groups in the model include landlords, employers, health care providers, criminal justice professionals, policy makers, and the media. Examples are provided of stigmatizing attitudes that influence the discriminatory behavior and social context in which the power group interacts with people with mental illness. Stigma change is most effective when it includes all the components that describe how a specific power group impacts people with mental illness."
Empowerment and Serious Mental Illness: Treatment Partnerships and Community Opportunities,Patrick W Corrigan,Psychiatric Quarterly,consumer empowerment; stigma; serious mental illness,"The health goals of persons with serious mental illness are greatly improved when their personal power is advanced. Two targets of empowerment are discussed in this paper: treatment partnerships and community opportunities. Strategies that enhance treatment partnerships include provider endorsement of recovery rather than promoting an approach that suggests poor prognoses, treatment plans that are collaborative rather than unilateral decision making that is perceived as coercive, and treatment services provided in the person's community rather than geographically or psychological distant institutions. Approaches that focus on the person and treatment relationship are not sufficient however. Stigma and discrimination are significant barriers to the kind of community opportunities that are necessary to help people attain life goals. Communities that substitute stigmatizing attitudes and discriminatory behaviors with realistic views of mental illness are more likely to provide the kind of reasonable accommodations that some people need for work and independent living opportunities."
Three strategies for changing attributions about severe mental illness.,"Patrick W Corrigan, L. Philip River,Robert K Lundin, David Lewis Penn,Kyle Uphoff-Wasowski, Jerry Campion,Jay Mathisen, Carey Gagnon, MoeBergman, Hillel Goldstein, Mary AnneKubiak",Schizophrenia Bulletin,"Recent life events, suicide, schizophrenia","The effects of three strategies for changing stigmatizing attitudes—education (which replaces myths about mental illness with accurate conceptions), contact (which challenges public attitudes about mental illness through direct interactions with persons who have these disorders), and protest (which seeks to suppress stigmatizing attitudes about mental illness)—were examined on attributions about schizophrenia and other severe mental illnesses. One hundred and fifty-two students at a community college were randomly assigned to one of the three strategies or a control condition. They completed a questionnaire about attributions toward six groups—depression, psychosis, cocaine addiction, mental retardation, cancer, and AIDS—prior to and after completing the assigned condition. As expected, results showed that education had no effect on attributions about physical disabilities but led to improved attributions in all four psychiatric groups. Contact produced positive changes that exceeded education effects in attributions about targeted psychiatric disabilities: depression and psychosis. Protest yielded no significant changes in attributions about any group. This study also examined the effects of these strategies on processing information about mental illness."
Reducing stigma by meeting and learning from people with mental illness.,"Amy B. Spagnolo, Ann A Murphy, LueAnn Librera",Psychiatric Rehabilitation Journal,,"This study examines the effects of a public education program, developed in large part by consumers of mental health services, on the attitudes of high school students toward people with mental illnesses. This study examines the effects of a public education program, developed in large part by consumers of mental health services, on the attitudes of high school students toward people with mental illnesses. After viewing these presentations, students reported less stigmatizing views toward people with mental illness on seven of the nine factors and the total scale score. A 1-hour informational session developed and facilitated by consumers of mental health services can significantly affect the attitudes of adolescents toward people with major mental illnesses. Future studies will evaluate the sustainability of attitude changes as the result of these presentations, as well as the effects of demographic and socioeconomic differences on attitude change."
Changing middle schoolers' attitudes about mental illness through education.,"A. Clinton Watson, Emeline Otey, AnneL. Westbrook, April L. Gardner,Theodore A. Lamb, Patrick W Corrigan,Wayne S. Fenton",Schizophrenia Bulletin,"Mental illness, stigma, science education, adolescents, attitudes","The field test of The Science of Mental Illness curriculum supplement for middle school (grades 6-8) children provided an opportunity to assess knowledge and attitudes about mental illness in more than 1,500 middle school students throughout the United States and to evaluate the impact of an educational intervention on stigma-related attitudes. Two primary questions were examined: (1) what are the baseline knowledge and attitudes about mental illness in this sample of middle school students, and (2) does participation in a curriculum about the science of mental illness increase knowledge and improve attitudes about mental illness? Consistent with findings from other studies, results indicate that students had some understanding of mental illness as a problem of the brain with biological and psychosocial causes; however, they lacked knowledge about treatment and overall were ""not sure"" about many aspects of mental illness. The students did not strongly endorse negative attitudes about mental illness at baseline. The curriculum produced significant improvements in both knowledge and attitudes at posttest and was most effective in improving attitudes among those with more negative baseline attitudes. These findings suggest that a brief educational program can be an effective intervention to increase knowledge and improve attitudes about mental illness."
Changing attitudes about schizophrenia.,"Earnestine P Holmes, Patrick WCorrigan, Penny Williams, Janet Cañar,Mary Anne Kubiak",Schizophrenia Bulletin,"Stigma, schizophrenia, attitudes, education","Research on the effectiveness of short-term education programs in changing societal attitudes about mental illness has been mixed. Education efforts seem to be mediated by characteristics of the program participants. This study determines whether the effects of a specially prepared, semester-long course on severe mental illness are mediated by pre-education knowledge about and contact with severe mental illness. Eighty-three participants who were enrolled in either a course on severe mental illness or general psychology completed the Opinions about Mental Illness Questionnaire before beginning the course and at completion. Research participants also completed a preand posttest of knowledge about mental illness and a pretest on their contact with people who have severe mental illness. The education program had positive effects on some attitudes about mental illness. Interestingly, the effects of education group interacted with pre-education knowledge and contact and varied depending on attitude. Participants with more preeducation knowledge and contact were less likely to endorse benevolence attitudes after completing the education program. Participants with more intimate contact showed less improvement in attitudes about social restrictiveness. Implications of these augmentation and ceiling effects are discussed."
"The Stigma of Psychiatric Disorders and the Gender, Ethnicity, and Education of the Perceiver","Patrick W Corrigan, A. Clinton Watson",Community Mental Health Journal,"stigma, psychiatric disorders, mental illness, substance abuse","The purpose of this study is to determine how the demographics of perceivers influence their stigma of people with mental illness or with substance abuse. A nationally representative sample (N = 968) was asked to respond to a vignette describing a person with a health condition (schizophrenia, drug dependence, or emphysema) and his/her family member. Consistent with our hypotheses, women were less likely to endorse stigma than men. Participants with higher education were also less likely to stigmatize than less educated participants. Contrary to our expectations, nonwhite research participants were more likely to endorse stigma than whites. Implications of these findings for better understanding the stigma of mental illness, and the development of anti-stigma programs, are reviewed."
Measuring the Self-Stigma Associated With Seeking Psychological Help,"David L. Vogel, Nathaniel G. Wade,Shawn Haake",Journal of Counseling Psychology,"self-stigma, public stigma, help seeking, psychological services","Self-stigma is an important factor in people’s decisions not to engage in therapy. To measure this construct, the authors developed the 10-item Self-Stigma of Seeking Help (SSOSH) scale. In Study 1 (n ! 583), the SSOSH had a unidimensional factor structure and good reliability (.91) among participants. Study 2 (n ! 470) confirmed the factor structure. Studies 2, 3 (n ! 546), and 4 (n ! 217) cross-validated the reliability (.86 to .90; test–retest, .72) and showed evidence of validity (construct, criterion, and predictive) across the study samples. The SSOSH uniquely predicted attitudes toward and intent to seek psychological help. Finally, in Study 5 (n ! 655) the SSOSH differentiated those who sought psychological services from those who did not across a 2-month period."
How adolescents perceive the stigma of mental illness and alcohol abuse.,"Patrick W Corrigan, Barbara DemmingLurie, Howard H. Goldman, NatalieSlopen, Krishna Medasani, Sean MPhelan",Psychiatric Services,,"Research among adults has yielded three sets of conclusions about the stigma of mental illness. First, people with mental illness are stigmatized more severely than those with physical health conditions; those who abuse alcohol are viewed more harshly than those with mental illness. Second, stereotypes of mental illness related to responsibility and dangerousness lead to negative emotional reactions and discriminatory behaviors. Third, familiarity with people with mental illness tends to diminish stigma. This study attempted to validate these findings with a large and diverse sample of adolescents. A total of 303 adolescents completed a revised version of the Attribution Questionnaire (rAQ) that presented four vignettes, each describing a different type of peer: a peer with mental illness, with mental illness caused by a brain tumor, with alcohol abuse problems, and with leukemia. The rAQ comprises seven Likert scale items of agreement that research participants rated for each vignette. Items included pity, danger, fear, responsibility, anger, help, and avoidance. Participants also completed a revised Level of Contact Report to assess their familiarity with mental illness. As with adults, adolescents stigmatized peers who abuse alcohol most severely, followed by those with mental illness. Peers with leukemia were treated more benignly than the other groups. Having a brain tumor mediated the stigmatizing effect of mental illness. Adolescents who agreed that persons with mental illness are responsible for their illness and are dangerous demonstrated more discrimination toward these persons. However, this finding was not supported for alcohol abuse. Familiarity yielded an unexpected effect among adolescents; those who reported more familiarity with mental illness were more likely to endorse stigma of mental illness. Adolescents tended to discriminate among conditions, viewing substance abuse more harshly than the other disorders. Blame and dangerousness were important variables leading to discrimination, and contact with persons with mental illness led to more discrimination."
Self-stigma in people with mental illness.,"A. Clinton Watson, Patrick M. Corrigan,Jonathon E. Larson, Molly Sells",Schizophrenia Bulletin,"self-stigma, mental illness, group identification, perceived legitimacy","Persons with mental illnesses such as schizophrenia may internalize mental illness stigma and experience diminished self-esteem and self-efficacy. In this article, we describe a model of self-stigma and examine a hierarchy of mediational processes within the model. Seventy-one individuals with serious mental illness were recruited from a community support program at an outpatient psychiatry department of a community hospital. All participants completed the Self-Stigma of Mental Illness Scale along with measures of group identification (GI), perceived legitimacy (PL), self-esteem, and self-efficacy. Models examining the steps involved in self-stigma process were tested. Specifically, after conducting preliminary bivariate analyses, we examine stereotype agreement as a mediator of GI and PL on stigma self-concurrence (SSC); SSC as a mediator of GI and PL on self-efficacy; and SSC as a mediator of GI and PL on self-esteem. Findings provide partial support for the proposed mediational processes and point to GI, PL, and stereotype agreement as areas to be considered for intervention."
Comparing Live and Video-taped Theatrical Performance in Changing Stigmatizing Attitudes towards People with Serious Mental Illness,David A. Faigin,Bowling Green State University,,"Social stigma can have a devastating effect on the lives of people coping with serious mental illness. Stigma can impact feelings of self-worth, and play a major role in limiting individuals’ access to community resources. The present study compared the effectiveness of live and video-taped theatrical presentations in reducing stigmatization of people living with serious mental illness. The study focused on the effect of a play written and performed by a group of actors who live with serious mental illnesses on attitudes about mental illness in a sample of 303 undergraduates. Attitudes related to tolerance and future contact with people with serious mental illness are assessed before, and after exposure to either 1) live performance 2) video-taped performance or 3) no performance in the context of a college course. The live theater and video groups also rated the affective impact of the presentations. Results indicate that the students who witnessed a live performance and the students who watched a video of the play generally reported significantly more tolerance towards those with serious mental illness compared to the control group immediately following the presentations, and one month later. The live performance group generally reported significantly higher scores of behavioral intentions compared with controls, immediately following the presentations. On average, ratings of overall positive affective impact were significantly greater for the live group compared with the video group. Implications for the development of innovative classroom interventions involving contact to reduce stigma against people living with mental illness are discussed."
Implicit stigma of mental illness: Attitudes in an evidence-based practice,Laura G. Stull,The Journal of Nervous and Mental Disease ,"Stigma, mental illness, implicit attitude, implicit association test, assertive community treatment","The extent to which explicit and implicit stigma are endorsed by mental health practitioners using evidence-based practices is unknown. The purposes of the current study were to a) examine implicit and explicit biases among Assertive Community Treatment (ACT) staff and b) explore the extent to which biases predicted the use of treatment control mechanisms. Participants were 154 ACT staff from nine states. Overall, the participants exhibited positive explicit and implicit attitudes toward people with mental illness. When modeled using latent factors, greater implicit, but not explicit, bias significantly predicted greater endorsement of restrictive or controlling clinical interventions. Thus, despite overall positive attitudes toward those with mental illness for the sample as a whole, individual differences in provider stigma were related to clinical care. Mental health professionals, and specifically ACT clinicians, should be educated on types of bias and ways in which biases influence clinical interventions."
The Stigma of Severe Mental Illness: Some Potential Solutions for a Recalcitrant Problem,"David Lewis Penn, Jr. J. A. Martin",Psychiatric Quarterly,,"Despite recent advances in the treatment of individuals with severe mental illness (SMI), their full integration into society is hindered by lingering negative attitudes towards them. In this paper, a brief overview is provided on stigmatization towards individuals with SMI, including its' impact on quality of life and self-esteem, as well as the factors which likely underlie it. Research is reviewed showing that lowered negative perceptions towards persons with SMI are associated with previous contact with this population and with presentation of empirically-based information on the association between violence and SMI. Limitations of these findings are discussed with an eye towards developing improved techniques for reducing stigma."
Methods to Fight Mental Illness Stigma.,"Miro Klarić, Sanjin Lovrić",Psychiatria Danubina,,"Mental illness stigma is still widely spread and present in all the cultures and nations. Even more, during the last half of century there hasn't been much change in the perception of mentally ill persons as ""incurable and dangerous individuals incapable of living on their own"". The significance of mental illness stigma is determined by the size of its negative effect on mentally ill individuals, their family members, and the psychiatric service as well as on the society as a whole. In order to reduce the negative effects of stigma on the life of mentally ill individuals as well as to provide equal lifestyle in the community, at the beginning of the 1990s the World Health Organization recommended a global and decisive fight against the mental health stigma and discrimination. Since then three effective methods proliferated in fighting the mental illness stigma. These methods consist of combining education, contact with stigmatized group representatives and protest. To achieve better efficiency of anti-stigma program, the fight should be led by citizens of all age groups, especially younger people, the media, health care providers involved in treating the patients, but also the patients themselves as well as their family members."
DSM-V and the stigma of mental illness.,"Dror Ben-Zeev, Michael A. Young,Patrick W Corrigan",Journal of Mental Health,"Stigma, diagnosis, DSM-V, mental illness, labeling","Stigma associated with mental illness has been shown to have devastating effects on the lives of people with psychiatric disorders, their families, and those who care for them. In the current article, the relationship between diagnostic labels and stigma is examined in the context of the forthcoming DSM-V. Three types of negative outcomes are reviewed in detail - public stigma, self-stigma, and label avoidance. The article illustrates how a clinical diagnosis may exacerbate these forms of stigma through socio-cognitive processes of groupness, homogeneity, and stability. Initial draft revisions recently proposed by the DSM-V work groups are presented, and their possible future implications for stigma associated with mental illness are discussed."
Perceived Public Stigma and the Willingness to Seek Counseling: The Mediating Roles of Self-Stigma and Attitudes Toward Counseling,"David L. Vogel, Nathaniel G. Wade,Ashley H. Hackler",Journal of Counseling Psychology,"public stigma, self-stigma, attitudes, counseling, help seeking","This study examined the mediating effects of the self-stigma associated with seeking counseling and attitudes toward seeking counseling on the link between perceived public stigma and willingness to seek counseling for psychological and interpersonal concerns. Structural equation modeling of data from 676 undergraduates indicated that the link between perceived public stigma and willingness to seek counseling was fully mediated by self-stigma and attitudes. Perceptions of public stigma contributed to the experience of self-stigma, which, in turn, influenced help-seeking attitudes and eventually help-seeking willingness. Furthermore, 57% of the variance in attitudes toward counseling and 34% of the variance in willingness to seek counseling for psychological and interpersonal concerns were accounted for in the proposed model."
Reducing the stigma of schizophrenia: understanding the process and options for interventions.,"Matthias C. Angermeyer, Beate Schulze",Epidemiology and Psychiatric Sciences,,"In 1996, the World Psychiatric Association initiated a programme to reduce stigma and discrimination because of schizophrenia (Sartorius, 1998). Starting in Alberta (Canada), it was later joined by Spain and Austria. In the meantime, 11 countries from around the globe (including Italy) are involved in the international effort. Based on the respective local particularities of the countries participating, a multitude of interventions have been carried out or initiated in the context of the WPA-programme. The spectrum of activities extends from media campaigns through legal regulations to the empowerment of patients and their relatives. In the following, it will be attempted to develop a-systematology of the various approaches aiming at reducing the stigma of schizophrenia. This is to facilitate orientation among the variety of strategies chosen. As a theoretical framework, the argument will draw on the conception of the stigma process developed by Link et al. (1997) (see also Link & Phelan, in press). The process begins with a situation where a difference in another person is identified and subsequently labelled. It continues by linking the person thus labelled to negative stereotypes that prevail in society about the group of persons in question. Consequently, the person thus labelled is separated from others to become part of a distinct category from which people dissociate themselves. The stigma process culminates in that the person is exposed to various forms of discrimination, resulting in the respective negative social consequences."
Measuring mental illness stigma.,"Bruce G Link, Lawrence H Yang, J.Christopher Phelan, Pamela Y Collins",Schizophrenia Bulletin,"Stigma, discrimination, public attitudes, measurement, social rejection","The effectiveness of efforts designed to address mental illness stigma will rest on our ability to understand stigma processes, the factors that produce and sustain such processes, and the mechanisms that lead from stigmatization to harmful consequences. Critical to such an understanding is our capacity to observe and measure the essential components of stigma processes. This article is designed to assist researchers in selecting or creating measures that can address critical research questions regarding stigma. Our conceptualization of stigma processes leads us to consider components of labeling, stereotyping, cognitive separating, emotional reactions, status loss, and discrimination. We review 123 empirical articles published between January 1995 and June 2003 that have sought to assess mental illness stigma and use these articles to provide a profile of current measurement in this area. From the articles we identify commonly used and promising measures and describe those measures in more detail so that readers can decide whether the described measures might be appropriate for their studies. We end by identifying gaps in stigma measurement in terms of concepts covered and populations assessed."
Development of Jaipur Stigma Questionnaire: A culturally relevant tool to assess stigma in contemporary Indian context,"Shiv Shankar Gautam, Nikhil Jain,Harful Singh",Journal of Mental Health and Human Behaviour,"Stigma, questionnaire, mental illness, India","The stigma attached to mental illness is a universal phenomenon, though its experiences may differ locally. Little work has been done to study the understanding of stigma amongst Indian psychiatrists and after a thorough review of literature, it was felt that there is a need to develop a stigma questionnaire suitable for Indian context. The objectives were to (a) study the understanding of stigma for severe mental illness among psychiatrists, (b) study various aspects of stigma for severe mental illness, and (c) prepare a culturally and contemporarily suitable stigma questionnaire. Sixty psychiatrists from North India were requested to frame at least five questions to tap stigma, of which fifteen responded. Using ten questions with maximum consensus, a tentative stigma questionnaire was prepared. In a pilot study, attendants of 30 mentally-ill patients were administered Camberwell Family Interview and tentatively-prepared stigma questionnaire to see the relevance of themes. Keeping these results in mind, the study tool, Jaipur Stigma questionnaire (JSQ), was prepared. JSQ was applied on a matched group of 30 attendants of mentally-ill patients and comparison done with other questionnaires on ease of administration, themes and potential to tap stigma. The JSQ was easier to administer, included more themes and tapped stigma efficiently. Many themes not felt to be important by the collegiate of psychiatrists were subsequently found to be relevant. Segregation of mentally ill and shame for consultation appear to be fading themes. The study has made an attempt to develop a new stigma questionnaire which is relevant for Indian setting and is reflective of contemporary themes of stigma"
Stigmatization Model: Strategies for Changing Stigma on Mental Disorders in the Community,Binar Alkautsar,"Advances in Social Science, Education and Humanities Research","stigma; mental disorders, strategies, social","One of the important problems faced by people with mental disorders today is when they have to deal with people in their social environment. The stereotypes attached to people with mental disorders lead to discrimination from the social environment they occupy. Many of them get unfair treatment, are exiled, shunned, rejected, and often accused of guilty of a crime. They are not treated as they should because of the stigma attached by the people around them. This article examines the process of stigma formation, the effects, the model of stigma formation, and how effective strategies must be applied to change stigma based on literature studies from a socio-cognitive and behavioral perspective. The study in this article includes: a) what is a stigma, b) what are the effects caused by people affected by this stigma, c) various models that explain the formation of stigma, d) strategies in developing programs that can change the stigma and the goals of this program to run effectively. There are three models of the formation of stigma, namely individual cognitive, motivational, and institutional/structural. Stigma change strategies can be done in four ways: education, contact, protest, and interactive media. As well as for this program to be successful and run effectively, the target of the program must be specific to the group affected by stigma."
Internalized stigma of mental illness: psychometric properties of a new measure,"Jennifer Boyd Ritsher, Poorni G.Otilingam, Monica Grajales",Psychiatry Research,"Stereotyping, Social alienation, Risk factors, Mental disorders, Questionnaires, Psychometrics","The study evaluated the Internalized Stigma of Mental Illness (ISMI) scale, designed to measure the subjective experience of stigma, with subscales measuring Alienation, Stereotype Endorsement, Perceived Discrimination, Social Withdrawal and Stigma Resistance. The ISMI was developed in collaboration with people with mental illnesses and contains 29 Likert items. The validation sample included 127 mental health outpatients. Results showed that the ISMI had high internal consistency and test-retest reliability. Construct validity was supported by comparisons against scales measuring related constructs with the same methodology. As expected, the ISMI had positive correlations with measures of stigma beliefs and depressive symptoms, and it had negative correlations with measures of self-esteem, empowerment and recovery orientation. Factor analyses of the joint set of items from the ISMI and each scale supported the distinction between constructs. Having a validated measure of internalized stigma may encourage clinicians to include stigma reduction as a verifiable treatment goal in addition to symptom reduction."
Understanding labeling effects in the area of mental disorders: An assessment of the effects of expectations of rejection.,Bruce G Link,American Sociological Review,,"This paper hypothesizes that official labeling gives personal relevance to an individual's beliefs about how others respond to mental patients. According to this view, people develop conceptions of what others think of mental patients long before they become patients. These conceptions include the belief that others devalue and discriminate against mental patients. When people enter psychiatric treatment and are labeled, these beliefs become personally applicable and lead to self-devaluation and/or the fear of rejection by others. Such reactions may have negative effects on both psychological and socialfunctioning. This hypothesis was tested by comparing samples of community residents and psychiatric patients from the Washington Heights section of New York city. Five groups were formed (1) first-treatment contact patients, (2) repeat-treatment contact patients, (3) formerly treated community residents, (4) untreated community cases, and (5) community residents with no evidence of severe psychopathology. These groups were administered a scale that measured beliefs that mental patients would be devalued and discriminated against by most people. Scores on this scale were associated with demoralization, income loss, and unemployment in labeled groups but not in unlabeled groups. The results suggest that labeling may produce negative outcomes like those specified by the classic concept of secondary deviance."
Examining Two Aspects of Contact on the Stigma of Mental Illness,"Rebecca R. Reinke, Patrick W Corrigan,Christoph Leonhard, Robert WilliamLundin, Mary Anne Kubiak",Journal of Social and Clinical Psychology,,"This study expands on earlier research by our group that has shown that contact with people with mental illness has significant effects on changing stigmatizing attitudes. Two factors that affect contact are examined in this study: the medium through which contact is experienced, and the level of stereotype disconfirmation engendered in contact. One hundred sixty-four individuals were randomly assigned to one of five conditions. Three of the conditions allowed us to examine the effects of medium: no stigma-control, in vivo contact with moderate disconfirmation, and videotaped contact with moderate disconfirmation. Along with the moderate disconfirmation videotape, two additional videotaped conditions —little or no disconfirmation and high disconfirmations—defined the three groups for our second set of hypotheses on disconfirmation. Research participants completed the Social Distance Scale prior to being assigned to condition and immediately upon completion. In terms of the medium of contact, results showed that both videotaped and in vivo contact led to significant change in stigmatizing attitudes. Two interesting results were found in terms of level of disconfirmation. First, viewing a videotape of a person with mental illness that does not disconfirm the stereotype (e.g., the person is manifestly psychotic) does not change stigmatizing attitudes. Second, videotapes of people who moderately and highly disconfirm the stereotype lead to significant improvement in attitudes, with nonsignificant trends suggesting that moderate disconfirmation yields better effects. Implications of these findings for future work on changing public attitudes are discussed."
Public beliefs about and attitudes towards people with mental illness: a review of population studies.,"Matthias C. Angermeyer, SandraDietrich",Acta Psychiatrica Scandinavica,"Attitude research in psychiatry made considerable progress over the past 15 years. However, there is still much to be done to provide an empirical basis for evidence-based interventions to reduce misconceptions about mental illness and improve attitudes towards persons with mental illness.","To provide a review of population-based attitude research in psychiatry during the past 15 years. An electronic search using PubMed, Medline, and Academic Search Premier plus a hand search of the literature was carried out for studies on public beliefs about mental illness and attitudes towards the mentally ill published between 1990 and 2004. Thirty-three national studies and 29 local and regional studies were identified, mostly from Europe. Although the majority are of descriptive nature, more recent publications include studies testing theory-based models of the stigmatization of mentally ill people, analyses of time trends and cross-cultural comparisons, and evaluations of antistigma interventions. Attitude research in psychiatry made considerable progress over the past 15 years. However, there is still much to be done to provide an empirical basis for evidence-based interventions to reduce misconceptions about mental illness and improve attitudes towards persons with mental illness."
The impact of contact on stigmatizing attitudes toward people with mental illness,"Laurel A. Alexander, Bruce G Link",Journal of Mental Health,"stigma, mental illness, contact, dangerousness, attitudes",": A growing body of research suggests that personal experience with people who have a mental illness can reduce stigmatizing attitudes towards mental illness. However, the generalizability of these findings has been restrained by their samples and operational definitions of contact and stigma. To test the contact-stigma link using a nationally representative sample and comprehensive measures of both contact and stigma. Data were collected in a 1990 American telephone survey of attitudes towards homelessness and homeless people with mental illnesses. By telephone, 1507 respondents
completed measures of the perceived dangerousness of people with mental illnesses and their contact experiences with mental illness. A subsample of 640 respondents was read a vignette of a character with mental illness and then completed measures of their desired social distance from the character and the perceived dangerousness of the character. All respondents completed measures of political conservatism, social desirability, and anomia as well. As total contact increased, the perceived dangerousness and desired social distance from the vignette character decreased, as did the perceived dangerousness of people with mental illnesses in general. However, the contact types did not consistently predict the vignette stigma measures. While more research is needed to clarify and extend these findings, this study provides strong evidence for the importance of different contact types in reducing stigmatizing attitudes and the potential usefulness of incorporating contact into any stigma reduction intervention."
Dispelling the stigma of schizophrenia: what sort of information is best?,"David Lewis Penn, K Guynan, T. Daily,William D. Spaulding, Calvin P. Garbin,Mauri Sullivan",Schizophrenia Bulletin,,"This study investigated what type of information reduces stigmatization of schizophrenia. Subjects were presented with one of six varying descriptions of a hypothetical case in which a target Individual had recovered from a mental disorder. Subjects were asked if they knew someone with a mental illness. Those individuals who had no previous contact perceived the mentally ill as dangerous and chose to maintain a greater social distance from them. In general, knowledge of the symptoms associated with the acute phase of schizophrenia created more stigma than the label of schizophrenia alone. In contrast, more information about the target individuals posttreatment living arrangements (i.e., supervised care) reduced negative judgments. Implications for public education and future research are discussed."
"Public conceptions of mental illness: labels, causes, dangerousness, and social distance.","Bruce G Link, J. Christopher Phelan,Michacline Bresnahan, Ann Stueve,Bernice A. Pescosolido",American Journal of Public Health,,"The authors used nationwide survey data to characterize current public conceptions related to recognition of mental illness and perceived causes, dangerousness, and desired social distance. Data were derived from a vignette experiment included in the 1996 General Social Survey. Respondents (n = 1444) were randomly assigned to 1 of 5 vignette conditions. Four vignettes described psychiatric disorders meeting diagnostic criteria, and the fifth depicted a ""troubled person"" with subclinical problems and worries. Results indicate that the majority of the public identifies schizophrenia (88%) and major depression (69%) as mental illnesses and that most report multicausal explanations combining stressful circumstances with biologic and genetic factors. Results also show, however, that smaller proportions associate alcohol (49%) or drug (44%) abuse with mental illness and that symptoms of mental illness remain strongly connected with public fears about potential violence and with a desire for limited social interaction. While there is reason for optimism in the public's recognition of mental illness and causal attributions, a strong stereotype of dangerousness and desire for social distance persist. These latter conceptions are likely to negatively affect people with mental illness."
Emotional openness as a predictor of college students' attitudes toward seeking psychological help.,"Noboru Komiya, Glenn E. Good, NancyB. Sherrod",Journal of Counseling Psychology,,"Fear of emotions is hypothesized to be a primary reason for individuals' negative attitudes toward seeking psychological treatment. This study examined the effects of emotional openness and other potential predictors of attitudes toward seeking psychological help in a sample of 311 college students. Results of simultaneous multiple regression analyses indicated that gender (male), perception of stigma, discomfort with emotions, and lower psychological distress accounted for 25% of variance in attitudes toward seeking psychological help. The implications of the findings and recommendations for increasing the effectiveness of public education efforts are discussed."
"Blame, shame, and contamination: the impact of mental illness and drug dependence stigma on family members.","Patrick W Corrigan, A. Clinton Watson,Frederick E. Miller",Journal of Family Psychology,,"Family members of relatives with mental illness or drug dependence or both report that they are frequently harmed by public stigma. No population-based survey, however, has assessed how members of the general public actually view family members. Hence, the authors examined ways that family role and psychiatric disorder influence family stigma. A national sample (N = 968) was recruited for this study. A vignette design describing a person with a health condition and a family member was used. Family stigma related to mental illnesses, such as schizophrenia, is not highly endorsed. Family stigma related to drug dependence, however, is worse than for other health conditions, with family members being blamed for both the onset and offset of a relative's disorder and likely to be socially shunned."
Internalized stigma predicts erosion of morale among psychiatric outpatients,"Jennifer Boyd Ritsher, J. ChristopherPhelan",Psychiatry Research,Severe mental illness (SMI); Mental disorders; Stereotyping; Social alienation; Risk factors; Depressive symptoms,"Stigma in society causes harm to people with severe mental illness (SMI) and internalized stigma represents its psychological point of impact. We evaluated the extent of internalized stigma in a sample of outpatients with SMI, using the Internalized Stigma of Mental Illness (ISMI) Scale, developed with consumer input. About a third of the sample reported high levels of internalized stigma. We tested whether internalized stigma predicted increased depressive symptoms and reduced self-esteem at 4-month follow-up, controlling for baseline levels. Depression was predicted by Alienation, Stereotype Endorsement, Social Withdrawal Scales and total ISMI score. Reduced self-esteem was predicted by Alienation. ISMI results were stronger than those for the widely used Devaluation-Discrimination Scale. The finding that alienation further reduces morale speaks to the difficulty of pulling oneself out of this type of vicious cycle without assistance."
Towards Learning Word Representation,Magdalena Wiercioch,Schedae Informaticae,"representation learning, n-gram model, NLP","Continuous vector representations, as a distributed representations for words have gained a lot of attention in Natural Language Processing (NLP) field. Although they are considered as valuable methods to model both semantic and syntactic features, they still may be improved. For instance, the open issue seems to be to develop different strategies to introduce the knowledge about the morphology of words. It is a core point in case of either dense languages where many rare words appear and texts which have numerous metaphors or similies. In this paper, we extend a recent approach to represent word information. The underlying idea of our technique is to present a word in form of a bag of syllable and letter n-grams. More specifically, we provide a vector representation for each extracted syllable-based and letter-based n-gram, and perform concatenation. Moreover, in contrast to the previous method, we accept n-grams of varied length n. Further various experiments, like tasks-word similarity ranking or sentiment analysis report our method is competitive with respect to other state-of-theart techniques and takes a step toward more informative word representation construction."
Charagram: Embedding Words and Sentences via Character n-grams,"John Wieting, Mohit Bansal, KevinGimpel, Karen Livescu",arXiv,,"We present Charagram embeddings, a simple approach for learning character-based compositional models to embed textual sequences. A word or sentence is represented using a character n-gram count vector, followed by a single nonlinear transformation to yield a low-dimensional embedding. We use three tasks for evaluation: word similarity, sentence similarity, and part-of-speech tagging. We demonstrate that Charagram embeddings outperform more complex architectures based on character-level recurrent and convolutional neural networks, achieving new state-of-the-art performance on several similarity tasks."
Entropy-Based Subword Mining with an Application to Word Embeddings,"Ahmed El-Kishky, Frank F. Xu, AstonZhang, Stephen Macke, Jiawei Han",ACL,,"Recent literature has shown a wide variety of benefits to mapping traditional one-hot representations of words and phrases to lower-dimensional real-valued vectors known as word embeddings. Traditionally, most word embedding algorithms treat each word as the finest meaningful semantic granularity and perform embedding by learning distinct embedding vectors for each word. Contrary to this line of thought, technical domains such as scientific and medical literature compose words from subword structures such as prefixes, suffixes, and root-words as well as compound words. Treating individual words as the finest-granularity unit discards meaningful shared semantic structure between words sharing substructures. This not only leads to poor embeddings for text corpora that have long-tail distributions, but also heuristic methods for handling out-of-vocabulary words. In this paper we propose SubwordMine, an entropy-based subword mining algorithm that is fast, unsupervised, and fully data-driven. We show that this allows for great cross-domain performance in identifying semantically meaningful subwords. We then investigate utilizing the mined subwords within the FastText embedding model and compare performance of the learned representations in a downstream language modeling task."
Character-Aware Neural Language Models,"Yoon Kim, Yacine Jernite, David ASontag, Alexander M. Rush",arXiv,,"We describe a simple neural language model that relies only on character-level inputs. Predictions are still made at the word-level. Our model employs a convolutional neural network (CNN) and a highway network over characters, whose output is given to a long short-term memory (LSTM) recurrent neural network language model (RNN-LM). On the English Penn Treebank the model is on par with the existing state-of-the-art despite having 60% fewer parameters. On languages with rich morphology (Arabic, Czech, French, German, Spanish, Russian), the model outperforms word-level/morpheme-level LSTM baselines, again with fewer parameters. The results suggest that on many languages, character inputs are sufficient for language modeling. Analysis of word representations obtained from the character composition part of the model reveals that the model is able to encode, from characters only, both semantic and orthographic information."
Learning to Generate Word Representations using Subword Information,"Yeachan Kim, Kang-Min Kim, Ji-MinLee, Sangkeun Lee",ACL,,"Distributed representations of words play a major role in the field of natural language processing by encoding semantic and syntactic information of words. However, most existing works on learning word representations typically regard words as individual atomic units and thus are blind to subword information in words. This further gives rise to a difficulty in representing out-of-vocabulary (OOV) words. In this paper, we present a character-based word representation approach to deal with this limitation. The proposed model learns to generate word representations from characters. In our model, we employ a convolutional neural network and a highway network over characters to extract salient features effectively. Unlike previous models that learn word representations from a large corpus, we take a set of pre-trained word embeddings and generalize it to word entries, including OOV words. To demonstrate the efficacy of the proposed model, we perform both an intrinsic and an extrinsic task which are word similarity and language modeling, respectively. Experimental results show clearly that the proposed model significantly outperforms strong baseline models that regard words or their subwords as atomic units. For example, we achieve as much as 18.5% improvement on average in perplexity for morphologically rich languages compared to strong baselines in the language modeling task."
Parsimonious Morpheme Segmentation with an Application to Enriching Word Embeddings,"Ahmed El-Kishky, Frank F. Xu, AstonZhang, Jiawei Han",arXiv,,"Traditionally, many text-mining tasks treat individual word-tokens as the finest meaningful semantic granularity. However, in many languages and specialized corpora, words are composed by concatenating semantically meaningful subword structures. Word-level analysis cannot leverage the semantic information present in such subword structures. With regard to word embedding techniques, this leads to not only poor embeddings for infrequent words in long-tailed text corpora but also weak capabilities for handling out-of-vocabulary words. In this paper we propose MorphMine for unsupervised morpheme segmentation. MorphMine applies a parsimony criterion to hierarchically segment words into the fewest number of morphemes at each level of the hierarchy. This leads to longer shared morphemes at each level of segmentation. Experiments show that MorphMine segments words in a variety of languages into human-verified morphemes. Additionally, we experimentally demonstrate that utilizing MorphMine morphemes to enrich word embeddings consistently improves embedding quality on a variety of of embedding evaluations and a downstream language modeling task."
Subword-level Composition Functions for Learning Word Embeddings,"Bofang Li, Aleksandr Drozd, Tao Liu,Xiaoyong Du",ACL,,"Subword-level information is crucial for capturing the meaning and morphology of words, especially for out-of-vocabulary entries. We propose CNN- and RNN-based subword-level composition functions for learning word embeddings, and systematically compare them with popular word-level and subword-level models (Skip-Gram and FastText). Additionally, we propose a hybrid training scheme in which a pure subword-level model is trained jointly with a conventional word-level embedding model based on lookup-tables. This increases the fitness of all types of subword-level word embeddings; the word-level embeddings can be discarded after training, leaving only compact subword-level representation with much smaller data volume. We evaluate these embeddings on a set of intrinsic and extrinsic tasks, showing that subword-level models have advantage on tasks related to morphology and datasets with high OOV rate, and can be combined with other types of embeddings."
Morphological Word Embeddings for Arabic Neural Machine Translation in Low-Resource Settings,"Pamela Shapiro, Kevin Duh",ACL,,"Neural machine translation has achieved impressive results in the last few years, but its success has been limited to settings with large amounts of parallel data. One way to improve NMT for lower-resource settings is to initialize a word-based NMT model with pretrained word embeddings. However, rare words still suffer from lower quality word embeddings when trained with standard word-level objectives. We introduce word embeddings that utilize morphological resources, and compare to purely unsupervised alternatives. We work with Arabic, a morphologically rich language with available linguistic resources, and perform Ar-to-En MT experiments on a small corpus of TED subtitles. We find that word embeddings utilizing subword information consistently outperform standard word embeddings on a word similarity task and as initialization of the source word embeddings in a low-resource NMT system."
Bag of Tricks for Efficient Text Classification,"Armand Joulin, Edouard Grave, PiotrBojanowski, Shaobo He",arXiv,,"This paper explores a simple and efficient baseline for text classification. Our experiments show that our fast text classifier fastText is often on par with deep learning classifiers in terms of accuracy, and many orders of magnitude faster for training and evaluation. We can train fastText on more than one billion words in less than ten minutes using a standard multicore~CPU, and classify half a million sentences among~312K classes in less than a minute."
A Syllable-based Technique for Word Embeddings of Korean Words,"Sanghyuk Choi, Taeuk Kim, JinseokSeol, Sang-goo Lee",ACL,,"Word embedding has become a fundamental component to many NLP tasks such as named entity recognition and machine translation. However, popular models that learn such embeddings are unaware of the morphology of words, so it is not directly applicable to highly agglutinative languages such as Korean. We propose a syllable-based learning model for Korean using a convolutional neural network, in which word representation is composed of trained syllable vectors. Our model successfully produces morphologically meaningful representation of Korean words compared to the original Skip-gram embeddings. The results also show that it is quite robust to the Out-of-Vocabulary problem."
Deep contextualized word representations,"Matthew E. Peters, Mark Neumann,Mohit Iyyer, Matt Gardner, ChristopherClark, Kenton Lee, Luke Zettlemoyer",arXiv,,"We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals."
Inside Out: Two Jointly Predictive Models for Word Representations and Phrase Representations,"Fei Sun, Jiafeng Guo, Yanyan Lan, JunXu, Xueqi Cheng",AAAI,,"Distributional hypothesis lies in the root of most existing word representation models by inferring word meaning from its external contexts. However, distributional models cannot handle rare and morphologically complex words very well and fail to identify some fine-grained linguistic regularity as they are ignoring the word forms. On the contrary, morphology points out that words are built from some basic units, i.e., morphemes. Therefore, the meaning and function of such rare words can be inferred from the words sharing the same morphemes, and many syntactic relations can be directly identified based on the word forms. However, the limitation of morphology is that it cannot infer the relationship between two words that do not share any morphemes. Considering the advantages and limitations of both approaches, we propose two novel models to build better word representations by modeling both external contexts and internal morphemes in a jointly predictive way, called BEING and SEING. These two models can also be extended to learn phrase representations according to the distributed morphology theory. We evaluate the proposed models on similarity tasks and analogy tasks. The results demonstrate that the proposed models can outperform state-of-the-art models significantly on both word and phrase representation learning."
A Character-Enhanced Chinese Word Embedding Model,"Gang Yang, Hongzhe Xu, Tianhao He,Zaishang Cai",arXiv,,"Distributed word representations are very useful for capturing semantic information and have been successfully applied in a variety of NLP tasks, especially on English. In this work, we innovatively develop two component-enhanced Chinese character embedding models and their bigram extensions. Distinguished from English word embeddings, our models explore the compositions of Chinese characters, which often serve as semantic indictors inherently. The evaluations on both word similarity and text classification demonstrate the effectiveness of our models."
Character-Based Convolutional Grid Neural Network for Breast Cancer Classification,"Qiao Pan, Yuanyuan Zhang, DehuaChen, Guangwei Xu",IEEE,deep learning; character vector; grid-LSTM; residual layer,"According to the World Health Organization (WHO)1, an early detection of cancer greatly increases the chances of making the right decision in a successful treatment plan. Over the last decade, the increasing world-wide demand for early detection of breast cancer at the hospitals has resulted in necessity of new research avenues. The traditional domain knowledge based diagnostic method requires hand-crafted features, which are not only time consuming, but also corpus dependent. In this paper, we propose a novel neural net-work architecture for the disease classification that relies only on character level representations. Our model leverages subword information through a convolutional neural net-work (CNN) and a residual network over characters, whose output is given to a Grid long short-term memory (Grid-LSTM) recurrent neural network language model (RNN-LM). It's truly an end-to-end model requiring no task-specific feature engineering or data pre-processing beyond pre-trained character embedding on unlabeled corpora. Thus, it can be easily applied to a wide range of NLP tasks in different domains. We evaluate our module using NCBI disease dataset for classification tasks, finding that it can achieve a state-of-the-art performance with minimal computational cost."
Incorporating Latent Meanings of Morphological Compositions to Enhance Word Embeddings,"Yang Xu, Jiawei Liu, Wei Yang,Liusheng Huang",ACL,,"Traditional word embedding approaches learn semantic information at word level while ignoring the meaningful internal structures of words like morphemes. Furthermore, existing morphology-based models directly incorporate morphemes to train word embeddings, but still neglect the latent meanings of morphemes. In this paper, we explore to employ the latent meanings of morphological compositions of words to train and enhance word embeddings. Based on this purpose, we propose three Latent Meaning Models (LMMs), named LMM-A, LMM-S and LMM-M respectively, which adopt different strategies to incorporate the latent meanings of morphemes during the training process. Experiments on word similarity, syntactic analogy and text classification are conducted to validate the feasibility of our models. The results demonstrate that our models outperform the baselines on five word similarity datasets. On Wordsim-353 and RG-65 datasets, our models nearly achieve 5% and 7% gains over the classic CBOW model, respectively. For the syntactic analogy and text classification tasks, our models also surpass all the baselines including a morphology-based model."
Word Translation Without Parallel Data,"Alexis Conneau, Guillaume Lample,Marc'Aurelio Ranzato, Ludovic Denoyer,Hervé Jégou",arXiv,,"State-of-the-art methods for learning cross-lingual word embeddings have relied on bilingual dictionaries or parallel corpora. Recent studies showed that the need for parallel data supervision can be alleviated with character-level information. While these methods showed encouraging results, they are not on par with their supervised counterparts and are limited to pairs of languages sharing a common alphabet. In this work, we show that we can build a bilingual dictionary between two languages without using any parallel corpora, by aligning monolingual word embedding spaces in an unsupervised way. Without using any character information, our model even outperforms existing supervised methods on cross-lingual tasks for some language pairs. Our experiments demonstrate that our method works very well also for distant language pairs, like English-Russian or English-Chinese. We finally describe experiments on the English-Esperanto low-resource language pair, on which there only exists a limited amount of parallel data, to show the potential impact of our method in fully unsupervised machine translation. Our code, embeddings and dictionaries are publicly available."
Generalizing Word Embeddings using Bag of Subwords,"Jinman Zhao, Sidharth Mudgal, YingyuLiang",arXiv,,"We approach the problem of generalizing pre-trained word embeddings beyond fixed-size vocabularies without using additional contextual information. We propose a subword-level word vector generation model that views words as bags of character n-grams. The model is simple, fast to train and provides good vectors for rare or unseen words. Experiments show that our model achieves state-of-the-art performances in English word similarity task and in joint prediction of part-of-speech tag and morphosyntactic attributes in 23 languages, suggesting our model's ability in capturing the relationship between words' textual representations and their embeddings."
Character-based Neural Machine Translation,"Marta R. Costa-jussà, José A. R.Fonollosa",arXiv,,"We introduce a neural machine translation model that views the input and output sentences as sequences of characters rather than words. Since word-level information provides a crucial source of bias, our input model composes representations of character sequences into representations of words (as determined by whitespace boundaries), and then these are translated using a joint attention/translation model. In the target language, the translation is modeled as a sequence of word vectors, but each word is generated one character at a time, conditional on the previous character generations in each word. As the representation and generation of words is performed at the character level, our model is capable of interpreting and generating unseen word forms. A secondary benefit of this approach is that it alleviates much of the challenges associated with preprocessing/tokenization of the source and target languages. We show that our model can achieve translation results that are on par with conventional word-based models."
Revisiting Recurrent Networks for Paraphrastic Sentence Embeddings,"John Wieting, Kevin Gimpel",arXiv,,"We consider the problem of learning general-purpose, paraphrastic sentence embeddings, revisiting the setting of Wieting et al. (2016b). While they found LSTM recurrent networks to underperform word averaging, we present several developments that together produce the opposite conclusion. These include training on sentence pairs rather than phrase pairs, averaging states to represent sequences, and regularizing aggressively. These improve LSTMs in both transfer learning and supervised settings. We also introduce a new recurrent architecture, the Gated Recurrent Averaging Network, that is inspired by averaging and LSTMs while outperforming them both. We analyze our learned models, finding evidence of preferences for particular parts of speech and dependency relations."
NAACL HLT 2018 Subword and Character LEvel Models in NLP Proceedings of the Second Workshop,"June, Yadollah Yaghoobzadeh, AhmedEl-Kishky, Frank Xu, Aston Zhang,Stephen Macke",ACL,,"Neural machine translation has achieved impressive results in the last few years, but its success has been limited to settings with large amounts of parallel data. One way to improve NMT for lower-resource settings is to initialize a word-based NMT model with pretrained word embeddings. However, rare words still suffer from lower quality word embeddings when trained with standard word-level objectives. We introduce word embeddings that utilize morphological resources, and compare to purely unsupervised alternatives. We work with Arabic, a morphologically rich language with available linguistic resources, and perform Ar-to-En MT experiments on a small corpus of TED subtitles. We find that word embeddings utilizing subword information consistently outperform standard word embeddings on a word similarity task and as initialization of the source word embeddings in a low-resource NMT system."
BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,"Jacob Devlin, Ming-Wei Chang, KentonLee, Kristina Toutanova",arXiv,,"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement)."
Enhancing the LexVec Distributed Word Representation Model Using Positional Contexts and External Memory,"Alexandre Salle, Marco Idiart, AlineVillavicencio",arXiv,,"In this paper we take a state-of-the-art model for distributed word representation that explicitly factorizes the positive pointwise mutual information (PPMI) matrix using window sampling and negative sampling and address two of its shortcomings. We improve syntactic performance by using positional contexts, and solve the need to store the PPMI matrix in memory by working on aggregate data in external memory. The effectiveness of both modifications is shown using word similarity and analogy tasks."
Improving Word Embeddings for Low Frequency Words by Pseudo Contexts,"Fang Li, Xiaojie Wang",Springer International Publishing,"Word embedding, Low frequency word","This paper investigates relations between word semantic density and word frequency. A distributed representations based word average similarity is defined as the measure of word semantic density. We find that the average similarities of low frequency words are always bigger than that of high frequency words, when the frequency approaches to 400 around, the average similarity tends to stable. The finding keeps correct with changes of the size of training corpus, dimension of distributed representations and number of negative samples in skip-gram model. It also keeps on 17 different languages. Basing on the finding, we propose a pseudo context skip-gram model, which makes use of context words of semantic nearest neighbors of target words. Experiment results show our model achieves significant performance improvements in both word similarity and analogy tasks."
Unsupervised Morphology Induction Using Word Embeddings,"Radu Soricut, Franz Josef Och",ACL,,"We present a language agnostic, unsupervised method for inducing morphological transformations between words. The method relies on certain regularities manifest in highdimensional vector spaces. We show that this method is capable of discovering a wide range of morphological rules, which in turn are used to build morphological analyzers. We evaluate this method across six different languages and nine datasets, and show significant improvements across all languages."
Improving Distributional Similarity with Lessons Learned from Word Embeddings,"Omer Levy, Yoav Goldberg, Ido Dagan",ACL,,"Recent trends suggest that neural-network-inspired word embedding models outperform traditional count-based distributional models on word similarity and analogy detection tasks. We reveal that much of the performance gains of word embeddings are due to certain system design choices and hyperparameter optimizations, rather than the embedding algorithms themselves. Furthermore, we show that these modifications can be transferred to traditional distributional models, yielding similar gains. In contrast to prior reports, we observe mostly local or insignificant performance differences between the methods, with no global advantage to any single approach over the others."
Nonsymbolic Text Representation,"Hinrich Schütze,  Heike Adel, Ehsaneddin Asgari",arXiv,,"We introduce the first generic text representation model that is completely nonsymbolic, i.e., it does not require the availability of a segmentation or tokenization method that attempts to identify words or other symbolic units in text. This applies to training the parameters of the model on a training corpus as well as to applying it when computing the representation of a new text. We show that our model performs better than prior work on an information extraction and a text denoising task."
Learning Word Representations by Jointly Modeling Syntagmatic and Paradigmatic Relations,"Fei Sun, Jiafeng Guo, Yanyan Lan, JunXu, Xueqi Cheng",ACL,,"Vector space representation of words has been widely used to capture fine-grained linguistic regularities, and proven to be successful in various natural language processing tasks in recent years. However, existing models for learning word representations focus on either syntagmatic or paradigmatic relations alone. In this paper, we argue that it is beneficial to jointly modeling both relations so that we can not only encode different types of linguistic properties in a unified way, but also boost the representation learning due to the mutual enhancement between these two types of relations. We propose two novel distributional models for word representation using both syntagmatic and paradigmatic relations via a joint training objective. The proposed models are trained on a public Wikipedia corpus, and the learned representations are evaluated on word analogy and word similarity tasks. The results demonstrate that the proposed models can perform significantly better than all the state-of-the-art baseline methods on both tasks."
Exploring the Limits of Language Modeling,"Rafal Józefowicz, Oriol Vinyals, MikeSchuster, Noam Shazeer, Yonghui Wu",arXiv,,"In this work we explore recent advances in Recurrent Neural Networks for large scale Language Modeling, a task central to language understanding. We extend current models to deal with two key challenges present in this task: corpora and vocabulary sizes, and complex, long term structure of language. We perform an exhaustive study on techniques such as character Convolutional Neural Networks or Long-Short Term Memory, on the One Billion Word Benchmark. Our best single model significantly improves state-of-the-art perplexity from 51.3 down to 30.0 (whilst reducing the number of parameters by a factor of 20), while an ensemble of models sets a new record by improving perplexity from 41.0 down to 23.7. We also release these models for the NLP and ML community to study and improve upon."
Rehabilitation of Count-Based Models for Word Vector Representations,"Rémi Lebret, Ronan Collobert",arXiv,,"Recent works on word representations mostly rely on predictive models. Distributed word representations (aka word embeddings) are trained to optimally predict the contexts in which the corresponding words tend to appear. Such models have succeeded in capturing word similarties as well as semantic and syntactic regularities. Instead, we aim at reviving interest in a model based on counts. We present a systematic study of the use of the Hellinger distance to extract semantic representations from the word co-occurence statistics of large text corpora. We show that this distance gives good performance on word similarity and analogy tasks, with a proper type and size of context, and a dimensionality reduction based on a stochastic low-rank approximation. Besides being both simple and intuitive, this method also provides an encoding function which can be used to infer unseen words or phrases. This becomes a clear advantage compared to predictive models which must train these new words."
Word Embeddings for Morphologically Complex Languages,Grzegorz Jurdzinski,Schedae Informaticae,"machine learning, word embeddings, natural language processing, morphology","Recent methods for learning word embeddings, like GloVe or Word2Vec, succeeded in spatial representation of semantic and syntactic relations. We extend GloVe by introducing separate vectors for base form and grammatical form of a word, using morphosyntactic dictionary for this. This allows vectors to capture properties of words better. We also present model results for word analogy test and introduce a new test based on WordNet."
Misspelling Oblivious Word Embeddings,"Bora Edizel, Aleksandra Piktus, PiotrBojanowski, Rui Ferreira, EdouardGrave, Fabrizio Silvestri",arXiv,,"In this paper we present a method to learn word embeddings that are resilient to misspellings. Existing word embeddings have limited applicability to malformed texts, which contain a non-negligible amount of out-of-vocabulary words. We propose a method combining FastText with subwords and a supervised task of learning misspelling patterns. In our method, misspellings of each word are embedded close to their correct variants. We train these embeddings on a new dataset we are releasing publicly. Finally, we experimentally show the advantages of this approach on both intrinsic and extrinsic NLP tasks using public test sets."
From Characters to Words to in Between: Do We Capture Morphology?,"Clara Vania, Adam Lopez",arXiv,,"Words can be represented by composing the representations of subword units such as word segments, characters, and/or character n-grams. While such representations are effective and may capture the morphological regularities of words, they have not been systematically compared, and it is not understood how they interact with different morphological typologies. On a language modeling task, we present experiments that systematically vary (1) the basic unit of representation, (2) the composition of these representations, and (3) the morphological typology of the language modeled. Our results extend previous findings that character representations are effective across typologies, and we find that a previously unstudied combination of character trigram representations composed with bi-LSTMs outperforms most others. But we also find room for improvement: none of the character-level models match the predictive accuracy of a model with access to true morphological analyses, even when learned from an order of magnitude more data."
An Unsupervised Approach to Relatedness Analysis of Legal Language,Ying Wang,University of Waterloo,,"Learning distributed representations of sentences and analyzing semantic similarity between sentences is one of the essential works in the field of Natural Language Processing. In the domain of legal language, the future of Artificial Intelligence-related legal-tech applications is very promising. This thesis comprises a very detailed investigation of distributional representations of words and sentences, and the related machine learning and deep learning techniques. Then, we proposed an innovative approach, Word2Sent, for measuring the degree of similarity between sentences. The proposed model is completely in an unsupervised manner. Thus, it can be well applied with unlabeled data. An enhancement of the other unsupervised sentence embeddings model, SIF-model, is made by this thesis. Demonstrated by multiple experiments, our proposed model can effectively work with long legal sentences on several textual similarity tasks."
Integrating Semantic Knowledge into Lexical Embeddings Based on Information Content Measurement,"Hsin-Yang Wang, Wei-Yun Ma",ACL,,"Distributional word representations are widely used in NLP tasks. These representations are based on an assumption that words with a similar context tend to have a similar meaning. To improve the quality of the context-based embeddings, many researches have explored how to make full use of existing lexical resources. In this paper, we argue that while we incorporate the prior knowledge with context-based embeddings, words with different occurrences should be treated differently. Therefore, we propose to rely on the measurement of information content to control the degree of applying prior knowledge into context-based embeddings - different words would have different learning rates when adjusting their embeddings. In the result, we demonstrate that our embeddings get significant improvements on two different tasks: Word Similarity and Analogical Reasoning."
Clustering Decision Makers with respect to similarity of views,"Edward Abel, Ludmil Mikhailov, John A.Keane",IEEE,"Multi-criteria decision making, Pairwise comparison, Inconsistency, Multi-objective optimization, Genetic algorithms, Clustering","Within a large group of decision makers, varying amounts of both conflicting and harmonious views will be prevalent within the group, but obscured due to group size. When the number of Decision Makers is large, utilizing clustering during the process of aggregation of their views should aid both knowledge discovery - about the group's conflict and consensus - as well as helping to streamline the aggregation process to reach a group consensus. We conjecture that this can be realized by using the similarity of views of a large group of decision makers to define clusters of analogous opinions. From each cluster of decision makers, a representation of the views of its members can then be sought. This set of representations can then be utilized for aggregation to help reach a final whole group consensus."
Group aggregation of pairwise comparisons using multi-objective optimization,"Edward Abel, Ludmil Mikhailov, John A.Keane",Information Sciences,"Group decision making, Pairwise comparison, Multi-criteria decision making, Inconsistency, Multi-objective optimization, Genetic algorithm","In group decision making, multiple decision makers (DMs) aim to reach a consensus ranking of alternatives in a decision problem. The differing expertise, experience and, potentially conflicting, interests of the DMs will result in the need for some form of conciliation to achieve consensus. Pairwise comparisons are commonly used to elicit values of preference of a DM. The aggregation of the preferences of multiple DMs must additionally consider potential conflict between DMs and how these conflicts may result in a need for compromise to reach group consensus. We present an approach to aggregating the preferences of multiple DMs, utilizing multi-objective optimization, to derive and highlight underlying conflict between the DMs when seeking to achieve consensus. Extracting knowledge of conflict facilitates both traceability and transparency of the trade-offs involved when reaching a group consensus. Further, the approach incorporates inconsistency reduction during the aggregation process to seek to diminish adverse effects upon decision outcomes. The approach can determine a single final solution based on either global compromise information or through utilizing weights of importance of the DMs. Within multi-criteria decision making, we present a case study within the Analytical Hierarchy Process from which we derive a richer final ranking of the decision alternatives."
Reducing Inconsistency in Pairwise Comparisons Using Multi-objective Evolutionary Computing,"Edward Abel, Ludmil Mikhailov, John A.Keane",IEEE,"Decision analysis, Inconsistency, Evolutionary computing, Genetic algorithmns, Multi-objective optimiszation","Pair wise comparisons are commonly used to estimate values of preference among a finite set of decision alternatives with regards to intangible factors. Inconsistency within decision making judgments may occur. This work proposes an approach to reducing inconsistency using multi-objective optimization with the objectives of different inconsistency types and judgment modification measures. The approach allows the decision maker to choose both the inconsistency measure(s) and the modification measure(s) employed to suit their needs and attitudes. Utilizing multi-objective optimization allows for a range of possible tradeoff solutions to be presented to the decision maker for selection, aiding them in their pursuit of inconsistency reduction. It also enables better understanding of the characteristics of the decision problem and its inconsistency."
Inconsistency reduction in decision making via multi-objective optimisation,"Edward Abel, Ludmil Mikhailov, John A.Keane",European Journal of Operational Research,"Multi criteria analysis, Pairwise comparisons, Inconsistency, Multi-objective optimization, Analytic hierarchy process","Within Multi-Criteria Decision Analysis (MCDA), pairwise comparison facilitates a separation of concerns helping to accurately represent a decision maker's preferences. Inconsistency within a set of pairwise comparisons has adverse effects upon the accuracy of the preferences derived from them. Inconsistency within pairwise comparisons is almost inevitable, hence consideration of its reduction is essential. This paper presents INSITE, an approach to inconsistency reduction within a set of pairwise comparisons via multi-objective optimisation. When seeking to reduce inconsistency within a set of pairwise comparisons there is a trade-off between alteration to the comparisons and the reduction of inconsistency within them. For such trade-offs no trade-off solution is superior per se to the others. Therefore, INSITE seeks to optimally reduce inconsistency within a set of comparisons by modelling inconsistency and alteration as separate objectives. In this way the nature of the trade-offs between inconsistency reduction and alteration are revealed, thus better informing a decision maker's awareness and knowledge of the problem and increasing validity of outcomes by providing a more evidential, transparent, auditable and traceable process. In this way a decision maker can look to make a more informed choice of the level of trade-off that is most suitable for them. INSITE is flexible regarding how inconsistency within judgments is measured; alteration to a decision maker's views is modelled via fine-grained measures of compromise that seek to be meaningful and relevant. Furthermore, the approach allows a decision maker to set constraints on both inconsistency and measures of compromise objectives."
Preference similarity network structural equivalence clustering based consensus group decision making model,"Nor Hanimah Kamis, FranciscoChiclana, Jeremy Levesley",Applied Soft Computing,"Consensus group decision making, Social network analysis, Opinion similarity, Structural equivalence, Agglomerative hierarchical clustering, IOWA-based aggregation operator","Social network analysis (SNA) methods have been developed to analyse social structures and patterns of network relationships, although they have been least explored and/or exploited purposely for decision-making processes. In this study, we bridge a gap between SNA and consensus-based decision making by defining undirected weighted preference network from the similarity of expert preferences using the concept of ‘structural equivalence’. Structurally equivalent experts are represented using the agglomerative hierarchical clustering algorithm with complete link function, thus intra-clusters’ experts are high in density and inter-clusters’ experts are rich in sparsity. We derive cluster consensus based on internal and external cohesions, while group consensus is obtained by identifying the highest level consensus at optimal level of clustering. Thus, the clustering based approach to consensus measure contributes to present homogeneity of experts preferences as a whole. In the event of insufficient group consensus state, we construct a feedback mechanism procedure based on clustering that consists of three main phases: (1) identification of experts that contribute less to consensus; (2) identification of a leader in the network; and (3) advice generation. We make use of the centrality concept in SNA as a way of determining the most important person in a network, who is presented as a leader to provide advices in the feedback process. It is proved that the implementation of the proposed feedback mechanism increases consensus and, because of the bounded condition of consensus measure, convergence to sufficient group agreement is guaranteed. The centrality concept is also applied in the construction of a new aggregation operator, namely as cent-IOWA operator, that is used to derive the collective preference relation from which the feasible alternative of consensus solution, based on the concept of dominance, is achieved according to a majority of the central experts in the network, which is represented in this paper by the linguistic quantifier ‘most of.’ For validation purposes, an existing literature study is used to perform a comparative analysis from which conclusions are drawn and explained."
Synergy: A Workbench for Collaborative Filtering Algorithms on User Interaction Data,"Babar Khan Tareen, Jaewon Lee, Sang-goo Lee",ACM,"Collaborative filtering, Recommender systems, Information retrieval","Collaborative Filtering (CF) is a process used by many recommender systems for recommending content based on similarities between users. CF traditionally used item purchase history or rating information only, for finding out similar users. Nowadays users interact with the content in many different ways. Users can rate, tag, like, dislike or subscribe to the content and some information about relationship between users is also available usually in social network form. This additional interaction information can be used to filter out similar users more effectively. Various CF algorithms have been proposed to take into account this additional information and suggest better content. But it is very hard to figure out which algorithm will work best on a particular dataset. In this paper, we propose a generic data model, for storing user interaction data, which can easily support many collaborative filtering algorithms. We have also implemented a tool which assists in creating, running and comparing different collaborative filtering algorithms. The tool is based on the proposed data model and can easily be extended by using plugins. It is helpful in figuring out which algorithm works best on a particular domain."
Preference elicitation from pairwise comparisons for traceable multi-criteria decision making,Edward Abel,University of Manchester,,"For many decisions validation of their outcomes is invariably problematic to objectively assess. Therefore to aid analysis and validation of decision outcomes, approaches which provide improved traceability and more semantically meaningful measurements of the decision process are required. Hence, this research investigates traceability, transparency, interactivity and auditability to improve the decision making process. Approaches and evaluation measures are proposed to facilitate a richer decision making experience. Multi-Criteria Decision Analysis (MCDA) seeks to determine the suitability of alternatives of a goal with respect to multiple criteria. A key component of prominent MCDA methods is the concept of pairwise comparison. For a set of elements, pairwise comparison enables an accurate and transparent extraction and codification of a decision maker’s preferences, though facilitating a separation of concerns. From a set of pairwise comparisons, a ranking of the elements under consideration can be calculated. There are scenarios when a set of pairwise comparisons undergo alteration, both for individual and multiple decision makers. A set of measures of compromise are proposed to quantify the alteration that a set of pairwise comparisons undergo in such scenarios. The measures seek to provide a decision maker with meaningful knowledge regarding how their views have altered. A set of pairwise comparisons may be inconsistent. When inconsistency is present it adversely affects a ranking of the elements derived from the comparisons. Moreover inconsistency within pairwise comparisons used for consideration of more than a handful of elements is almost inevitable. Existing approaches that seek to alter a set of comparisons to reduce inconsistency lack traceability, flexibility, and specific consideration of alteration to the judgments in a way that is meaningful to a decision maker. An approach to inconsistency reduction is proposed that seeks to address these issues. For many decisions the opinions of multiple decision makers are utilized, either to avail of their combined expertise or to incorporate conflicting views. Aggregation of multiple decision makers’ pairwise companions seek to combine the views of the group into a single representation of views. An approach to group aggregation of pairwise comparisons is proposed that models compromise between the decision makers, facilitates decision maker constraints, considers inconsistency reduction during aggregation and dynamically incorporates decision maker weights of importance. With internet access becoming widespread being able to garner the views of a large group of decision makers’ views has become feasible. An approach to the aggregation of a large group of decision makers’ preferences is proposed. The approach facilitates understanding regarding both the agreement and conflict within the group during calculation of an overall group consensus. A Multi-Objective Optimisation Decision Software (MOODS) prototype tool has been developed that implements both the new measures of compromise and the proposed approaches to inconsistency reduction and group aggregation."
Eye color and sex: Their relationship to modeled learning.,"A. L. Gary, John A. Glover","Psychotherapy: Theory, Research & Practice",,"Studied the relationship between eye color and sex to modeled learning in 25 male and 25 female college students, divided about equally between light-eyed and dark-eyed. Ss were randomly assigned to 3 experimental and 2 control groups. All Ss were administered the Unusual Uses Test (UUT), then the treatment procedures, and then the UUT again. Under the experimental treatments, Group 1 listened to a tape of a model who gave an extremely high number of uses for the object to which the Ss had just responded; Group 2 heard only a few uses for the object; and Group 3 listened to a recording of their own voices reading their own list of uses. Control Group 1 listened to taped music as a treatment, and Group 2 was left in a sound-proof room. The differences in response frequency were used as the dependent variable. The main effect for groups was significant. Main effects for eye color and sex were not significant; however, 2 of the 1st-order interactions were significant: Groups × Sex and Groups × Eye color. It appears that the efficacy of modeling also is extendable to situations in which an increase in creative behavior is the objective. The frequency of production goes up in positive relation to the frequency of responses modeled. The self-modeling treatment has either a neutral or a negative effect on level of responses, depending on eye color. Dark-eyed Ss were markedly negative in their production of creative responses in relation to their baseline measures after exposure to their own responses. (23 ref)"
Contribution of individual judgments toward inconsistency in pairwise comparisons,"Sajid Siraj, Ludmil Mikhailov, John A.Keane",European Journal of Operational Research,"Decision support systems, Multi-criteria decision making, Pairwise comparison, Intuitionistic preference modeling, Analytic hierarchy process","Pairwise comparison (PC) is a well-established method to assist decision makers in estimating their preferences. In PCs, the acquired judgments are used to construct a PC matrix (PCM) that is used to check whether the inconsistency in judgments is acceptable or requires revision. The use of Consistency Ratio (CR)—a widely used measure for inconsistency—has been widely debated and the literature survey has identified a need for a more appropriate measure. Considering this need, a new measure, termed congruence, is proposed in this paper. The measure is shown to be useful in finding the contribution of individual judgments toward overall inconsistency of a PCM and, therefore, can be used to detect and correct cardinally inconsistent judgments. The proposed measure is applicable to incomplete sets of PC judgments without modification, unlike CR which requires a complete set of PC judgments. To address ordinal inconsistency, another measure termed dissonance, is proposed as a supplement to the congruence measure. The two measures appear useful in detecting both outliers and the phenomenon of consistency deadlock where all judgments equally contribute toward the overall inconsistency."
Consensus in Group Decision Making and Social Networks,"Enrique Herrera-Viedma, FranciscoJavier Cabrerizo, Francisco Chiclana,Jian Wu, Manuel Jesus Cobo,Samuylov Konstantin",Studies in Informatics and Control,"Consensus, Group decision making, Social networks","The consensus reaching process is the most important step in a group decision making scenario. This step is most frequently identified as a process consisting of some discussion rounds in which several decision makers, which are involved in the problem, discuss their points of view with the purpose of obtaining the maximum agreement before making the decision. Consensus reaching processes have been well studied and a large number of consensus approaches have been developed. In recent years, the researchers in the field of decision making have shown their interest in social networks since they may be successfully used for modelling communication among decision makers. However, a social network presents some features differentiating it from the classical scenarios in which the consensus reaching processes have been applied. The objective of this study is to investigate the main consensus methods proposed in social networks and bring out the new challenges that should be faced in this research field."
Consensus decision models for preferential voting with abstentions,"Zaiwu Gong, Ning Zhang, Kevin W. Li,Luis Martínez, Wei Zhao",Computers & Industrial Engineering,"Group decision making, Consensus, Preferential voting, Data envelopment analysis (DEA)","Proper use of the data envelopment analysis (DEA) for aggregating preferential rankings helps improve efficiency of a voting system. It has been observed that many recent elections often have low turnouts, a large number of abstentions and invalid ballots. If these voters can be influenced to cast their votes for or against a candidate, it is understandable that the voting result can be quite different. The purpose of this research is to incorporate abstentions into preferential voting models. To this end, we first introduce a preferential voting DEA model with abstentions, in which the raw votes are expressed as interval values and the width of the interval characterizes the number of uncertain votes, the objective function is to maximize a candidate’s weighted voting score, and the constraints put restrictions on the place weights to ensure a proper importance order of different places. Secondly, given the fact that opinion leaders often employ different means such as social media and advertisement to influence voters in real-world elections, we explicitly incorporate these opinion leaders/brokers as a moderator into a preferential voting model with abstentions and introduce a moderator-involved-consensus preferential voting (MICPV) model. This model aims to capture the moderator’s influences on the uncertain voters from a consensus perspective. The optimal allocation of all uncertain votes allows the moderator to maximize his/her influence over the voters to achieve the minimum deviation between his/her expected and the aggregate scores of the candidates. At the optimality, for those candidates where a complete consensus is achievable, the model identifies the optimal allocation scheme. We also analyze the economic significance of the MICPV model."
Approaches to improving consistency of interval fuzzy preference relations,"Wu-yong Qian, Kevin W. Li, Zhou-JingWang",Journal of Systems Science and Systems Engineering,"Interval fuzzy preference relation, additive consistency, acceptable consistency, weak transitivity, decision making","This article introduces a consistency index for measuring the consistency level of an interval fuzzy preference relation (IFPR). An approach is then proposed to construct an additive consistent IFPR from a given inconsistent IFPR. By using a weighted averaging method combining the original IFPR and the constructed consistent IFPR, a formula is put forward to repair an inconsistent IFPR to generate an IFPR with acceptable consistency. An iterative algorithm is subsequently developed to rectify an inconsistent IFPR and derive one with acceptable consistency and weak transitivity. The proposed approaches can not only improve consistency of IFPRs but also preserve the initial interval uncertainty information as much as possible. Numerical examples are presented to illustrate how to apply the proposed approaches."
Analysis of New Aggregation Operators: Mean 3 Π,"Andrei Doncescu, Sébastien Régis,Katsumi Inoue, Richard Emilion",Journal of Advanced Computational Intelligence and Intelligent Informatics,"fusion, mean operators, clustering","Knowledge based systems need to deal with aggregation and fusion of data with uncertainty. To use many sources of information in numerical forms for the purpose of decision or conclusion, systems suppose to have tools able to represent the knowledge in a mathematical form. One of the solutions is to use fuzzy logic operators. We present in this article an improvement of the triple Π operator introduced by Yager and Rybalov, which is called mean 3Π. Whereas triple Π is an operator completely reinforced, the presented operator is a mean operator, which makes it more robust to noise."
Simulation Experiments for Improving the Consistency Ratio of Reciprocal Matrices,"Daji Ergu, Gang Kou, Yi Peng, XinfengYang",International Journal of Computers Communication & Control ,"Reciprocal random matrix, Consistency ratio, induced bias matrix, simu-lation experiment; analytic hierarchy process (AHP)/analytic network  process (ANP)","The consistency issue is one of the hot research topics in the analytichierarchy process (AHP) and analytic network process (ANP). To identify the mostinconsistent elements for improving the consistency ratio of a reciprocal pairwisecomparison matrix (PCM), a bias matrix can be induced to efficiently identify themost inconsistent elements, which is only based on the original PCM. The goal of thispaper is to conduct simulation experiments by randomly generating millions numbersof reciprocal matrices with different orders in order to validate the effectiveness ofthe induced bias matrix model. The experimental results show that the consistencyratios of most of the random inconsistent matrices can be improved by the inducedbias matrix model, few random inconsistent matrices with high orders failed theconsistency adjustment."
A heuristic method to rectify intransitive judgments in pairwise comparison matrices,"Sajid Siraj, Ludmil Mikhailov, John A.Keane",Technological and Economic Development of Economy,"Analytical Hierarchy Process (AHP), Analytical Network Process (ANP), consistency, pairwise comparison matrix (PCM), missing judgment estimation, priority derivation, multicriteria decision-making (MCDM)","The measurement scales, consistency index, inconsistency issues, missing judgment estimation and priority derivation methods have been extensively studied in the pairwise comparison matrix (PCM). Various approaches have been proposed to handle these problems, and made great contributions to the decision making. This paper reviews the literature of the main developments of the PCM. There are plenty of literature related to these issues, thus we mainly focus on the literature published in 37 peer reviewed international journals from 2010 to 2015 (searched via ISI Web of science). We attempt to analyze and classify these literatures so as to find the current hot research topics and research techniques in the PCM, and point out the future directions on the PCM. It is hoped that this paper will provide a comprehensive literature review on PCM, and act as informative summary of the main developments of the PCM for the researchers for their future research."
Enhancing data consistency in decision matrix: Adapting Hadamard model to mitigate judgment contradiction,"Gang Kou, Daji Ergu, Jennifer Shang",European Journal of Operational Research,"Multiple criteria analysis, Hadamard product induced bias matrix, Pairwise comparison matrix, Cardinal and ordinal inconsistency, Graph theory","Cardinal and ordinal inconsistencies are important and popular research topics in the study of decision making with pair-wise comparison matrices (PCMs). Few of the currently-employed tactics are capable of simultaneously dealing with both cardinal and ordinal inconsistency issues in one model, and most are heavily dependent on the method chosen for weight (priorities) derivation or the obtained closest matrix by optimization method that may change many of the original values. In this paper, we propose a Hadamard product induced bias matrix model, which only requires the use of the data in the original matrix to identify and adjust the cardinally inconsistent element(s) in a PCM. Through graph theory and numerical examples, we show that the adapted Hadamard model is effective in identifying and eliminating the ordinal inconsistencies. Also, for the most inconsistent element identified in the matrix, we develop innovative methods to improve the consistency of a PCM. The proposed model is only dependent on the original matrix, is independent of the methods chosen to derive the priority vectors, and preserves most of the original information in matrix A since only the most inconsistent element(s) need(s) to be modified. Our method is much easier to implement than any of the existing models, and the values it recommends for replacement outperform those derived from the literature. It significantly enhances matrix consistency and improves the reliability of PCM decision making."
A visual interaction consensus model for social network group decision making with trust propagation,"Jian Wu, Francisco Chiclana, HamidoFujita, Enrique Herrera-Viedma",Knowledge-Based Systems,"Social network group decision making, Visual interaction, Consensus, Trust recommendation, Adoption mechanism, Trust propagation","A theoretical visual interaction framework to model consensus in social network group decision making (SN-GDM) is put forward with following three main components: (1) construction of trust relationship; (2) trust based recommendation mechanism; and (3) visual adoption mechanism. To do that, dual trust propagation is investigated to connect incomplete trust relationship by trusted third partners, in a way that it can fit our intuition in these cases: trust values decrease while distrust values increase. Trust relationship is proposed to be used in determining the trust degree of experts and in aggregating individual opinions into a collective one. Three levels of consensus degree are defined and used to identify the inconsistent experts. A trust based recommendation mechanism is developed to generate advices according to individual trust relationship, making recommendations more likeable to be implemented by the inconsistent experts to achieve higher levels of consensus. Therefore, it has an advantage with respect to existing interaction models because it does not force the inconsistent experts to accept advices irrespective of their trust on them. Finally, a visual adoption mechanism, which provides visual information representations on experts’ individual consensus positions before and after adopting the recommendation advices, is presented and analysed theoretically. Experts can select their appropriate feedback parameters to achieve a balance between group consensus and individual independence. Consequently, the proposed visual interaction model adds real and needed flexibility in guiding the consensus reaching process in SN-GDM."
Group decision-making based on heterogeneous preference relations with self-confidence,"Wenqi Liu, Yucheng Dong, FranciscoChiclana, Francisco Javier Cabrerizo,Enrique Herrera-Viedma",Fuzzy Optimization and Decision Making ,"Preference relations, Self-confidence levels, Collective preference vector, Linear programming model","Preference relations are very useful to express decision makers’ preferences over alternatives in the process of group decision-making. However, the multiple selfconfidence levels are not considered in existing preference relations. In this study, we define the preference relation with self-confidence by taking multiple self-confidence levels into consideration, and we call it the preference relation with self-confidence. Furthermore, we present a two-stage linear programming model for estimating the collective preference vector for the group decision-making based on heterogeneous preference relations with self-confidence. Finally, numerical examples are used to illustrate the two-stage linear programming model, and a comparative analysis is carried out to show how self-confidence levels influence on the group decision-making results."
"Suicidal ideation and behavior in adults with major depressive disorder treated with vortioxetine: post hoc pooled analyses of randomized, placebo-controlled, short-term and open-label, long-term extension trials.","Atul R. Mahableshwarkar, John Affinito,Elin Heldbo Reines, Judith Xu, GeorgeNomikos, Paula L Jacobsen",CNS Spectrums,"Antidepressant, Columbia-Suicide Severity Rating Scale (C-SSRS), depression, suicidal behavior, suicidal ideation, suicide, vortioxetine","This study aimed to evaluate the risk of suicidal ideation and behavior associated with vortioxetine treatment in adults with major depressive disorder (MDD). Suicide-related events were evaluated post hoc using 2 study pools: one short-term pool of 10 randomized, placebo-controlled studies (6–8 weeks) and another long-term pool that included 3 open-label extension studies (52 weeks). Evaluation of suicide-related events was performed using Columbia-Suicide Severity Rating Scale (C-SSRS) scores and treatment-emergent adverse events (TEAEs) data. At baseline, the percentage of patients reporting any C-SSRS ideation or behavior events in short-term studies was similar between placebo (14.7%), vortioxetine (19.8%, 13.0%, 11.2%, and 13.7% for 5-, 10-, 15-, and 20-mg groups, respectively), and duloxetine active reference (13.2%) and did not change throughout the 6- to 8-week treatment period for placebo (17.0%), vortioxetine (19.3%, 13.5%, 12.6%, and 15% for 5-, 10-, 15-, and 20-mg groups, respectively), or duloxetine (11.3%). The incidence of suicide-related events for TEAEs in the short-term pool was 0.4% for placebo, 0.2% or 1.0% for vortioxetine 5 mg or 10 mg, and 0.7% each for vortioxetine 15 mg and 20 mg, as well as duloxetine. After 52-week treatment with vortioxetine, suicidal ideation based on C-SSRS was 9.8%, C-SSRS suicidal behavior was 0.2%, and the incidence of suicide-related events based on TEAEs was <1%. There were no completed suicides in any study.Vortioxetine is not associated with increased risk of suicidal ideation or behavior in MDD patients."
Introduction to the Special Issue on Language in Social Media: Exploiting Discourse and Other Contextual Information,"Farah Benamara, Diana Inkpen, MaiteTaboada",ACL,,"Social media content is changing the way people interact with each other and share information, personal messages, and opinions about situations, objects, and past experiences. Most social media texts are short online conversational posts or comments that do not contain enough information for natural language processing (NLP) tools, as they are often accompanied by non-linguistic contextual information, including meta-data (e.g., the user’s profile, the social network of the user, and their interactions with other users). Exploiting such different types of context and their interactions makes the automatic processing of social media texts a challenging research task. Indeed, simply applying traditional text mining tools is clearly sub-optimal, as, typically, these tools take into account neither the interactive dimension nor the particular nature of this data, which shares properties with both spoken and written language. This special issue contributes to a deeper understanding of the role of these interactions to process social media data from a new perspective in discourse interpretation. This introduction first provides the necessary background to understand what context is from both the linguistic and computational linguistic perspectives, then presents the most recent context-based approaches to NLP for social media. We conclude with an overview of the papers accepted in this special issue, highlighting what we believe are the future directions in processing social media texts."
Fuzzy decision making and consensus: Challenges,"Francisco Javier Cabrerizo, FranciscoChiclana, Rami Al-Hmouz, Ali Morfeq,Abdullah Saeed Balamash, EnriqueHerrera-Viedma",Journal of Intelligent & Fuzzy Systems,"Group decision making, consensus, fuzzy set theory, fuzzy logic","Group decision making is part of every organizational life. It is a type of participatory process in which multiple decision makers acting collectively, analyze problems, consider and evaluate several alternatives, and select from among the alternatives a solution. In such a situation, an important issue is the level of agreement or consensus achieved among the group of decision makers before obtaining the solution. In the beginning, consensus was meant as a full and unanimous agreement. Regrettably, this stringent concept of consensus in many cases is a utopia. As a result, and from a pragmatic point of view, it makes more sense to speak about a degree of consensus and, here, the theory of fuzzy sets has delivered new tools for the analysis of such imprecise phenomena like consensus. Given the significance of reaching an accepted solution by all the decision makers, consensus is a major aim of group decision making problems and, in such a way, it has obtained a great attention in the literature. However, there still exist several dares which have to be tackled by the researchers. The purpose of this paper is to bring out several issues that represent challenges that have to be faced."
"Performance management: Appraising performance, providing feedback, and developing for creativity","Ginamarie Ligon, Katrina A. Graham, A.M. Edwards, Holly K. Osburn, SamuelTodd Hunter",Handbook of Organizational Creativity,,"Appraising and developing, both integral components of performance management are complicated endeavors for innovation. At all levels of the organization, employees face some type of performance evaluation. There are three related processes to describe activities associated with these formal evaluations. Performance appraisal is the process of assessing or evaluating performance to make decisions (e.g., about promotions). Performance development refers to the evaluation of performance with the goal of providing feedback and suggesting developmental activities to improve that performance. Performance management (PM) is the integration of the two in order to make performance-based decisions and improve organizational performance. Performance management consists of two central purposes (Murphy & Cleveland, 1995), and each has potential to enhance (or lessen) innovation. One PM objective is to align employee behaviors with the overarching goals of the organization. Since a key step in performance management involves the setting and evaluation of work goals, one would expect that organizations with more innovative missions would also have PM systems that encourage individual behavior toward this high-level objective."
A trust induced recommendation mechanism for reaching consensus in group decision making,"Yujia Liu, Changyong Liang, FranciscoChiclana, Jian Wu",Knowledge-Based Systems,"Group decision making, Recommendation mechanism, Group consensus, Trust degree, Harmony degree","This article addresses the inconsistency problem in group decision making caused by disparate opinions of multiple experts. To do so, a trust induced recommendation mechanism is investigated to generate personalised advices for the inconsistent experts to reach higher consensus level. The concept of trust degree (TD) is defined to identify the trusted opinion from group experts, and then the visual trust relationship is built to help experts ‘see’ their own trust preferences within the group. Consequently, trust based personalised advices are generated for the inconsistent experts to revisit their opinions. To model the uncertainty of experts, an interval-valued trust decision making space is defined. It includes the novel concepts of interval-valued trust functions, interval-valued trust score (IVTS) and interval-valued knowledge degree (IVKD). The concepts of consensus degree (CD) between an expert and the rest of experts in the group as well as the harmony degree (HD) between the original opinion and the revised opinion are developed for interval-valued trust functions. Combining HD and CD, a more reasonable policy for group consensus is proposed as it should arrive at the threshold value with the maximum value of harmony and consensus degrees simultaneously. Furthermore, because the trust induced recommendation mechanism focuses on changing inconsistent opinions using only opinions from the trusted experts and not from the distrusted ones, the HD based changes cost to reach the threshold value of consensus is lower than previous mechanisms based on the average of the opinion of all experts. Finally, once consensus has been achieved, a ranking order relation for interval-valued trust functions is constructed to select the most appropriate alternative."
A General Version of the Triple Π Operator,"Richard Emilion, Sébastien Régis,Andrei Doncescu",International Journal of Intelligent Systems ,,"Recent developments of sensors and computers have raised the problem of handling huge amounts of complex data that users try to synthesize for decision making. Aggregation operators, such as those appearing in fuzzy sets theory, are useful tools for this synthesis but in their present formulation, these operators only deal with a finite set of arguments. In this paper, we introduce G3, an extension of both Yager–Rybalov Triple and Mean Triple operators to general measure spaces that can deal with temporal or spatiotemporal intensive data streams. Known properties and inequalities are extended in this more general setting. The notion of moving G3 is also introduced and it can be applied to a solar radiation data stream. This may lead to further works on data fusion and on similar extensions of some other operators. C 2013 Wiley Periodicals, Inc."
Ordinal proximity measures in the context of unbalanced qualitative scales and some applications to consensus and clustering,"José Luis García-Lapresta, David Pérez-Román",Applied Soft Computing,"Decision making, Qualitative scales, Proximity, Difference measurement, Consensus, Clustering","In this paper, we introduce ordinal proximity measures in the setting of unbalanced qualitative scales by comparing the proximities between linguistic terms without numbers, in a purely ordinal approach. With this new tool, we propose how to measure the consensus in a set of agents when they assess a set of alternatives through an unbalanced qualitative scale. We also introduce an agglomerative hierarchical clustering procedure based on these consensus measures."
Trust based consensus model for social network in an incomplete linguistic information context,"Jian Wu, Francisco Chiclana, EnriqueHerrera-Viedma",Applied Soft Computing,"Social network, Multiple criteria group decision making, Trust propagation, Trust aggregation, Visual feedback, Incomplete linguistic information","A theoretical framework to consensus building within a networked social group is put forward. This article investigates a trust based estimation and aggregation methods as part of a visual consensus model for multiple criteria group decision making with incomplete linguistic information. A novel trust propagation method is proposed to derive trust relationship from an incomplete connected trust network and the trust score induced order weighted averaging operator is presented to aggregate the orthopairs of trust/distrust values obtained from different trust paths. Then, the concept of relative trust score is defined, whose use is twofold: (1) to estimate the unknown preference values and (2) as a reliable source to determine experts’ weights. A visual feedback process is developed to provide experts with graphical representations of their consensus status within the group as well as to identify the alternatives and preference values that should be reconsidered for changing in the subsequent consensus round. The feedback process also includes a recommendation mechanism to provide advice to those experts that are identified as contributing less to consensus on how to change their identified preference values. It is proved that the implementation of the visual feedback mechanism guarantees the convergence of the consensus reaching process."
A bipolar consensus approach for group decision making problems,"Yasmina Bouzarour-Amokrane, AyeleyP. Tchangani, François Pérès",Expert Systems with Applications,"Group decision making (GDM), Consensus process, Bipolarity, Concordance, Discordance, Influence","This paper addresses the collaborative group decision making problems considering a consensus processes to achieve a common legitimate solution. The proposed resolution model is based on individual bipolar assessment. Each decision maker evaluates alternatives through selectability and rejectability measures which respectively represent the positive and negative aspects of alternatives considering objectives achievement. The impact of human behavior (influence, individualism, fear, caution, etc.) on decisional capacity has been taken into account. The influence degrees exerted mutually by decision makers are modeled through concordance and discordance measures. The individualistic nature of decision makers has been taken into account from the individualism degree. In order to achieve a common solution(s), models of consensus building are proposed based on the satisficing game theory formalism for collective decision problems. An application example is given to illustrate the proposed concepts."
Prize: an R package for prioritization estimation based on analytic hierarchy process,Daryanaz Dargahi April,,,"The high throughput studies often produce large amounts of numerous genes and proteins of interest. While it is difficult to study and validate all of them. In order to narrow down such lists, one approach is to use a series of criteria to rank and prioritize the potential candidates based on how well they meet the research goal. Analytic hierarchy process (AHP) [1] is one of the most popular group decision-making techniques for ranking and prioritizing alternatives when multiple criteria must be considered. It provides a comprehensive and rational framework to address complicated decisions by modeling the problem in a hierarchical structure, showing the relationships of the goal, objectives (criteria and subcriteria), and alternatives. AHP has unique advantages when communication among team members is impeded by their different specializations or perspectives. It also enables decision makers to evaluate decision alternatives when important elements of the decision are difficult to quantify or compare. The AHP technique uses pairwise comparisons to measure the impact of items on one level of the hierarchy on the next higher level. It has two models for arriving at a ranking of alternatives. (A) The relative model, where alternatives are compared in a pairwise manner regarding their ability to achieve each of the criteria. (B) The rating model is often used when the number of alternatives is large, or if the possibility of adding or deleting alternatives exists [2]. This model requires establishing a series of rating scales (categories) for each criterion. These scales must be pairwise compared to determine the relative importance of each rating category, and then alternatives are evaluated one at a time by selecting the appropriate rating category for each criterion. Here, we introduce an R package for AHP, ”Prize”. Prize offers the implementation of both relative and rating AHP models. In order to rank and prioritize a set of alternatives with AHP, decision makers must take four steps: 1. Define the problem and determine the criteria, subcriteria, and alternatives 2. Structure the decision hierarchy 3. Construct pairwise comparison matrices 4. Estimate and visualize priorities In the following, we describe a brief example use case for Prize in translational oncology."
A consensus model for group decision making under interval type-2 fuzzy environment,"Xiao-Xiong Zhang, Bingfeng Ge, YuejinTan",Frontiers of Information Technology & Electronic Engineering,"Group decision making (GDM), Interval type-2 fuzzy sets (IT2 FSs), Feedback mechanism","We propose a new consensus model for group decision making (GDM) problems, using an interval type-2 fuzzy environment. In our model, experts are asked to express their preferences using linguistic terms characterized by interval type-2 fuzzy sets (IT2 FSs), because these can provide decision makers with greater freedom to express the vagueness in real-life situations. Consensus and proximity measures based on the arithmetic operations of IT2 FSs are used simultaneously to guide the decision-making process. The majority of previous studies have taken into account only the importance of the experts in the aggregation process, which may give unreasonable results. Thus, we propose a new feedback mechanism that generates different advice strategies for experts according to their levels of importance. In general, experts with a lower level of importance require a larger number of suggestions to change their initial preferences. Finally, we investigate a numerical example and execute comparable models and ours, to demonstrate the performance of our proposed model. The results indicate that the proposed model provides greater insight into the GDM process."
A minimum adjustment cost feedback mechanism based consensus model for group decision making under social network with distributed linguistic trust,"Jian Wu, Lifang Dai, FranciscoChiclana, Hamido Fujita, EnriqueHerrera-Viedma",Information Fusion,"Group decision making, Feedback mechanism, Minimum adjustment optimization model, Consensus, Social network analysis, Distributed linguistic trust","A theoretical feedback mechanism framework to model consensus in social network group decision making (SN-GDM) is proposed with following two main components: (1) the modelling of trust relationship with linguistic information; and (2) the minimum adjustment cost feedback mechanism. To do so, a distributed linguistic trust decision making space is defined, which includes the novel concepts of distributed linguistic trust functions, expectation degree, uncertainty degrees and ranking method. Then, a social network analysis (SNA) methodology is developed to represent and model trust relationship between a networked group, and the trust in-degree centrality indexes are calculated to assign an importance degree to the associated user. To identify the inconsistent users, three levels of consensus degree with distributed linguistic trust functions are calculated. Then, a novel feedback mechanism is activated to generate recommendation advices for the inconsistent users to increase the group consensus degree. Its novelty is that it produces the boundary feedback parameter based on the minimum adjustment cost optimisation model. Therefore, the inconsistent users are able to reach the threshold value of group consensus incurring a minimum modification of their opinions or adjustment cost, which provides the optimum balance between group consensus and individual independence. Finally, after consensus has been achieved, a ranking order relation for distributed linguistic trust functions is constructed to select the most appropriate alternative of consensus."
A comparative study on consensus measures in group decision making,"Maria José del Moral, FranciscoChiclana, Juan Miguel Tapia García,Enrique Herrera-Viedma",International Journal of Intelligent Systems,"consensus, decision support rules, fuzzy preferences, group decision making, similarity","Decision situations in which several individual are involved are known as group decision-making (GDM) problems. In such problems, each member of the group, recognizing the existence of a common problem, tries to come to a collective decision. A high level of consensus among experts is needed before reaching a solution. It is customary to construct consensus measures by using similarity functions to quantify the closeness of experts preferences. The use of a metric that describes the distance between experts preferences allows the definition of similarity functions. Different distance functions have been proposed in order to implement consensus measures. This paper examines how the use of different aggregation operators affects the level of consensus achieved by experts through different distance functions, once the number of experts has been established in the GDM problem. In this situation, the experimental study performed establishes that the speed of the consensus process is significantly affected by the use of diverse aggregation operators and distance functions. Several decision support rules that can be useful in controlling the convergence speed of the consensus process are also derived."
Consensus-based clustering under hesitant qualitative assessments,"José Luis García-Lapresta, David Pérez-Román",Fuzzy Sets and Systems,"Clustering, Consensus, Linguistic assessments","In this paper, we consider that agents judge the feasible alternatives through linguistic terms – when they are confident in their opinions – or linguistic expressions formed by several consecutive linguistic terms – when they hesitate. In this context, we propose an agglomerative hierarchical clustering process where the clusters of agents are generated by using a distance-based consensus measure."
Consensus Building for the Heterogeneous Large-Scale GDM With the Individual Concerns and Satisfactions,"Hengjie Zhang, Yucheng Dong, EnriqueHerrera-Viedma",IEEE TRANSACTIONS ON FUZZY SYSTEMS,"2-tuple linguistic model, consensus, heterogeneous preference representation structures, individual concerns, individual satisfactions, large-scale group decision-making (GDM)","Nowadays, societal and technological trends demand the management of large scale of decision makers in group decisionmaking (GDM) contexts. In a large-scale GDM, decision makers often have individual concerns and satisfactions, and also they will use heterogeneous preference representation structures to express their preferences. Meanwhile, it is difficult to set the numerical consensus threshold to judge whether a consensus degree can be acceptable or not in the consensus reaching process in a large-scale GDM. This study proposes a novel consensus reaching model for the heterogeneous large-scale GDM with the individual concerns and satisfactions. In this consensus reaching model, a selection process is proposed to obtain the individual preference vectors, to divide decision makers into different clusters, and to yield the preference vector of the large group. Following this, a consensus measure method that considers the individual concerns on alternatives is defined for measuring the consensus degree, and a linguistic approach is developed to measure the individual and collective satisfactions regarding the consensus degree. Finally, a feedback adjustment process is proposed and utilized to help decision makers adjust their preferences. A practical example and a simulation analysis are presented to demonstrate the validity of the proposed consensus reaching model."
A group decision-making method considering both the group consensus and multiplicative consistency of interval-valued intuitionistic fuzzy preference relations,"Shuping Wan, Feng Wang, Jiuying Dong",Information Sciences,"Interval-valued intuitionistic fuzzy preference relation, Group decision making, Multiplicative consistency, Group consensus","This paper investigates a group decision-making (GDM) method that considers group consensus and multiplicative consistency of interval-valued intuitionistic fuzzy (IVIF) preference relations (IVIFPRs). First, the mean and variance of IVIF values (IVIFVs) are defined and a ranking method for IVIFVs is proposed considering the risk attitude of the expert. Then, the group consensus is presented by the individual similarity between experts. An iteration algorithm is designed to improve the group consensus. A statistical comparative analysis validates this algorithm. Subsequently, a new multiplicative consistency of IVIFPR is defined based on the multiplicative consistency of interval fuzzy preference relation. Two single-objective programming models are established to extract the most optimistic and pessimistic interval priority weight vectors from an IVIFPR, respectively. In particular, if the feasible domains of these two models are empty, two adjusted programs are constructed to replace the originals. Combining the most optimistic and pessimistic interval priority weights, the IVIF priority weights are generated. Further, expert weights are derived from Markov model and used to derive the collective IVIFPR for generating the IVIF priority weights. Therefore, a new method is proposed to solve the GDM with IVIFPRs. Finally, two cases are analyzed to verify the effectiveness of the proposed method."
A new type of preference relations: Fuzzy preference relations with self-confidence,"Wenqi Liu, Yucheng Dong, FranciscoChiclana, Enrique Herrera-Viedma,Francisco Javier Cabrerizo",IEEE  ,Fuzzy preference relations; selfconfidence levels; priority vector; linear programming model,"Preference relations are very useful to express decision makers’ preferences over alternatives in the process of decision-making. However, multiple self-confidence levels are not considered in existing preference relations. In this study, we propose a new type of preference relations: fuzzy preference relations with self-confidence. A linear programming model is proposed for estimating priority vectors of this new type of preference relations. Finally, two numerical examples are provided to demonstrate the linear programming model, and a comparative analysis is used to show the influence of self-confidence levels on the decision-making results."
GDM-R: A new framework in R to support fuzzy group decision making processes,"Raquel Ureña, Francisco JavierCabrerizo, Juan Antonio Morente-Molinera, Enrique Herrera-Viedma",Information Sciences,"Group decision making, Fuzzy preference modeling, Software development, R","With the incorporation of web 2.0 frameworks the complexity of decision making situations has exponentially increased, involving in many cases a huge number of decision makers, and many different alternatives. In the literature we can find a great variety of methodologies to assist multi-person decision making. However these classical approaches are not suitable to deal with such complexity since there are no tools able to carry out automatically the decision making processes, providing graphical information about its evolution. The main objective of this contribution is to present an open source framework fully developed in R to carry out consensus guided decision making processes using fuzzy preference relations and providing mechanism to deal with missing information. The system includes tools to visualize the evolution of the decision making process and presents various operation modes, including a test operation one which automatically creates a customized decision scenario to validate, test and compare among various decision making approaches."
Visual Consensus Feedback Mechanism for Group Decision Making with Complementary Linguistic Preference Relations,"Francisco Chiclana, Jian Wu, EnriqueHerrera-Viedma",Modeling Decisions for Artifical Intelligence,"Group decisions making, Consensus, linguistic preferences, Visual feedback mechanism","A visual consensus feedback mechanism for group decision making (GDM) problems with complementary linguistic preference relations is presented. Linguistic preferences are modelled using triangular fuzzy membership functions, and the concepts of similarity degree (SD) between two experts as well as the proximity degree (PD) between an expert and the rest of experts in the group are defined and used to measure the consensus level (CL). A feedback mechanism is proposed to identify experts, alternatives and corresponding preference values that contribute less to consensus. The novelty of this feedback mechanism is that it provides experts with visual representations of their consensus status to easily ‘see’ their consensus position within the group as well as to identify the alternatives and preference values that should be reconsidered for changing in the subsequent consensus round. The feedback mechanism also includes individualised recommendations to those identified experts on changing their identified preference values and visual graphical simulation of future consensus status if the recommended values were to be implemented."
Consistency based estimation of fuzzy linguistic preferences. The case of reciprocal intuitionistic fuzzy preference relations,"Francisco Chiclana, Jian Wu, EnriqueHerrera-Viedma",IEEE,,"The decision-making assumption of all experts being able to express their preferences on all available alternatives of a decision-making problem might be considered unrealistic. This is specially true when the number of alternatives is considerable high and/or when sources of information are conflicting and dynamic. Thus, the presence of incomplete information, which is not equivalent to low quality information, is worth investigation and its processing within decision-making processes desirable. A consistency based approach to deal with incomplete fuzzy linguistic preferences is the focus of this contribution. Consistency is considered here as linked to the transitivity of preferences, and in particular to Tanino’s multiplicative transitivity property of reciprocal fuzzy preference relations. The first result presented is the formal modelling and representation of Tanino’s multiplicative transitivity property to the case of fuzzy linguistic preference relations. This is done via Zadeh’s extension principle and the representation theorem of fuzzy sets. The second result derives the multiplicative transitivity property of reciprocal intuitionistic fuzzy preference relations, which can be isomorphically mapped to a particular type of linguistic preference relation: reciprocal interval-valued fuzzy preference relations. The third result is the computation of the consistency based estimated reciprocal intuitionistic fuzzy preference values using an indirect chain of alternatives, which can be used to address incomplete information in decision-making problems with this type of preference relations."
Improving the Ordinal Inconsistency of Pairwise Comparison Matrices,"L. Mikhailov, Sajid Siraj",Proceedings of the 11th International Symposium on the AHP,"Pairwise Comparisons, Inconsistency, Non-transitive Judgements, Decision Analysis, Heuristics","This paper investigates the effects of non-transitive judgments on the consistency of pairwise comparison matrices and proposes a heuristic algorithm for identifying and eliminating their ordinal inconsistencies. The algorithm is based on graphical representation of the comparison matrices and identifies the edges in the digraph, which are mostly responsible for three-way cycles, representing the ordinal inconsistencies. The algorithm tries to minimize the number of edge reversals and provides results, similar to those obtained by an optimization method."
A review of soft consensus models in a fuzzy environment,"Enrique Herrera-Viedma, FranciscoJavier Cabrerizo, Janusz Kacprzyk,Witold Pedrycz",Information Fusion,"Group decision making, Consensus, Soft consensus measures, Fuzzy logic","In the consensus reaching processes developed in group decision making problems we need to measure the closeness among experts’ opinions in order to obtain a consensus degree. As it is known, to achieve a full and unanimous consensus is often not reachable in practice. An alternative approach is to use softer consensus measures, which reflect better all possible partial agreements, guiding the consensus process until high agreement is achieved among individuals. Consensus models based on soft consensus measures have been widely used because these measures represent better the human perception of the essence of consensus. This paper presents an overview of consensus models based on soft consensus measures, showing the pioneering and prominent papers, the main existing approaches and the new trends and challenges."
Knowledge Graph Embedding: A Survey of Approaches and Applications,"Qi-shan Wang, Zhendong Mao, BiwuWang, Li Guo",IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING,"Statistical relational learning, knowledge graph embedding, latent factor models, tensor/matrix factorization models","Knowledge graph (KG) embedding is to embed components of a KG including entities and relations into continuous vector spaces, so as to simplify the manipulation while preserving the inherent structure of the KG. It can benefit a variety of downstream tasks such as KG completion and relation extraction, and hence has quickly gained massive attention. In this article, we provide a systematic review of existing techniques, including not only the state-of-the-arts but also those with latest trends. Particularly, we make the review based on the type of information used in the embedding task. Techniques that conduct embedding using only facts observed in the KG are first introduced. We describe the overall framework, specific model design, typical training procedures, as well as pros and cons of such techniques. After that, we discuss techniques that further incorporate additional information besides facts. We focus specifically on the use of entity types, relation paths, textual descriptions, and logical rules. Finally, we briefly introduce how KG embedding can be applied to and benefit a wide variety of downstream tasks such as KG completion, relation extraction, question answering, and so forth."
Deep Representation Learning for Social Network Analysis,"Qiaoyu Tan, Ninghao Liu, Xia Hu",arXiv,"Deep learning, social networks, deep social network analysis, representation learning, network embedding","Social network analysis is an important problem in data mining. A fundamental step for analyzing social networks is to encode network data into low-dimensional representations, i.e., network embeddings, so that the network topology structure and other attribute information can be effectively preserved. Network representation leaning facilitates further applications such as classification, link prediction, anomaly detection and clustering. In addition, techniques based on deep neural networks have attracted great interests over the past a few years. In this survey, we conduct a comprehensive review of current literature in network representation learning utilizing neural network models. First, we introduce the basic models for learning node representations in homogeneous networks. Meanwhile, we will also introduce some extensions of the base models in tackling more complex scenarios, such as analyzing attributed networks, heterogeneous networks and dynamic networks. Then, we introduce the techniques for embedding subgraphs. After that, we present the applications of network representation learning. At the end, we discuss some promising research directions for future work."
Knowledge Representation Learning: A Quantitative Review,"Yankai Lin, Xu Han, Ruobing Xie,Zhiyuan Liu, Maosong Sun",arXiv,"Knowledge representation and reasoning, Surveys and overviews","Knowledge representation learning (KRL) aims to represent entities and relations in knowledge graph in low-dimensional semantic space, which have been widely used in massive knowledge-driven tasks. In this article, we introduce the reader to the motivations for KRL, and overview existing approaches for KRL. Afterwards, we extensively conduct and quantitative comparison and analysis of several typical KRL methods on three evaluation tasks of knowledge acquisition including knowledge graph completion, triple classification, and relation extraction. We also review the real-world applications of KRL, such as language modeling, question answering, information retrieval, and recommender systems. Finally, we discuss the remaining challenges and outlook the future directions for KRL."
Graph Representation Learning: A Survey,"Fenxiao Chen, Yuncheng Wang, BinWang, C.-C. Jay Kuo",arXiv,,"Research on graph representation learning has received a lot of attention in recent years since many data in real-world applications come in form of graphs. High-dimensional graph data are often in irregular form, which makes them more difficult to analyze than image/video/audio data defined on regular lattices. Various graph embedding techniques have been developed to convert the raw graph data into a low-dimensional vector representation while preserving the intrinsic graph properties. In this review, we first explain the graph embedding task and its challenges. Next, we review a wide range of graph embedding techniques with insights. Then, we evaluate several state-of-the-art methods against small and large datasets and compare their performance. Finally, potential applications and future directions are presented."
Substructure Assembling Network for Graph Classification,"Xiaohan Zhao, Bo Zong, Ziyu Guan, KaiZhang, Wei Zhao",AAAI,graph learning; graph representation learning; graph classification; deep graph neural network; deep learning,"Graphs are natural data structures adopted to represent realworld data of complex relationships. In recent years, a surge of interest has been received to build predictive models over graphs, with prominent examples in chemistry, computational biology, and social networks. The overwhelming complexity of graph space often makes it challenging to extract interpretable and discriminative structural features for classification tasks. In this work, we propose a novel neural network structure called Substructure Assembling Network (SAN) to extract graph features and improve the generalization performance of graph classification. The key innovation of our work is a unified substructure assembling unit, which is a variant of Recurrent Neural Network (RNN) designed to hierarchically assemble useful pieces of graph components so as to fabricate discriminative substructures. SAN adopts a sequential, probabilistic decision process, and therefore it can tune substructure features in a finer granularity. Meanwhile, the parameterized soft decisions can be continuously improved with supervised learning through back-propagation, leading to optimizable search trajectories. Overall, SAN embraces both the flexibility of combinatorial pattern search and the strong optimizability of deep learning, and delivers promising results as well as interpretable structural features in graph classification against state-of-the-art techniques."
An overview of embedding models of entities and relationships for knowledge base completion,Dat Quoc Nguyen,arXiv,"Knowledge base completion, link prediction, embedding model, entity prediction","Knowledge bases (KBs) of real-world facts about entities and their relationships are useful resources for a variety of natural language processing tasks. However, because knowledge bases are typically incomplete, it is useful to be able to perform knowledge base completion or link prediction, i.e., predict whether a relationship not in the knowledge base is likely to be true. This paper serves as a comprehensive overview of embedding models of entities and relationships for knowledge base completion, summarizing up-to-date experimental results on standard benchmark datasets."
Scalable Graph Embedding for Asymmetric Proximity,"Chang Zhou, Yuqiong Liu, Xiaofei Liu,Zhongyi Liu, Jun Gao",AAAI,,"Graph Embedding methods are aimed at mapping each vertex into a low dimensional vector space, which preserves certain structural relationships among the vertices in the original graph. Recently, several works have been proposed to learn embeddings based on sampled paths from the graph, e.g., DeepWalk, Line, Node2Vec. However, their methods only preserve symmetric proximities, which could be insufficient in many applications, even the underlying graph is undirected. Besides, they lack of theoretical analysis of what exactly the relationships they preserve in their embedding space. In this paper, we propose an asymmetric proximity preserving (APP) graph embedding method via random walk with restart, which captures both asymmetric and high-order similarities between node pairs. We give theoretical analysis that our method implicitly preserves the Rooted PageRank score for any two vertices. We conduct extensive experiments on tasks of link prediction and node recommendation on open source datasets, as well as online recommendation services in Alibaba Group, in which the training graph has over 290 million vertices and 18 billion edges, showing our method to be highly scalable and effective."
Max-Margin DeepWalk: Discriminative Learning of Network Representation,"Cunchao Tu, Weicheng Zhang, ZhiyuanLiu, Maosong Sun",IJCAI,,"DeepWalk is a typical representation learning method that learns low-dimensional representations for vertices in social networks. Similar to other network representation learning (NRL) models, it encodes the network structure into vertex representations and is learnt in unsupervised form. However, the learnt representations usually lack the ability of discrimination when applied to machine learning tasks, such as vertex classification. In this paper, we overcome this challenge by proposing a novel semi-supervised model, max-margin DeepWalk (MMDW). MMDW is a unified NRL framework that jointly optimizes the max-margin classifier and the aimed social representation learning model. Influenced by the max-margin classifier, the learnt representations not only contain the network structure, but also have the characteristic of discrimination. The visualizations of learnt representations indicate that our model is more discriminative than unsupervised ones, and the experimental results on vertex classification demonstrate that our method achieves a significant improvement than other state-of-the-art methods. The source code can be obtained from https://github. com/thunlp/MMDW."
Primitives for Dynamic Big Model Parallelism,"Seunghak Lee, Jin Kyu Kim, Xun Zheng,Qirong Ho, Garth A. Gibson, Eric P. Xing",arXiv,,"When training large machine learning models with many variables or parameters, a single machine is often inadequate since the model may be too large to fit in memory, while training can take a long time even with stochastic updates. A natural recourse is to turn to distributed cluster computing, in order to harness additional memory and processors. However, naive, unstructured parallelization of ML algorithms can make inefficient use of distributed memory, while failing to obtain proportional convergence speedups - or can even result in divergence. We develop a framework of primitives for dynamic model-parallelism, STRADS, in order to explore partitioning and update scheduling of model variables in distributed ML algorithms - thus improving their memory efficiency while presenting new opportunities to speed up convergence without compromising inference correctness. We demonstrate the efficacy of model-parallel algorithms implemented in STRADS versus popular implementations for Topic Modeling, Matrix Factorization and Lasso."
Embedding of Embedding (EOE): Joint Embedding for Coupled Heterogeneous Networks,"Linchuan Xu, Xiaokai Wei, JiannongCao, Philip S. Yu",ACM,Network Embedding; Coupled Heterogeneous Networks; Data Mining,"Network embedding is increasingly employed to assist network analysis as it is effective to learn latent features that encode linkage information. Various network embedding methods have been proposed, but they are only designed for a single network scenario. In the era of big data, different types of related information can be fused together to form a coupled heterogeneous network, which consists of two different but related sub-networks connected by inter-network edges. In this scenario, the inter-network edges can act as complementary information in the presence of intra-network ones. This complementary information is important because it can make latent features more comprehensive and accurate. And it is more important when the intra-network edges are absent, which can be referred to as the cold-start problem. In this paper, we thus propose a method named embedding of embedding (EOE) for coupled heterogeneous networks. In the EOE, latent features encode not only intra-network edges, but also inter-network ones. To tackle the challenge of heterogeneities of two networks, the EOE incorporates a harmonious embedding matrix to further embed the embeddings that only encode intra-network edges. Empirical experiments on a variety of real-world datasets demonstrate the EOE outperforms consistently single network embedding methods in applications including visualization, link prediction multi-class classification, and multi-label classification."
RI:Small:Collaborative Research: Distributed Inference Algorithms for Machine Learning,"Alexander J. Smola, David G. Andersen",,,
Attributed Network Embedding for Learning in a Dynamic Environment,"Jundong Li, Harsh Dani, Xia Hu, JiliangTang, Yi Chang, Huan Liu",arXiv,Dynamic Networks; Attributed Networks; Network Embedding,"Network embedding leverages the node proximity manifested to learn a low-dimensional node vector representation for each node in the network. The learned embeddings could advance various learning tasks such as node classification, network clustering, and link prediction. Most, if not all, of the existing works, are overwhelmingly performed in the context of plain and static networks. Nonetheless, in reality, network structure often evolves over time with addition/deletion of links and nodes. Also, a vast majority of real-world networks are associated with a rich set of node attributes, and their attribute values are also naturally changing, with the emerging of new content patterns and the fading of old content patterns. These changing characteristics motivate us to seek an effective embedding representation to capture network and attribute evolving patterns, which is of fundamental importance for learning in a dynamic environment. To our best knowledge, we are the first to tackle this problem with the following two challenges: (1) the inherently correlated network and node attributes could be noisy and incomplete, it necessitates a robust consensus representation to capture their individual properties and correlations; (2) the embedding learning needs to be performed in an online fashion to adapt to the changes accordingly. In this paper, we tackle this problem by proposing a novel dynamic attributed network embedding framework - DANE. In particular, DANE first provides an offline method for a consensus embedding and then leverages matrix perturbation theory to maintain the freshness of the end embedding results in an online manner. We perform extensive experiments on both synthetic and real attributed networks to corroborate the effectiveness and efficiency of the proposed framework."
Harp: A Machine Learning Framework on Top of the Collective Communication Layer for the Big Data Software Stack,Bingjing Zhang,Indiana University,MACHINE LEARNING; COLLECTIVE COMMUNICATION; BIG DATA,"Almost every field of science is now undergoing a data-driven revolution requiring analyzing massive datasets. Machine learning algorithms are widely used to find meaning in a given dataset and discover properties of complex systems. At the same time, the landscape of computing has evolved towards computers exhibiting many-core architectures of increasing complexity. However, there is no simple and unified programming framework allowing for these machine learning applications to exploit these new machines’ parallel computing capability. Instead, many efforts focus on specialized ways to speed up individual algorithms. In this thesis, the Harp framework, which uses collective communication techniques, is prototyped to improve the performance of data movement and provides high-level APIs for various synchronization patterns in iterative computation. In contrast to traditional parallelization strategies that focus on handling high volume training data, a less known challenge is that the high dimensional model is also in high volume and difficult to synchronize. As an extension of the Hadoop MapReduce system, Harp includes a collective communication layer and a set of programming interfaces. Iterative machine learning algorithms can be parallelized through efficient synchronization methods utilizing both inter-node and intra-node parallelism. The usability and efficiency of Harp’s approach is validated on applications such as K-means Clustering, Multi-Dimensional Scaling, Latent Dirichlet Allocation and Matrix Factorization. The results show that these machine learning applications can achieve high parallel performance on Harp."
Differentiating Concepts and Instances for Knowledge Graph Embedding,"Xin Lv, Lei Hou, Juan-Zi Li, Zhiyuan Liu",arXiv,,"Concepts, which represent a group of different instances sharing common properties, are essential information in knowledge representation. Most conventional knowledge embedding methods encode both entities (concepts and instances) and relations as vectors in a low dimensional semantic space equally, ignoring the difference between concepts and instances. In this paper, we propose a novel knowledge graph embedding model named TransC by differentiating concepts and instances. Specifically, TransC encodes each concept in knowledge graph as a sphere and each instance as a vector in the same semantic space. We use the relative positions to model the relations between concepts and instances (i.e., instanceOf), and the relations between concepts and sub-concepts (i.e., subClassOf). We evaluate our model on both link prediction and triple classification tasks on the dataset based on YAGO. Experimental results show that TransC outperforms state-of-the-art methods, and captures the semantic transitivity for instanceOf and subClassOf relation."
Knowledge Graph Embedding with Hierarchical Relation Structure,"Zhao Zhang, Fuzhen Zhuang, Meng Qu,Fen Lin, Qing He",ACL,,"The rapid development of knowledge graphs (KGs), such as Freebase and WordNet, has changed the paradigm for AI-related applications. However, even though these KGs are impressively large, most of them are suffering from incompleteness, which leads to performance degradation of AI applications. Most existing researches are focusing on knowledge graph embedding (KGE) models. Nevertheless, those models simply embed entities and relations into latent vectors without leveraging the rich information from the relation structure. Indeed, relations in KGs conform to a three-layer hierarchical relation structure (HRS), i.e., semantically similar relations can make up relation clusters and some relations can be further split into several fine-grained sub-relations. Relation clusters, relations and sub-relations can fit in the top, the middle and the bottom layer of three-layer HRS respectively. To this end, in this paper, we extend existing KGE models TransE, TransH and DistMult, to learn knowledge representations by leveraging the information from the HRS. Particularly, our approach is capable to extend other KGE models. Finally, the experiment results clearly validate the effectiveness of the proposed approach against baselines."
KG-BERT: BERT for Knowledge Graph Completion,"Liang Yao, Chengsheng Mao, Yuan Luo",arXiv,,"Knowledge graphs are important resources for many artificial intelligence tasks but often suffer from incompleteness. In this work, we propose to use pre-trained language models for knowledge graph completion. We treat triples in knowledge graphs as textual sequences and propose a novel framework named Knowledge Graph Bidirectional Encoder Representations from Transformer (KG-BERT) to model these triples. Our method takes entity and relation descriptions of a triple as input and computes scoring function of the triple with the KG-BERT language model. Experimental results on multiple benchmark knowledge graphs show that our method can achieve state-of-the-art performance in triple classification, link prediction and relation prediction tasks."
A Model of Text-Enhanced Knowledge Graph Representation Learning with Collaborative Attention,"Yashen Wang, Huanhuan Zhang,Haiyong Xie",Proceedings of Machine Learning Research,"Knowledge Graph, Representation Learning, collaborative attention","This paper proposes a novel collaborative attention mechanism, to fully utilize the mutually reinforcing relationship among the knowledge graph representation learning procedure (i.e., structure representation) and textual relation representation learning procedure (i.e., text representation). Based on this collaborative attention mechanism, a text-enhanced knowledge graph (KG) representation model is proposed, which could utilize textual information to enhance the knowledge representations and make the multi-direction signals to be fully integrated to learn more accurate textual representations for further improving structure representation and vice versa. Experimental results demonstrate the efficiency of the proposed model on both link prediction task and triple classification task. Keywords: Knowledge Graph, Representation Learning, collaborative attention."
KSR: A Semantic Representation of Knowledge Graph within a Novel Unsupervised Paradigm,"Han Xiao, Minlie Huang, Xiaoyan Zhu",arXiv,"Knowledge Graph, Semantic Analysis, Knowledge Representation, Multi-View Clustering","Knowledge representation is a long-history topic in AI, which is very important. A variety of models have been proposed for knowledge graph embedding, which projects symbolic entities and relations into continuous vector space. However, most related methods merely focus on the data-fitting of knowledge graph, and ignore the interpretable semantic expression. Thus, traditional embedding methods are not friendly for applications that require semantic analysis, such as question answering and entity retrieval. To this end, this paper proposes a semantic representation method for knowledge graph \textbf{(KSR)}, which imposes a two-level hierarchical generative process that globally extracts many aspects and then locally assigns a specific category in each aspect for every triple. Since both aspects and categories are semantics-relevant, the collection of categories in each aspect is treated as the semantic representation of this triple. Extensive experiments show that our model outperforms other state-of-the-art baselines substantially."
GTrans: Generic Knowledge Graph Embedding via Multi-State Entities and Dynamic Relation Spaces,"Zhen Tan, Xiang Zhao, Yang Fang,Weidong Xiao",Semantic Web ,"Knowledge graph embedding, Multi-state entities, Dynamic relation spaces, Triplets classification, Link prediction","Knowledge graph embedding aims to construct a low-dimensional and continuous space, which is able to describe the semantics of high-dimensional and sparse knowledge graphs. Among existing solutions, translation models have drawn much attention lately, which use a relation vector to translate the head entity vector, the result of which is close to the tail entity vector. Compared with classical embedding methods, translation models achieve state-of-the-art performance; nonetheless, the rationale and mechanism behind them still aspire after understanding and investigation. In this connection, we quest into the essence of translation models, and present a generic model, namely, GTrans, to entail all the existing translation models. In GTrans, each entity is interpreted by a combination of two states - eigenstate and mimesis. Eigenstate represents the features that an entity intrinsically owns, and mimesis expresses the features that are affected by associated relations. The weighting of the two states can be tuned, and hence, dynamic and static weighting strategies are put forward to best describe entities in the problem domain. Besides, GTrans incorporates a dynamic relation space for each relation, which not only enables the flexibility of our model, but also reduces the noise from other relation spaces. In experiments, we evaluate our proposed model with two benchmark tasks - triplets classification and link prediction. Experiment results witness significant and consistent performance gain that is offered by GTrans over existing alternatives."
TransG : A Generative Model for Knowledge Graph Embedding,"Han Xiao, Minlie Huang, Xiaoyan Zhu",ACL,,"Recently, knowledge graph embedding, which projects symbolic entities and relations into continuous vector space, has become a new, hot topic in artificial intelligence. This paper proposes a novel generative model (TransG) to address the issue of multiple relation semantics that a relation may have multiple meanings revealed by the entity pairs associated with the corresponding triples. The new model can discover latent semantics for a relation and leverage a mixture of relationspecific component vectors to embed a fact triple. To the best of our knowledge, this is the first generative model for knowledge graph embedding, and at the first time, the issue of multiple relation semantics is formally discussed. Extensive experiments show that the proposed model achieves substantial improvements against the state-of-the-art baselines."
Improve the translational distance models for knowledge graph embedding,"Siheng Zhang, Zhengya Sun, WenshengZhang",Journal of Intelligent Information Systems,"Knowledge graph embedding,Translational distance model, Positional encoding, Self-attention","Knowledge graph embedding techniques can be roughly divided into two mainstream, translational distance models and semantic matching models. Though intuitive, translational distance models fail to deal with the circle structure and hierarchical structure in knowledge graphs. In this paper, we propose a general learning framework named TransX-pa, which takes various models (TransE, TransR, TransH and TransD) into consideration. From this unified viewpoint, we analyse the learning bottlenecks are: (i) the common assumption that the inverse of a relation r is modelled as its opposite −r; and (ii) the failure to capture the rich interactions between entities and relations. Correspondingly, we introduce position-aware embeddings and self-attention blocks, and show that they can be adapted to various translational distance models. Experiments are conducted on different datasets extracted from real-world knowledge graphs Freebase and WordNet in the tasks of both triplet classification and link prediction. The results show that our approach makes a great improvement, showing a better, or comparable, performance with state-of-the-art methods."
EHP: Entity Hyperplane Projection for Knowledge Graph Embedding with Entity Descriptions,"Shuai Qin, Nianbin Wang, Hong Wang,Lian-Ke Zhou, Haomin Zhan",IEEE,"Knowledge Graph Embedding, Projection, Text Descriptions, Semantic Hyperplane","Knowledge graph embedding aims to project entities and relations into a low-dimensional and continuous vector space to represent the semantic information of entities and relations. Most existing models of knowledge graph embedding only concentrate on the structured information of the knowledge graph and merely use knowledge triples that can also be called the fact triples to learn the representation of entities and relations, but ignore some useful information that emerge in text descriptions of entities. To this end, this paper proposes the entity hyperplane projection (EHP) model. EHP learns both from knowledge triples and text descriptions, project the entity embedding onto the semantic hyperplane corresponding to entity descriptions to build interactions between the two information sources. Extensive experiments show that EHP model achieves substantial improvements against baselines on the tasks of knowledge graph completion and entity classification."
Joint Knowledge Base Embedding with Neighborhood Context,"Binling Nie, Shouqian Sun",IEEE,,"Knowledge graph embedding significantly promotes the performance of link prediction and knowledge reasoning, which aims to encode both entities and relations into a lowdimensional semantic space. Existing translation-based methods have achieved state-of-art performances. However, the diversity of connectivity patterns observed in knowledge graph, i.e., structural equivalences, may not be effectively utilized to enhance knowledge graph embedding. To address this issue, we propose a concise but effective model, Context-enhanced Knowledge Graph Embedding (CKGE), for joint knowledge base embedding with neighborhood context. Neighborhood context obtained in our approach gain a deep insight into the diversity of connectivity patterns of knowledge graph. We incorporate the rich structural information contained in neighborhood context to expand the semantic structure of the knowledge graph, which is enable to model complex relations more precisely. We conduct extensive experiments on link prediction, triplet classification on bench-mark datasets. The experiment results show CKGE achieve significant improvements against the baseline methods."
Knowledge Graph Completion via Complete Attention between Knowledge Graph and Entity Descriptions,"Minjun Zhao, Yawei Zhao, Ben Xu",ACM,"Complete Attention, Link Prediction, Entity Descriptions, Deep Learning","The objective of learning representation of knowledge graph is assumed to encode both entities and relations into a continuous low-dimensional vector space. Previous methods usually represent the same entity in different triples with the same representation. Considering the fact that different entities should have different semantics in different triples, this paper proposes a method to learn entity description information based on the triple, under the complete attention (CATT) mechanism, in the knowledge graphs. By doing so, the entity has different representations of corresponding semantics in different triples. For encoding the information of entity description, we use three deep learning methods including CNN, Bi-LSTM and Transformer. Experimental results show that, with the proposed method, the performance on both entity prediction and relationship prediction improved significantly."
Relation path embedding in knowledge graphs,"Xixun Lin, Yanchun Liang, FaustoGiunchiglia, Xiaoyue Feng, RenchuGuan",Neural Computing and Applications,"Knowledge graph completion, Relation paths, Path projection, Type constraints, Knowledge representation learning","Large-scale knowledge graphs have currently reached impressive sizes; however, they are still far from complete. In addition, most existing methods for knowledge graph completion only consider the direct links between entities, ignoring the vital impact of the semantics of relation paths. In this paper, we study the problem of how to better embed entities and relations of knowledge graphs into different low-dimensional spaces by taking full advantage of the additional semantics of relation paths and propose a novel relation path embedding model named as RPE. Specifically, with the corresponding relation and path projections, RPE can simultaneously embed each entity into two types of latent spaces. Moreover, type constraints are extended from traditional relation-specific type constraints to the proposed path-specific type constraints and both of the two type constraints can be seamlessly incorporated into RPE. The proposed model is evaluated on the benchmark tasks of link prediction and triple classification. The results of experiments demonstrate our method outperforms all baselines on both tasks. They indicate that our model is capable of catching the semantics of relation paths, which is significant for knowledge representation learning."
A Model of Text-Enhanced Knowledge Graph Representation Learning With Mutual Attention,"Yashen Wang, Huan-Huan Zhang, GeShi, Zhirun Liu, Qiang Zhou",IEEE,"Knowledge graph representation, textual relation representation, mutual attention mechanism, representation learning.","Recently, it has gained lots of interests to jointly learn the embeddings of knowledge graph (KG) and text information. However, previous work fails to incorporate the complex structural signals (from structure representation) and semantic signals (from text representation). This paper proposes a novel text-enhanced knowledge graph representation model, which can utilize textual information to enhance the knowledge representations. Especially, a mutual attention mechanism between KG and text is proposed to learn more accurate textual representations for further improving knowledge graph representation, within a unified parameter sharing semantic space. Different from conventional joint models, no complicated linguistic analysis or strict alignments between KG and text are required to train our model. Besides, the proposed model could fully incorporate the multi-direction signals. Experimental results show that the proposed model achieves the state-of-the-art performance on both link prediction and triple cla"
Knowledge Graph Embedding by Dynamic Translation,"Liang Chang, Manli Zhu, Tianlong Gu,Chenzhong Bin, Junyan Qian, Ji Zhang",IEEE,"Dynamic translation, embeddings, knowledge graph, translation-based models","Knowledge graph embedding aims at representing entities and relations in a knowledge graph as dense, low-dimensional and real-valued vectors. It can efficiently measure semantic correlations of entities and relations in knowledge graphs, and improve the performance of knowledge acquisition, fusion and inference. Among various embedding models appeared in recent years, the translation-based models such as TransE, TransH, TransR and TranSparse achieve state-of-the-art performance. However, the translation principle applied in these models is too strict and can not deal with complex entities and relations very well. In this paper, by introducing parameter vectors into the translation principle which treats each relation as a translation from the head entity to the tail entity, we propose a novel dynamic translation principle which supports flexible translation between the embeddings of entities and relations. We use this principle to improve the TransE, TransR and TranSparse models respectively and build new models named TransE-DT, TransR-DT and TranSparse-DT correspondingly. Experimental results show that our dynamic translation principle achieves great improvement in both the link prediction task and the triple classification task."
OpenKE: An Open Toolkit for Knowledge Embedding,"Xu Han, Shulin Cao, Xin Lv, Yankai Lin,Zhiyuan Liu, Maosong Sun, Juan-Zi Li",ACL,,"We release an open toolkit for knowledge embedding (OpenKE), which provides a unified framework and various fundamental models to embed knowledge graphs into a continuous low-dimensional space. OpenKE prioritizes operational efficiency to support quick model validation and large-scale knowledge representation learning. Meanwhile, OpenKE maintains sufficient modularity and extensibility to easily incorporate new models into the framework. Besides the toolkit, the embeddings of some existing large-scale knowledge graphs pre-trained by OpenKE are also available, which can be directly applied for many applications including information retrieval, personalized recommendation and question answering."
GAKE: Graph Aware Knowledge Embedding,"Jun Feng, Minlie Huang, Yang Yang,Xiaoyan Zhu",ACL,,"Knowledge embedding, which projects triples in a given knowledge base to d-dimensional vectors, has attracted considerable research efforts recently. Most existing approaches treat the given knowledge base as a set of triplets, each of whose representation is then learned separately. However, as a fact, triples are connected and depend on each other. In this paper, we propose a graph aware knowledge embedding method (GAKE), which formulates knowledge base as a directed graph, and learns representations for any vertices or edges by leveraging the graph’s structural information. We introduce three types of graph context for embedding: neighbor context, path context, and edge context, each reflects properties of knowledge from different perspectives. We also design an attention mechanism to learn representative power of different vertices or edges. To validate our method, we conduct several experiments on two tasks. Experimental results suggest that our method outperforms several state-of-art knowledge embedding models."
Domain Representation for Knowledge Graph Embedding,"Cunxiang Wang, Yue Zhang, FeiliangRen, Chenxu Zhao, Zhichao Lin, TianXie",arXiv,"Representation learning, Knowledge graph, Domain","Embedding entities and relations into a continuous multi-dimensional vector space have become the dominant method for knowledge graph embedding in representation learning. However, most existing models ignore to represent hierarchical knowledge, such as the similarities and dissimilarities of entities in one domain. We proposed to learn a Domain Representations over existing knowledge graph embedding models, such that entities that have similar attributes are organized into the same domain. Such hierarchical knowledge of domains can give further evidence in link prediction. Experimental results show that domain embeddings give a significant improvement over the most recent state-of-art baseline knowledge graph embedding models."
Incorporating GAN for Negative Sampling in Knowledge Representation Learning,"PeiFeng Wang, Shuangyin Li, Rong Pan",arXiv,,"Knowledge representation learning aims at modeling knowledge graph by encoding entities and relations into a low dimensional space. Most of the traditional works for knowledge embedding need negative sampling to minimize a margin-based ranking loss. However, those works construct negative samples through a random mode, by which the samples are often too trivial to fit the model efficiently. In this paper, we propose a novel knowledge representation learning framework based on Generative Adversarial Networks (GAN). In this GAN-based framework, we take advantage of a generator to obtain high-quality negative samples. Meanwhile, the discriminator in GAN learns the embeddings of the entities and relations in knowledge graph. Thus, we can incorporate the proposed GAN-based framework into various traditional models to improve the ability of knowledge representation learning. Experimental results show that our proposed GAN-based framework outperforms baselines on triplets classification and link prediction tasks."
Knowledge Semantic Representation: A Generative Model for Interpretable Knowledge Graph Embedding,"Han Xiao, Minlie Huang, Xiaoyan Zhu",arXiv,,"Knowledge representation is a critical topic in AI, and currently embedding as a key branch of knowledge representation takes the numerical form of entities and relations to joint the statistical models. However, most embedding methods merely concentrate on the triple fitting and ignore the explicit semantic expression, leading to an uninterpretable representation form. Thus, traditional embedding methods do not only degrade the performance, but also restrict many potential applications. For this end, this paper proposes a semantic representation method for knowledge graph (KSR), which imposes a two-level hierarchical generative process that globally extracts many aspects and then locally assigns a specific category in each aspect for every triple. Because both the aspects and categories are semantics-relevant, the collection of categories in each aspect is treated as the semantic representation of this triple. Extensive experiments justify our model outperforms other state-of-the-art baselines in a substantial extent."
Learning Knowledge Graph Embeddings via Generalized Hyperplanes,"Qiannan Zhu, Xiaofei Zhou, JianlongTan, Ping Liu, Li Guo",Computational Science - ICCS 2018,"Knowledge Representation,Knowledge Embedding,Knowledge Graph Completion","For knowledge graph completion, translation-based methods such as Trans(E and H) are promising, which embed knowledge graphs into continuous vector spaces and construct translation operation between head and tail entities. However, TransE and TransH still have limitations in preserving mapping properties of complex relation facts for knowledge graphs. In this paper, we propose a novel translation-based method called translation on generalized hyperplanes (TransGH), which extends TransH by defining a generalized hyperplane for entities projection. TransGH projects head and tail embeddings from a triplet into a generalized relation-specific hyperplane determined by a set of basis vectors, and then fulfills translation operation on the hyperplane. Compared with TransH, TransGH can capture more fertile interactions between entities and relations, and simultaneously has strong expression in mapping properties for knowledge graphs. Experimental results on two tasks, link prediction and triplet classification, show that TransGH can significantly outperform the state-of-the-art embedding methods."
Logic Rules Powered Knowledge Graph Embedding,"Pengwei Wang, Dejing Dou, FangzhaoWu, Nisansa de Silva, Lianwen Jin",arXiv,"Knowledge graph embedding, logic rule, rule-enhanced method","Large scale knowledge graph embedding has attracted much attention from both academia and industry in the field of Artificial Intelligence. However, most existing methods concentrate solely on fact triples contained in the given knowledge graph. Inspired by the fact that logic rules can provide a flexible and declarative language for expressing rich background knowledge, it is natural to integrate logic rules into knowledge graph embedding, to transfer human knowledge to entity and relation embedding, and strengthen the learning process. In this paper, we propose a novel logic rule-enhanced method which can be easily integrated with any translation based knowledge graph embedding model, such as TransE . We first introduce a method to automatically mine the logic rules and corresponding confidences from the triples. And then, to put both triples and mined logic rules within the same semantic space, all triples in the knowledge graph are represented as first-order logic. Finally, we define several operations on the first-order logic and minimize a global loss over both of the mined logic rules and the transformed first-order logics. We conduct extensive experiments for link prediction and triple classification on three datasets: WN18, FB166, and FB15K. Experiments show that the rule-enhanced method can significantly improve the performance of several baselines. The highlight of our model is that the filtered Hits@1, which is a pivotal evaluation in the knowledge inference task, has a significant improvement (up to 700% improvement)."
Knowledge Representation Learning via Dynamic Relation Spaces,"Zhen Tan, Xiang Zhao, Yang Fang,Weidong Xiao, Jiuyang Tang",IEEE,,"Knowledge graphs are an important part in AI domain, and contain large scale of structured knowledge, but they are far from completeness. Previous translation models, such as TransE, TransH, TransR/CTransR and TransD, use a relation vector to translate head entity vector, the result of translation is close to tail entity vector. Compared with other classical models, these translation models achieve state-of-the-art performance. In this paper, we propose a more flexible model named TransDR, which is an improvement of TransD. In TransDR, we use two vectors to represent each entity and three vectors to represent relation. Compared with TransD, TransDR adds another vector for each relation which could not only represent model more flexibly but also reduce the noise from other relation spaces. In experiments, we evaluate our model on two typical tasks including triplets classification and link prediction. Experiment results show significant and consistent improvements compared to previous state-of-the-art models."
TorusE: Knowledge Graph Embedding on a Lie Group,"Takuma Ebisu, Ryutaro Ichise",arXiv,,"Knowledge graphs are useful for many artificial intelligence (AI) tasks. However, knowledge graphs often have missing facts. To populate the graphs, knowledge graph embedding models have been developed. Knowledge graph embedding models map entities and relations in a knowledge graph to a vector space and predict unknown triples by scoring candidate triples. TransE is the first translation-based method and it is well known because of its simplicity and efficiency for knowledge graph completion. It employs the principle that the differences between entity embeddings represent their relations. The principle seems very simple, but it can effectively capture the rules of a knowledge graph. However, TransE has a problem with its regularization. TransE forces entity embeddings to be on a sphere in the embedding vector space. This regularization warps the embeddings and makes it difficult for them to fulfill the abovementioned principle. The regularization also affects adversely the accuracies of the link predictions. On the other hand, regularization is important because entity embeddings diverge by negative sampling without it. This paper proposes a novel embedding model, TorusE, to solve the regularization problem. The principle of TransE can be defined on any Lie group. A torus, which is one of the compact Lie groups, can be chosen for the embedding space to avoid regularization. To the best of our knowledge, TorusE is the first model that embeds objects on other than a real or complex vector space, and this paper is the first to formally discuss the problem of regularization of TransE. Our approach outperforms other state-of-the-art approaches such as TransE, DistMult and ComplEx on a standard link prediction task. We show that TorusE is scalable to large-size knowledge graphs and is faster than the original TransE."
Multimodal Data Enhanced Representation Learning for Knowledge Graphs,"Zi-kang Wang, Linjing Li, Qiudan Li,Daniel Dajun Zeng",IEEE,"representation learning, knowledge graph, multimodal","Knowledge graph, or knowledge base, plays an important role in a variety of applications in the field of artificial intelligence. In both research and application of knowledge graph, knowledge representation learning is one of the fundamental tasks. Existing representation learning approaches are mainly based on structural knowledge between entities and relations, while knowledge among entities per se is largely ignored. Though a few approaches integrated entity knowledge while learning representations, these methods lack the flexibility to apply to multimodalities. To tackle this problem, in this paper, we propose a new representation learning method, TransAE, by combining multimodal autoencoder with TransE model, where TransE is a simple and effective representation learning method for knowledge graphs. In TransAE, the hidden layer of autoencoder is used as the representation of entities in the TransE model, thus it encodes not only the structural knowledge, but also the multimodal knowledge, such as visual and textural knowledge, into the final representation. Compared with traditional methods based on only structural knowledge, TransAE can significantly improve the performance in the sense of link prediction and triplet classification. Also, TransAE has the ability to learn representations for entities out of knowledge base in zero-shot. Experiments on various tasks demonstrate the effectiveness of our proposed TransAE method."
Knowledge Graph Embedding via Dynamic Mapping Matrix,"Guoliang Ji, Shizhu He, Liheng Xu, KangLiu, Jun Zhao",ACL,,"Knowledge graphs are useful resources for numerous AI applications, but they are far from completeness. Previous work such as TransE, TransH and TransR/CTransR regard a relation as translation from head entity to tail entity and the CTransR achieves state-of-the-art performance. In this paper, we propose a more fine-grained model named TransD, which is an improvement of TransR/CTransR. In TransD, we use two vectors to represent a named symbol object (entity and relation). The first one represents the meaning of a(n) entity (relation), the other one is used to construct mapping matrix dynamically. Compared with TransR/CTransR, TransD not only considers the diversity of relations, but also entities. TransD has less parameters and has no matrix-vector multiplication operations, which makes it can be applied on large scale graphs. In Experiments, we evaluate our model on two typical tasks including triplets classification and link prediction. Evaluation results show that our approach outperforms stateof-the-art methods."
Towards Understanding the Geometry of Knowledge Graph Embeddings,"Chandrahas, Aditya Sharma, Partha P.Talukdar",ACL,,"Knowledge Graph (KG) embedding has emerged as a very active area of research over the last few years, resulting in the development of several embedding methods. These KG embedding methods represent KG entities and relations as vectors in a high-dimensional space. Despite this popularity and effectiveness of KG embeddings in various tasks (e.g., link prediction), geometric understanding of such embeddings (i.e., arrangement of entity and relation vectors in vector space) is unexplored – we fill this gap in the paper. We initiate a study to analyze the geometry of KG embeddings and correlate it with task performance and other hyperparameters. To the best of our knowledge, this is the first study of its kind. Through extensive experiments on real-world datasets, we discover several insights. For example, we find that there are sharp differences between the geometry of embeddings learnt by different classes of KG embeddings methods. We hope that this initial study will inspire other follow-up research on this important but unexplored problem."
Representation Learning of Knowledge Graphs with Entity Descriptions,"Ruobing Xie, Zhiyuan Liu, Jia Jia,Huanbo Luan, Maosong Sun",AAAI,,"Representation learning (RL) of knowledge graphs aims to project both entities and relations into a continuous low-dimensional space. Most methods concentrate on learning representations with knowledge triples indicating relations between entities. In fact, in most knowledge graphs there are usually concise descriptions for entities, which cannot be well utilized by existing methods. In this paper, we propose a novel RL method for knowledge graphs taking advantages of entity descriptions. More specifically, we explore two encoders, including continuous bag-of-words and deep convolutional neural models to encode semantics of entity descriptions. We further learn knowledge representations with both triples and descriptions. We evaluate our method on two tasks, including knowledge graph completion and entity classification. Experimental results on real-world datasets show that, our method outperforms other baselines on the two tasks, especially under the zero-shot setting, which indicates that our method is capable of building representations for novel entities according to their descriptions."
Relational Memory-based Knowledge Graph Embedding,"Dai Quoc Nguyen, Tu Dinh Nguyen,Dinh Q. Phung",arXiv,,"Knowledge graph embedding methods often suffer from a limitation of memorizing valid triples to predict new ones for triple classification and search personalization problems. To this end, we introduce a novel embedding model, named R-MeN, that explores a relational memory network to encode potential dependencies in relationship triples. R-MeN considers each triple as a sequence of 3 input vectors that recurrently interact with a memory using a transformer self-attention mechanism. Thus R-MeN encodes new information from interactions between the memory and each input vector to return a corresponding vector. Consequently, R-MeN feeds these 3 returned vectors to a convolutional neural network-based decoder to produce a scalar score for the triple. Experimental results show that our proposed R-MeN obtains state-of-the-art results on SEARCH17 for the search personalization task, and on WN11 and FB13 for the triple classification task."
Knowledge Graph Embedding with Diversity of Structures,Wen Zhang,ACM,"knowledge graph embedding, substructure diversity, link prediction,knowledge graph completion","In recent years, different web knowledge graphs, both free and commercial, have been created. Knowledge graphs use relations between entities to describe facts in the world. We engage in embedding a large scale knowledge graph into a continuous vector space. TransE, TransH, TransR and TransD are promising methods proposed in recent years and achieved state-of-the-art predictive performance. In this paper, we discuss that graph structures should be considered in embedding and propose to embed substructures called “one-relation-circle” (ORC) to further improve the performance of the above methods as they are unable to encode ORC substructures. Some complex models are capable of handling ORC structures but sacrifice efficiency in the process. To make a good trade-off between the model capacity and efficiency, we propose a method to decompose ORC substructures by using two vectors to represent the entity as a head or tail entity with the same relation. In this way, we can encode the ORC structure properly when apply it to TransH, TransR and TransD with almost the same model complexity of themselves. We conduct experiments on link prediction with benchmark dataset WordNet. Our experiments show that applying our method improves the results compared with the corresponding original results of TransH, TransR and TransD."
Representation Learning of Knowledge Graphs with Hierarchical Types,"Ruobing Xie, Zhiyuan Liu, Maosong Sun",IJCAI,,"Representation learning of knowledge graphs aims to encode both entities and relations into a continuous low-dimensional vector space. Most existing methods only concentrate on learning representations with structured information located in triples, regardless of the rich information located in hierarchical types of entities, which could be collected in most knowledge graphs. In this paper, we propose a novel method named Type-embodied Knowledge Representation Learning (TKRL) to take advantages of hierarchical entity types. We suggest that entities should have multiple representations in different types. More specifically, we consider hierarchical types as projection matrices for entities, with two type encoders designed to model hierarchical structures. Meanwhile, type information is also utilized as relation-specific type constraints. We evaluate our models on two tasks including knowledge graph completion and triple classification, and further explore the performances on long-tail dataset. Experimental results show that our models significantly outperform all baselines on both tasks, especially with long-tail distribution. It indicates that our models are capable of capturing hierarchical type information which is significant when constructing representations of knowledge graphs."
Knowledge Graph Embedding Bi-Vector Models for Symmetric Relation,"Jinkui Yao, Lianghua Xu",arXiv,,"Knowledge graph embedding (KGE) models have been proposed to improve the performance of knowledge graph reasoning. However, there is a general phenomenon in most of KGEs, as the training progresses, the symmetric relations tend to zero vector, if the symmetric triples ratio is high enough in the dataset. This phenomenon causes subsequent tasks, e.g. link prediction etc., of symmetric relations to fail. The root cause of the problem is that KGEs do not utilize the semantic information of symmetric relations. We propose KGE bi-vector models, which represent the symmetric relations as vector pair, significantly increasing the processing capability of the symmetry relations. We generate the benchmark datasets based on FB15k and WN18 by completing the symmetric relation triples to verify models. The experiment results of our models clearly affirm the effectiveness and superiority of our models against baseline."
Knowledge Graph Representation with Jointly Structural and Textual Encoding,"Jiacheng Xu, Xipeng Qiu, Kan Chen,Xuanjing Huang",IJCAI,,"The objective of knowledge graph embedding is to encode both entities and relations of knowledge graphs into continuous low-dimensional vector spaces. Previously, most works focused on symbolic representation of knowledge graph with structure information, which can not handle new entities or entities with few facts well. In this paper, we propose a novel deep architecture to utilize both structural and textual information of entities. Specifically, we introduce three neural models to encode the valuable information from text description of entity, among which an attentive model can select related information as needed. Then, a gating mechanism is applied to integrate representations of structure and text into a unified architecture. Experiments show that our models outperform baseline and obtain state-of-the-art results on link prediction and triplet classification tasks."
TransA: An Adaptive Approach for Knowledge Graph Embedding,"Han Xiao, Minlie Huang, Yu Hao,Xiaoyan Zhu",arXiv,,"Knowledge representation is a major topic in AI, and many studies attempt to represent entities and relations of knowledge base in a continuous vector space. Among these attempts, translation-based methods build entity and relation vectors by minimizing the translation loss from a head entity to a tail one. In spite of the success of these methods, translation-based methods also suffer from the oversimplified loss metric, and are not competitive enough to model various and complex entities/relations in knowledge bases. To address this issue, we propose \textbf{TransA}, an adaptive metric approach for embedding, utilizing the metric learning ideas to provide a more flexible embedding method. Experiments are conducted on the benchmark datasets and our proposed method makes significant and consistent improvements over the state-of-the-art baselines."
AWML: adaptive weighted margin learning for knowledge graph embedding,"Chenchen Guo, Chunhong Zhang, XiaoHan, Yang Ji",Journal of Intelligent Information Systems,"Knowledge graph, Knowledge representation learning, Adaptive margin, Adaptive importance weight
","Knowledge representation learning (KRL), exploited by various applications such as question answering and information retrieval, aims to embed the entities and relations contained by the knowledge graph into points of a vector space such that the semantic and structure information of the graph is well preserved in the representing space. However, the previous works mainly learned the embedding representations by treating each entity and relation equally which tends to ignore the inherent imbalance and heterogeneous properties existing in knowledge graph. By visualizing the representation results obtained from classic algorithm TransE in detail, we reveal the disadvantages caused by this homogeneous learning strategy and gain insight of designing policy for the homogeneous representation learning. In this paper, we propose a novel margin-based pairwise representation learning framework to be incorporated into many KRL approaches, with the method of introducing adaptivity according to the degree of knowledge heterogeneity. More specially, an adaptive margin appropriate to separate the real samples from fake samples in the embedding space is first proposed based on the sample’s distribution density, and then an adaptive weight is suggested to explicitly address the trade-off between the different contributions coming from the real and fake samples respectively. The experiments show that our Adaptive Weighted Margin Learning (AWML) framework can help the previous work achieve a better performance on real-world Knowledge Graphs Freebase and WordNet in the tasks of both link prediction and triplet classification."
Learning Knowledge Embeddings by Combining Limit-based Scoring Loss,"Xiaofei Zhou, Qiannan Zhu, Ping Liu, LiGuo",ACM,Embedding; Knowledge graph; Representation learning; Distributed representation,"In knowledge graph embedding models, the margin-based ranking loss as the common loss function is usually used to encourage discrimination between golden triplets and incorrect triplets, which has proved effective in many translation-based models for knowledge graph embedding. However, we find that the loss function cannot ensure the fact that the scoring of correct triplets must be low enough to fulfill the translation. In this paper, we present a limit-based scoring loss to provide lower scoring of a golden triplet, and then to extend two basic translation models TransE and TransH, separately to TransE-RS and TransH-RS by combining limit-based scoring loss with margin-based ranking loss. Both the presented models have low complexities of parameters benefiting for application on large scale graphs. In experiments, we evaluate our models on two typical tasks including triplet classification and link prediction, and also analyze the scoring distributions of positive and negative triplets by different models. Experimental results show that the introduced limit-based scoring loss is effective to improve the capacities of knowledge graph embedding."
Knowledge Graph Embedding by Bias Vectors,"Minjie Ding, Wei-Qin Tong, Xuehai Ding,Xiaoli Zhi, Xiao Wang, Guoqing Zhang",IEEE,knowledge embedding; knowledge completion; link prediction; triplets;,"Knowledge graph completion can predict the possible relation between entities. Previous work such as TransE, TransR, TransPES and GTrans embed knowledge graph into vector space and treat relations between entities as translations. In most cases, the more complex the algorithm is, the better the result will be, but it is difficult to apply to large-scale knowledge graphs. Therefore, we propose TransB, an efficient model, in this paper. We avoid the complex matrix or vector multiplication operation. Meanwhile, we make the representation of entities not too simple, which can satisfy the operation in the case of non-one-to-one relation. We use link prediction to evaluate the performance of our model in the experiment. The experimental results show that our model is valid and has low time complexity."
Learning Entity and Relation Embeddings with Entity Description for Knowledge Graph Completion,"Shaozhi Dai, Yanchun Liang, ShuyanLiu, Ying Wang, Wenle Shao, Xixun Lin,Xiaoyue Feng",ICAITA,knowledge graph completion; entity description; natural language processing,"With the growth of existing knowledge graph, the completion of knowledge graph has become a crucial problem. In this paper, we propose a novel model based on description-embodied knowledge representation learning framework, which is able to take advantages of both fact triples and entity description. Specifically, the relation projection is combined with description-embodied representation learning to learn entity and relation embeddings. Convolutional neural network and TransR are adopted to get the description-based and structure-based representation of entity and relation, respectively. We employ FB15K dataset generated from a large knowledge graph freebase, to evaluate the performances of the proposed model. Experimental results show that our proposed model greatly outperforms other existing baseline models."
Knowledge graph embedding via multiplicative interaction,"Zichao Huang, Bo Li, Jian Yin",ACM,knowledge graph; knowledge representation; representation learning,"Knowledge graphs are playing a crucial role in many machine learning applications. Since most of the knowledge graphs are far from complete, many knowledge graph completion models have been proposed. TransE and its extended models all model knowledge graphs with additive interaction. DistMult demonstrates that multiplicative interaction is more effective for modeling knowledge graphs. However, DistMult performs poorly on 1-to-N, N-to-1 and N-to-N relations. Besides, it does not consider the case that an entity could be a head entity or a tail entity which should be modeled separately. We propose a more fine-grained knowledge graph embedding model called MultE, which models knowledge graphs with multiplicative interaction. In MultE, an entity would have one representation when serving as head entity and another representation when serving as tail entity. For improving performance on 1-to-N, N-to-1 and N-to-N relations, MultE considers all valid tail(or head) entities during training and treats the prediction task as a classification problem. Experiment results show that MultE obtains consistent improvements compared with DistMult and achieves state-of-theart performance."
Reducing psychiatric stigma and discrimination: evaluation of educational interventions in UK secondary schools.,"Vanessa Pinfold, Hilary Toulmin, GThornicroft, Peter John Huxley, PaulFarmer, Tanya R. Graham",The British Journal of Psychiatry,,"The persistent and disabling nature of psychiatric stigma has led to the establishment of global programmes to challenge the negative stereotypes and discriminatory responses that generate social disability but these initiatives are rarely evaluated.To assess the effectiveness of an intervention with young people aimed at increasing mental health literacy and challenging negative stereotypes associated with severe mental illness. A total of 472 secondary school students attended two mental health awareness workshops and completed pre- and post-questionnaires detailing knowledge, attitudes and behavioural intentions. Young people use an extensive vocabulary of 270 different words and phrases to describe people with mental health problems: most were derogatory terms. Mean positive attitude scores rose significantly from 1.2 at baseline to 2.8 at 1-week follow-up and 2.3 at a 6-month follow-up. Changes were most marked for female students and those reporting personal contact with people with mental illness. Short educational workshops can produce positive changes in participants' reported attitudes towards people with mental health problems."
Reducing mental illness stigma and discrimination - everybody's business.,Barbara Hocking,The Medical Journal of Australia,"General medicine, Medical Disorders","The stigma associated with schizophrenia is pervasive, both in the community and among healthcare workers, and forms a real barrier to optimal recovery from the illness. The negative consequences of stigma include discrimination in housing, education and employment, and increased feelings of hopelessness in people with schizophrenia. Health professionals have a responsibility to improve their own attitudes and behaviour towards people with schizophrenia so they do not contribute to the stigma. Educational campaigns aimed at people in the community and media personnel could help to demystify mental illness and reduce the portrayal of offensive stereotypes of people with schizophrenia."
Attitudes of mental health professionals toward people with schizophrenia and major depression.,"Carlos Nordt, Wulf Rössler, ChristophLauber",Schizophrenia Bulletin,"stigma, stereotypes, social distance, mental illness","Several studies reveal poor knowledge about mental illness in the general population and stigmatizing attitudes toward people with mental illness. However, it is unknown whether mental health professionals hold fewer stigmatizing attitudes than the general population. A survey was conducted of the attitudes of mental health professionals (n = 1073) and members of the public (n = 1737) toward mental illness and their specific reaction toward a person with and without psychiatric symptoms (“non-case” as a reference category). Psychiatrists had more negative stereotypes than the general population. Mental health professionals accepted restrictions toward people with mental illness 3 times less often than the public. Most professionals were able to recognize cases of schizophrenia and depression, but 1 in 4 psychiatrists and psychologists also considered the non-case as mentally ill. The social distance toward both major depression and the non-case was lower than toward schizophrenia. However, in this regard, there was no difference between professionals and the public. The study concludes that the better knowledge of mental health professionals and their support of individual rights neither entail fewer stereotypes nor enhance the willingness to closely interact with mentally ill people."
Stigma and Quality of Life as Experienced by People with Mental Illness,"Selim M El-Badri, Graham W. Mellsop",Australasian Psychiatry,"mental illness, quality of life, stigma","The aim of this study was to assess the extent to which people with mental illness in a New Zealand setting encounter stigma and discrimination and to examine their satisfaction with quality of life.  Patients under the care of a range of community mental health services were invited to participate in a survey. Fifty-three females and 47 males completed questionnaires concerning stigma, discrimination and quality of life. Demographic and diagnostic characteristics were also recorded. The majority of participants reported experiencing stigma and discrimination in a variety of contexts. In association with this, they had experienced dissatisfaction with their quality of life in a number of areas. The experience of stigma and dissatisfaction with quality of life among people with mental illness is common. This has implications for clinical assessment and management."
Crazy? So what! Effects of a school project on students' attitudes towards people with schizophrenia.,"Beate Schulze, M. Richter-Werling,Herbert Matschinger, Matthias C.Angermeyer",Acta Psychiatrica Scandinavica,schizophrenia; stigmatization; attitudes; health education; adolescents; schools; secondary,"Aiming at promoting young people's mental health and reducing stigma towards people with schizophrenia, project weeks were carried out with secondary school students aged 14-18 years (n=90). Key to the project week is meeting a (young) person with schizophrenia. Students' attitudes and behavioural intentions towards people with schizophrenia were assessed before and after the project. Parallelly, a control group of students were questioned (n=60). Assessment was repeated after 1 month. Despite expected ceiling effects, the project led to a significant reduction of negative stereotypes. For social distance, a positive trend could be observed. These developments were not present with the controls. Attitude changes were still evident at the 1-month follow-up. Results support the hypothesis that young people's attitudes about schizophrenia are susceptible to change. Antistigma projects at school level could thus be a promising approach to improving public attitudes and to preventing stereotypes from becoming reinforced."
Public beliefs about schizophrenia and depression: similarities and differences,"Matthias C. Angermeyer, HerbertMatschinger",Social Psychiatry and Psychiatric Epidemiology,"lay beliefs, attitudes, schizophrenia, major depression, population survey","Stigma research in psychiatry has mainly focused on mental illness per se. However, recent studies suggest that considerable differences exist between the various disorders. Therefore, we set out to examine similarities and differences of the public’s conceptions of schizophrenia and major depression. In the spring of 2001, a representative survey was carried out in Germany involving individuals of German nationality who were at least 18 years old and who were living in private households (n=5025). Both disorders have in common that they are identified by the majority of the public as an indication of mental illness, that acute stress is most frequently endorsed as cause, that from most respondents a poor natural course is expected which contrasts with a remarkably favorable treatment prognosis, and that people suffering from the two disorders most frequently evoke pity and a desire to help. The perception of dangerousness is closely associated with increased fear and anger, and decreased pity. One of the most notable differences between the two disorders is that while in the case of schizophrenia, labeling as mental illness primarily affects respondents’ emotional reactions negatively, in the case of major depression a positive effect prevails. People with schizophrenia are, by far, more frequently considered as dangerous and unpredictable. They evoke more fear while people with major depression evoke more pro-social reactions. The described similarities and differences of public beliefs and attitudes with regard to schizophrenia and major depression have important implications for the planning of anti-stigma programs and may help to develop more tailor-made interventions."
Working with young people: the impact of mental health awareness programmes in schools in the UK and Canada,"Vanessa Pinfold, Heather L. Stuart, GThornicroft, Julio César Arboleda",World Psychiatry ,"Mental health literacy, schools, schizophrenia","The persistent and disabling nature of psychiatric stigma has led to the establishment of global programmes to challenge the negative stereotypes and discriminatory responses that generate social disability, but these initiatives are rarely evaluated. This study compares the effectiveness of school-based interventions with young people aged 14-16 aimed at increasing mental health literacy and challenging negative stereotypes associated with severe mental illness in sites in Canada and the UK. In both countries, short educational sessions were delivered involving a facilitator with direct experience of mental illness. Students in Canada at baseline (N=1501) were significantly more aware than those in the UK (N=635) that schizophrenia is not a split personality, that mental illness is prevalent and that it is a myth that people with schizophrenia are any more likely to be violent than members of the general population. Both the UK and Canada programmes had a favourable impact on students factual recall and reported attitudes at first follow-up. The cumulative proportion of students expressing no social distance across 4 key items improved over time in both the UK (N=512) and Canada (N=634). Therefore, this study shows that short educational workshops can produce positive change in young people’s views of mental illness. However, more robust evaluations are needed to assess the long-term impact of both short and integrated whole school approaches to increasing mental health literacy across the globe."
Predictors of depression stigma,"Kathleen Margaret Griffiths, HelenChristensen, Anthony F Jorm",BMC Psychiatry,,"To investigate and compare the predictors of personal and perceived stigma associated with depression. Three samples were surveyed to investigate the predictors: a national sample of 1,001 Australian adults; a local community sample of 5,572 residents of the Australian Capital Territory and Queanbeyan aged 18 to 50 years; and a psychologically distressed subset (n = 487) of the latter sample. Personal and Perceived Stigma were measured using the two subscales of the Depression Stigma Scale. Potential predictors included demographic variables (age, gender, education, country of birth, remoteness of residence), psychological distress, awareness of Australia's national depression initiative beyondblue, depression literacy and level of exposure to depression. Not all predictors were used for all samples. Personal stigma was consistently higher among men, those with less education and those born overseas. It was also associated with greater current psychological distress, lower prior contact with depression, not having heard of a national awareness raising initiative, and lower depression literacy. These findings differed from those for perceived stigma except for psychological distress which was associated with both higher personal and higher perceived stigma. Remoteness of residence was not associated with either type of stigma. The findings highlight the importance of treating the concepts of personal and perceived stigma separately in designing measures of stigma, in interpreting the pattern of findings in studies of the predictors of stigma, and in designing, interpreting the impact of and disseminating interventions for stigma."
Can antistigma campaigns be improved? A test of the impact of biogenetic vs psychosocial causal explanations on implicit and explicit attitudes to schizophrenia.,"Tania Marie Lincoln, Elisabeth A. Arens,Cornelia Berger, Winfried Rief",Schizophrenia Bulletin,"stigmatization, psychoeducation, biogenetic, psychosocial","Antistigma campaigns have been promoting a medical view of schizophrenia. Given the growing body of research finding negative associations between biogenetic (BG) causal attributions and stigmatizing attitudes, this approach must be reappraised. The present study investigates the impact of different psychoeducational interventions on the etiology of schizophrenia (BG and psychosocial [PS], vs a neutral condition) and on stigmatizing attitudes in medical (n = 60) and psychology students (n = 61). Information was presented via information brochures and a video presentation. Attitudes were assessed before and after the interventions on an explicit level using the stereotype questionnaire and the Social Distance Scale as well as on an implicit level, using the Implicit Association Test. Both educational interventions produced a significant decrease in several stereotype components, which was not the case in the neutral condition. The BG intervention decreased the attribution of blame in both groups. It also decreased the stereotype unpredictability/incompetence and social distance in the medical students but increased the negative outlook on prognosis in the psychology students. The PS intervention reduced the widespread stereotype of dangerousness as well as social distance in the group of medical students. While further research into antistigma interventions is necessary, the proposal for antistigma campaigns is to take a multidimensional and balanced approach, which is adapted to target groups and provides additional facts that challenge the myths maintaining stigma."
Valoración por parte de los profesionalesde educación de un videojuego (stigma-stop) para sensibilizar en el aula sobre losproblemas de salud mental: un estudiopreliminar,"Adolfo J. Cangas, Juan J. Ojeda",Actas del V Congreso Internacional de Videojuegos y Educación,"estigma, adolescencia, salud mental, videojuegos, SeriousGame","En el presente estudio se evalúa el interés y utilidad que los profesionales docentes dan a Stigma Stop, un videojuego encaminado a sensibilizar a los jóvenes sobre el estigma en salud mental a través de la historia de cuatro personajes con diferentes trastornos (esquizofrenia, agorafobia, trastorno bipolar y depresión). Los resultados mostraron la utilidad del videojuego, recomendando su utilización para la comprensión de lo que son los trastornos psicológicos y cómo trabajar con el estigma."
Do mental health professionals stigmatize their patients?,"Christoph Lauber, Carlos Nordt, CBraunschweig, Wulf Rössler",Acta Psychiatrica Scandinavica,mental disorder; attitude; professional; stereotype; survey,"Assessing stereotypes towards people with mental illness among mental health professionals, comparing their view to the Swiss general population and analysing the influence of demographic factors, profession and work place variables (type of ward, employment time and professional experience). Conducting a representative telephone survey (n = 1073). Factor analysis was used to achieve one-dimensional scales, which were analysed by regression analysis. Most positive depictions were regarded as less characterizing people with mental illness, whereas most negative descriptions were viewed as more typing these people. Compared with the Swiss general population, mental health professionals have not consistently less negative or more positive stereotypes against mentally ill people. Of the 22 stereotypes five factors were detected: 'social disturbance', 'dangerousness', 'normal healthy', 'skills' and 'sympathy'. Stereotypes about people with mental illness are influenced by the professional background and if at all only slightly affected by gender, age, ward type, participation rate of the hospital, weekly working hours or years of professional experience. Mental health professionals must improve their attitudes towards people with mental illness. Different ways, e.g. improving their professional education or their quality of professional contacts by regular supervision to prevent burn-out, are discussed."
Poor Appearance as a Never Ending Stigmatization for People with Severe Mental Health Problems,Fauzan Eka Saputra,Belitung Nursing Journal,,"As a social creature, human will always try to have connection with the others. Unconsciously, in the middle process of the interaction, human is forced to behave like others’ expectation. This situation is very common in adolescence, but it can be exist following the life cycle of human.1 The term of expectation has two different impacts, which is not only motivating human to become a better person or successfully survive and adapt with the expectation, but also separating human from a better one or failed to fulfill the expectation. In this term, stigma may derive from the second impact of the expectation, when a person is being insulted or humiliated by the others for having different situation and condition, that alienates them from their environment. One of conditions that may put person in stigmatization is a severe mental health problem. People with schizophrenia, severe depressive disorder and bipolar disorder are easily to get stigmatized by other people. One of reasons is because they tend to have poor appearances. People with those conditions are unable to take care of themselves, they refuse to take bath and change clothes. They let their hair, mustache and beard grow too long and unaware to smooth them. These typical appearances become common in community and are often described as people with severe mental health problems. In addition, the media worsen the situation by introducing young generations with the concept of stigmatization in the terms of “crazy”, “mad” and “losing your mind” with all characteristics of poor appearances. At this point, recurrent misconception about mental health problem will result to misleading belief, and if it starts from the children, they will treat it as true information. "
Impact of a mental health teaching programme on adolescents.,"Paul B. Naylor, Helen Cowie, Stephen J.Walters, Lorenzo Talamelli, JudithDawkins",The British Journal of Psychiatry,,"Child and adolescent mental health disorders are present in around 10% of the population. Research indicates that many young people possess negative attitudes towards mental health difficulties among peers. To assess the impact of a mental health teaching programme on adolescent pupils' understanding. Two-group pre-test–post-test control group study in two English secondary schools. Experimental classes (School E) received a six-lesson teaching intervention on mental health; control classes (School C) did not. Participants were 14- and 15-year-old pupils. The intervention consisted of six lessons on mental health issues common to young people: stress; depression; suicide/self-harm; eating disorders; being bullied; and intellectual disability. School C was given access to these lesson plans and materials on completion of the study. Understanding was measured at two time points, Time 1 (T 1) and Time 2 (T 2), 8 months apart, by a Mental Health Questionnaire. Behavioural, emotional and relationship strengths and difficulties were measured by the self-rated Strengths and Difficulties Questionnaire (SDQ) with five subscales: hyperactivity, emotional symptoms, conduct problems, peer problems and prosocial behaviour. At T 2, pupils in School E compared with those in School C showed significantly more sensitivity and empathy towards people with mental health difficulties. They also used significantly fewer pejorative expressions to describe mental health difficulties. There was a significant reduction in SDQ scores on conduct problems and a significant increase on prosocial behaviour among School E pupils compared with controls. Pupils valued the intervention highly, in particular the lessons on suicide/self-harm. Teaching 14- and 15-year-olds about mental health difficulties helps to reduce stigma by increasing knowledge and promoting positive attitudes. The intervention also reduced self-reported conduct problems and increased prosocial behaviour. Generally, participating pupils were positive about the importance of lessons on mental health, and said that they had learnt much about the lesson topics."
Reducing psychiatric stigma and discrimination--evaluating an educational intervention with the police force in England.,"Vanessa Pinfold, Peter John Huxley, GThornicroft, Paul Farmer, HilaryToulmin, Thornicroft Graham",Social Psychiatry and Psychiatric Epidemiology,"attitudes, police, mental health","Across the world there are programmes challenging negative stereotypes of people with mental health problems and associated discriminatory behaviours, but the evidence base describing what works in practice is still underdeveloped. This paper evaluates the effectiveness of a mental health training intervention with the police force in England. A total of 109 police officers attended training workshops and completed pre- and post-questionnaires detailing knowledge, attitudes and behavioural interventions. Mean attitude scores fell from 2.4 at baseline to 2.3 at follow-up (p < 0.0001) using a 5-point Likert scale. Five key message statements were assessed - 70 % of cases successfully reported more messages at follow-up as compared to baseline; however, the stereotype linking people with mental health problems with violent behaviour overall was not successfully challenged. Positive impacts on police work, particularly improvements in communication between officers and subjects, were reported by a third of cases. Short educational interventions can produce changes in participants' reported attitudes towards people with mental health problems, and can leave police officers feeling more informed and more confident to support people in mental distress."
Stigma and mental health professionals: a review of the evidence on an intricate relationship.,Beate Schulze,International Review of Psychiatry,"Stigma, attitudes, public images, mental health professionals, burnout, psychiatry, anti-stigma programmes","In the past decade, mental health professionals have initiated a number of national and international efforts against the stigma of mental illness. While largely successful in beating stigma and discrimination, these programmes have, in part, been criticized to be largely uninformed by the lived realities of people with mental illness and their families. Some critics claimed that anti-stigma efforts led by mental health professionals were in fact a concealed attempt at de-stigmatizing psychiatry itself as a profession. This paper will attempt to throw light on the various ways in which mental health professionals are 'entangled' in anti-stigma activities. It will outline the complex relationships between stigma and the psychiatric profession, presenting evidence on how its members can simultaneously be stigmatizers, stigma recipients and powerful agents of de-stigmatization. In exploring the role of mental health professionals as targets of stigma, new findings will be presented on the role of stigma as a professional stressor in psychiatry. Conclusions will be drawn on how the pursuit of professional self-interest can be a legitimate goal of anti-stigma programmes. Further, ways in which acknowledging psychiatry's own agenda can contribute to both credibility and success of fighting stigma from within psychiatry will be discussed."
Factors Influencing Social Distance Toward People with Mental Illness,"Christoph Lauber, Carlos Nordt, LuisFalcato, Wulf Rössler",Community Mental Health Journal,mental illness; attitude; public opinion survey; social distance; stigmatization,"When identifying ways to reduce stigmatization because of mental illness it is crucial to understand contributing factors. Social distance-the willingness to engage in relationships of varying intimacy with a person--is an indicator of public attitudes toward persons with mental illness. Multiple linear regression analysis of the results of a vignette-based opinion survey conducted on a representative population sample in Switzerland (n = 594).The level of social distance increases if situations imply 'social closeness.' The vignette describing a person with schizophrenia, attitudes to general aspects of mental health (lay helping, community psychiatry), emotions toward those affected, and the attitude toward consequences of mental illness (medical treatment, medication side effects, negative sanctions, e.g. withdrawal of the driver license) were found to predict social distance. Demographic factors such as age, gender, and the cultural background influence social distance. The explained variance (R2) is 44.8%.  Social distance is a multifaceted concept influenced by, e.g., socio-economic and cultural factors, but also by the respondent's general attitude toward (mental) health issues. These results suggest that more knowledge about mental illnesses, especially schizophrenia, may increase social distance. The findings presented here may help to focus anti-stigma campaigns not only on transmission of knowledge, but on integrating different approaches."
Reaching Out to High School Youth: The Effectiveness of a Video-Based Antistigma Program,Heather L. Stuart,The Canadian Journal of Psychiatry,"stigma, antistigma, evaluation, high school antistigma program","To evaluate the impact on high school students of a video-based antistigma program portraying real life experiences of individuals with schizophrenia and lesson plans to guide classroom discussions and active learning. We used a pre- and posttest design to measure the short-term impact of the program on student's knowledge of schizophrenia and its treatment as well as students' self-reported socially distancing behaviours. Participants (571 students) were from 8 high schools across Canada. Following the Reaching Out antistigma program, high school students were significantly more knowledgeable and less socially distancing. Impact also varied by age group and sex. Video-based antistigma programs are comparable to programs that deliver educational messages through direct contact with individuals with mental illnesses. Video-based programs are more easily disseminated on a broad scale."
Reducing psychiatric stigma and discrimination,"Vanessa Pinfold, Peter John Huxley, GThornicroft, Paul Farmer, HilaryToulmin, Tiffany Graham",The British Journal of Psychiatry,,"The persistent and disabling nature of psychiatric stigma has led to the establishment of global programmes to challenge the negative stereotypes and discriminatory responses that generate social disability, but these initiatives are rarely evaluated. To assess the effectiveness of an intervention with young people aimed at increasing mental health literacy and challenging negative stereotypes associated with severe mental illness. A total of 472 secondary school students attended two mental health awareness workshops and completed pre- and post-questionnaires detailing knowledge, attitudes and behavioural intentions. Young people use an extensive vocabulary of 270 different words and phrases to describe people with mental health problems: most were derogatory terms. Mean positive attitude scores rose significantly from 1.2 at baseline to 2.8 at 1-week follow-up and 2.3 at a 6-month follow-up. Changes were most marked for female students and those reporting personal contact with people with mental illness. Short educational workshops can produce positive changes in participants' reported attitudes towards people with mental health problems."
How children stigmatize people with mental illness.,"Patrick W Corrigan, A. Clinton Watson",International Journal of Social Psychiatry,"stigma, children","Many advocates have called for more anti-stigma programs targeting the attitudes of children towards people with mental illness as a way to forestall subsequent prejudice and discrimination as they age and develop. In order to better understand how children stigmatize people with mental illness, we reviewed the substantial literature on social cognitive development and ethnic prejudice. This literature suggests a curvilinear relationship. Children as young as three show some endorsement of stereotypes about people of color, which slowly increases and seems to peak around age five to six. Older children, interestingly, show lower rates of ethnic prejudice. Differences between mental illness and ethnicity-related stigma may influence the form of this relationship and we provide some hypotheses representing this difference. We then summarize the literature on stigma change, focusing on how specific strategies interact with what is known about social cognitive development and prejudice. Strategies that are reviewed include education, contact, social cognitive skills training, role play for empathy, peer interaction, protest and consequences. Implications for continued research in this area are highlighted throughout the article."
What about psychiatrists' attitude to mentally ill people?,"Christoph Lauber, Marion Anthony,Vladeta Ajdacic-Gross, Wulf Rössler",European Psychiatry,"Expert and lay attitude, Mental illness, Community psychiatry, Social distance, Anti-stigma campaign","Firstly, to assess and, secondly, to compare experts' and lay attitudes towards community psychiatry and the respective social distance towards mentally ill people. Comparison of two representative Swiss samples, one comprising of 90 psychiatrists, the other including 786 individuals of the general population. The psychiatrists' attitude was significantly more positive than that of the general population although both samples have a positive attitude to community psychiatry. The statement that mental health facilities devalue a residential area has revealed most agreement. Psychiatrists and the public do not differ in their social distance to mentally ill people. Among both samples, the level of social distance increases the more the situation described implies ""social closeness"". The strategy to use psychiatrists as role models or opinion leaders in anti-stigma campaigns cannot be realised without accompanying actions. Psychiatrists must be aware that their attitudes do not differ from the general public and, thus, they should improve their knowledge about stigma and discrimination towards people with mental illnesses."
Descriptive epidemiology of stigma against depression in a general population sample in Alberta,"Trevor M. Cook, JianLi Wang",BMC Psychiatry,,"Mental health illnesses, such as depression, are responsible for a growing disease burden worldwide. Unfortunately, effective treatment is often impeded by stigmatizing attitudes of other individuals, which have been found to lead to a number of negative consequences including reduced help-seeking behavior and increased social distance. Despite the high prevalence of depression in Canada, little research has been conducted to examine stigma against depression in the Canadian general population. Such information is crucial to understanding the current state of stigmatizing attitudes in the Canadian communities, and framing future stigma reduction initiatives. The objectives of this study were to estimate the percentages of various stigmatizing attitudes toward depression in a general population sample and to compare the percentages by demographics and socioeconomic characteristics. We conducted a cross-sectional telephone survey in Alberta, Canada, between February and June 2006. Random digit dialing was used to recruit participants who were aged 18-74 years old (n = 3047). Participants were presented a case vignette describing a depressed individual, and responded to a 9-item Personal Stigma questionnaire. The percentages of stigmatizing attitudes were estimated and compared by demographic and socioeconomic variables. Among the participants, 45.9% endorsed that depressed individuals were unpredictable and 21.9% held the view that people with depression were dangerous. Significant differences in stigmatizing attitudes were found by gender, age, education, and immigration status. A greater proportion of men than women held stigmatizing views on each stigma item. No consistent trend emerged by age in stigma against depression. Participants with higher levels of education reported less stigmatizing attitudes than those with less education. Participants who were not born in Canada were more likely to hold stigmatizing attitudes than those who were born in Canada. In the general population, stigmatizing attitudes towards depression differ by demographic characteristics. Men, those with less education and immigrants should be the targets of stigma reduction campaigns."
Attitudes Towards People with a Mental Disorder: A Survey of the Australian Public and Health Professionals,"Anthony F Jorm, Ailsa E. Korten,Patricia A. Jacomb, Helen Christensen,Scott Henderson",Australian and New Zealand Journal of Psychiatry,"attitudes, depression, general practitioners, psychiatrists, psychologists, schizophrenia, stigma","The aim of this paper was to compare the Australian public's attitudes towards people who have been treated for a mental disorder with the attitudes of general practitioners, psychiatrists and clinical psychologists. The study involved a household survey of 2031 members of the Australian public and a postal survey of 872 general practitioners, 1128 psychiatrists and 454 clinical psychologists. Survey participants were presented with a vignette describing a person with schizophrenia or one with depression. They were asked opinions about the person's long-term outcome in various areas of life after receiving treatment. Participants were also asked whether they thought the person described would be discriminated against by others. Both the public and professionals rated outcomes as poorer and discrimination as more likely for the person with schizophrenia than for the one with depression. The professionals made more negative ratings than the public, although the clinical psychologists had similar attitudes to the public about depression. Compared to the public, health professionals rate long-term outcomes more negatively and discrimination as more likely. It is possible that these more negative attitudes are realistic, being based on greater knowledge of mental disorders. However, professional attitudes may be biased by greater contact with patients who have chronic or recurrent disorders. Either way, health professionals need to be aware of the effects that their negative attitudes might have on patients and the public.

"
Stigma in response to mental disorders: a comparison of Australia and Japan,"Kathleen Margaret Griffiths, YoshibumiNakane, Helen Christensen, KumikoYoshioka, Anthony F Jorm, HideyukiNakane",BMC Psychiatry,,"There are few national or cross-cultural studies of the stigma associated with mental disorders. Australia and Japan have different systems of psychiatric health care, and distinct differences in cultural values, but enjoy similar standards of living. This study seeks to compare the nature and extent of stigma among the public in the two countries. A household survey of the public was conducted in each country using similar methodologies. The Australian study comprised a national survey of 3998 adults aged over 18 years. The Japanese survey involved 2000 adults aged 20 to 69 from 25 regional sites distributed across the country. Interviewees reported their personal attitudes (personal stigma, social distance) and perceptions of the attitudes of others (perceived stigma, perceived discrimination) in the community with respect to four case vignettes. These vignettes described a person with: depression; depression with suicidal ideation; early schizophrenia; and chronic schizophrenia. Personal stigma and social distance were typically greater among the Japanese than the Australian public whereas the reverse was true with respect to the perception of the attitudes and discriminatory behaviour of others. In both countries, personal stigma was significantly greater than perceived stigma. The public in both countries showed evidence of greater social distance, greater personal stigma and greater perceived stigma for schizophrenia (particularly in its chronic form) than for depression. There was little evidence of a difference in stigma for depression with and without suicide for either country. However, social distance was greater for chronic compared to early schizophrenia for the Australian public. Stigmatising attitudes were common in both countries, but negative attitudes were greater among the Japanese than the Australian public. The results suggest that there is a need to implement national public awareness interventions tailored to the needs of each country. The current results provide a baseline for future tracking of national stigma levels in each country."
"Public perceptions of stigma towards people with schizophrenia, depression, and anxiety","Lisa Wood, Michele Birtel, SarahAlsawy, Melissa Pyle, Anthony PMorrison",Psychiatry Research,Anxiety disorder; Depression; Public attitudes; Schizophrenia; Stigma; Survey data,"Stigma is one of the greatest challenges facing people with a psychiatric diagnosis. They are widely stigmatised by the general public in the western world. The aim of this study was to examine public stigma attitudes towards schizophrenia, depression and anxiety. The Office of National Statistics (ONS) 2008 opinions survey (n=1070) was utilised. Percentage of endorsements for stigma items were initially compared to the previous 1998 and 2003 databases. Overall stigma attitudes had decreased (from 1998 to 2008) but increased since 2003. A principal components factor analysis identified that stigma attitudes have the same three factors structure across all diagnoses; negative stereotypes, patient blame and inability to recover. Schizophrenia was significantly associated with the most negative stereotypes, least blamed and viewed as least likely to recover compared to anxiety and depression. Public and individualised interventions that target diagnostic variability in stigma attitudes need to be developed and examined in future research."
Labeling—stereotype—discrimination,"Matthias C. Angermeyer, HerbertMatschinger",Social Psychiatry and Psychiatric Epidemiology,"labeling, stereotype, discrimination, population survey, schizophrenia","Using Link and Phelan’s concept of the stigma process, public attitudes towards people with schizophrenia are examined. In the spring of 2001, a representative population survey was conducted in Germany (n=5025). A fully structured personal interview was carried out, beginning with the presentation of a case vignette. Labeling as mental illness increased the likelihood that someone suffering from schizophrenia was considered as being unpredictable and dangerous. This, in turn, led to an increase of the preference for social distance. Although much weaker, labeling also had a positive effect on public attitudes insofar as it was associated with a decrease of the tendency to attribute the responsibility for the occurrence of the disorder to the afflicted person. However, this had no significant impact on the desire for social distance. There was no significant association between labeling and the anticipation of poor prognosis. There were some differences between respondents who are familiar with mental illness and those who are not. Our findings have some implications for the planning of interventions aimed at reducing stigma and discrimination because of schizophrenia. These interventions should primarily address the stereotypes of unpredictability and dangerousness since they are most likely to have a negative impact on the public’s willingness to engage in social relationships with those suffering from this disorder. The interventions should also be tailored according to whether the target population is familiar with mental illness or not."
Determinants that shape public attitudes towards the mentally ill,"Job T.B. van ‘t Veer, Herro F. Kraan,Stans H.C. Drosseart, J. M. Modde",Social Psychiatry and Psychiatric Epidemiology,"public study, mental illness, attitudes, social distance, stereotypes","The stigmatisation of the mentally ill is considered a well-established fact. To improve negative attitudes among the general public, we need to identify the factors that cause them. Drawing from previous studies, we combined a variety of variables to examine a comprehensive explanative model. We examined a sample of the Dutch public on their willingness to interact with mental patients. We examined a number of determinants concerning their influence on levels of social distance: demographical characteristics of the public, their beliefs about stereotypes of mental patients, their beliefs about causes of mental problems, their familiarity with mental illness. We employed a questionnaire survey among two sub-samples of the Dutch public (n = 812, response 33%). Attributing psychiatric problems to structural causes (i.e. causes beyond patients' control and responsibility, such as genetic transmission) is associated with less social distance. Conversely, attribution to individual factors (e.g. drug abuse) related to more distant attitudes. Stereotypical beliefs about mental patients (e.g. untrustworthiness, aggressiveness, causing disturbances) relate to more social distance from mental patients. Results implied that our comprehensive model explains only a modest amount of variance, but shows that to improve public mental health literacy and attitudes should first deal with the most negative stereotypical beliefs."
Effect of web-based depression literacy and cognitive-behavioural therapy interventions on stigmatising attitudes to depression: randomised controlled trial.,"Kathleen Margaret Griffiths, HelenChristensen, Anthony F Jorm,Kimberley Evans, Chloe Groves",The British Journal of Psychiatry,,"Little is known about the efficacy of educational interventions for reducing the stigma associated with depression. To investigate the effects on stigma of two internet depression sites. A sample of 525 individuals with elevated scores on a depression assessment scale were randomly allocated to a depression information website (BluePages), a cognitive-behavioural skills training website (MoodGYM) or an attention control condition. Personal stigma (personal stigmatising attitudes to depression) and perceived stigma (perception of what most other people believe) were assessed before and after the intervention. Relative to the control, the internet sites significantly reduced personal stigma, although the effects were small. BluePages had no effect on perceived stigma and MoodGYM was associated with an increase in perceived stigma relative to the control. Changes in stigma were not mediated by changes in depression, depression literacy or cognitive-behavioural therapy literacy. The internet warrants further investigation as a means of delivering stigma reduction programmes for depression."
Familiarity with mental illness and social distance from people with schizophrenia and major depression: testing a model using data from a representative population survey,"Matthias C. Angermeyer, HerbertMatschinger, Patrick W Corrigan",Schizophrenia Research,"Mental illness, Schizophrenia, Major depression","The main purpose of this study is to examine whether the relationship between familiarity with mental illness and stigmatizing attitudes about mental illness, which had been observed in a previous study based on a sample of community college students (Psychiatr. Serv. 52 (2001) 953), can be replicated using data from a representative population survey. In spring 2001, a representative survey was carried out in Germany (n=5025). A personal, fully structured interview was conducted which began with the presentation of a vignette depicting someone with either schizophrenia or major depression. Respondents were asked to respond to measures assessing familiarity, perception of dangerousness, fear, and social distance. Path analysis with manifest variable structural modeling techniques was applied to test the model used in the previous study. Despite differences in methods, most findings of the previous study were replicated. Respondents who were familiar with mental illness were less likely to believe that people with schizophrenia or major depression are dangerous. Weaker perceptions of dangerousness corresponded closely with less fear of such people, which in turn was associated with less social distance. The effect of familiarity was somewhat pervasive: respondents who reported to be familiar with mental illness expressed a less strong desire for social distance. There is also a relatively strong relationship between perceived dangerousness and social distance. Our findings fully support the notion that approaches to social change which increase the public's familiarity with mental illness will decrease stigma."
Attitudes towards people with mental illness: a cross-sectional study among nursing staff in psychiatric and somatic care.,"Tommy Björkman, Therese Angelman,Malin Jönsson",Scandinavian Journal of Caring Sciences ,"attitudes, discrimination, health professionals, mental illness, nursing staff, stigma","Stigma and discrimination have been identified as important obstacles to the integration of people with mental illness in society. In efforts to reduce stigma and discrimination, health professionals play an important role as they have frequent contact with and responsibility for treatment and rehabilitation of consumers. The aim of the present study was to investigate attitudes towards mental illness and people with mental illness among nursing staff working in psychiatric or somatic care. The sample consisted of 120 registered or assistant nurses who were interviewed about intimacy with mental illness and attitudes about seven different mental illnesses. The results showed that nursing staff in somatic care, to a higher degree than nursing staff in mental health, reported more negative attitudes with regard to people with schizophrenia as being more dangerous and unpredictable. In contrast, professional experience, intimacy with mental illness and type of care organization were found to be more associated with attitudes to specific mental illnesses concerning the prospect of improvement with treatment and the prospect of recovery. In conclusion, attitudes among nursing staff are in several respects comparable with public opinions about mental illness and mentally ill persons. In order to elucidate if negative attitudes about dangerousness and unpredictability of persons with specific mental illnesses are associated with realistic experiences or with prejudices further studies with a qualitative design are suggested."
The Relationship Between Public Causal Beliefs and Social Distance Toward Mentally Ill People,"Sandra Dietrich, Michael Beck, BujanaBujantugs, Denis Kenzine, HerbertMatschinger, Matthias C. Angermeyer",Australian and New Zealand Journal of Psychiatry,"causal beliefs, major depression, population surveys, schizophrenia, social distance","The aim of this study is to investigate the nature of the relationship between public causal beliefs and social distance toward people with mental disorders, particularly schizophrenia and depression. In total, three representative surveys were carried out in Germany, Russia and Mongolia using personal, fully structured interviews. Despite the subjects' different cultural backgrounds, their responses show similar trends with regard to attributing depression and schizophrenia to psychosocial causes: 'acute stress' (life event) was most frequently endorsed as the cause for these two disorders. The biological causes ('brain disease' and 'heredity') were less frequently selected for depression than for schizophrenia. Irrespective of place and type of mental disorder, endorsing biological factors as the cause of schizophrenia was associated with a greater desire for social distance, the same relationship applies to depression in half the instances. It would be premature to draw conclusions with regard to interventions aimed at reducing discrimination based on stigma. However, our study provides stimulus for re-considering the assumptions underlying antistigma interventions: that promulgating biological concepts among the public might not contribute to a desired reduction in social distance toward people with mental disorders."
Prejudice and schizophrenia: a review of the 'mental illness is an illness like any other' approach.,"John Read, Nick Haslam, Liz Sayce,Elise Davies",Acta Psychiatrica Scandinavica,"prejudice, attitudes, stigma, mental illness, schizophrenia","Many anti-stigma programmes use the 'mental illness is an illness like any other' approach. This review evaluates the effectiveness of this approach in relation to schizophrenia. The academic literature was searched, via PsycINFO and MEDLINE, to identify peer-reviewed studies addressing whether public espousal of a biogenetic paradigm has increased over time, and whether biogenetic causal beliefs and diagnostic labelling are associated with less negative attitudes. The public, internationally, continues to prefer psychosocial to biogenetic explanations and treatments for schizophrenia. Biogenetic causal theories and diagnostic labelling as 'illness', are both positively related to perceptions of dangerousness and unpredictability, and to fear and desire for social distance. An evidence-based approach to reducing discrimination would seek a range of alternatives to the 'mental illness is an illness like any other' approach, based on enhanced understanding, from multi-disciplinary research, of the causes of prejudice."
Mental health consumers' experience of stigma.,Otto F. Wahl,Schizophrenia Bulletin,"Mental illness, stigma, discrimination, mental health consumers","The extent to which mental health consumers encounter stigma in their daily lives is a matter of substantial importance for their recovery and quality of life. This article summarizes the results of a nationwide survey of 1,301 mental health consumers concerning their experience of stigma and discrimination. Survey results and followup interviews with 100 respondents revealed experience of stigma from a variety of sources, including communities, families, churches, coworkers, and mental health caregivers. The majority of respondents tended to try to conceal their disorders and worried a great deal that others would find out about their psychiatric status and treat them unfavorably. They reported discouragement, hurt, anger, and lowered self-esteem as results of their experiences, and they urged public education as a means for reducing stigma. Some reported that involvement in advocacy and speaking out when stigma and discrimination were encountered helped them to cope with stigma. Limitations to generalization of results include the self-selection, relatively high functioning of participants, and respondent connections to a specific advocacy organization—the National Alliance for the Mentally Ill."
On stigma and its consequences: evidence from a longitudinal study of men with dual diagnoses of mental illness and substance abuse.,"Bruce G Link, Elmer L. Struening,Michael Rahav, J. Christopher Phelan,Larry Nuttbrock",Journal of Health and Social Behavior,,"Numerous studies have demonstrated a strong connection between the experience of stigma and the well-being of the stigmatized. But in the area of mental illness there has been controversy surrounding the magnitude and duration of the effects of label- ing and stigma. One of the arguments that has been used to downplay the impor- tance of these factors is the substantial body of evidence suggesting that labeling leads to positive effects through mental health treatment. However, as Rosenfield (1997) points out, labeling can simultaneously induce both positive consequences through treatment and negative consequences through stigma. In this study we test whether stigma has enduring effects on well-being by interviewing 84 men with dual diagnoses of mental disorder and substance abuse at two points in time-at entry into treatment, when they were addicted to drugs and had many psychiatric symp- toms and then again after a year of treatment, when they were far less symptomatic and largely drug- and alcohol-free. We found a relatively strong and enduring effect of stigma on well-being. This finding indicates that stigma continues to complicate the lives of the stigmatized even as treatment improves their symptoms and func- tioning. Itfollows that if health professionals want to maximize the well-being of the people they treat, they must address stigma as a separate and importantfactor in its own right."
Familiarity with and social distance from people who have serious mental illness.,"Patrick W Corrigan, Andrew Green,Robert K Lundin, Mary Anne Kubiak,David Lewis Penn",Psychiatry Services ,,"This study examined the effects of familiarity with and social distance from persons who have serious mental illness on stigmatizing attitudes about mental illness. A total of 208 community college students completed three written measures about familiarity, perception of dangerousness, fear, and social distance. Path analysis with manifest-variable structural modeling techniques was used to test a version of a model in which familiarity influences the perception of dangerousness, which in turn influences fear, which influences social distance from persons with serious mental illness. Most of the participants reported experience with mental illness. Scores on the three written measures largely supported the path model. Correlations between the perception of dangerousness and fear as well as between fear and social distance were particularly strong. Approaches to social change that increase the public's familiarity with serious mental illness will decrease stigma. Further studies are warranted that focus on how contact between members of the general public and persons who have serious mental illness may be facilitated."
"Of fear and loathing: The role of ""disturbing behavior,"" labels, and causal attributions in shaping public attitudes toward people with mental illness.","Jack K. Martin, Bernice A. Pescosolido,Steven A. Tuch",Journal of Health and Social Behavior,,"Our paper couples previous research on attitudes toward people with mental illness and more general sociological research on attitudes toward ""out-groups "" to examine the role offive factors that influence the public s willingness to interact with people with mental health problems, including. the nature of the behavior described, causal attributions of the behavior s source, perceived dangerousness of the person, the label of ""mental illness,"" and the sociodemographic characteristics of respondents. Using vignette data from the 1996 General Social Survey (N = 1,444), we find that respon- dents discriminate among different types of mental health problems by expressing more desire to avoid those with drug and alcohol problems than with those with men- tal illness. Consistent with research on racial attitudes, we also find that Americans who attribute mental health problems to structural causes (e.g., stress or genetic/bio- logical causes) are more willing to interact with the vignette person than those who see individual causes (e.g., ""bad character"" or the ""way the person was raised"") as the root of the problem. However, even controlling for these factors, respondents who label the vignette a ""mental illness "" also express a preference for greater social dis- tance. Finally, while the sociodemographic characteristics of the respondent appear to play a minimal role in preferencesfor social distance, the degree of dangerousness that the public ascribes to people with mental health problems is important and appears to mediate the influence of effects of labeling a person as mental"
"Prejudice, social distance, and familiarity with mental illness.","Patrick W Corrigan, A B Edwards,Andrew Green, Sarah Lickey Diwan,David Lewis Penn",Schizophrenia Bulletin,"Mental illness stigma, familiarity, prejudice","In this study, the paths between two prejudicial attitudes (authoritarianism and benevolence) and a proxy measure of behavioral discrimination (social distance) were examined in a sample drawn from the general public Moreover, the effects of two person variables (familiarity with mental illness and ethnicity) on prejudice were examined in the path analysis. One hundred fifty-one research participants completed measures of prejudice toward, social distance from, and familiarity with mental illness. Goodness-of-fit indexes from path analyses supported our hypotheses. Social distance is influenced by both kinds of prejudice: authoritarianism (the belief that persons with mental illness cannot care for themselves, so a paternalistic health system must do so) and benevolence (the belief that persons with mental illness are innocent and childlike). These forms of prejudice, in turn, are influenced by the believers' familiarity with mental illness and their ethnicity. We also discuss how these findings might contribute to a fuller understanding of mental illness stigma"
"The public's view of the competence,dangerousness, and need for legal coercion of persons with mental health problems.","Bernice A. Pescosolido, John Monahan,Bruce G Link, Ann Stueve, SaekoKikuzawa",American Journal of Public Health,,"The authors examined Americans' opinions about financial and treatment competence of people with mental health problems, potential for harm to self or others, and the use of legal means to force treatment. The 1996 General Social Survey provided interview data with a nationally representative sample (n = 1444). Respondents were given a vignette based on diagnostic criteria for schizophrenia, major depression, alcohol dependence, or drug dependence, or a ""control"" case.The specific nature of the problem was the most important factor shaping public reaction. Respondents viewed those with ""troubles,"" alcohol dependence, or depression as able to make treatment decisions. Most reported that persons with alcohol or drug problems or schizophrenia cannot manage money and are likely to be violent toward others. Respondents indicated a willingness to coerce individuals into treatment. Respondent and other case characteristics rarely affected opinions.  Americans report greater concern with individuals who have drug or alcohol problems than with persons who have other mental health problems. Evaluations of dangerousness and coercion indicate a continuing need for public education."
Experiences of Stigma among Outpatients with Psychotic Illnesses in a Tertiary Hospital,"Mercian Daniel, Arvind Kumar",Indian Journal of Psychiatric Social Work,"Stigmatizing experiences, psychosis, outpatients, tertiary hospital"," Studies in most parts of the world, which have included persons with a mental illness in general and those with psychotic illnesses in particular conclusively show that they experience being stigmatized. These responses are seen as a major obstacle to recovery limiting opportunities and undermining self-esteem of people with mental illnesses. There is a conspicuous absence of this in the Indian context. This study assessed the nature and degree of stigma experienced by the persons with a psychotic disorder and examined its relationship with various clinical and demographic characteristics.The sample comprised of 100 consecutive remitted adults with a psychotic disorder as per DCR, ICD-10 attending outpatient services. Stigma was assessed using Wahlâ€™s self-administered stigma questionnaire. After computing a composite score, groups experiencing â€˜highâ€™ stigma were differentiated from those having â€˜lowâ€™ stigma scores on the basis of the median. R Results showed that participants tend to conceal their disorders, worry of being treated unfavorably, were treated as less competent and experienced offensive media portrayals of mental illness. Lower educational levels and history of psychiatric illness in the family significantly related with higher degrees of stigma.  The findings of this study may be seen as a serious call for sustained attention to issues related to stigma as a central and powerful experience among those with a psychotic illness in the Indian context. Those who have another family member suffering from a psychiatric illness, and having lower levels of education should be particularly assessed and managed for stigma during routine outpatient evaluations."
The Social Rejection of Former Mental Patients: Understanding Why Labels Matter',"Bruce G Link, Francis T. Cullen, JamesFrank, John F. Wozniak",American Journal of Sociology,,"Recent research shows that the crucial factor determining the rejection of former mental patients is their behavior rather than their stigmantized status. The study reported here, based on a vignette experiment (with a design that varies patient status with the nature of behavior), challenges this conclusion. Like previous research, it indicates that a simple assessment of labelings shows little effect on a social distance scale. However, when a measure of perceived dangerousness of mental patients is introduced, strong labeling effects emerge. Specifically, the data reveal that the lable of ""previous hospitalization"" fosters high social distance among those who perceive mental patients to be dangerous and low social distance among those who do not see patients as a threat. It appears that past investigators have missed these effects because they have averaged excessively lenient responses with excessively rejecting ones. This suggests that labels play an important role in how former mental patients are perceived and that labeling theory should not be dismissed as a framework for understanding social factors in mental illness."
Public conceptions of mental illness in 1950 and 1996: What is mental illness and is it to be feared?,"J. Christopher Phelan, Bruce G Link,Ann Stueve, Bernice A. Pescosolido",Journal of Health and Social Behavior,,"In the 1950s, the public defined mental illness in much narrower and more extreme terms than did psychiatry, and fearful and rejecting attitudes toward people with mental illnesses were common. Several indicators suggest that definitions of mental illness may have broadened and that rejection and nega- tive stereotypes may have decreased since that time. However, lack of compara- ble data over time prevents us from drawing firm conclusions on these questions. To address this problem, the Mental Health Module of the 1996 General Social Survey repeated a question regarding the meaning of mental illness that was first asked of a nationally representative sample in 1950. A comparison of 1950 and 1996 results shows that conceptions of mental illness have broadened some- what over this time period to include a greater proportion of non-psychotic dis- orders, but that perceptions that mentally ill people are violent or frightening substantially increased, rather than decreased. This increase was limited to respondents who viewed mental illness in terms of psychosis. Among such respondents, the proportion who described a mentally ill person as being violent increased by nearly 2 1/2 times between 1950 and 1996. We discuss the possi- bility that there has been a real move toward acceptance of many forms of men- tal illness as something that can happen to one of ""us,"" but that people with psy- chosis remain a ""them "" who are more feared than they were half a century ago"
Experiences of stigma among outpatients with schizophrenia.,"Faith Dickerson, Jewel Sommerville,Andrea E. Origoni, Norman B. Ringel,Frederick J. Parenté",Schizophrenia Bulletin,"Schizophrenia, stigma, discrimination, mental illness","Many individuals with schizophrenia are devalued and discriminated against because of their mental illness. There has been only limited study of how individuals with schizophrenia experience mental illness stigma. We evaluated 74 stable outpatients with schizophrenia receiving community care. Study participants were interviewed with the Consumer Experiences of Stigma Questionnaire (CESQ), the Positive and Negative Syndrome Scale, and several social functioning measures. On the CESQ, all but one respondent indicated having at least one stigma experience. The most frequently reported CESQ items were respondents' worry about being viewed unfavorably because of their psychiatric illness (70%) and avoidance of telling others about it (58%). Many respondents also indicated having heard offensive statements (55%) and media accounts (43%) about persons with psychiatric disorders. Socioeconomic variables, but not symptoms or social functioning measures, were related to the extent of stigma and discrimination experiences. These results document the extent to which persons with mental illness experience negative reactions from others. Strategies are needed to enhance how persons with schizophrenia cope with stigma."
Stigma and mental illness: A review and critique,"Peter Hayward, Jenifer A. Bright",Journal of Mental Health,,"Research on the extent and nature of psychiatric stigma is reviewed, with a goal of offering insights useful to the practising clinician. Many findings support the view that a label of psychiatric illness is stigmatising, but the effects of this stigma in practice seem to be complex. A number of factors, including age, sex and experience of psychiatric patients seem to affect levels of stigma, and selfstigmatisation also seems to be variable in its effects. Possible causes of stigma and approaches to combatting it are also discussed."
"Subjective experiences of stigma. A focus group study of schizophrenic patients, their relatives and mental health professionals.","Beate Schulze, Matthias C. Angermeyer",Social Science and Medicine,"Stigma, Discrimination, Schizophrenia, Germany","Schizophrenia has been found to be one of the most stigmatising conditions. To the present, most research on stigma related to mental illness has drawn conclusions on the adverse reactions faced by people with schizophrenia from studies on public attitudes or analogue behavioural studies. The views of those exposed to the stigmatising reactions, however, has largely been absent. Aiming to explore stigma from the subjective perspective of people with schizophrenia, a focus group study was carried out at the four centres involved in the WPA Global Programme against Stigma and Discrimination because of Schizophrenia in Germany. In order to get a comprehensive picture of how stigma affects the lives of schizophrenic patients, collateral information was sought from relatives and mental health professionals. The focus groups enquired about concrete stigmatisation experiences of the patients and incidences of stigma witnessed by the other two groups. Focus group sessions were tape-recorded and transcripts were coded using an inductive method. Results reveal four dimensions of stigma: interpersonal interaction, structural discrimination, public images of mental illness and access to social roles. Examples are given for the views of patients, relatives and mental health professionals on each of the four stigma types. The consequences for conceptualisations of stigma and the development of effective strategies to reduce stigma and discrimination because of schizophrenia are discussed."
The stigma of mental illness: effects of labelling on public attitudes towards people with mental disorder.,"Matthias C. Angermeyer, HerbertMatschinger",Acta Psychiatrica Scandinavica,"stigma, labelling, attitudes, schizophrenia, major depression","Aim of the study is to examine the impact of labelling on public attitudes towards people with schizophrenia and major depression. In Spring 2001, a representative survey was carried out in Germany involving adults of German nationality (n = 5025). Labelling as mental illness has an impact on public attitudes towards people with schizophrenia, with negative effects clearly outweighing positive effects. Endorsing the stereotype of dangerousness has a strong negative effect on the way people react emotionally to someone with schizophrenia and increases the preference for social distance. By contrast, perceiving someone with schizophrenia as being in need for help evokes mixed feelings and affects people's desire for social distance both positively and negatively. Labelling has practically no effect on public attitudes towards people with major depression. Our findings illustrate the need for differentiation, differentiation between the different components of stigma as well as differentiation between the various mental disorders."
Stigma as a barrier to recovery: The consequences of stigma for the self-esteem of people with mental illnesses.,"Bruce G Link, Elmer L. Struening,Sheree Neese-Todd, Sven Asmussen, J.Christopher Phelan",Psychiatric Services ,,"The objective of this study was to determine whether stigma affects the self-esteem of persons who have serious mental illnesses or whether stigma has few, if any, effects on self-esteem. Self-esteem and two aspects of stigma, namely, perceptions of devaluation-discrimination and social withdrawal because of perceived rejection, were assessed among 70 members of a clubhouse program for people with mental illness at baseline and at follow-up six and 24 months later. The two measures of perceptions of stigma strongly predicted self-esteem at follow-up when baseline self-esteem, depressive symptoms, demographic characteristics, and diagnosis were controlled for. Participants whose scores on the measures of stigma were at the 90th percentile were seven to nine times as likely as those with scores at the 10th percentile to have low self-esteem at follow-up. The stigma associated with mental illness harms the self-esteem of many people who have serious mental illnesses. An important consequence of reducing stigma would be to improve the self-esteem of people who have mental illnesses."
Psychiatric illness and family stigma.,"J. Christopher Phelan, Evelyn J.Bromet, Bruce G Link",Schizophrenia Bulletin,"family, stigma","Considerable research has documented the stigmatization of people with mental illnesses and its negative consequences. Recently it has been shown that stigma may also seriously affect families of psychiatric patients, but little empirical research has addressed this problem. We examine perceptions of and reactions to stigma among 156 parents and spouses of a population-based sample of first-admission psychiatric patients. While most family members did not perceive themselves as being avoided by others because of their relative's hospitalization, half reported concealing the hospitalization at least to some degree. Both the characteristics of the mental illness (the stigmatizing mark) and the social characteristics of the family were significantly related to levels of family stigma. Family members were more likely to conceal the mental illness if they did not live with their ill relative, if the relative was female, and if the relative had less severe positive symptoms. Family members with more education and whose relative had experienced an episode of illness within the past 6 months reported greater avoidance by others."
Contact with the mentally ill and perceptions of how dangerous they are.,"Bruce G Link, Francis T. Cullen",Journal of Health and Social Behavior,,"Jones et al. (1984) proposes that contact between a ""marked"" and an ""unmarked"" person will modifr the preconceptions each has about the stigmatized condition and about its impact on subsequent social interaction. To test this notion, wee used two general population samples-one drawn from Macomb, Illinois (N= 153) and the other from Cincinnati, Ohio (N= 152)-and found a statisticallv significant inverse association between contact with mental patients' perceptions of how dangerous they are. We find that increased contact is associated with reduced fear among the old and the young, the educated and the less educated, and males and females. Two explanations are possible: (1) contact reduces fear; or (2) perceptions of danger influence the extent to which individuals interact with the mentallY ill. We showt that when contact is generated by external circumstances so that pre-existing attitudes are unlikely to have brought it on, contact is associated wi'ith reduced fear. We interpret this as consistent wi'ith the conceptual scheme offered by Jones et al. The implications are optimistic in that former patients maY be able to influence attitudes of those theY interact with. We note, however, changing others' attitudes maY prove problematic in a number of wa'ays for former patients. Finally we indicate some possible policy implications that our results suggest."
"""A disease like any other""? A decade of change in public reactions to schizophrenia, depression, and alcohol dependence.","Bernice A. Pescosolido, Jack K. Martin,J. Scott Long, Tait R. Medina, J.Christopher Phelan, Bruce G Link",,,"Clinicians, advocates, and policy makers have presented mental illnesses as medical diseases in efforts to overcome low service use, poor adherence rates, and stigma. The authors examined the impact of this approach with a 10-year comparison of public endorsement of treatment and prejudice. The authors analyzed responses to vignettes in the mental health modules of the 1996 and 2006 General Social Survey describing individuals meeting DSM-IV criteria for schizophrenia, major depression, and alcohol dependence to explore whether more of the public 1) embraces neurobiological understandings of mental illness; 2) endorses treatment from providers, including psychiatrists; and 3) reports community acceptance or rejection of people with these disorders. Multivariate analyses examined whether acceptance of neurobiological causes increased treatment support and lessened stigma. In 2006, 67% of the public attributed major depression to neurobiological causes, compared with 54% in 1996. High proportions of respondents endorsed treatment, with general increases in the proportion endorsing treatment from doctors and specific increases in the proportions endorsing psychiatrists for treatment of alcohol dependence (from 61% in 1996 to 79% in 2006) and major depression (from 75% in 1996 to 85% in 2006). Social distance and perceived danger associated with people with these disorders did not decrease significantly. Holding a neurobiological conception of these disorders increased the likelihood of support for treatment but was generally unrelated to stigma. Where associated, the effect was to increase, not decrease, community rejection. More of the public embraces a neurobiological understanding of mental illness. This view translates into support for services but not into a decrease in stigma. Reconfiguring stigma reduction strategies may require providers and advocates to shift to an emphasis on competence and inclusion."
The community's tolerance of the mentally ill.,"Ian F. Brockington, Phillips Hall, JudithM. Levings, Caroline Murphy",The British Journal of Psychiatry,,"A survey of attitudes to mental illness was conducted in a quota sample of about 2000 subjects in Malvern and Bromsgrove. Factor analysis showed three main components - benevolence, authoritarianism, and fear of the mentally ill. Residents of Bromsgrove, which is served by a traditional mental hospital, were slightly more tolerant than those living in Malvern, which has a community-based service, and has seen the closure of two mental hospitals in its vicinity during the last 10 years. The main demographic determinants of tolerance are age, education, occupation, and acquaintance with the mentally ill."
Task-Guided and Path-Augmented Heterogeneous Network Embedding for Author Identification,"Ting Chen, Yizhou Sun",arXiv,Heterogeneous Information Networks; Network Embedding; Author Identification; Meta Path; Task-guided; Path-augmented,"In this paper, we study the problem of author identification under double-blind review setting, which is to identify potential authors given information of an anonymized paper. Different from existing approaches that rely heavily on feature engineering, we propose to use network embedding approach to address the problem, which can automatically represent nodes into lower dimensional feature vectors. However, there are two major limitations in recent studies on network embedding: (1) they are usually general-purpose embedding methods, which are independent of the specific tasks; and (2) most of these approaches can only deal with homogeneous networks, where the heterogeneity of the network is ignored. Hence, challenges faced here are two folds: (1) how to embed the network under the guidance of the author identification task, and (2) how to select the best type of information due to the heterogeneity of the network. To address the challenges, we propose a task-guided and path-augmented heterogeneous network embedding model. In our model, nodes are first embedded as vectors in latent feature space. Embeddings are then shared and jointly trained according to task-specific and network-general objectives. We extend the existing unsupervised network embedding to incorporate meta paths in heterogeneous networks, and select paths according to the specific task. The guidance from author identification task for network embedding is provided both explicitly in joint training and implicitly during meta path selection. Our experiments demonstrate that by using path-augmented network embedding with task guidance, our model can obtain significantly better accuracy at identifying the true authors comparing to existing methods."
"Deep learning for network analysis: Problems, approaches and challenges","Siddharth Pal, Yuxiao Dong, BishalThapa, Nitesh V. Chawla, AnanthramSwami, Ram Ramanathan",IEEE,,"The analysis of social, communication and information networks for identifying patterns, evolutionary characteristics and anomalies is a key problem for the military, for instance in the Intelligence community. Current techniques do not have the ability to discern unusual features or patterns that are not a priori known. We investigate the use of deep learning for network analysis. Over the last few years, deep learning has had unprecedented success in areas such as image classification, speech recognition, etc. However, research on the use of deep learning to network or graph analysis is limited. We present three preliminary techniques that we have developed as part of the ARL Network Science CTA program: (a) unsupervised classification using a very highly trained image recognizer, namely Caffe; (b) supervised classification using a variant of convolutional neural networks on node features such as degree and assortativity; and (c) a framework called node2vec for learning representations of nodes in a network using a mapping to natural language processing."
PathSim: Meta Path-Based Top-K Similarity Search in Heterogeneous Information Networks,"Yizhou Sun, Jiawei Han, Xifeng Yan,Philip S. Yu, Tianyi Wu",VLDB,,"Similarity search is a primitive operation in database and Web search engines. With the advent of large-scale heterogeneous information networks that consist of multi-typed, interconnected objects, such as the bibliographic networks and social media networks, it is important to study similarity search in such networks. Intuitively, two objects are similar if they are linked by many paths in the network. However, most existing similarity measures are defined for homogeneous networks. Different semantic meanings behind paths are not taken into consideration. Thus they cannot be directly applied to heterogeneous networks. In this paper, we study similarity search that is defined among the same type of objects in heterogeneous networks. Moreover, by considering different linkage paths in a network, one could derive various similarity semantics. Therefore, we introduce the concept of meta path-based similarity, where a meta path is a path consisting of a sequence of relations defined between different object types (i.e., structural paths at the meta level). No matter whether a user would like to explicitly specify a path combination given sufficient domain knowledge, or choose the best path by experimental trials, or simply provide training examples to learn it, meta path forms a common base for a network-based similarity search engine. In particular, under the meta path framework we define a novel similarity measure called PathSim that is able to find peer objects in the network (e.g., find authors in the similar field and with similar reputation), which turns out to be more meaningful in many scenarios compared with random-walk based similarity measures. In order to support fast online query processing for PathSim queries, we develop an efficient solution that partially materializes short meta paths and then concatenates them online to compute top-k results. Experiments on real data sets demonstrate the effectiveness and efficiency of our proposed paradigm."
Node Representations from Structural Identity,"Daniel R. Figueiredo, R. Laura Alves",arXiv,feature learning; node embeddings; structural identity,"Structural identity is a concept of symmetry in which network nodes are identified according to the network structure and their relationship to other nodes. Structural identity has been studied in theory and practice over the past decades, but only recently has it been addressed with representational learning techniques. This work presents struc2vec, a novel and flexible framework for learning latent representations for the structural identity of nodes. struc2vec uses a hierarchy to measure node similarity at different scales, and constructs a multilayer graph to encode structural similarities and generate structural context for nodes. Numerical experiments indicate that state-of-the-art techniques for learning node representations fail in capturing stronger notions of structural identity, while struc2vec exhibits much superior performance in this task, as it overcomes limitations of prior approaches. As a consequence, numerical experiments indicate that struc2vec improves performance on classification tasks that depend more on structural identity."
Meta-Path Guided Embedding for Similarity Search in Large-Scale Heterogeneous Information Networks,"Jingbo Shang, Meng Qu, Jialu Liu,Lance M. Kaplan, Jiawei Han, JianPeng",arXiv,,"Most real-world data can be modeled as heterogeneous information networks (HINs) consisting of vertices of multiple types and their relationships. Search for similar vertices of the same type in large HINs, such as bibliographic networks and business-review networks, is a fundamental problem with broad applications. Although similarity search in HINs has been studied previously, most existing approaches neither explore rich semantic information embedded in the network structures nor take user's preference as a guidance. In this paper, we re-examine similarity search in HINs and propose a novel embedding-based framework. It models vertices as low-dimensional vectors to explore network structure-embedded similarity. To accommodate user preferences at defining similarity semantics, our proposed framework, ESim, accepts user-defined meta-paths as guidance to learn vertex vectors in a user-preferred embedding space. Moreover, an efficient and parallel sampling-based optimization algorithm has been developed to learn embeddings in large-scale HINs. Extensive experiments on real-world large-scale HINs demonstrate a significant improvement on the effectiveness of ESim over several state-of-the-art algorithms as well as its scalability."
Large-Scale Embedding Learning in Heterogeneous Event Data,"Huan Gui, Jialu Liu, Fangbo Tao, MengJiang, Brandon Norick, Jiawei Han",University of Illinois Urbana-Champaign,,"Heterogeneous events, which are defined as events connecting strongly-typed objects, are ubiquitous in the real world. We propose a HyperEdge-Based Embedding (HEBE) framework for heterogeneous event data, where a hyperedge represents the interaction among a set of involving objects in an event. The HEBE framework models the proximity among objects in an event by predicting a target object given the other participating objects in the event (hyperedge). Since each hyperedge encapsulates more information on a given event, HEBE is robust to data sparseness. In addition, HEBE is scalable when the data size spirals. Extensive experiments on large-scale real-world datasets demonstrate the efficacy and robustness of HEBE."
The topological relationship between the large-scale attributes and local interaction patterns of complex networks.,"Alexei Vázquez, Radu Dobrin, DaniloSergi, J-P Eckmann, Zoltán N. Oltvai, A.-L. Barab'asi",PNAS,"aggregation, subgraphs","Recent evidence indicates that the abundance of recurring elementary interaction patterns in complex networks, often called subgraphs or motifs, carry significant information about their function and overall organization. Yet, the underlying reasons for the variable quantity of different subgraph types, their propensity to form clusters, and their relationship with the networks' global organization remain poorly understood. Here we show that a network's large-scale topological organization and its local subgraph structure mutually define and predict each other, as confirmed by direct measurements in five well studied cellular networks. We also demonstrate the inherent existence of two distinct classes of subgraphs, and show that, in contrast to the low-density type II subgraphs, the highly abundant type I subgraphs cannot exist in isolation but must naturally aggregate into subgraph clusters. The identified topological framework may have important implications for our understanding of the origin and function of subgraphs in all complex networks."
"Coherence thresholds in models of language change and evolution: the effects of noise, dynamics, and network of interactions.","J M Tavares, Margarida M Telo daGama, Ana Nunes",Physical Review E,,"A simple model of language evolution proposed by Komarova, Niyogi, and Nowak is characterized by a payoff in communicative function and by an error in learning that measure the accuracy in language acquisition. The time scale for language change is generational, and the model’s equations in the mean-field approximation are a particular case of the replicator-mutator equations of evolutionary dynamics. In well-mixed populations, this model exhibits a critical coherence threshold; i.e., a minimal accuracy in the learning process is required to maintain linguistic coherence. In this work, we analyze in detail the effects of different fitness-based dynamics driving linguistic coherence and of the network of interactions on the nature of the coherence threshold by performing numerical simulations and theoretical analyses of three different models of language change in finite populations with two types of structure: fully connected networks and regular random graphs. We find that although the threshold of the original replicator-mutator evolutionary model is robust with respect to the structure of the network of contacts, the coherence threshold of related fitness-driven models may be strongly affected by this feature."
Length of optimal path in random networks with strong disorder,"Sergey V. Buldyrev, Lidia A. Braunstein,Reuven Cohen, Shlomo Havlin, HarryEugene Stanley",Physica A: Statistical Mechanics and its Applications,"Scale-free networks, Small-world networks, Percolation, Strong disorder, Optimal path","We study the optimal distance ℓopt in random networks in the presence of disorder implemented by assigning random weights to the links. The optimal distance between two nodes is the length of the path for which the sum of weights along the path (“cost”) is a minimum. We study the case of strong disorder for which the distribution of weights is so broad that its sum along any path is dominated by the largest link weight in the path. We find that in random graphs, ℓopt scales as N1/3, where N is the number of nodes in the network. Thus, ℓopt increases dramatically compared to the known small-world result for the minimum distance ℓmin, which scales as logN. We also study, theoretically and by simulations, scale-free networks characterized by a power law distribution for the number of links, P(k)∼k−λ, and find that ℓopt scales as N1/3 for λ>4 and as N(λ−3)/(λ−1) for 3<λ<4. For 2<λ<3, our numerical results suggest that ℓopt scales logarithmically with N."
Enhance Robustness of Scale-free Networks,"Qiang Guo, Jianguo Liu, Datian Niu",Scientific Reports,,Many real-world systems can be described by scale-free networks with power-law degree distributions. Scale-free networks show a “robust yet fragile” feature due to their heterogeneous degree distributions. We propose to enhance the structural robustness of scale-free networks against intentional attacks by changing the displayed network structure information rather than modifying the network structure itself. We first introduce a simple mathematical model for attack information and investigate the impact of attack information on the structural robustness of scale-free networks. Both analytical and numerical results show that decreasing slightly the attack information perfection by information disturbance can dramatically enhance the structural robustness of scale-free networks. Then we propose an optimization model of disturbance strategies in which the cost constraint is considered. We analyze the optimal disturbance strategies and show an interesting but counterintuitive finding that disturbing “poor nodes” with low degrees preferentially is more effective than disturbing “rich nodes” with high degrees preferentially. We demonstrate the efficiency of our method by comparison with edge addition method and validate the feasibility of our method in two real-world critical infrastructure networks.
Weighted evolving networks: coupling topology and weight dynamics.,"Alain Barrat, Marc Barthelemy,Alessandro Vespignani",arXiv,,"We propose a model for the growth of weighted networks that couples the establishment of new edges and vertices and the weights' dynamical evolution. The model is based on a simple weight-driven dynamics and generates networks exhibiting the statistical properties observed in several real-world systems. In particular, the model yields a non-trivial time evolution of vertices' properties and scale-free behavior for the weight, strength and degree distributions."
Percolation theory applied to measures of fragmentation in social networks.,"YiPing Chen, Gerald Paul, ReuvenCohen, Shlomo Havlin, Stephen P.Borgatti, Fredrik Liljeros, Harry EugeneStanley",Physical Review E,,"We apply percolation theory to a recently proposed measure of fragmentation F for social networks. The measure F is defined as the ratio between the number of pairs of nodes that are not connected in the fragmented network after removing a fraction q of nodes and the total number of pairs in the original fully connected network. We compare F with the traditional measure used in percolation theory, P, the fraction of nodes in the largest cluster relative to the total number of nodes. Using both analytical and numerical methods from percolation, we study Erdős-Rényi and scale-free networks under various types of node removal strategies. The removal strategies are random removal, high degree removal, and high betweenness centrality removal. We find that for a network obtained after removal all strategies of a fraction q of nodes above percolation threshold, P 1−F 1/2. For fixed P and close to percolation threshold q=qc, we show that 1−F better reflects the actual fragmentation. Close to qc, for a given P, 1−F has a broad distribution and it is thus possible to improve the fragmentation of the network. We also study and compare the fragmentation measure F and the percolation measure P for a real social network of workplaces linked by the households of the employees and find similar results."
Arrival time statistics in global disease spread,"Aurélien Gautreau, Alain Barrat, MarcBarthelemy",arXiv,,"Metapopulation models describing cities with different populations coupled by the travel of individuals are of great importance in the understanding of disease spread on a large scale. An important example is the Rvachev-Longini model [{\it Math. Biosci.} {\bf 75}, 3-22 (1985)] which is widely used in computational epidemiology. Few analytical results are however available and in particular little is known about paths followed by epidemics and disease arrival times. We study the arrival time of a disease in a city as a function of the starting seed of the epidemics. We propose an analytical Ansatz, test it in the case of a spreading on the world wide air transportation network, and show that it predicts accurately the arrival order of a disease in world-wide cities."
Activity driven modeling of dynamic networks,"Nicola Perra, Bruno Gonçalves,Romualdo Pastor-Satorras, AlessandroVespignani",Scientific Reports,,"Network modeling plays a critical role in identifying statistical regularities and structural principles common to many systems. The large majority of recent modeling approaches are connectivity driven. The structural patterns of the network are at the basis of the mechanisms ruling the network formation. Connectivity driven models necessarily provide a time-aggregated representation that may fail to describe the instantaneous and fluctuating dynamics of many networks. We address this challenge by defining the activity potential, a time invariant function characterizing the agents' interactions and constructing an activity driven model capable of encoding the instantaneous time description of the network dynamics. The model provides an explanation of structural features such as the presence of hubs, which simply originate from the heterogeneous activity of agents. Within this framework, highly dynamical networks can be described analytically, allowing a quantitative discussion of the biases induced by the time-aggregated representations in the analysis of dynamical processes."
Evolving networks consist of cliques,"Zhongzhi Zhang, Shuigeng Zhou",arXiv,,"Many real networks have cliques as their constitutional units. Here we present a family of scale-free network model consist of cliques, which is established by a simple recursive algorithm. We investigate the networks both analytically and numerically. The obtained analytical solution shows that the networks follow a power-law degree distribution, with degree exponent continuously tuned between 2 and 3, coinciding with the empirically found results. The exact expression of clustering coefficient is also provided for the networks. Furthermore, the investigation of the average path length reveals that the networks possess small-world feature."
Evolving networks by merging cliques.,"Kazuhiro Takemoto, Chikoo Oosawa",Physical Review E,,"We propose a model for evolving networks by merging building blocks represented as complete graphs, reminiscent of modules in biological system or communities in sociology. The model shows power-law degree distributions, power-law clustering spectra, and high average clustering coefficients independent of network size. The analytical solutions indicate that a degree exponent is determined by the ratio of the number of merging nodes to that of all nodes in the blocks, demonstrating that the exponent is tunable, and are also applicable when the blocks are classical networks such as Erdös-Rényi or regular graphs. Our model becomes the same model as the Barabási-Albert model under a specific condition."
Optimization of Robustness of Scale-free Network to Random and Targeted Attacks,"Jian-Guo Liu, Zhong-tuo Wang, Yan-Zhong Dang",Modern Physics Letters B,"Scale-free network, optimal programme, power-law distribution, random failure","Scale-free networks, having connectivity distribution P(k)~k-α (where k is the site connectivity), are very resilient to random failures but are fragile to intentional attacks. The purpose of this paper is to find the network design guideline which can make the robustness of the network to both random failures and intentional attacks maximum while keeping the average connectivity <k> per node constant. We find that when <k> = 3 the robustness of the scale-free networks reach its maximum value if the minimal connectivity m = 1, but when <k> is larger than four, the networks will become more robust to random failures and targeted attacks as the minimal connectivity m gets larger."
Scaling of optimal-path-lengths distribution in complex networks.,"Tomer Kalisky, Lidia A. Braunstein,Sergey V. Buldyrev, Shlomo Havlin,Harry Eugene Stanley",arXiv,,"We study the distribution of optimal path lengths in random graphs with random weights associated with each link (``disorder''). With each link i we associate a weight τi=exp(ari) where ri is a random number taken from a uniform distribution between 0 and 1, and the parameter a controls the strength of the disorder. We suggest, in analogy with the average length of the optimal path, that the distribution of optimal path lengths has a universal form which is controlled by the expression 1pcℓ∞a, where ℓ∞ is the optimal path length in strong disorder (a→∞) and pc is the percolation threshold. This relation is supported by numerical simulations for Erdős-Rényi and scale-free graphs. We explain this phenomenon by showing explicitly the transition between strong disorder and weak disorder at different length scales in a single network."
Localization transition on complex networks via spectral statistics.,"Matti Sade, Tomer Kalisky, ShlomoHavlin, Richard Berkovits",arXiv,,"The spectral statistics of complex networks are numerically studied. The features of the Anderson metal-insulator transition are found to be similar for a wide range of different networks. A metal-insulator transition as a function of the disorder can be observed for different classes of complex networks for which the average connectivity is small. The critical index of the transition corresponds to the mean field expectation. When the connectivity is higher, the amount of disorder needed to reach a certain degree of localization is proportional to the average connectivity, though a precise transition cannot be identified. The absence of a clear transition at high connectivity is probably due to the very compact structure of the highly connected networks, resulting in a small diameter even for a large number of sites."
Comparing community structure identification,"Leon Danon, Jordi Duch, Albert Díaz-Guilera, Alex Arenas",arXiv,,"We compare recent approaches to community structure identification in terms of sensitivity and computational cost. The recently proposed modularity measure is revisited and the performance of the methods as applied to ad hoc networks with known community structure, is compared. We find that the most accurate methods tend to be more computationally expensive, and that both aspects need to be considered when choosing a method for practical purposes. The work is intended as an introduction as well as a proposal for a standard benchmark test of community detection methods."
Finding and evaluating community structure in networks.,"Micaleah Newman, Michelle Girvan",arXiv,,"We propose and study a set of algorithms for discovering community structure in networks -- natural divisions of network nodes into densely connected subgroups. Our algorithms all share two definitive features: first, they involve iterative removal of edges from the network to split it into communities, the edges removed being identified using one of a number of possible ""betweenness"" measures, and second, these measures are, crucially, recalculated after each removal. We also propose a measure for the strength of the community structure found by our algorithms, which gives us an objective metric for choosing the number of communities into which a network should be divided. We demonstrate that our algorithms are highly effective at discovering community structure in both computer-generated and real-world network data, and show how they can be used to shed light on the sometimes dauntingly complex structure of networked systems."
Community detection in graphs,Santo Fortunato,Physics Reports,"Graphs, Clusters, Statistical Physics","The modern science of networks has brought significant advances to our understanding of complex systems. One of the most relevant features of graphs representing real systems is community structure, or clustering, i.e. the organization of vertices in clusters, with many edges joining vertices of the same cluster and comparatively few edges joining vertices of different clusters. Such clusters, or communities, can be considered as fairly independent compartments of a graph, playing a similar role like, e.g., the tissues or the organs in the human body. Detecting communities is of great importance in sociology, biology and computer science, disciplines where systems are often represented as graphs. This problem is very hard and not yet satisfactorily solved, despite the huge effort of a large interdisciplinary community of scientists working on it over the past few years. We will attempt a thorough exposition of the topic, from the definition of the main elements of the problem, to the presentation of most methods developed, with a special focus on techniques designed by statistical physicists, from the discussion of crucial issues like the significance of clustering and how methods should be tested and compared against each other, to the description of applications to real networks."
Fast algorithm for detecting community structure in networks.,Micaleah Newman,arXiv,,"It has been found that many networks display community structure -- groups of vertices within which connections are dense but between which they are sparser -- and highly sensitive computer algorithms have in recent years been developed for detecting such structure. These algorithms however are computationally demanding, which limits their application to small networks. Here we describe a new algorithm which gives excellent results when tested on both computer-generated and real-world networks and is much faster, typically thousands of times faster than previous algorithms. We give several example applications, including one to a collaboration network of more than 50000 physicists."
Statistical mechanics of community detection.,"Jörg Reichardt, Stefan Bornholdt",arXiv,,"Starting from a general \textit{ansatz}, we show how community detection can be interpreted as finding the ground state of an infinite range spin glass. Our approach applies to weighted and directed networks alike. It contains the \textit{at hoc} introduced quality function from \cite{ReichardtPRL} and the modularity Q as defined by Newman and Girvan \cite{Girvan03} as special cases. The community structure of the network is interpreted as the spin configuration that minimizes the energy of the spin glass with the spin states being the community indices. We elucidate the properties of the ground state configuration to give a concise definition of communities as cohesive subgroups in networks that is adaptive to the specific class of network under study. Further we show, how hierarchies and overlap in the community structure can be detected. Computationally effective local update rules for optimization procedures to find the ground state are given. We show how the \textit{ansatz} may be used to discover the community around a given node without detecting all communities in the full network and we give benchmarks for the performance of this extension. Finally, we give expectation values for the modularity of random graphs, which can be used in the assessment of statistical significance of community structure."
Benchmark graphs for testing community detection algorithms.,"Andrea Lancichinetti, Santo Fortunato,Filippo Radicchi",arXiv,"Networks, community structure, testing","Community structure is one of the most important features of real networks and reveals the internal organization of the nodes. Many algorithms have been proposed but the crucial issue of testing, i.e. the question of how good an algorithm is, with respect to others, is still open. Standard tests include the analysis of simple artificial graphs with a built-in community structure, that the algorithm has to recover. However, the special graphs adopted in actual tests have a structure that does not reflect the real properties of nodes and communities found in real networks. Here we introduce a new class of benchmark graphs, that account for the heterogeneity in the distributions of node degrees and of community sizes. We use this new benchmark to test two popular methods of community detection, modularity optimization and Potts model clustering. The results show that the new benchmark poses a much more severe test to algorithms than standard benchmarks, revealing limits that may not be apparent at a first analysis."
Performance of modularity maximization in practical contexts.,"Benjamin H. Good, Yves-Alexandre deMontjoye, Aaron Clauset",arXiv,,"Although widely used in practice, the behavior and accuracy of the popular module identification technique called modularity maximization is not well understood in practical contexts. Here, we present a broad characterization of its performance in such situations. First, we revisit and clarify the resolution limit phenomenon for modularity maximization. Second, we show that the modularity function Q exhibits extreme degeneracies: it typically admits an exponential number of distinct high-scoring solutions and typically lacks a clear global maximum. Third, we derive the limiting behavior of the maximum modularity Q_max for one model of infinitely modular networks, showing that it depends strongly both on the size of the network and on the number of modules it contains. Finally, using three real-world metabolic networks as examples, we show that the degenerate solutions can fundamentally disagree on many, but not all, partition properties such as the composition of the largest modules and the distribution of module sizes. These results imply that the output of any modularity maximization procedure should be interpreted cautiously in scientific contexts. They also explain why many heuristics are often successful at finding high-scoring partitions in practice and why different heuristics can disagree on the modular structure of the same network. We conclude by discussing avenues for mitigating some of these behaviors, such as combining information from many degenerate solutions or using generative models."
Detecting the overlapping and hierarchical community structure in complex networks,"Andrea Lancichinetti, Santo Fortunato,János Kertész",arXiv,,"Many networks in nature, society and technology are characterized by a mesoscopic level of organization, with groups of nodes forming tightly connected units, called communities or modules, that are only weakly linked to each other. Uncovering this community structure is one of the most important problems in the field of complex networks. Networks often show a hierarchical organization, with communities embedded within other communities; moreover, nodes can be shared between different communities. Here we present the first algorithm that finds both overlapping communities and the hierarchical structure. The method is based on the local optimization of a fitness function. Community structure is revealed by peaks in the fitness histogram. The resolution can be tuned by a parameter enabling to investigate different hierarchical levels of organization. Tests on real and artificial networks give excellent results."
Prominence and control: the weighted rich-club effect.,"Tore Opsahl, Vittoria Colizza, PietroPanzarasa, José J. Ramasco",Physical Review Letters,,"Complex systems are often characterized by large-scale hierarchical organizations. Whether the prominent elements, at the top of the hierarchy, share and control resources or avoid one another lies at the heart of a system’s global organization and functioning. Inspired by network perspectives, we propose a new general framework for studying the tendency of prominent elements to form clubs with exclusive control over the majority of a system’s resources. We explore associations between prominence and control in the fields of transportation, scientific collaboration, and online communication."
Microscopic activity patterns in the Naming Game,"Luca Dall'Asta, Andrea Baronchelli",Journal of Physics A: Mathematical and General,,"The models of statistical physics used to study collective phenomena in some interdisciplinary contexts, such as social dynamics and opinion spreading, do not consider the effects of the memory on individual decision processes. In contrast, in the naming game, a recently proposed model of language formation, each agent chooses a particular state, or opinion, by means of a memory-based negotiation process, during which a variable number of states is collected and kept in memory. In this perspective, the statistical features of the number of states collected by the agents become a relevant quantity to understand the dynamics of the model, and the influence of topological properties on memorybased models. By means of a master equation approach, we analyse the internal agent dynamics of the naming game in populations embedded on networks, finding that it strongly depends on very general topological properties of the system (e.g. average and fluctuations of the degree). However, the influence of topological properties on the microscopic individual dynamics is a general phenomenon that should characterize all those social interactions that can be modelled by memory-based negotiation processes."
The effects of spatial constraints on the evolution of weighted complex networks,"Alain Barrat, Marc Barthelemy,Alessandro Vespignani",arXiv,,"Motivated by the empirical analysis of the air transportation system, we define a network model that includes geographical attributes along with topological and weight (traffic) properties. The introduction of geographical attributes is made by constraining the network in real space. Interestingly, the inclusion of geometrical features induces non-trivial correlations between the weights, the connectivity pattern and the actual spatial distances of vertices. The model also recovers the emergence of anomalous fluctuations in the betweenness-degree correlation function as first observed by Guimerà and Amaral [Eur. Phys. J. B {\bf 38}, 381 (2004)]. The presented results suggest that the interplay between weight dynamics and spatial constraints is a key ingredient in order to understand the formation of real-world weighted networks."
"Apollonian networks: simultaneously scale-free, small world, euclidean, space filling, and with matching graphs.","José S. Andrade, Hans J. Herrmann,Roberto F S Andrade, Luciano da Silva",Physical Review Letters,,"We introduce a new family of networks, the Apollonian networks, that are simultaneously scale-free, small-world, Euclidean, space filling, and with matching graphs. These networks describe force chains in polydisperse granular packings and could also be applied to the geometry of fully fragmented porous media, hierarchical road systems, and area-covering electrical supply networks. Some of the properties of these networks, namely, the connectivity exponent, the clustering coefficient, and the shortest path are calculated and found to be particularly rich. The percolation, the electrical conduction, and the Ising models on such networks are also studied and found to be quite peculiar. Consequences for applications are also discussed."
Fractal boundaries of complex networks,"Jia Shao, Sergey V. Buldyrev, ReuvenCohen, Maksim Kitsak, Shlomo Havlin,Harry Eugene Stanley",arXiv,,"We introduce the concept of boundaries of a complex network as the set of nodes at distance larger than the mean distance from a given node in the network. We study the statistical properties of the boundaries nodes of complex networks. We find that for both Erdös-Rényi and scale-free model networks, as well as for several real networks, the boundaries have fractal properties. In particular, the number of boundaries nodes {\it B} follows a power-law probability density function which scales as B−2. The clusters formed by the boundary nodes are fractals with a fractal dimension df≈2. We present analytical and numerical evidence supporting these results for a broad class of networks. Our findings imply potential applications for epidemic spreading."
Vulnerability of weighted networks,"Luca Dall’Asta, Alain Barrat, MarcBarthelemy, Alessandro Vespignani",arXiv,,"In real networks complex topological features are often associated with a diversity of interactions as measured by the weights of the links. Moreover, spatial constraints may as well play an important role, resulting in a complex interplay between topology, weight, and geography. In order to study the vulnerability of such networks to intentional attacks, these attributes must be therefore considered along with the topological quantities. In order to tackle this issue, we consider the case of the world-wide airport network, which is a weighted heterogeneous network whose evolution and structure are influenced by traffic and geographical constraints. We first characterize relevant topological and weighted centrality measures and then use these quantities as selection criteria for the removal of vertices. We consider different attack strategies and different measures of the damage achieved in the network. The analysis of weighted properties shows that centrality driven attacks are capable to shatter the network's communication or transport properties even at very low level of damage in the connectivity pattern. The inclusion of weight and traffic therefore provides evidence for the extreme vulnerability of complex networks to any targeted strategy and need to be considered as key features in the finding and development of defensive strategies."
Prediction and predictability of global epidemics: the role of the airline transportation network,"Vittoria Colizza, Alexandre Barrat, MarcBarthelemy, Alessandro Vespignani",arXiv,,"The systematic study of large-scale networks has unveiled the ubiquitous presence of connectivity patterns characterized by large scale heterogeneities and unbounded statistical fluctuations. These features affect dramatically the behavior of the diffusion processes occurring on networks, determining the ensuing statistical properties of their evolution pattern and dynamics. In this paper, we investigate the role of the large scale properties of the airline transportation network in determining the global evolution of emerging disease. We present a stochastic computational framework for the forecast of global epidemics that considers the complete world-wide air travel infrastructure complemented with census population data. We address two basic issues in global epidemic modeling: i) We study the role of the large scale properties of the airline transportation network in determining the global diffusion pattern of emerging diseases; ii) We evaluate the reliability of forecasts and outbreak scenarios with respect to the intrinsic stochasticity of disease transmission and traffic flows. In order to address these issues we define a set of novel quantitative measures able to characterize the level of heterogeneity and predictability of the epidemic pattern. These measures may be used for the analysis of containment policies and epidemic risk assessment."
Optimal convergence in naming game with geography-based negotiation on small-world networks,"Run-Ran Liu, Wen-Xu Wang, Ying-ChengLai, Guanrong Chen, Bing Hong Wang",Physics Letters A,"Naming game, Convergence, Small-world networks, Geographical distance",We propose a negotiation strategy to address the effect of geography on the dynamics of naming games over small-world networks. Communication and negotiation frequencies between two agents are determined by their geographical distance in terms of a parameter characterizing the correlation between interaction strength and the distance. A finding is that there exists an optimal parameter value leading to fastest convergence to global consensus on naming. Numerical computations and a theoretical analysis are provided to substantiate our findings.
Characterization and modeling of weighted networks,"Marc Barthelemy, Alexandre Barrat,Romualdo Pastor-Satorras, AlessandroVespignani",Physica A: Statistical Mechanics and its Applications,"Disordered system, Networks","We review the main tools which allow for the statistical characterization of weighted networks. We then present two case studies, the airline connection network and the scientific collaboration network which are representatives of critical infrastructure and social system, respectively. The main empirical results are (i) the broad distributions of various quantities and (ii) the existence of weight-topology correlations. These measurements show that weights are relevant and that in general the modeling of complex networks must go beyond topology. We review a model which provides an explanation for the features observed in several real-world networks. This model of weighted network formation relies on the dynamical coupling between topology and weights, considering the rearrangement of new links are introduced in the system."
The concept of roles in complex networks,"K. J. Parousis‐Orthodoxou, M MStamos, D. S. Vlachos",Nature Physics,,"In physical, biological, technological and social systems, interactions between units give rise to intricate networks. These—typically non-trivial—structures, in turn, critically affect the dynamics and properties of the system. The focus of most current research on complex networks is, still, on global network properties. A caveat of this approach is that the relevance of global properties hinges on the premise that networks are homogeneous, whereas most real-world networks have a markedly modular structure. Here, we report that networks with different functions, including the Internet, metabolic, air transportation and protein interaction networks, have distinct patterns of connections among nodes with different roles, and that, as a consequence, complex networks can be classified into two distinct functional classes on the basis of their link type frequency. Importantly, we demonstrate that these structural features cannot be captured by means of often studied global properties."
Flow Of Emotional Messages In Artificial Social Networks,"Anna M. Chmiel, Janusz A. Holyst",International Journal of Modern Physics C,"Weighted networks, emotions, sociophysics","Models of message flows in an artificial group of users communicating via the Internet are introduced and investigated using numerical simulations. We assumed that messages possess an emotional character with a positive valence and that the willingness to send the next affective message to a given person increases with the number of messages received from this person. As a result, the weights of links between group members evolve over time. Memory effects are introduced, taking into account that the preferential selection of message receivers depends on the communication intensity during the recent period only. We also model the phenomenon of secondary social sharing when the reception of an emotional e-mail triggers the distribution of several emotional e-mails to other people."
Finding community structure in very large networks.,"Aaron Clauset, Mark E. J. Newman,Cristopher Moore",arXiv,,"The discovery and analysis of community structure in networks is a topic of considerable recent interest within the physics community, but most methods proposed so far are unsuitable for very large networks because of their computational cost. Here we present a hierarchical agglomeration algorithm for detecting community structure which is faster than many competing algorithms: its running time on a network with n vertices and m edges is O(m d log n) where d is the depth of the dendrogram describing the community structure. Many real-world networks are sparse and hierarchical, with m ~ n and d ~ log n, in which case our algorithm runs in essentially linear time, O(n log^2 n). As an example of the application of this algorithm we use it to analyze a network of items for sale on the web-site of a large online retailer, items in the network being linked if they are frequently purchased by the same buyer. The network has more than 400,000 vertices and 2 million edges. We show that our algorithm can extract meaningful communities from this network, revealing large-scale patterns present in the purchasing habits of customers."
Fast unfolding of communities in large networks,"Vincent D. Blondel, Jean-LoupGuillaume, Renaud Lambiotte, EtienneLefebvre",arXiv,"Random graphs, networks; Critical phenomena of socio-economic systems; Socio-economic networks","We propose a simple method to extract the community structure of large networks. Our method is a heuristic method that is based on modularity optimization. It is shown to outperform all other known community detection method in terms of computation time. Moreover, the quality of the communities detected is very good, as measured by the so-called modularity. This is shown first by identifying language communities in a Belgian mobile phone network of 2.6 million customers and by analyzing a web graph of 118 million nodes and more than one billion links. The accuracy of our algorithm is also verified on ad-hoc modular networks. ."
On Modularity Clustering,"Ulrik Brandes, Daniel Delling, MarcoGaertler, Robert Görke, Martin Hoefer,Zoran Nikoloski, Dorothea Wagner",IEEE,"Graph Clustering, Graph Partitioning, Modularity, Community Structure, Greedy Algorithm","Modularity is a recently introduced quality measure for graph clusterings. It has immediately received considerable attention in several disciplines, and in particular in the complex systems literature, although its properties are not well understood. We study the problem of finding clusterings with maximum modularity, thus providing theoretical foundations for past and present work based on this measure. More precisely, we prove the conjectured hardness of maximizing modularity both in the general case and with the restriction to cuts, and give an Integer Linear Programming formulation. This is complemented by first insights into the behavior and performance of the commonly applied greedy agglomerative approach."
An Information Flow Model for Conflict and Fission in Small Groups,Wayne W. Zachary,Journal of Anthropological Research,,"Data from a voluntary association are used to construct a new formal modelfor a traditional anthropological problem, fission in small groups. The process leading tofission is viewed as an unequal flow of sentiments and information across the ties in a social network. This flow is unequal because it is uniquely constrained by the contextual range and sensitivity of each relationship in the network. The subsequent differential sharing of sentiments leads to the formation of subgroups with more internal stability than the group as a whole, and results in fission. The Ford-Fulkerson labeling algorithm allows an accurate prediction of membership in the subgroups and of the locus of thefission to be madefrom measurements of the potential for information flow across each edge in the network. Methodsfor measurement of potential informationflow are discussed, and it is shown that all appropriate techniques will generate the same predictions"
Community structure in social and biological networks.,"Michelle Girvan, M. E. J. Newman",PNAS,,"A number of recent studies have focused on the statistical properties of networked systems such as social networks and the Worldwide Web. Researchers have concentrated particularly on a few properties that seem to be common to many networks: the small-world property, power-law degree distributions, and network transitivity. In this article, we highlight another property that is found in many networks, the property of community structure, in which network nodes are joined together in tightly knit groups, between which there are only looser connections. We propose a method for detecting such communities, built around the idea of using centrality indices to find community boundaries. We test our method on computer-generated and real-world graphs whose community structure is already known and find that the method detects this known structure with high sensitivity and reliability. We also apply the method to two networks whose community structure is not well known—a collaboration network and a food web—and find that it detects significant and informative community divisions in both cases."
Modularity and community structure in networks.,Micaleah Newman,PNAS,"clustering, partitioning, modules, metabolic network, social network","Many networks of interest in the sciences, including social networks, computer networks, and metabolic and regulatory networks, are found to divide naturally into communities or modules. The problem of detecting and characterizing this community structure is one of the outstanding issues in the study of networked systems. One highly effective approach is the optimization of the quality function known as ‘‘modularity’’ over the possible divisions of a network. Here I show that the modularity can be expressed in terms of the eigenvectors of a characteristic matrix for the network, which I call the modularity matrix, and that this expression leads to a spectral algorithm for community detection that returns results of demonstrably higher quality than competing methods in shorter running times. I illustrate the method with applications to several published network data sets."
Defining and identifying communities in networks.,"Filippo Radicchi, Claudio Castellano,Federico Cecconi, Vittorio Loreto,Domenico Parisi",arXiv,,"The investigation of community structures in networks is an important issue in many domains and disciplines. This problem is relevant for social tasks (objective analysis of relationships on the web), biological inquiries (functional studies in metabolic, cellular or protein networks) or technological problems (optimization of large infrastructures). Several types of algorithm exist for revealing the community structure in networks, but a general and quantitative definition of community is still lacking, leading to an intrinsic difficulty in the interpretation of the results of the algorithms without any additional non-topological information. In this paper we face this problem by introducing two quantitative definitions of community and by showing how they are implemented in practice in the existing algorithms. In this way the algorithms for the identification of the community structure become fully self-contained. Furthermore, we propose a new local algorithm to detect communities which outperforms the existing algorithms with respect to the computational cost, keeping the same level of reliability. The new algorithm is tested on artificial and real-world graphs. In particular we show the application of the new algorithm to a network of scientific collaborations, which, for its size, can not be attacked with the usual methods. This new class of local algorithms could open the way to applications to large-scale technological and biological applications."
Maps of random walks on complex networks reveal community structure.,"Martin Rosvall, Carl T. Bergstrom",arXiv,"clustering, compression, information theory, map of science, bibiometrics","To comprehend the multipartite organization of large-scale biological and social systems, we introduce an information theoretic approach that reveals community structure in weighted and directed networks. We use the probability flow of random walks on a network as a proxy for information flows in the real system and decompose the network into modules by compressing a description of the probability flow. The result is a map that both simplifies and highlights the regularities in the structure and their relationships. We illustrate the method by making a map of scientific communication as captured in the citation patterns of >6,000 journals. We discover a multicentric organization with fields that vary dramatically in size and degree of integration into the network of science. Along the backbone of the network—including physics, chemistry, molecular biology, and medicine—information flows bidirectionally, but the map reveals a directional pattern of citation from the applied fields to the basic sciences."
The ground truth about metadata and community detection in networks,"Leto Peel, Daniel B. Larremore, AaronClauset",Science Advances,"networks, community detection, metadata, ground truth, algorithm performance, no free lunch","Across many scientific domains, there is a common need to automatically extract a simplified view or coarse-graining of how a complex system’s components interact. This general task is called community detection in networks and is analogous to searching for clusters in independent vector data. It is common to evaluate the performance of community detection algorithms by their ability to find so-called ground truth communities. This works well in synthetic networks with planted communities because these networks’ links are formed explicitly based on those known communities. However, there are no planted communities in real-world networks. Instead, it is standard practice to treat some observed discrete-valued node attributes, or metadata, as ground truth. We show that metadata are not the same as ground truth and that treating them as such induces severe theoretical and practical problems. We prove that no algorithm can uniquely solve community detection, and we prove a general No Free Lunch theorem for community detection, which implies that there can be no algorithm that is optimal for all possible community detection tasks. However, community detection remains a powerful tool and node metadata still have value, so a careful exploration of their relationship with network structure can yield insights of genuine worth. We illustrate this point by introducing two statistical techniques that can quantify the relationship between metadata and community structure for a broad class of models. We demonstrate these techniques using both synthetic and real-world networks, and for multiple types of metadata and community structures."
Communities in Networks,"Mason A. Porter, Jukka-Pekka Onnela,Peter J. Mucha",Notices of AMS,,"From an abstract perspective, the term network is used as a synonym for a mathematical graph. However, to scientists across a variety of fields, this label means so much more. In sociology, each node (or vertex) of a network represents an agent, and a pair of nodes can be connected by a link (or edge) that signifies some social interaction or tie between them. Each node has a degree given by the number of edges connected to it and a strength given by the total weight of those edges. Graphs can represent either man-made or natural constructs, such as the World Wide Web or neuronal synaptic networks in the brain. Agents in such networked systems are like particles in traditional statistical mechanics that we all know and (presumably) love, and the structure of interactions between agents reflects the microscopic rules that govern their behavior. The simplest types of links are binary pairwise connections, in which one only cares about the presence or absence of a tie. However, in many situations, links can also be assigned a direction and a (positive or negative) weight to designate different interaction strengths"
Stochastic blockmodels and community structure in networks,"Brian Karrer, Mark E. J. Newman",arXiv,,"Stochastic blockmodels have been proposed as a tool for detecting community structure in networks as well as for generating synthetic networks for use as benchmarks. Most blockmodels, however, ignore variation in vertex degree, making them unsuitable for applications to real-world networks, which typically display broad degree distributions that can significantly distort the results. Here we demonstrate how the generalization of blockmodels to incorporate this missing element leads to an improved objective function for community detection in complex networks. We also propose a heuristic algorithm for community detection using this objective function or its non-degree-corrected counterpart and show that the degree-corrected version dramatically outperforms the uncorrected one in both real-world and synthetic networks."
Near linear time algorithm to detect community structures in large-scale networks.,"Usha Nandini Raghavan, Réka Albert,Soundar Kumara",arXiv,,Community detection and analysis is an important methodology for understanding the organization of various real-world networks and has applications in problems as diverse as consensus formation in social communities or the identification of functional modules in biochemical networks. Currently used algorithms that identify the community structures in large-scale real-world networks require a priori information such as the number and sizes of communities or are computationally expensive. In this paper we investigate a simple label propagation algorithm that uses the network structure alone as its guide and requires neither optimization of a pre-defined objective function nor prior information about the communities. In our algorithm every node is initialized with a unique label and at every step each node adopts the label that most of its neighbors currently have. In this iterative process densely connected groups of nodes form a consensus on a unique label to form communities. We validate the algorithm by applying it to networks whose community structures are known. We also demonstrate that the algorithm takes an almost linear time and hence it is computationally less expensive than what was possible so far.
Community detection algorithms: a comparative analysis.,"Andrea Lancichinetti, Santo Fortunato",arXiv,"Networks, community structure",
"Network structure, metadata and the prediction of missing nodes","Darko Hric, Tiago P. Peixoto, SantoFortunato",arXiv,,"The empirical validation of community detection methods is often based on available annotations on the nodes that serve as putative indicators of the large-scale network structure. Most often, the suitability of the annotations as topological descriptors itself is not assessed, and without this it is not possible to ultimately distinguish between actual shortcomings of the community detection algorithms on one hand, and the incompleteness, inaccuracy or structured nature of the data annotations themselves on the other. In this work we present a principled method to access both aspects simultaneously. We construct a joint generative model for the data and metadata, and a nonparametric Bayesian framework to infer its parameters from annotated datasets. We assess the quality of the metadata not according to its direct alignment with the network communities, but rather in its capacity to predict the placement of edges in the network. We also show how this feature can be used to predict the connections to missing nodes when only the metadata is available, as well as missing metadata. By investigating a wide range of datasets, we show that while there are seldom exact agreements between metadata tokens and the inferred data groups, the metadata is often informative of the network structure nevertheless, and can improve the prediction of missing nodes."
Benchmarks for testing community detection algorithms on directed and weighted graphs with overlapping communities.,"Andrea Lancichinetti, Santo Fortunato",arXiv,"Networks, community structure","Many complex networks display a mesoscopic structure with groups of nodes sharing many links with the other nodes in their group and comparatively few with nodes of different groups. This feature is known as community structure and encodes precious information about the organization and the function of the nodes. Many algorithms have been proposed but it is not yet clear how they should be tested. Recently we have proposed a general class of undirected and unweighted benchmark graphs, with heterogenous distributions of node degree and community size. An increasing attention has been recently devoted to develop algorithms able to consider the direction and the weight of the links, which require suitable benchmark graphs for testing. In this paper we extend the basic ideas behind our previous benchmark to generate directed and weighted networks with built-in community structure. We also consider the possibility that nodes belong to more communities, a feature occurring in real systems, like, e. g., social networks. As a practical application, we show how modularity optimization performs on our new benchmark."
Structure and inference in annotated networks,"Mark E. J. Newman, Aaron Clauset",Nature Communications,,"For many networks of scientific interest we know both the connections of the network and information about the network nodes, such as the age or gender of individuals in a social network. Here we demonstrate how this ‘metadata’ can be used to improve our understanding of network structure. We focus in particular on the problem of community detection in networks and develop a mathematically principled approach that combines a network and its metadata to detect communities more accurately than can be done with either alone. Crucially, the method does not assume that the metadata are correlated with the communities we are trying to find. Instead, the method learns whether a correlation exists and correctly uses or ignores the metadata depending on whether they contain useful information. We demonstrate our method on synthetic networks with known structure and on real-world networks, large and small, drawn from social, biological and technological domains."
Equivalence between modularity optimization and maximum likelihood methods for community detection.,Micaleah Newman,Physical Review E,,"We demonstrate an equivalence between two widely used methods of community detection in networks, the method of modularity maximization and the method of maximum likelihood applied to the degree-corrected stochastic block model. Specifically, we show an exact equivalence between maximization of the generalized modularity that includes a resolution parameter and the special case of the block model known as the planted partition model, in which all communities in a network are assumed to have statistically similar properties. Among other things, this equivalence provides a mathematically principled derivation of the modularity function, clarifies the conditions and assumptions of its use, and gives an explicit formula for the optimal value of the resolution parameter."
Finding Statistically Significant Communities in Networks,"Andrea Lancichinetti, Filippo Radicchi,José J. Ramasco, Santo Fortunato",Plos One,,"Community structure is one of the main structural features of networks, revealing both their internal organization and the similarity of their elementary units. Despite the large variety of methods proposed to detect communities in graphs, there is a big need for multi-purpose techniques, able to handle different types of datasets and the subtleties of community structure. In this paper we present OSLOM (Order Statistics Local Optimization Method), the first method capable to detect clusters in networks accounting for edge directions, edge weights, overlapping communities, hierarchies and community dynamics. It is based on the local optimization of a fitness function expressing the statistical significance of clusters with respect to random fluctuations, which is estimated with tools of Extreme and Order Statistics. OSLOM can be used alone or as a refinement procedure of partitions/covers delivered by other techniques. We have also implemented sequential algorithms combining OSLOM with other fast techniques, so that the community structure of very large networks can be uncovered. Our method has a comparable performance as the best existing algorithms on artificial benchmark graphs. Several applications on real networks are shown as well. OSLOM is implemented in a freely available software (http://www.oslom.org), and we believe it will be a valuable tool in the analysis of networks."
The bottlenose dolphin community of Doubtful Sound features a large proportion of long-lasting associations,"David Lusseau, Karsten Schneider,Oliver Boisseau, Patti A. Haase,Elisabeth Slooten, Steve Dawson",Behavioral Ecology and Sociobiology,"Social organisation,Tursiops spp, Environmental influences on sociality, Sex segregation, Grandmother hypothesis","More than 12 studies of different bottlenose dolphin populations, spanning from tropical to cold temperate waters, have shown that the species typically lives in societies in which relationships among individuals are predominantly fluid. In all cases dolphins lived in small groups characterised by fluid and dynamic interactions and some degree of dispersal from the natal group by both sexes. We describe a small, closed population of bottlenose dolphins living at the southern extreme of the species' range. Individuals live in large, mixed-sex groups in which no permanent emigration/immigration has been observed over the past 7 years. All members within the community are relatively closely associated (average half-weight index>0.4). Both male–male and female–female networks of preferred associates are present, as are long-lasting associations across sexes. The community structure is temporally stable, compared to other bottlenose dolphin populations, and constant companionship seems to be prevalent in the temporal association pattern. Such high degrees of stability are unprecedented in studies of bottlenose dolphins and may be related to the ecological constraints of Doubtful Sound. Fjords are low-productivity systems in which survival may easily require a greater level of co-operation, and hence group stability. These conditions are also present in other cetacean populations forming stable groups. We therefore hypothesise that ecological constraints are important factors shaping social interactions within cetacean societies.

"
Community detection in complex networks using extremal optimization.,"Jordi Duch, Alex Arenas",arXiv,,We propose a novel method to find the community structure in complex networks based on an extremal optimization of the value of modularity. The method outperforms the optimal modularity found by the existing algorithms in the literature. We present the results of the algorithm for computer simulated and real networks and compare them with other approaches. The efficiency and accuracy of the method make it feasible to be used for the accurate identification of community structure in large complex networks.
System crash as dynamics of complex networks SI (Supplementary Information ) Appendix,"Yi Yu, Gaoxi Xiao, Jie Zhou, Yubo Wang,Zhen Wang, Juergen Kurths, HansJoachim Schellnhuber",PNAS,,
Empirical comparison of network sampling techniques,"Neli Blagus, Lovro Šubelj, Marko Bajec",arXiv,"complex networks, network sampling, comparison of sampling techniques, subgraph induction, sampling accuracy","In the past few years, the storage and analysis of large-scale and fast evolving networks present a great challenge. Therefore, a number of different techniques have been proposed for sampling large networks. In general, network exploration techniques approximate the original networks more accurately than random node and link selection. Yet, link selection with additional subgraph induction step outperforms most other techniques. In this paper, we apply subgraph induction also to random walk and forest-fire sampling. We analyze different real-world networks and the changes of their properties introduced by sampling. We compare several sampling techniques based on the match between the original networks and their sampled variants. The results reveal that the techniques with subgraph induction underestimate the degree and clustering distribution, while overestimate average degree and density of the original networks. Techniques without subgraph induction step exhibit exactly the opposite behavior. Hence, the performance of the sampling techniques from random selection category compared to network exploration sampling does not differ significantly, while clear differences exist between the techniques with subgraph induction step and the ones without it."
Sampling on networks: estimating eigenvector centrality on incomplete graphs,"Nicolò Ruggeri, Caterina De Bacco",arXiv,,"We develop a new sampling method to estimate eigenvector centrality on incomplete networks. Our goal is to estimate this global centrality measure having at disposal a limited amount of data. This is the case in many real-world scenarios where data collection is expensive, the network is too big for data storage capacity or only partial information is available. The sampling algorithm is theoretically grounded by results derived from spectral approximation theory. We studied the problem on both synthetic and real data and tested the performance comparing with traditional methods, such as random walk and uniform sampling. We show that approximations obtained from such methods are not always reliable and that our algorithm, while preserving computational scalability, improves performance under different error measures."
Empirical comparison of network sampling: How to choose the most appropriate method?,"Neli Blagus, Lovro Šubelj, Marko Bajec",Physica A: Statistical Mechanics and its Applications,"Complex networks, Network sampling, Comparison of sampling techniques, Subgraph induction, Sampling accuracy, Sampling selection scheme","In the past few years, the storage and the analysis of large-scale and fast evolving networks presents a great challenge. Therefore, a number of different techniques have been proposed for sampling large networks. Studies on network sampling primarily analyze the changes of network properties under the sampling. In general, network exploration techniques approximate the original networks more accurate than random node and link selection. Yet, link selection with additional subgraph induction step outperforms most other techniques. In this paper, we apply subgraph induction also to random walk and forest-fire sampling and evaluate the effects of subgraph induction on the sampling accuracy. We analyze different real-world networks and the changes of their properties introduced by sampling. The results reveal that the techniques with subgraph induction improve the performance of techniques without induction and create denser sample networks with larger average degree. Furthermore, the accuracy of sampling decrease consistently across various sampling techniques, when the sampled networks are smaller. Based on the results of the comparison, we introduce the scheme for selecting the most appropriate technique for network sampling. Overall, the breadth-first exploration sampling proves as the best performing technique."
Graph sampling: Estimation of degree distributions,"Joya A. Deri, José M. F. Moura",IEEE,"Graph sampling, Markov Chain Monte Carlo (MCMC) sampling, Pareto optimality, large-scale networks","Online social networks and the World Wide Web lead to large underlying graphs that might not be completely known because of their size. To compute reliable statistics, we have to resort to sampling the network. In this paper, we investigate four network sampling methods to estimate the network degree distribution and the so-called biased degree distribution of a 3.7 million wireless subscriber network. We measure the quality of our estimates of the degree distributions by using the Kolmogorov-Smirnov statistic. Among all four sampling methods, node sampling yields Pareto optimal sample sizes in terms of the Kolomogorov-Smirnov statistic for the degree distribution, while node-by-edge sampling yields optimal sample sizes for the biased distribution. We also find that random walk sampling performs better than the Metropolis-Hastings random walk."
On Classifying Complex Networks by their Topological Features,Marina von Steinkirch,Stony Brook University ,,"The study of complex networks pervades all of the sciences. Characterizing complex network’s structure is a key to understand any unifying principles underlying their topology. Previous works have shown that many topological properties can vary for different types of system. However these works generally focus only on a few characteristics at time. In this work we present methods and results for an extensive analysis of 20 global and local graph topological features of 1245 publicly available networks. The raw networks can have orders ranging from a few hundred nodes (eg, some small biological and small ego-centered examples) to hundred of thousand nodes (eg, roads and large ego-centered examples). In order to perform the classification task, we sample them into five sets of different graph orders, assigning each of them to one of following four classes: technological networks, information networks"
Monotone Sampling of Networks,"Tim Grube, Benjamin Schiller, ThorstenStrufe",Proceedings of the 2nd International Workshop on Dynamic Networks and Knowledge Discovery,,"Determining the graph-theoretic properties of large real-world networks like social, computer, and biological networks, is a challenging task. Many of those networks are too large to be processed eciently and some are not even available in their entirety. In order to reduce the size of available data or collect a sample of an existing network, several sampling algorithms were developed. They aim to produce samples whose properties are close to the original network. It is unclear what sample size is sucient to obtain a sample whose properties can be used to estimate those of the original network. This estimation requires sampling algorithms that produce results that converge smoothly to the original properties since estimations based on unsteady data are unreliable. Consequently, we evaluate the monotonicity of sampled properties while increasing the sample size. We provide a ranking of common sampling algorithms based on their monotonicity of relevant network properties using the results from four nework classes."
Understanding Graph Sampling Algorithms for Social Network Analysis,"Tianyi Wang, Yang Chen, ZengbinZhang, Tianyin Xu, Long Jin, Pan Hui,Beixing Deng, Xing Li",IEEE,,"Being able to keep the graph scale small while capturing the properties of the original social graph, graph sampling provides an efficient, yet inexpensive solution for social network analysis. The challenge is how to create a small, but representative sample out of the massive social graph with millions or even billions of nodes. Several sampling algorithms have been proposed in previous studies, but there lacks fair evaluation and comparison among them. In this paper, we analyze the state-of art graph sampling algorithms and evaluate their performance on some widely recognized graph properties on directed graphs using large-scale social network datasets. We evaluate not only the commonly used node degree distribution, but also clustering coefficient, which quantifies how well connected are the neighbors of a node in a graph. Through the comparison we have found that none of the algorithms is able to obtain satisfied sampling results in both of these properties, and the performance of each algorithm differs much in different kinds of datasets."
Rank degree: An efficient algorithm for graph sampling,"Elli Voudigari, Nikos Salamanos,Theodore Papageorgiou, Emmanuel J.Yannakoudakis",IEEE,,"The study of a large real world network in terms of graph sample representation constitutes a very powerful and useful tool in several domains of network analysis. This is the motivation that has led the work of this paper towards the development of a new graph sampling algorithm. Previous research in this area proposed simple processes such as the classic Random Walk algorithm, Random node and Random edge sampling and has evolved during the last decade to more advanced graph exploration approaches such as Forest Fire and Frontier sampling. In this paper, we propose a new graph sampling method based on edge selection. In addition, we crawled Facebook collecting a large dataset consisting of 10 million users and 80 million users' relations, which we have also used to evaluate our sampling algorithm. The experimental evaluation on several datasets proves that our approach preserves several properties of the initial graphs, leading to representative samples and outperforms all the other approaches."
Sampling on networks: estimating spectral centrality measures and their impact in evaluating other relevant network measures,"Nicolò Ruggeri, Caterina De Bacco",arXiv,,"We perform an extensive analysis of how sampling impacts the estimate of several relevant network measures. In particular, we focus on how a sampling strategy optimized to recover a particular spectral centrality measure impacts other topological quantities. Our goal is on one hand to extend the analysis of the behavior of TCEC [Ruggeri2019], a theoretically-grounded sampling method for eigenvector centrality estimation. On the other hand, to demonstrate more broadly how sampling can impact the estimation of relevant network properties like centrality measures different than the one aimed at optimizing, community structure and node attribute distribution. Finally, we adapt the theoretical framework behind TCEC for the case of PageRank centrality and propose a sampling algorithm aimed at optimizing its estimation. We show that, while the theoretical derivation can be suitably adapted to cover this case, the resulting algorithm suffers of a high computational complexity that requires further approximations compared to the eigenvector centrality case."
Parameter estimation in social network models.,Saisuke Okabayashi,University of Minnesota,,"A social network is an example of a phenomenon with complex stochastic dependence that is commonly modeled with a class of exponential families called exponential random graph models (ERGM). Maximum likelihood estimators (MLE) for such exponential families can be difficult to estimate when the likelihood is difficult to compute. Most methodologies rely on iterated estimates and are sensitive to the starting value, failing to converge if started too far from the solution. Even more problematic is that the MLE may not exist, a situation that occurs with positive probability for ERGMs. In such a case, the MLE is actually ""at infinity"" in some direction of the parameter space. Here we present a simple line search algorithm to find the MLE of a regular exponential family when the MLE exists and is unique. The algorithm can be started from any initial value and avoids trial-and-error experimentation. When the MLE does not exist, our algorithm adapts Geyer's (2009a) approach to detect non-existent MLEs and construct one-sided confidence intervals for how close the parameter is to infinity."
Enhancing Stratified Graph Sampling Algorithms based on Approximate Degree Distribution,"Junpeng Zhu, Hui Li, Mei Chen, ZhenyuDai, Ming Zhu",arXiv,graph sampling; sampling bias; stratified sampling; approximate degree distribution; vector clustering,"Sampling technique has become one of the recent research focuses in the graph-related fields. Most of the existing graph sampling algorithms tend to sample the high degree or low degree nodes in the complex networks because of the characteristic of scale-free. Scale-free means that degrees of different nodes are subject to a power law distribution. So, there is a significant difference in the degrees between the overall sampling nodes. In this paper, we propose an idea of approximate degree distribution and devise a stratified strategy using it in the complex networks. We also develop two graph sampling algorithms combining the node selection method with the stratified strategy. The experimental results show that our sampling algorithms preserve several properties of different graphs and behave more accurately than other algorithms. Further, we prove the proposed algorithms are superior to the off-the-shelf algorithms in terms of the unbiasedness of the degrees and more efficient than state-of-the-art FFS and ES-i algorithms."
A Survey on Breadth First Search (bfs) & Metropolis Hasting Random Walk (mhrw),"Ms. Bhagyashree, M. Gayathri",International Journal of Computer Science and Mobile Computing,"Graph sampling, Social networks, Social search, BFS, MHRW, OPICS","Graph sampling is a technique of selecting a subset of the original graph making the scale small for improved computations. This technique provides an efficient and yet an inexpensive solution. In this paper, we examine Breadth First Search (BFS) and Metropolis Hasting Random Walk (MHRW) graph sampling algorithm and find out which algorithm performs better than the other"
Reconsidering the Foundations of Network Sampling,"Nesreen Ahmed, Jennifer Neville,Ramana Rao Kompella",Proceedings of the 2nd Workshop of Information in Networks,,"Recently, there has been a great deal of research focusing on the development of sampling algorithms for networks with small-world and/or power-law structure. The peerto-peer research community (e.g., [7]) have used sampling to quickly explore and obtain a good representative sample of the network topology, as these networks are hard to explore completely and have significant amounts of churn in their topology. For collecting data from social networks, researchers often use snowball sampling (e.g., [2]) due to the lack of access to the complete graph. Leskovec et al. have developed Forest Fire Sampling, which uses a hybrid combination of snowball sampling and random-walk sampling to produce samples that match the temporal evolution of the underlying social network [5]. Hubler et al. have developed a Metropolis algorithm which samples in a manner designed to match desired properties in the original network [3]. Although there has been a great deal of research focusing on the the development of sampling algorithms, much of this work is based on empirical study and evaluation (i.e., measuring the similarity between sampled and original network properties). There has been some work (e.g., [4, 8, 6]) that has studied the statistical properties of samples of complex networks produced by traditional sampling algorithms such as node sampling, edge sampling and random walks. However, there has been relatively little attention paid to the development of a theoretical foundation for sampling from networks—including a formal framework for sampling, an understanding of various network characteristics and their dependencies, and an analysis of their impact on the accuracy of sampling algorithms. In this paper, we reconsider the foundations of network sampling and attempt to formalize the goals, and process of, sampling, in order to frame future development and analysis of sampling algorithms."
CS224W Project Write-up Static Crawling on Social Graph,"Chantat Eksombatchai, NorasesVesdapunt, PhumchanitWatanaprakornkul",,,"Our problem is crawling a static social graph (snapshot). Given limited resource and some methods to explore the graph with some constant cost, we want to discover as many distinct nodes and edges as possible. This is adapted from the problem that we try to crawl twitter social graph using twitter API [1] with some restrictions such as we can’t make more than 150 requests per hour. In this scenario, we want to mine real data from twitter as much as possible and forward it to do something else. Our goal is not an unbiased representative of the structure of the graph. In our problem, we also assume that there is no node/edge deletion/addition for simplicity. We first evaluate baseline crawlers on synthetic forest fire graphs [6]: always teleport, random walk, greedy, and lottery (see Relevant Prior Work section for more information) [4]. We test each model using first our synthetic forest fire networks and finally Twitter follower data [2]. We then develop our own model inspired by discount degree heuristics [5] for influence maximization. This model tries to learn the best distribution for randomwalk from sampled networks. We also try other variances of greedy approach and mixed method: optimized greedy model, random seeds to be the starting point of greedy algorithm. Finally, because the result of teleport is the best in the beginning of the crawling process and optimized greedy gets better later on, we try the mixed method between teleport and greedy. Our experiment indicates that seeded greedy is the best model we have for twitter graph for discovering edges and teleport is the best for discovering nodes."
Large networks grow smaller: How to choose the right simplification method ?,"Neli Blagus, Gregor Weiss, Marko Bajec",,,"Network simplification proved as effective tool for reducing large real-world networks and at the same time providing for sufficient fit of original network [1, 2]. However, even though a number of analyses have been performed observing the changes of networks under the simplification, broad understanding of the whole process remains incomplete. The questions such as “How to compare original (i.e., complete) and simplified (i.e., incomplete) network?”, “What factors impact the effectiveness of simplification process?”, “What size of simplified networks provides for the best fit of original networks?”, “What simplification method to use?” are far from solved in the literature."
Performance comparison of sampling techniques for web-based networks,"Simrat Pal Kaur, Sarbjeet Singh, SakshiKaushal",IEEE,Social network; sampling; BFS; DFS; random walk; Metropolis Hastings; average path lengh; clustering coefficient,"The gaining popularity of social networks is attracting a large number of researchers to study the behaviour and characteristics of social networks at a large scale. But it is difficult to capture full view of many social networks due to their large size and access limitations. Therefore, sampling techniques are essential to analyse Online Social Network's characteristics and behaviours. It is a challenging task to create a small but representative sample from a large social graph having millions of nodes. Many graph sampling algorithms have been proposed in past like BFS (Breadth First Search), DFS (Depth First Search), Snowball sampling, Random Walk sampling and their variations. In this paper, we evaluated the performance of Random Walk (RW) and Metropolis Hastings Random Walk (MHRW) algorithm on web-based network datasets. Evaluation is done on the basis of two parameters: average path length and average clustering coefficient. Our results show that MHRW technique performed better than RW technique for both the parameters."
Assessing the effectiveness of real-world network simplification,"Neli Blagus, Lovro Šubelj, Marko Bajec",arXiv,"complex networks, network simplification, sampling, merging, simplification effectiveness","Many real-world networks are large, complex and thus hard to understand, analyze or visualize. The data about networks is not always complete, their structure may be hidden or they change quickly over time. Therefore, understanding how incomplete system differs from complete one is crucial. In this paper, we study the changes in networks under simplification (i.e., reduction in size). We simplify 30 real-world networks with six simplification methods and analyze the similarity between original and simplified networks based on preservation of several properties, for example degree distribution, clustering coefficient, betweenness centrality, density and degree mixing. We propose an approach for assessing the effectiveness of simplification process to define the most appropriate size of simplified networks and to determine the method, which preserves the most properties of original networks. The results reveal the type and size of original networks do not influence the changes of networks under simplification process, while the size of simplified networks does. Moreover, we investigate the performance of simplification methods when the size of simplified networks is 10% of the original networks. The findings show that sampling methods outperform merging ones, particularly random node selection based on degree and breadth-first sampling perform the best."
Deterministic graph exploration for efficient graph sampling,"Nikos Salamanos, Elli Voudigari,Emmanuel J. Yannakoudakis",Social Network Analysis and Mining ,,"Graph sampling is a widely used procedure in social network analysis, has attracted great interest in the scientific community and is considered as a very powerful and useful tool in several domains of network analysis. Apart from initial research in this area, which has proposed simple processes such as the classic Random Walk algorithm, Random Node and Random Edge sampling, during the last decade, more advanced graph sampling approaches have been emerged. In this paper, we extensively study the properties of a newly proposed method, the Rank Degree method, which leads to representative graph subgraphs. The Rank Degree is a novel graph exploration method which significantly differs from other existing methods in the literature. The novelty of the Rank Degree lies on the fact that its core methodology corresponds to a deterministic graph exploration; one specific variation corresponds to a number of parallel deterministic traverses that explore the graph. We perform extensive experiments on twelve real-world datasets of a different type, using a variety of measures and comparing our method with Forest Fire, Metropolis Hastings Random Walk and Metropolis Hastings. We provide strong evidence that our approach leads to highly efficient graph sampling; the generated samples preserve several graph properties, to a large extent."
Can Sampling Preserve Application Adoption Process over OSN Graphs ?,"Mohammad Rezaur Rahman, Chen-NeeChuah",,,"Online social network (OSN)-based applications often rely on user interactions to propagate information or to recruit more users. Understanding the adoption or cascade process of an idea, a product, or a new application over OSN graph is of great interest to advertisers, application developers, and OSN providers. Such adoption or information cascade process is an example of ‘function’ on OSN graphs. In this work, we investigate if existing graph sampling techniques known to preserve static graph properties can be equally effective in preserving dynamic ‘functions ’ taking place over the OSN graphs. There is a rich literature on sampling techniques that preserve static properties of social network graphs [1]–[4]. Leskovec et al. [1] examined how well various sampling methods preserve nine different graph properties, and measured the performance of those methods using D-statistic. It was found that Forest Fire algorithm performed best in preserving most of the graph properties [1]. Random walk is another commonly deployed technique in graph sampling [4]. Although different crawling and sampling techniques start with a single randomly chosen node, Ribeiro and Towsley [3] proposed to use multiple uniformly sampled starting nodes to randomly walk on the graph to prevent the walker from being trapped inside a small area of the whole graph. As a first step towards understanding how well graph sampling techniques preserve ‘functions ’ on networks, we consider OSNapplication adoption process as a case study. In our previous work [5], we have performed detailed characterization of the adoption cascade of a popular Facebook gifting application, iHeart 1, in terms of the following properties: a) Cascade size distribution, b)"
Crawling Social Internetworking Systems,"Francesco Buccafurri, Gianluca Lax,Antonino Nocera, Domenico Ursino",IEEE,"Social Networks, Crawling Strategies, Social Internetworking Systems","In new generation social networks, we expect that the paradigm of Social Internetworking Systems (SISs, for short) will be more and more important. In this new scenario, the role of Social Network Analysis is of course still crucial but the preliminary step to do is designing a good way to crawl the underlying graph. While this aspect has been deeply investigated in the field of social networks, it is an open issue when moving towards SISs. Indeed, we cannot expect that a crawling strategy which is good for social networks, is still valid in a Social Internetworking Scenario, due to its specific topological features. In this paper, we first confirm the above claim and, then, define a new crawling strategy specifically conceived for SISs. Finally, we show that it fully overcomes the drawbacks of the state-of-the-art crawling strategies."
Towards Unbiased BFS Sampling,"Maciej Kurant, Athina Markopoulou,Patrick Thiran",arXiv,"BFS, Breadth First Search, graph sampling, estimation, bias correction, Internet topologies, Online Social Networks.","Breadth First Search (BFS) is a widely used approach for sampling large unknown Internet topologies. Its main advantage over random walks and other exploration techniques is that a BFS sample is a plausible graph on its own, and therefore we can study its topological characteristics. However, it has been empirically observed that incomplete BFS is biased toward high-degree nodes, which may strongly affect the measurements. In this paper, we first analytically quantify the degree bias of BFS sampling. In particular, we calculate the node degree distribution expected to be observed by BFS as a function of the fraction f of covered nodes, in a random graph RG(pk) with an arbitrary degree distribution pk. We also show that, for RG(pk), all commonly used graph traversal techniques (BFS, DFS, Forest Fire, Snowball Sampling, RDS) suffer from exactly the same bias. Next, based on our theoretical analysis, we propose a practical BFS-bias correction procedure. It takes as input a collected BFS sample together with its fraction f. Even though RG(pk) does not capture many graph properties common in real-life graphs (such as assortativity), our RG(pk)-based correction technique performs well on a broad range of Internet topologies and on two large BFS samples of Facebook and Orkut networks. Finally, we consider and evaluate a family of alternative correction procedures, and demonstrate that, although they are unbiased for an arbitrary topology, their large variance makes them far less effective than the RG(pk)-based technique."
Albatross sampling: robust and effective hybrid vertex sampling for social graphs,"Long Jin, Yang Chen, Pan Hui, CongDing, Tianyi Wang, Athanasios V.Vasilakos, Beixing Deng, Xing Li",ACM,"Graph Sampling, Online Social Networks, Random Walk, Metropolis-Hasting Algorithm, Jump Strategy, Degree Distribution, Convergence Time","Nowadays, Online Social Networks (OSNs) have become dramatically popular and the study of social graphs attracts the interests of a large number of researchers. One critical challenge is the huge size of the social graph, which makes the graph analyzing or even the data crawling incredibly time consuming, and sometimes impossible to be completed. Thus, graph sampling algorithms have been introduced to obtain a smaller subgraph which reflects the properties of the original graph well. Breadth-First Sampling (BFS) is widely used in graph sampling, but it is biased towards high-degree vertices during the process of sampling. Besides, Metropolis-Hasting Random Walk (MHRW), which is proposed to get unbiased samples of the social graph, requires the graph to be well connected. In this paper, we propose a vertex sampling algorithm, so-called Albatross Sampling (AS), which introduces random jump strategy into MHRW during the sampling process. The embedded random jump makes the sampling procedure more flexible and avoids being trapped in some locally well connected part. According to our evaluation, we find that no matter using tightly or loosely connected graphs, AS performs significantly better than MHRW and BFS. On the one hand, AS estimates the degree distribution with much lower Normalized Mean Square Error (NMSE) by consuming the same resource budget. On the other hand, to get an acceptable estimation of the degree distribution, AS requires much less resource budget."
Testing for Characteristics of Attribute Linked Infinite Networks based on Small Samples,"Koushiki Sarkar, Diganta Mukherjee",arXiv,"The objective of this paper is to study the characteristics (geometric and otherwise) of very large attribute based undirected networks. Real-world networks are often very large and fast evolving. Their analysis and understanding present a great challenge. An Attribute based network is a graph in which the edges depend on certain properties of the vertices on which they are incident. In context of a social network, the existence of links between two individuals may depend on certain attributes of the two of them. We use the Lovasz type sampling strategy of observing a certain random process on a graph ”locally”, i.e., in the neighborhood of a node, and deriving information about ”global” properties of the graph. The corresponding adjacency matrix is our primary object of interest. We study the efficiency of recently proposed sampling strategies, modified to our set up, to estimate the degree distribution, centrality measures, planarity etc. The limiting distributions are derived using recently developed probabilistic techniques for random matrices and hence we devise relevant test statistics and confidence intervals for different parameters / hypotheses of interest. We hope that our work will be useful for social and computer scientists for designing sampling strategies and computational algorithms appropriate to their respective domains of inquiry. Extensive simulations studies are done to empirically verify the probabilistic statements made in the paper.","The objective of this paper is to study the characteristics (geometric and otherwise) of very large attribute based undirected networks. Real-world networks are often very large and fast evolving. Their analysis and understanding present a great challenge. An Attribute based network is a graph in which the edges depend on certain properties of the vertices on which they are incident. In context of a social network, the existence of links between two individuals may depend on certain attributes of the two of them. We use the Lovasz type sampling strategy of observing a certain random process on a graph locally , i.e., in the neighborhood of a node, and deriving information about global properties of the graph. The corresponding adjacency matrix is our primary object of interest. We study the efficiency of recently proposed sampling strategies, modified to our set up, to estimate the degree distribution, centrality measures, planarity etc. The limiting distributions are derived using recently developed probabilistic techniques for random matrices and hence we devise relevant test statistics and confidence intervals for different parameters / hypotheses of interest. We hope that our work will be useful for social and computer scientists for designing sampling strategies and computational algorithms appropriate to their respective domains of inquiry. Extensive simulations studies are done to empirically verify the probabilistic statements made in the paper."
QMSampler: Joint Sampling of Multiple Networks with Quality Guarantee,"Hong-Han Shuai, De-Nian Yang, Chih-YaShen, Philip S. Yu, Ming-Syan Chen",IEEE,"Social network, graph sampler, data quality analysis, optimization","Because Online Social Networks (OSNs) have become increasingly important in the last decade, they have motivated a great deal of research on Social Network Analysis (SNA). Currently, SNA algorithms are evaluated on real datasets obtained from large-scale OSNs, which are usually sampled by Breadth-First-Search (BFS), Random Walk (RW), or some variations of the latter. However, none of the released datasets provides any statistical guarantees on the difference between the sampled datasets and the ground truth. Moreover, all existing sampling algorithms only focus on sampling a single OSN, but each OSN is actually a sampling of a complete social network. Hence, even if the whole dataset from a single OSN is sampled, the results may still be skewed and may not fully reflect the properties of the complete social network. To address the above issues, we have made the first attempt to explore the joint sampling of multiple OSNs and propose an approach called Quality-guaranteed Multi-network Sampler (QMSampler) that can jointly sample multiple OSNs. QMSampler provides a statistical guarantee on the difference between the sampled real dataset and the ground truth (the perfect integration of all OSNs). Our experimental results demonstrate that the proposed approach generates a much smaller bias than any existing method. QMSampler has also been released as a free download."
Moving from social networks to social internetworking scenarios: The crawling perspective,"Francesco Buccafurri, Gianluca Lax,Antonino Nocera, Domenico Ursino",Information Sciences ,"Social networks, Crawling strategies, Social Internetworking Systems","In new generation social networks, we expect that the paradigm of Social Internetworking Systems (SISs) will become progressively more important. Indeed, the possibility of interconnecting users and resources of different social networks enables a lot of strategic applications whose main strength is the integration of different communities that nevertheless preserves their diversity and autonomy. In this new scenario, the role of Social Network Analysis is crucial in studying the evolution of structures, individuals, interactions, and so on, and in extracting powerful knowledge from them. But the preliminary step to do is designing a good way to crawl the underlying graph. Although this aspect has been deeply investigated in the field of social networks, it is an open issue when moving towards SISs. Indeed, we cannot expect that a crawling strategy, specifically designed for social networks, is still valid in a Social Internetworking Scenario, due to its specific topological features. In this paper, we confirm the above claim, giving a strong motivation for our second contribution, which is the definition of a new crawling strategy. This strategy, specifically conceived for SISs, is shown to fully overcome the drawbacks of the state-of-the-art crawling strategies."
SGP: Sampling Big Social Network Based on Graph Partition,"Xiaolin Du, Yunming Ye, Yan Li, YuepingLi",IEEE,sampling algorithms; social networks; graph partition; community structure; topology structure,"Deriving a representative sample from a big social network is essential for many Internet services that rely on accurate analysis of big social data. A good sampling method for social network should be able to generate small sample networks with similar structures as original big network. In this paper, we propose SGP, a new big social network sampling algorithm based on graph partition. In SGP, original network is firstly partitioned into several sub-networks that will be sampled evenly. This procedure enables SGP to effectively maintain the topological similarity and community structure similarity between the sampled network and its original network. We have evaluated SGP on several well-known data sets. The experimental results show that SGP outperforms six state-of-the-art methods."
Network Sampling via Edge-based Node Selection with Graph Induction,"Nesreen Ahmed, Jennifer Neville,Ramana Rao Kompella",Purdue University ,,"In order to efficiently study the characteristics of network domains and support development of network systems (e.g. algorithms, protocols that operate on networks), it is often necessary to sample a representative subgraph from a large complex network. While prior research has shown that topological (e.g. random-walk based) sampling methods produce more accurate samples than approaches based on node or edge sampling, they still do not produce samples that closely match the distributions of graph properties (e.g., degree) found in the original graph. In this paper, we observe that part of the problem is that any sampling process fundamentally biases the structure of the sampled subgraph, since all neighbors of a sample node may not be included in the sampled subgraph. We address this problem using a novel sampling algorithm called TIES that (1) aims to offset this bias by using edge-based node selection, which favors selection of high-degree nodes, and (2) uses a graph induction step to select additional edges between sampled nodes to restore connectivity and bring the structure closer to that of the original graph. To understand the properties of TIES we compare it analytically to random node and edge sampling. We also evaluate the efficacy of TIES empirically using several real-world data sets. Across all datasets, we found that TIES produces samples that better match the original distributions. In terms of two distributional distance metrics, KS distance and skew divergence, we found that samples produced by TIES consistently outperform other sampling algorithms—with up to 2× reduction in KS distance and up to 3- 7× reduction in skew divergence, compared to the current state-ofthe-art algorithms"
GSCALER: Synthetically Scaling A Given Graph,"J. W. Zhang, Y. C. Tay",19th International Conference on Extending Database Technology (EDBT),,"Enterprises and researchers often have datasets that can be represented as graphs (e.g. social networks). The owner of a large graph may want to scale it down to a smaller version, e.g. for application development. On the other hand, the owner of a small graph may want to scale it up to a larger version, e.g. to test system scalability. This paper investigates the Graph Scaling Problem (GSP): Given a directed graph G and positive integers ne and me , generate a similar directed graph Ge with ne nodes and me edges. This paper presents a graph scaling algorithm Gscaler for GSP. Analogous to DNA shotgun sequencing, Gscaler, decomposes G into small pieces, scales them, then uses the scaled pieces to construct Ge. This construction is based on the indegree/outdegree correlation of nodes and edges. Extensive tests with real graphs show that Gscaler is scalable and, for many graph properties, it generates a Ge that has greater similarity to G than other state-of-the-art solutions, like Stochastic Kronecker Graph and U pSizeR."
Bi-graph random walk sampling of directed online social networks,"Shen Luyi, Wang Xiao-fan",IEEE,"Complex network, Network sampling, OSNs, Random walk","During the past several decades, various Online Social Networks (OSNs) have experienced a huge development and have given rise to many related studies. However, the huge size of OSNs brings many difficulties to researchers and kinds of sampling methods have been used to get a relatively small but representative sample. Although some traditional sampling methods (e.g. Random Walk and its several improved forms) can help us to get a high-quality sample, there is still a lot of space for improvement in convergence rate, efficiency and their performance in directed OSNs. In this paper, we focus on sampling directed OSNs and propose Bi-graph Random Walk sampling (BRW) as a new sampling method. During each iteration of sampling, we treat directed structure as a combined graph of in-graph and out-graph, and then use a two-stage procedure to sample network. By evaluating this method in both synthetic graph and real OSNs, we find that BRW can achieve higher efficiency and faster convergence rate than traditional sampling methods."
Guided sampling for large graphs,"Muhammad Irfan Yousuf, Suhyun Kim",Data Mining and Knowledge Discovery,"Big graphs, Graph sampling, Social networks","Large real-world graphs claim lots of resources in terms of memory and computational power to study them and this makes their full analysis extremely challenging. In order to understand the structure and properties of these graphs, we intend to extract a small representative subgraph from a big graph while preserving its topology and characteristics. In this work, we aim at producing good samples with sample size as low as 0.1% while maintaining the structure and some of the key properties of a network. We exploit the fact that average values of degree and clustering coefficient of a graph can be estimated accurately and efficiently. We use the estimated values to guide the sampling process and extract tiny samples that preserve the properties of the graph and closely approximate their distributions in the original graph. The distinguishing feature of our work is that we apply traversal based sampling that utilizes only the local information of nodes as opposed to the global information of the network and this makes our approach a practical choice for crawling online networks. We evaluate the effectiveness of our sampling technique using real-world datasets and show that it surpasses the existing methods."
Practical Recommendations on Crawling Online Social Networks,"Minas Gjoka, Maciej Kurant, Carter T.Butts, Athina Markopoulou",IEEE,"Sampling methods, Social network services, Facebook, Random Walks, Convergence, Measurements, Graph sampling","Our goal in this paper is to develop a practical framework for obtaining a uniform sample of users in an online social network (OSN) by crawling its social graph. Such a sample allows to estimate any user property and some topological properties as well. To this end, first, we consider and compare several candidate crawling techniques. Two approaches that can produce approximately uniform samples are the Metropolis-Hasting random walk (MHRW) and a re-weighted random walk (RWRW). Both have pros and cons, which we demonstrate through a comparison to each other as well as to the ""ground truth."" In contrast, using Breadth-First-Search (BFS) or an unadjusted Random Walk (RW) leads to substantially biased results. Second, and in addition to offline performance assessment, we introduce online formal convergence diagnostics to assess sample quality during the data collection process. We show how these diagnostics can be used to effectively determine when a random walk sample is of adequate size and quality. Third, as a case study, we apply the above methods to Facebook and we collect the first, to the best of our knowledge, representative sample of Facebook users. We make it publicly available and employ it to characterize several key properties of Facebook."
Network discovery using content and homophily,"Steven Thomas Smith, Rajmonda S.Caceres, Kenneth D. Senne, MollyMcMahon, Timothy Greer",IEEE,,"A new approach for targeted graph sampling is proposed in which graph sampling and classification occur together, and content-based homophily is exploited to achieve improved classification performance. The application of network discovery of relevant content is considered using an approach that may be generalized to a broad class of vertex properties. The resulting procedure provides the initial step of a graph analytic processing chain whose performance is directly affected by the quality of graph sampling. The performance of the algorithm is measured with real network data and content observed on a social media site. Precision-Recall performance improvements of 30% are demonstrated with this dataset, compared to a baseline approach that does not exploit homophily. Because real-world graphs grow exponentially, this performance improvement may have a significant impact on graph analytic algorithms with sensitivities to the graph sampling quality."
A graph exploration method for identifying influential spreaders in complex networks,"Nikos Salamanos, Elli Voudigari,Emmanuel J. Yannakoudakis",Applied Network Science,"Influential spreaders, Complex networks, Graph mining","The problem of identifying the influential spreaders - the important nodes - in a real world network is of high importance due to its theoretical interest as well as its practical applications, such as the acceleration of information diffusion, the control of the spread of a disease and the improvement of the resilience of networks to external attacks. In this paper, we propose a graph exploration sampling method that accurately identifies the influential spreaders in a complex network, without any prior knowledge of the original graph, apart from the collected samples/subgraphs. The method explores the graph, following a deterministic selection rule and outputs a graph sample - the set of edges that have been crossed. The proposed method is based on a version of Rank Degree graph sampling algorithm. We conduct extensive experiments in eight real world networks by simulating the susceptible-infected-recovered (SIR) and susceptible-infected-susceptible (SIS) epidemic models which serve as ground truth identifiers of nodes spreading efficiency. Experimentally, we show that by exploring only the 20% of the network and using the degree centrality as well as the k-core measure, we are able to identify the influential spreaders with at least the same accuracy as in the full information case, namely, the case where we have access to the original graph and in that graph, we compute the centrality measures. Finally and more importantly, we present strong evidence that the degree centrality - the degree of nodes in the collected samples - is almost as accurate as the k-core values obtained from the original graph."
Random walk based biased sampling for data collection on communication networks,Shigeo Shioda,ACM,"random walk, sampling, bias correction, measurement","Sampling via random walks is the first choice for collecting random samples of online-social networks, peer-to-peer networks, and the World Wide Web. This paper proposes an algorithm for random-walk sampling, which allows us to collect a biased (non-random) sample, depending on which nodes are to be investigated in detail. Since the stationary distribution of a random walker under the proposed algorithm can be analytically derived, the bias involved in a collected sample can be removed using the notion of change of measure in probability theory, which is also presented in this paper. The effectiveness of the proposals is verified using simulation experiments based on the data of real networks."
Faster random walks by rewiring online social networks on-the-fly,"Zhuojie Zhou, Nan Zhang, Zhiguo Gong,Gautam Das",arXiv,,"Many online social networks feature restrictive web interfaces which only allow the query of a user's local neighborhood through the interface. To enable analytics over such an online social network through its restrictive web interface, many recent efforts reuse the existing Markov Chain Monte Carlo methods such as random walks to sample the social network and support analytics based on the samples. The problem with such an approach, however, is the large amount of queries often required (i.e., a long ""mixing time"") for a random walk to reach a desired (stationary) sampling distribution. In this paper, we consider a novel problem of enabling a faster random walk over online social networks by ""rewiring"" the social network on-the-fly. Specifically, we develop Modified TOpology (MTO)-Sampler which, by using only information exposed by the restrictive web interface, constructs a ""virtual"" overlay topology of the social network while performing a random walk, and ensures that the random walk follows the modified overlay topology rather than the original one. We show that MTO-Sampler not only provably enhances the efficiency of sampling, but also achieves significant savings on query cost over real-world online social networks such as Google Plus, Epinion etc."
Graph Property Preservation under Community-Based Sampling,"Ruohan Gao, Pili Hu, Wing Cheong Lau",IEEE,"CBS sampling, graph property preservation, graph algorithm acceleration","With the explosion of graph scale of social networks, it becomes increasingly impractical to study the original large graph directly. Being able to derive a representative sample of the original graph, graph sampling provides an efficient solution for social network analysis. We expect this sample could preserve some important graph properties and represent the original graph well. If one algorithm relies on the preserved properties, we can expect that it gives similar output on the original graph and the sampled graph. This leads to a systematic way to accelerate a class of graph algorithms. Our work is based on the idea of stratified sampling [14], a widely used technique in statistics. We propose a heuristic approach to achieve efficient graph sampling based on community structure of social networks. With the aid of ground-truth of communities available in social networks, we find out that sampling from communities preserves community- related graph properties very well. The experimental results show that our framework improves the performance of traditional graph sampling algorithms and therefore, is an effective method of graph sampling."
Cohesive group detection in a social network by the segregation matrix index,Meir Fershtman,Social Networks ,"Network, Segregation, Cohesive groups","The number and intensity of the interactions between cohesive group members are higher than those with other actors. The segregation matrix index (SMI), which is based on the relative number and intensity of inward to outward interactions, serves as a measure of the cohesiveness of a group (Fershtman and Chen, 1993, Megamot, 34: 563–581). Based on the SMI, the paper proposes an operational definition of a cohesive group and an algorithm for detecting cohesive groups in (binary or valued) social networks. Examination of two actual cases demonstrates the efficiency of the algorithm."
Linking action to social structure within a system: Social capital within and between subgroups,"Kenneth A. Frank, Jeffrey Y. Yasumoto",American Journal of Sociology,,"Differences in transactions within and outside of cohesive subgroups are hypothesized to be a function of actors’ pursuit of different forms of social capital. In an example of the French financial elite, subgroups are identified based on the pattern of friendships, and graphical representations establish the descriptive link between social structure and action. Estimates from multilevel models quantify the extent to which actors abstain from hostile action against subgroup members but tend to support others not in their subgroup. These complementary findings establish the subgroup as a critical mesolevel entity, defined by the social structure while affecting action."
"Position in formal structure, personal characteristics and choices of advisors in a law firm: A logistic regression model for dyadic network data☆","Emmanuel Lazega, Marijtje A. J. VanDuijn",Social Networks ,,"This paper presents a statistical model for the analysis of binary sociometric choice data, the p2 model, which provides a flexible way for using explanatory variables to model network structure. It is applied to examine the influence of the formal structure of an organization on interactions among its members. It is shown to provide a general and precise method for addressing this substantive issue. We identify the respective effects of position in the formal structure (status, seniority, division of work and office membership) and selected personal characteristics of members of a corporate law firm on their choices of advisors. Flows of advice are shown to be consistently shaped by status games and the pecking order in the firm. Other dimensions help members in mitigating the effect of this strong rule. This approach ultimately provides more understanding of how members of such firms try to balance cooperation and competition in terms of access to and management of key resources."
Building stochastic blockmodels,"Carolyn Jane Anderson, StanleyWasserman, Katherine Faust",Social Networks ,,"The literature devoted to the construction of stochastic blockmodels is relatively rare compared to that of the deterministic variety. In this paper, a general definition of a stochastic blockmodel is given and a number of techniques for building such blockmodels are presented. In the statistical approach, the likelihood ratio statistic provides a natural index to evaluate the fit of the model to the data. The model itself consists of a set of actors partitioned into positions with respect to a definition of equivalence, and a representation based on estimated probabilities. The specific statistical model that is used to illustrate the techniques is p,, which was first introduced as a method for stochastic blockmodeling by Fienberg and Wasserman (19811, and developed by Holland et al. (1983) and Wasserman and Anderson (1987)."
Through Interpersonal Relations Chapter 5: Quantitative Methods for Studying Social Context in Multilevels and Through Interpersonal Relations,Kenneth A. Frank,,,"The connection between a volume on the social organization of learning and a chapter with a title that begins with the words ""Quantitative methods ... "" may not seem obvious, especially in view of the fact that so much of our recent socially grounded educational inquiry has been conducted within a qualitative or interpretive paradigm. In this chapter, I attempt to make as strong a case as possible for the importance of quantitative methods in understanding the social organization of learning. I want to argue that both at the level of macroanalysis (considering the effects of different levels of social organization, such as the district, school, and classroom) and at the level of microanaly sis (examining relations among individuals in their primary social settings), quantitative methods can help us achieve important insights and understanding about the nature, causes, and consequences of social relations."
Object oriented modeling of social networks,"Evelien P. H. Zeggelink, Reinier Oosten,Frans N. Stokman",Computational & Mathematical Organization Theory,"social networks, objected oriented modeling, dynamics ","The aim of this paper is to explain principles of object oriented modeling in the scope of modeling dynamic social networks. As such, the approach of object oriented modeling is advocated within the field of organizational research that focuses on networks. We provide a brief introduction into the field of social networks and present an overview of existing network models and methods. Subsequently we introduce an elementary problem field in the social sciences in general, and in studies of organizational change and design in particular: the micro-macro link. We argue that the most appropriate way to hadle this problem is the principle of methodological individualism. For social network analysis, to contribute to this theoretical perspective, it should include an individual choice mechanism and become more dynamically oriented. Subsequently, object oriented modeling is advocated as a tool to meet these requirements for social network analysis. We show that characteristics of social systems that are emphasized in the methodological individualistic approach have their direct equivalences in object oriented models. The link between the micro level where actors act, and the macro level where phenomena occur as a consequence and cause of these actions, can be modelled in a straightforward way."
Latent Space Approaches to Social Network Analysis,"Peter D. Hoff, Adrian E. Raftery, Mark S.Handcock",Journal of the American Statistical Association,Conditional independence model; Latent position model; Network data; Random graph; Visualization.,"Network models are widely used to represent relational information among interacting units. In studies of social networks, recent emphasis has been placed on random graph models where the nodes usually represent individual social actors and the edges represent the presence of a specified relation between actors. We develop a class of models where the probability of a relation between actors depends on the positions of individuals in an unobserved “social space.” We make inference for the social space within maximum likelihood and Bayesian frameworks, and propose Markov chain Monte Carlo procedures for making inference on latent positions and the effects of observed covariates. We present analyses of three standard datasets from the social networks literature, and compare the method to an alternative stochastic blockmodeling approach. In addition to improving on model fit for these datasets, our method provides a visual and interpretable model-based spatial representation of social relationships and improves on existing methods by allowing the statistical uncertainty in the social space to be quantified and graphically represented."
Identifying positions from affiliation networks: Preserving the duality of people and events,"Sam Field, Kenneth A. Frank, KathrynSchiller, Catherine Riegle-Crumb,Chandra Muller",Social Networks,"Affiliation networks, Clustering, Duality, p* models","Frank's [Frank, K.A., 1995. Identifying cohesive subgroups. Social Networks 17, 27-56] clustering technique for one-mode social network data is adapted to identify positions in affiliation networks by drawing on recent extensions of p(*) models to two-mode data. The algorithm is applied to the classic Deep South data on southern women and the social events in which they participated with results comparable to other algorithms. Monte Carlo simulations are used to generate sampling distributions to test for the presence of clustering in new data sets and to evaluate the performance of the algorithm. The algorithm and simulation results are then applied to high school students' transcripts from one school from the Adolescent Health and Academic Achievement (AHAA) extension of the National Longitudinal Study of Adolescent Health."
Social Network Analysis: A brief theoretical review and further perspectives in the study of Information Technology,"Francesco Martino, Andrea Spoto",,,
Blockmodels with maximum concentration,Alan Jessop,European Journal of Operational Research,"Quadratic programming, Blockmodel, Multiple criteria analysis","There are many circumstances in which binary relations are defined between pairs of objects: in sociology there are social relations between people; in business there are trading relations between firms; in design there are functional dependencies between components. In all of these the clustering of objects into densely interconnected blocks reveals something of the structure of the system. In this paper a criterion is presented which permits the construction of blocks to be formulated as a quadratic programme. The method is applied to two illustrative cases: the pattern of elective choices by MBA students and the performance assessment of British universities. The method is shown to give results which are readily interpreted and, for the purpose of performance ranking, leads to a more realistic description of achievement."
P2: A random effects model with covariates for directed graphs,"Marijtje A. J. Van Duijn, Tom A. B.Snijders, Bonne J H Zijlstra",University of Groningen,adjacency matrix; dependent binary data; GLMM; IGLS; logistic regression; p1 model; random effects; social network analysis,"A random effects model is proposed for the analysis of binary dyadic data that represent a social network or directed graph, using nodal and/or dyadic attributes as covariates. The network structure is reflected by modeling the dependence between the relations to and from the same actor or node. Parameter estimates are proposed that are based on an iterated generalized least squares procedure. An application is presented to a data set on friendship relations between American lawyers."
Model-based clustering for social networks,"Mark S. Handcock, Adrian E. Raftery,Jeremy Tantrum",Journal of the Royal Statistical Society ,Bayes factor; Dyad; Latent space; Markov chain Monte Carlo methods; Mixture model; Transitivity,"Network models are widely used to represent relations between interacting units or actors. Network data often exhibit transitivity, meaning that two actors that have ties to a third actor are more likely to be tied than actors that do not, homophily by attributes of the actors or dyads, and clustering. Interest often focuses on finding clusters of actors or ties, and the number of groups in the data is typically unknown. We propose a new model, the latent position cluster model, under which the probability of a tie between two actors depends on the distance between them in an unobserved Euclidean ‘social space’, and the actors’ locations in the latent social space arise from a mixture of distributions, each corresponding to a cluster. We propose two estimation methods: a two-stage maximum likelihood method and a fully Bayesian method that uses Markov chain Monte Carlo sampling. The former is quicker and simpler, but the latter performs better. We also propose a Bayesian way of determining the number of clusters that are present by using approximate conditional Bayes factors. Our model represents transitivity, homophily by attributes and clustering simultaneously and does not require the number of clusters to be known. The model makes it easy to simulate realistic networks with clustering, which are potentially useful as inputs to models of more complex systems of which the network is part, such as epidemic models of infectious disease. We apply the model to two networks of social relations. A free software package in the R statistical language, latentnet, is available to analyse data by using the model."
Roles in social networks: Methodologies and research issues,"Mathilde Forestier, Anna Stavrianou,Julien Velcin, Djamel A. Zighed",Web Intelligence and Agent Systems: An International Journa,"Social network, social role, online discussion","The expansion of web user roles is, nowadays, a fact due to the ability of users to interact, discuss, exchange ideas and opinions, and form social networks through the web. The interaction level among users leads to the appearance of several social roles which can be characterized as positions, behaviors, or virtual identities. These roles may be developed in social networks, and they keep changing and evolving over time. In this article, a survey of the state-of-the-art approaches is presented regarding the identification of roles within the context of a social network. It is shown that social roles exist as a function of each other; they appear and evolve through user interaction. Different approaches are analyzed and additional characteristics that should be taken into account during the role analysis are discussed."
Estimation and prediction for stochastic block structures,"Krzysztof Nowicki, Tom A. B. Snijders",Journal of the American Statistical Association,Cluster analysis; Colored graph; Gibbs sampling; Latent class model; Mixture model; Social network,"A statistical approach to a posteriori blockmodeling for digraphs and valued digraphs is proposed. The probability model assumes that the vertices of the digraph are partitioned iuto several unobserved (latent) classes and that the probability distribution of the relation between two vertices depends only on the classes to which they belong. A Bayesian estimator based on Gibbs sampling is proposed. The basic model is not identified. because class labels are arbitrary. The resulting identifiability problems are solved by restricting inference to the posterior distributions of invariant functions of the parameters and the vertex class membership. In addition, models are considered where class labels are identified by prior distributions for the class membership of some of the vertices. The model is illustrated by an example from the social networks literature (Kapferer's tailor shop)."
"Multiplexity, generalized exchange and cooperation in organizations: a case study","Emmanuel Lazega, Philippa Pattison",Social Networks,,"Cooperation in an organization can be studied empirically by examining the routine transfers or exchanges among members of various kinds of resources. We argue that local regularities in the form of these transfers and exchanges shape the structure of cooperation. Using a case study of resource networks in a corporate law firm, we model the structure of cooperation in a specific work environment, one that is characterized by multifunctional and sometimes multidisciplinary work groups in which `status competition' is argued to be a particularly strong motivation driving participation. Specific statistical tools, p* models, are used to identify local regularities in the interplay between exchanges and transfers of three types of social resource (coworkers' goodwill, advice and friendship). We propose that these regularities help to provide structural solutions for the problems of collective participation and status competition in such organizations."
Algorithmic Complexity and Structural Models of Social Networks,Christopher O. Wheat,,,"This article explores how the algorithmic complexity approach can be used to address the problem of identifying group structures in social networks. A specific implementation of the algorithmic complexity approach based on the principle of minimum description length (MDL) is compared to other model selection criteria, and compared and contrasted with a Bayesian approach to model selection. The method presented here provides a statistical basis for determining how many groups actors in a given network should be partitioned into. Additionally, this article explores the analysis of two independent mechanisms by which group structures might be produced in social networks—those associated with explicit categories and those associated with preferential attention to particular local structures. I outline a method for using p1 stochastic blockmodels and exponential random graph models (ERGMs) in the context of the identified algorithmic complexity approach to address this question, and demonstrate the method in two empirical settings."
Logistic Regression with Network Structure,"Xu Zhang, Rui Pan, Guoyu Guan,Xuening Zhu, Hansheng Wang",Statistica Sinica,Classification; Logistic Regression; Network Structure,"As one of the most popular classification methods, logistic regression (LR) model has been extensively studied in the past literature. It basically assumes that individual’s class label is influenced by a set of predictors. However, with the rapid advance of social network services (SNS), social network data are becoming increasingly available. As a result, how to take this additional network structure to improve classification accuracy becomes an important research problem. To this end, we propose a networkbased logistic regression (NLR) model taking the network structure into consideration. Four interesting scenarios about link formation of the network structure are discussed under the NLR model. Furthermore, in order to figure out the impact of network structure on classification, asymptotic properties are derived for the prediction rule under different sparsities of network. Lastly, simulation studies are conducted to demonstrate the finite sample performance of the proposed method, and a real Sina Weibo dataset is analyzed for illustration purpose."
Blockmodeling and Text Classification,Christopher Hundt May,,,"In this paper I discuss the application of stochastic blockmodeling to the domain of legal opinions, and specifically to the end of classifying those legal opinions into topics. I begin by defining the basic social network problem and the stochastic blockmodel in Section 2. In Section 3 I introduce the problem of labeling legal opinions and discuss the particular features of this domain. Section 4 describes the supervised methods that I will use. Then Section 5 shows how blockmodeling can be used with the citation information from legal opinions and presents evidence that it captures their natural relational structure. In Section 6 I combine blockmodeling with supervised methods to improve the resulting classifiers and give experimental results. Finally, Section 7 compares this method to other ways of using citation structure."
Logistic Regression with Network Structure,"Xu Zhang, Rui Pan, Guoyu Guan,Xuening Zhu, Hansheng Wang",Statistica Sinica,,"As one of the most popular classification methods, logistic regression (LR) model has been extensively studied in the past literature. It basically assumes that individual's class label is influenced by a set of predictors. However, with the rapid advance of social network services (SNS), social network data are becoming increasingly available. As a result, how to take this additional network structure to improve classification accuracy becomes an important research problem. To this end, we propose a networkbased logistic regression (NLR) model taking the network structure into consideration. Four interesting scenarios about link formation of the network structure are discussed under the NLR model. Furthermore, in order to figure out the impact of network structure on classification, asymptotic properties are derived for the prediction rule under different sparsities of network. Lastly, simulation studies are conducted to demonstrate the finite sample performance of the proposed method, and a real Sina Weibo dataset is analyzed for illustration purpose."
Stochastic Blockmodels for Directed Graphs,"Yuchung J. Wang, George Y. C. Wong",Journal of the American Statistical Association,Stochastic partitioned directed graph; Blockmodeling technique; Iterative scaling algorithm,"Holland and Leinhardt (1981) proposed thep, model for the analysis of binary directed graph data in network studies. Such a model provides information about the ""attractiveness"" and ""expansiveness"" of the individual nodes in the network, as well as the tendency of a pair of nodes to reciprocate relational ties. When the nodes are a priori partitioned into subgroups based on attributes such as race and sex, the density of ties from one subgroup to another can differ considerably from that relating another pair of subgroups, thus creating a situation called blocking in social networks. Thep, model completely ignores this extra piece of information and is, therefore, unable to explain the block structure. Blockmodels that are simple extensions of the p, model are proposed specifically for such data. An iterative scaling algorithm is presented for fitting the model parameters by maximum likelihood. The methodology is illustrated in detail on two empirical examples."
On Network Theory,"Stephen P. Borgatti, Daniel S. Halgin",Organization Science,theory; social network; flow model; bond model; endogeneity; structure,"Research on social networks has grown considerably in the last decade. However, there is a certain amount of confusion about network theory — for example, what it is, what is distinctive about it, and how to generate new theory. This paper attempts to remedy the situation by clarifying the fundamental concepts of the field (such as the network) and characterizing how network reasoning works. We start by considering the definition of network, noting some confusion caused by two different perspectives, which we refer to as realist and nominalist. We then analyze two well-known network theories, Granovetter’s strength of weak ties, to identify characteristic elements of network theorizing. We argue that both theories share an underlying theoretical model, which we label the network flow model, from which we derive additional implications. We also discuss network phenomena that do not appear to fit the flow model and discuss the possibility of a second fundamental model, which we call the bond model. We close with a discussion of the merits of model-based network theorizing for facilitating the generation of new theory, as well as a discussion of endogeneity in network theorizing."
World system analysis: Trade and diplomacy,Saeed Nasehi Moghadam,IEEE,"Social Network Analysis(SNA), blockmodeling, Positional Analysis, Likelihood ratio statistics, Clustering, K-Means, exponential random graph model, PI model","World system analysis is performed by various methods and techniques. Among these methods Social Network Analysis approach presents interesting propositions about the world system structure. In this work, using SNA technique, we analyze world trade and diplomatic data and show the world system structure using positional analysis. In fact we perform our blockmodeling attempt on trade and diplomacy relation independently and try to discover world system structure and interpret result of blockmodeling for each relation separately."
Stochastic blockmodels: First steps,"Paul W. Holland, Kathryn B. Laskey,Samuel Leinhardt",Social Networks,,"A stochastic model is proposed for social networks in which the actors in a network are partitioned into subgroups called blocks. The model provides a stochastic generalization of the blockmodel. Estimation techniques are developed for the special case of a single relation social network, with blocks specified a priori. An extension of the model allows for tendencies toward reciprocation of ties beyond those explained by the partition. The extended model provides a one degree-of-freedom test of the model. A numerical example from the social network literature is used to illustrate the methods."
A Spinning Top Model of Formal Organization and Informal Behavior: Dynamics of Advice Networks Among Judges in a Commercial Court,"Emmanuel Lazega, Claire Lemercier,Use Mounier",European Management Review,formal organization; dynamics; advice network; learning; commercial court; spinning top,"The longitudinal study of advice networks among 240 judges at the Commercial Court of Paris permits the examination of learning as an interactive process. We argue that a spinning top model is a useful heuristic for intra-organizational learning in dynamic advice networks. This model proposes that a stabilized elite preserves accumulated knowledge in a community that overall experiences high turnover and systematic job rotation, and hence runs the danger of inadequately sharing knowledge among its members. We test the model by analyzing the structure and dynamics of advice networks among judges at the Commercial Court of Paris. This dynamic structure reflects the informal homophilous preferences among judges organized in a strong formal system, a high relational turnover in the selection of advisors, and the emergence of an elite of senior advisors that stabilizes the learning process - much like the behavior of a spinning top. This case study also identifies an endogenous process of increasing and then decreasing centralization of this network over time, raising questions about the maintenance of the stability of the pecking order and about the relationship between learning and seniority. Results illustrate the importance of dynamic over static network analysis and call for a renewed attention to formal structure in organizations."
Organizational Culture As a Complex System: Balance and Information in Models of Influence and Selection,"Kenneth A. Frank, Kyle Fahrbach",Organization Science,Complexity in Organizations; Interpersonal Influence; Selection Models; Simulation,"We define the complex system underlying organizational culture by incorporating the social-psychological principles of balance and information (B-I) into models of influence (changes in attitudes as a function of interaction) and selection (changes in interaction). We identify information based influence as a potential anchor for actors' sentiments so that they are not overwhelmed by normative influence. In the model of selection, we identify the pursuit of information as an important counterbalance to the effect of homophily (interacting with others like oneself). Using the tools of dynamic systems we show how our models generate the full range of equilibria of complex systems. Through simulations we also explore how our system responds to exogenous effects."
A graph‐theoretic definition of a sociometric clique,Richard D. Alba,Journal of Mathematical Sociology,,"The intent of this paper is to provide a definition of a sociometric clique in the language of graph theory. This problem is viewed from two perspectives: maintaining fidelity to the intuitive notion of a clique; and providing adequate computational mechanics for large bodies of data. Luce's (1950) concept of an K-clique is used, but further qualifications are added. Two statistics or measures with associated probability distributions are defined for testing the adequacy of a subgraph which qualifies according to the definition."
Network Theorizing,Stephen P. Borgatti,,Theory; Social Network; Flow Model; Bond Model; Endogeneity; Structure,"Research on social networks has grown considerably in the last decade. However, there is a certain amount of confusion about network theory – what it is, what is distinctive about it, how to generate new theory. This article attempts to remedy the situation by clarifying the fundamental concepts of the field (such as the network) and characterizing how network reasoning works. We start by considering the definition of network, noting some confusion caused by two different perspectives, which we refer to as realist and nominalist. We then analyze two well-known network theories, Granovetter’s (1973) strength of weak ties theory and Burt’s (1992) structural holes theory, in order to identify characteristic elements of network theorizing. We argue that both theories share an underlying theoretical model, which we label the network flow model, from which we derive additional implications. We also discuss network phenomena that do not appear to fit the flow model, and discuss the possibility of a second fundamental model, which we call the bond model. We close with a discussion of the merits of model-based network theorizing for facilitating the generation of new theory, as well as a discussion of endogeneity in network theorizing."
Joint analysis of trade and diplomacy,"Saeed Nasehi Moghadam, MehdiGhazanfari",IEEE,"Social Network Analysis(SNA), blockmodeling, Positional Analysis, Likelihood ratio statistics, Clustering, KMeans, exponential random graph model, p1 model","World system analysis is an interesting case in social network analysis. The nature of multirelational of world system requires studies about associations between this multiple relations. In this paper we perform positional analysis of trade and diplomacy relations jointly. Intriguing interpretations emerged, using joint blockmodeling, were presented and then direction of dependency between trade and diplomacy in world system structure was examined."
Dynamic degree-corrected blockmodels for social networks: a nonparametric approach,"Linda S. L. Tan, Maria De Iorio",Statistical Modelling,"Community detection, degree correction, Dirichlet process, stochastic blockmodels","A nonparametric approach to the modelling of social networks using degree-corrected stochastic blockmodels is proposed. The model for static network consists of a stochastic blockmodel using a probit regression formulation, and popularity parameters are incorporated to account for degree heterogeneity. We specify a Dirichlet process prior to detect community structure as well as to induce clustering in the popularity parameters. This approach is flexible yet parsimonious as it allows the appropriate number of communities and popularity clusters to be determined automatically by the data. We further discuss and implement extensions of the static model to dynamic networks. In a Bayesian framework, we perform posterior inference through MCMC algorithms. The models are illustrated using several real-world benchmark social networks."
Blockmodels: Interpretation and evaluation,"Katherine Faust, Stanley Wasserman",Social Networks,,"Many methods for the description of social network structural properties are concerned with the dual notions of social position and social role. Common goals of these methods are to represent patterns in complex social network data in simplified form, to reveal sets of actors who are similarly embedded in networks of relations, and to describe the associations among relations in multirelational social networks. Often these representations take the form of a blockmodel. In a blockmodel actors are assigned to positions and network relations are presented among positions, rather than among actors, The literature on blockmodels is extensive and is overflowing with computation and applications of blockmodels. However, there is a surprising lack of attention to two very important aspects of blockmodel analyses: the interpretation and evaluation of the results. The purpose of this paper is to focus on these topics, primarily reviewing and synthesizing the approaches to
interpretation and evaluation currently in use. "
Jaccard-Spline index of structural proximity in contact networks,Noah E. Friedkin,Social Networks,"Contact, Network, Agreement, Influence","Network analysts are increasingly being called upon to apply their expertise to groups for which the only available or reliable data is a contact network. With no opportunity to gather additional data, the merits of such applications depend on empirical studies that validate the employment of structural constructs based on contact networks. Fortunately, we possess such studies in abundance. One of the strongest research traditions in social network analysis is the development of formal constructs that may be employed in analyses of networks. I suggest that greater insight into predictive success of network constructs may be acquired by addressing the following question: what features of the contact network in which a dyad is situated allow the prediction of other relations with an accuracy that validates the imputation of the latter given data on the former? In this article, I present findings on the structural contexts of dyads in contact networks and the relationship of these contexts with two fundamental forms of cohesive cognitive relations—accorded interpersonal influence and perceived interpersonal agreement. Based on these findings, I formalize a measure of structural proximity in contact networks with values that correspond to the conditional probabilities of these two forms of cohesive cognitive relations. The substantive settings of this analysis are policy groups with members who are embedded in contact structures based on regular interpersonal communication on policy issues and cognitive structures based on perceived interpersonal agreement and accorded interpersonal influence."
An Exponential Family of Probability Distributions for Directed Graphs,"Paul W. Holland, Samuel Leinhardt",Journal of the American Statistical Association,Random digraphs; Networks; Sociome- try; Generalized iterative scaling,"Directed graph (or digraph) data arise in many fields, especially in contemporary research on structures of so- cial relationships. We describe an exponential family of distributions that can be used for analyzing such data. A substantive rationale for the general model is presented, and several special cases are discussed along with some possible substantive interpretations. A computational al- gorithm based on iterative scaling procedures for use in fitting data is described, as are the results of a pilot sim- ulation study. An example using previously reported em- pirical data is worked out in detail. An extension to mul- tiple relationship data is discussed briefly."
Stochastic a posteriori blockmodels: Construction and assessment,"Stanley Wasserman, Carolyn JaneAnderson",Social Networks,,"In 1983, Holland, Laskey, and Leinhardt, using the ideas of Holland and Leinhardt, and Fienberg and Wasserman, introduced the notion of a stochastic blockmodel. The mathematics for stochastic a priori blockmodels, in which exogenous actor attribute data are used to partition actors independently of any statistical analysis of the available relational data, have been refined by several researchers and the resulting models used by many. Attempts to simultaneously partition actors and to perform relational data analyses using statistical methods that yield stochastic a posteriori blockmodels are still quite rare. In this paper, we discuss some old suggestions for producing such posterior blockmodels, and comment on other new suggestions based on multiple comparisons of model parameters, log-linear models for ordinal categorical data, and correspondence analysis. We also review measures for goodness-of-fit of a blockmodel, and we describe a natural approach to this problem using likelihood-ratio statistics generated from a popular model for relational data."
An introduction to exponential randomgraph (p*) models for social networks,"Garry Robins, Pip Pattison, Yuval Kalish,Dean Lusher",Social Networks,"Exponential random graph models, Statistical models for social networks, p* models","This article provides an introductory summary to the formulation and application of exponential random graph models for social networks. The possible ties among nodes of a network are regarded as random variables, and assumptions about dependencies among these random tie variables determine the general form of the exponential random graph model for the network. Examples of different dependence assumptions and their associated models are given, including Bernoulli, dyad-independent and Markov random graph models. The incorporation of actor attributes in social selection models is also reviewed. Newer, more complex dependence assumptions are briefly outlined. Estimation procedures are discussed, including new methods for Monte Carlo maximum likelihood estimation. We foreshadow the discussion taken up in other papers in this special edition: that the homogeneous Markov random graph models of Frank and Strauss [Frank, O., Strauss, D., 1986. Markov graphs. Journal of the American Statistical Association 81, 832–842] are not appropriate for many observed networks, whereas the new model specifications of Snijders et al. [Snijders, T.A.B., Pattison, P., Robins, G.L., Handock, M. New specifications for exponential random graph models. Sociological Methodology, in press] offer substantial improvement."
Spectral clustering and the high-dimensional stochastic blockmodel,"Karl Rohe, Sourav Chatterjee, Bin Yu",arXiv,,"Networks or graphs can easily represent a diverse set of data sources that are characterized by interacting units or actors. Social networks, representing people who communicate with each other, are one example. Communities or clusters of highly connected actors form an essential feature in the structure of several empirical networks. Spectral clustering is a popular and computationally feasible method to discover these communities. The stochastic blockmodel [Social Networks 5 (1983) 109--137] is a social network model with well-defined communities; each node is a member of one community. For a network generated from the Stochastic Blockmodel, we bound the number of nodes ""misclustered"" by spectral clustering. The asymptotic results in this paper are the first clustering results that allow the number of clusters in the model to grow with the number of nodes, hence the name high-dimensional. In order to study spectral clustering under the stochastic blockmodel, we first show that under the more general latent space model, the eigenvectors of the normalized graph Laplacian asymptotically converge to the eigenvectors of a ""population"" normalized graph Laplacian. Aside from the implication for spectral clustering, this provides insight into a graph visualization technique. Our method of studying the eigenvectors of random matrices is original."
"Friends, Relatives, and Relevant Others: Conducting Ethnographic Network Studies",Robert T. Trotter,,,"There is a Spanish proverb that states, ""Di me con quien andan, y dire quien eres,"" which generally translates as ""Tell me who you walk with, and I will tell you who you are."" We all reflect our values and beliefs, as well as our hopes and accomplishments, through the people with whom we choose to associate and those whom we avoid. Our social world is made up primarily of our family and friends, work partners, acquaintances, and the organizations and communities in which we participate. Anthropologists have studied the composition of these relationships, or social networks, in villages, towns, and urban centers all over the world. Social scientists most frequently hav
"
Markov Chain Monte Carlo Estimation of Exponential Random Graph Models,Tom A. B. Snijders,,p ∗ model; Markov graph; digraphs; exponential family; maximum likelihood; method of moments; Robbins-Monro algorithm; Gibbs sampling; Metropolis-Hastings algorithm,"This paper is about estimating the parameters of the exponential random graph model, also known as the p ∗ model, using frequentist Markov chain Monte Carlo (MCMC) methods. The exponential random graph model is simulated using Gibbs or MetropolisHastings sampling. The estimation procedures considered are based on the Robbins-Monro algorithm for approximating a solution to the likelihood equation. A major problem with exponential random graph models resides in the fact that such models can have, for certain parameter values, bimodal (or multimodal) distributions for the sufficient statistics such as the number of ties. The bimodality of the exponential graph distribution for certain parameter values seems a severe limitation to its practical usefulness. The possibility of bi- or multimodality is reflected in the possibility that the outcome space is divided into two (or more) regions such that the more usual type of MCMC algorithms, updating only single relations, dyads, or triplets, have extremely long sojourn times within such regions, and a negligible probability to move from one region to another. In such situations, convergence to the target distribution is extremely slow. To be useful, MCMC algorithms must be able to make transitions from a given graph to a very different graph. It is proposed to include transitions to the graph complement as updating steps to improve the speed of convergence to the target distribution. Estimation procedures implementing these ideas work satisfactorily for some data sets and model specifications, but not for all."
The Multilevel p2 Model : A Random Effects Model for the Analysis of Multiple Social Networks,"Bonne J H Zijlstra, Marijtje A. J. VanDuijn, Tom A. B. Snijders",Methodology,"social network analysis, random effects, multilevel modeling, p2 model","The p2 model is a random effects model with covariates for the analysis of binary directed social network data coming from a singleobservation of a social network. Here, a multilevel variant of the p2 model is proposed for the case of multiple observations of social networks,for example, in a sample of schools. The multilevel  p2 model deﬁnes an identical p2 model for each independent observation of the socialnetwork, where parameters are allowed to vary across the multiple networks. The multilevel p2 model is estimated with a Bayesian MarkovChain Monte Carlo (MCMC) algorithm that was implemented in free software for the statistical analysis of complete social network data, called StOCNET. The new model is illustrated with a study on the received practical support by Dutch high school pupils of different ethnic back-grounds."
LOGIT MODELS AND LOGISTIC REGRESSIONS FOR SOCIAL NETWORKS: I. AN INTRODUCTION TO MARKOV GRAPHS AND p* ,Philippa Pattison,Psychometrika,,"Spanning nearly sixty years of research, statistical network analysis has passed through (at least) two generations of researchers and models. Beginning in the late 1930's, the first generation of research dealt with the distribution of various network statistics, under a variety of null models. The second generation, beginning in the 1970's and continuing into the 1980's, concerned models, usually for probabilities of relational ties among very small subsets of actors, in which various simple substantive tendencies were parameterized. Much of this research, most of which utilized log linear models, first appeared in applied statistics publications.But recent developments in social network analysis promise to bring us into a third generation. The Markov random graphs of Frank and Strauss (1986) and especially the estimation strategy for these models developed by Strauss and Ikeda (1990; described in brief in Strauss, 1992), are very recent and promising contributions to this field. Here we describe a large class of models that can be used to investigate structure in social networks. These models include several generalizations of stochastic blockmodels, as well as models parameterizing global tendencies towards clustering and centralization, and individual differences in such tendencies. Approximate model fits are obtained using Strauss and Ikeda's (1990) estimation strategy.In this paper we describe and extend these models and demonstrate how they can be used to address a variety of substantive questions about structure in social networks."
Computationally modeling organizational learning and adaptability as resource allocation: An artificial adaptive systems approach,"David L. Paul, John C. Butler, Keri E.Pearlson, Andrew B. Whinston",Computational & Mathematical Organization Theory,"complex adaptive system, organizational learning, genetic algorithm, resource allocation","A framework for and a computational model of organizational behavior based on an artificial adaptive system (AAS) is presented. An AAS, a modeling approach based on genetic algorithms, enables the modeling of organizational learning and adaptability. This learning can be represented as decisions to allocate resources to the higher performing organizational agents (i.e., individuals, groups, departments, or processes, depending on the level of analysis) critical to the organization's survival in different environments. Adaptability results from the learning function enabling the organizations to change as the environment changes. An AAS models organizational behavior from a micro-unit perspective, where organizational behavior is a function of the aggregate actions and interactions of each of the individual agents of which the organization is composed. An AAS enables organizational decision making in a dynamic environment to be modeled as a satisficing process and not as a maximization process. To demonstrate the feasibility and usefulness of such an approach, a financial trading adaptive system (FTAS) organization is computationally modeled based on the AAS framework. An FTAS is an example of how the learning mechanism in an AAS can be used to allocate resources to critical individuals, processes, functions, or departments within an organization."
"Social Network Analysis, Graph Theoretical Approaches to",Wouter de Nooy,,"Network Structure, Social Network Analysis, Betweenness Centrality, Structural Hole, Closeness Centrality","Social network analysis (SNA) focuses on the structure of ties within a set of social entities or actors, e. g., persons, groups,organizations, and nations, or the products of human activity or cognition such as semantic concepts, web sites, and so on. In a graph theoreticalapproach, a social network is conceptualized as a graph , that is, a set of vertices (or nodes, units, points) representing social actorsand a set of lines representing one or more social relations among them. A network , however, is more than a graph because it contains additional information onthe vertices and lines. Characteristics of the social actors, for instance a person's sex, age, or income, are represented by discrete or continuousattributes of the vertices in the network, and the intensity, frequency, valence, or type of social relation are represented by line weight or value, linesign, or line type. Formally (see pp. 94–95, 127–128 in [1]),a network N can be defined as   N=(U,L,FU,FL)  containing a graph   G=(U,L) , which is an ordered pair of a unit or vertexset U and a line set L, extended with a function F U specifying a property of the units (  f:U→X ) and a function F L specifying a property of the lines (  f:L→Y ). The set of lines L may be regarded as the union of a set of undirected edges E and a set ofdirected arcs   A(L=E∪A) . Eachelement e of E is an unordered pair of units u and v (vertices) from U, that is,  e(u:v) , and eachelement a of A is an ordered pair of units u and v (vertices) from U, that is,  a(u:v) .The application of graph theory to social relations can be traced back to at least the 1940s (see pp. 69–72 in [2]) when the mathematician R. Duncan Luce and the engineer Albert Perry teamed up with the social psychologist LeonFestinger [3] and when the mathematician Frank Harary started his collaboration with Leon Festingerand afterwards with Dorwin Cartwright [4]. They extended pioneering work in SNA that had been donenotably in sociometry [5,6] andanthropology [7,8,9]. In the 1960s, advances in graph theoretical approaches to SNA such as the contributions by ØysteinOre [10], Claude Flament [11], FrankHarary [12], and innovative applications such as Everett M. Rogers' work on the diffusion ofinnovations [13], prepared the ground for the rise of SNA in both the USA [14] and Europe [15] as a new set of methods or a newmethodology [16] in the 1970s."
Why Stratification of Networks Emerges in Innovative Society: Intelligent Poly-Agent Systems Approach,Kyoichi Kijima,Computational & Mathematical Organization Theory,"innovation, poly-agent system, emergence, social networks","This paper rigorously shows in the framework of poly-agent systems theory that it is very natural for an innovative society to emerge stratification of networks to cope with complexity intelligent decision makers of it have to deal with. Before introducing poly-agent systems theory, I will first refer to empirical observations of emergence of stratification of networks in innovative societies, which motivate this research. I, then, theoretically show that coexistence of both networks and hierarchies is reasonable and inevitable for a tightly interrelated society because it can provide the decision makers with mediation, which is beneficial for the decision makers as well as the society as a whole. Finally, I will go back again to implications from our theoretical study."
A p* primer: logit models for social networks,"Carolyn J. Anderson, StanleyWasserman, Bradley Crouch",Social Networks,,"A major criticism of the statistical models for analyzing social networks developed by Holland, Leinhardt, and others [Holland, P.W., Leinhardt, S., 1977. Notes on the statistical analysis of social network data; Holland, P.W., Leinhardt, S., 1981. An exponential family of probability distributions for directed graphs. Journal of the American Statistical Association. 76, pp. 33–65 (with discussion); Fienberg, S.E., Wasserman, S., 1981. Categorical data analysis of single sociometric relations. In: Leinhardt, S. (Ed.), Sociological Methodology 1981, San Francisco: Jossey-Bass, pp. 156–192; Fienberg, S.E., Meyer, M.M., Wasserman, S., 1985. Statistical analysis of multiple sociometric relations. Journal of the American Statistical Association, 80, pp. 51–67; Wasserman, S., Weaver, S., 1985. Statistical analysis of binary relational data: Parameter estimation. Journal of Mathematical Psychology. 29, pp. 406–427; Wasserman, S., 1987. Conformity of two sociometric relations. Psychometrika. 52, pp. 3–18] is the very strong independence assumption made on interacting individuals or units within a network or group. This limiting assumption is no longer necessary given recent developments on models for random graphs made by Frank and Strauss [Frank, O., Strauss, D., 1986. Markov graphs. Journal of the American Statistical Association. 81, pp. 832–842] and Strauss and Ikeda [Strauss, D., Ikeda, M., 1990. Pseudolikelihood estimation for social networks. Journal of the American Statistical Association. 85, pp. 204–212]. The resulting models are extremely flexible and easy to fit to data. Although Wasserman and Pattison [Wasserman, S., Pattison, P., 1996. Logit models and logistic regressions for social networks: I. An introduction to Markov random graphs and p*. Psychometrika. 60, pp. 401–426] present a derivation and extension of these models, this paper is a primer on how to use these important breakthroughs to model the relationships between actors (individuals, units) within a single network and provides an extension of the models to multiple networks. The models for multiple networks permit researchers to study how groups are similar and/or how they are different. The models for single and multiple networks and the modeling process are illustrated using friendship data from elementary school children from a study by Parker and Asher [Parker, J.G., Asher, S.R., 1993. Friendship and friendship quality in middle childhood: Links with peer group acceptance and feelings of loneliness and social dissatisfaction. Developmental Psychology. 29, pp. 611–621]."
An approach to evolving novel organizational forms,Kevin Crowston,Computational & Mathematical Organization Theory,"genetic algorithms, organizational form, organizational structure","A key problem in organization theory is to suggest new organizational forms. In this paper, I suggest the use of genetic algorithms to search for novel organizational forms by reproducing some of the mechanics of organizational evolution. Issues in using genetic algorithms include identification of the unit of selection, development of a representation and determination of a method for calculating organizational fitness. As an example of the approach, I test a proposition of Thompson's about how interdependent positions should be assigned to groups. Representing an organization as a collection of routines might be more general and still amenable to evolution with a genetic algorithm. I conclude by discussing possible objections to the application of this technique."
Structural Analysis in Multi-Relational Social Networks,"Bing Tian Dai, Freddy Chong Tat Chua,Ee-Peng Lim",SIAM,,"Modern social networks often consist of multiple relations among individuals. Understanding the structure of such multi-relational network is essential. In sociology, one way of structural analysis is to identify different positions and roles using blockmodels. In this paper, we generalize stochastic blockmodels to Generalized Stochastic Blockmodels (GSBM) for performing positional and role analysis on multi-relational networks. Our GSBM generalizes many different kinds of Multivariate Probability Distribution Function (MVPDF) to model different kinds of multi-relational networks. In particular, we propose to use multivariate Poisson distribution for multi-relational social networks. Our experiments show that GSBM is able to identify the structures for both synthetic and real world network data. These structures can further be used for predicting relationships between individuals.
"
The Evolution of Intra-Organizational Trust Networks The Case of a German Paper Factory: An Empirical Test of Six Trust Mechanisms,"Gerhard G. van der Bunt, Rafael Wittek,Maurits de Klepper",International Sociology,"balance, control, gossip, homophily, relational signalling, sharing groups, structural holes","Based on the distinction between expressive and instrumental motives, six theoretical mechanisms for the formation of trust relationships are elaborated and empirically tested. When expressive motives drive tie formation, individuals primarily attach emotional value to social relationships. Three mechanisms have been tested: the homophily, the balancing, and the gossiping effect. When instrumental, control-related, motives drive tie formation, actors strategically establish relationships because of their potential use for the realization of material benefits or the avoidance of material losses. Again, three mechanisms have been tested: the signalling, the sharing group and the structural hole effect. Longitudinal data come from a sociometric panel study of 17 members of the management team of a German paper factory. Actor-oriented statistical modelling shows that all effects significantly affect trust formation separately. In a simultaneous test incorporating all six mechanisms, the pattern of structural holes turns out to be the major predictor of network evolution. The implications of structural hole theory for modelling the evolution of intra-organizational networks are discussed"
Stochastic actor-oriented models for network change 1,Tom A. B. Snijders,Journal of Mathematical Sociology,methodological individualism; Markov process; Newcomb data; balance; Robbins-Monro process; simulation models; method of moments; simulated moments; random utility,"A class of models is proposed for longitudinal network data. These models are along the lines of methodological individualism: actors use heuristics to try to achieve their individual goals, subject to constraints. The current network structure is among these constraints. The models are continuous time Markov chain models that can be implemented as simulation models. They incorporate random change in addition to the purposeful change that follows from the actors’ pursuit of their goals, and include parameters that must be estimated from observed data. Statistical methods are proposed for estimating and testing these models. These methods can also be used for parameter estimation for other simulation models. The statistical procedures are based on the method of moments, and use computer simulation to estimate the theoretical moments. The Robbins-Monro process is used to deal with the stochastic nature of the estimated theoretical moments. An example is given for Newcomb’s fraternity data, using a model that expresses reciprocity and balance."
Logit models and logistic regressions for social networks: II. Multivariate relations.,"Philippa Pattison, Stanley Wasserman",British Journal of Mathematical and Statistical Psychology,,"The research described here builds on our previous work by generalizing the univariate models described there to models for multivariate relations. This family, labelled p*, generalizes the Markov random graphs of Frank and Strauss, which were further developed by them and others, building on Besag's ideas on estimation. These models were first used to model random variables embedded in lattices by Ising, and have been quite common in the study of spatial data. Here, they are applied to the statistical analysis of multigraphs, in general, and the analysis of multivariate social networks, in particular. In this paper, we show how to formulate models for multivariate social networks by considering a range of theoretical claims about social structure. We illustrate the models by developing structural models for several multivariate networks."
A Comparative Study on Cross-Function Structure of Social Network and Its Management Enlightenment,"Min Li, Cuilong Huang",IEEE,advice network; intelligence network; density; group degree centrality; group betweenness centrality; knowledge management,"Based on the theory of organizational social networks and combined with six companies' case study of social network structure. We conduct a comparative study on the structural differences of cross-function advice network and intelligence network from the point of density, group degree centrality and group betweenness centrality. The results reveal that: the density of advice network is lower than the density of intelligence network; in the aspect of the group degree centrality and group betweenness centrality, advice network is higher than intelligence network. Finally, we discuss implications of the conclusions in understanding the transmission of information, organizational communication and knowledge management."
Triadic evolution in a large-scale mobile phone network,"Cheng Wang, Omar Lizardo, David S.Hachen",Journal of Complex Networks ,triadic evolution; triangle stability; triangle formation,"In this paper, we examine the evolution of triadic motifs in a large-scale human communication network. We consider extant models of triadic evolution, emphasizing vertex-, dyadic-, triadic- and higher-level processes in order to generate testable hypotheses of the predictors of both over time triangle survival and triangle emergence from lower-order motifs. We find that the stability and formation of triangles can be predicted by factors operating at multiple levels of analysis, with dyadic processes related to strength and reciprocity and triadic processes associated with coherence in edge-weights having the most predictive power."
Researching Mental Health Disorders in the Era of Social Media: Systematic Review,"Akkapon Wongkoblap, Miguel A.Vadillo, Vasa Curcin",Journal of Medical Internet Research,anxiety; artificial intelligence; depression; infodemiology; machine learning; mental disorders; mental health; public health informatics; social networking,"Mental illness is quickly becoming one of the most prevalent public health problems worldwide. Social network platforms, where users can express their emotions, feelings, and thoughts, are a valuable source of data for researching mental health, and techniques based on machine learning are increasingly used for this purpose. The objective of this review was to explore the scope and limits of cutting-edge techniques that researchers are using for predictive analytics in mental health and to review associated issues, such as ethical concerns, in this area of research. We performed a systematic literature review in March 2017, using keywords to search articles on data mining of social network data in the context of common mental health disorders, published between 2010 and March 8, 2017 in medical and computer science journals.The initial search returned a total of 5386 articles. Following a careful analysis of the titles, abstracts, and main texts, we selected 48 articles for review. We coded the articles according to key characteristics, techniques used for data collection, data preprocessing, feature extraction, feature selection, model construction, and model verification. The most common analytical method was text analysis, with several studies using different flavors of image analysis and social interaction graph analysis.Despite an increasing number of studies investigating mental health issues using social network data, some common problems persist. Assembling large, high-quality datasets of social media users with mental disorder is problematic, not only due to biases associated with the collection methods, but also with regard to managing consent and selecting appropriate analytics techniques."
The language of mental health problems in social media,"George Gkotsis, Anika Oellrich, Tim J.P. Hubbard, Richard J. B. Dobson,Maria Liakata, Sumithra Velupillai, RinaDutta",ACL,,"Online social media, such as Reddit, has become an important resource to share personal experiences and communicate with others. Among other personal information, some social media users communicate about mental health problems they are experiencing, with the intention of getting advice, support or empathy from other users. Here, we investigate the language of Reddit posts specific to mental health, to define linguistic characteristics that could be helpful for further applications. The latter include attempting to identify posts that need urgent attention due to their nature, e.g. when someone announces their intentions of ending their life by suicide or harming others. Our results show that there are a variety of linguistic features that are discriminative across mental health user communities and that can be further exploited in subsequent classification tasks. Furthermore, while negative sentiment is almost uniformly expressed across the entire data set, we demonstrate that there are also condition-specific vocabularies used in social media to communicate about particular disorders."
Quantifying Mental Health from Social Media with Neural User Embeddings,"Silvio Amir, Glen Coppersmith, PaulaCarvalho, Mário J. Silva, Byron C.Wallace",arXiv,,"Mental illnesses adversely affect a significant proportion of the population worldwide. However, the methods traditionally used for estimating and characterizing the prevalence of mental health conditions are time-consuming and expensive. Consequently, best-available estimates concerning the prevalence of mental health conditions are often years out of date. Automated approaches to supplement these survey methods with broad, aggregated information derived from social media content provides a potential means for near real-time estimates at scale. These may, in turn, provide grist for supporting, evaluating and iteratively improving upon public health programs and interventions. We propose a novel model for automated mental health status quantification that incorporates user embeddings. This builds upon recent work exploring representation learning methods that induce embeddings by leveraging social media post histories. Such embeddings capture latent characteristics of individuals (e.g., political leanings) and encode a soft notion of homophily. In this paper, we investigate whether user embeddings learned from twitter post histories encode information that correlates with mental health statuses. To this end, we estimated user embeddings for a set of users known to be affected by depression and post-traumatic stress disorder (PTSD), and for a set of demographically matched `control' users. We then evaluated these embeddings with respect to: (i) their ability to capture homophilic relations with respect to mental health status; and (ii) the performance of downstream mental health prediction models based on these features. Our experimental results demonstrate that the user embeddings capture similarities between users with respect to mental conditions, and are predictive of mental health."
Detecting Signs of Depression in Tweets in Spanish: Behavioral and Linguistic Analysis,"Angela Leis, Francesco Ronzano,Miguel Angel Mayer, Laura InésFurlong, Ferran Sanz",Journal of Medical Internet Research,"depression; social media; mental health; text mining 
","Mental disorders have become a major concern in public health, and they are one of the main causes of the overall disease burden worldwide. Social media platforms allow us to observe the activities, thoughts, and feelings of people’s daily lives, including those of patients suffering from mental disorders. There are studies that have analyzed the influence of mental disorders, including depression, in the behavior of social media users, but they have been usually focused on messages written in English. The study aimed to identify the linguistic features of tweets in Spanish and the behavioral patterns of Twitter users who generate them, which could suggest signs of depression. This study was developed in 2 steps. In the first step, the selection of users and the compilation of tweets were performed. A total of 3 datasets of tweets were created, a depressive users dataset (made up of the timeline of 90 users who explicitly mentioned that they suffer from depression), a depressive tweets dataset (a manual selection of tweets from the previous users, which included expressions indicative of depression), and a control dataset (made up of the timeline of 450 randomly selected users). In the second step, the comparison and analysis of the 3 datasets of tweets were carried out. In comparison with the control dataset, the depressive users are less active in posting tweets, doing it more frequently between 23:00 and 6:00 (P<.001). The percentage of nouns used by the control dataset almost doubles that of the depressive users (P<.001). By contrast, the use of verbs is more common in the depressive users dataset (P<.001). The first-person singular pronoun was by far the most used in the depressive users dataset (80%), and the first- and the second-person plural pronouns were the least frequent (0.4% in both cases), this distribution being different from that of the control dataset (P<.001). Emotions related to sadness, anger, and disgust were more common in the depressive users and depressive tweets datasets, with significant differences when comparing these datasets with the control dataset (P<.001). As for negation words, they were detected in 34% and 46% of tweets in among depressive users and in depressive tweets, respectively, which are significantly different from the control dataset (P<.001). Negative polarity was more frequent in the depressive users (54%) and depressive tweets (65%) datasets than in the control dataset (43.5%; P<.001).Twitter users who are potentially suffering from depression modify the general characteristics of their language and the way they interact on social media. On the basis of these changes, these users can be monitored and supported, thus introducing new opportunities for studying depression and providing additional health care services to people with this disorder."
Monitoring Tweets for Depression to Detect At-risk Users,"Zunaira Jamil, Diana Inkpen, PrasadithBuddhitha, Kenton White",ACL,,"We propose an automated system that can identify at-risk users from their public social media activity, more specifically, from Twitter. The data that we collected is from the #BellLetsTalk campaign, which is a wide-reaching, multi-year program designed to break the silence around mental illness and support mental health across Canada. To achieve our goal, we trained a user-level classifier that can detect atrisk users that achieves a reasonable precision and recall. We also trained a tweetlevel classifier that predicts if a tweet indicates depression. This task was much more difficult due to the imbalanced data. In the dataset that we labeled, we came across 5% depression tweets and 95% non-depression tweets. To handle this class imbalance, we used undersampling methods. The resulting classifier had high recall, but low precision. Therefore, we only use this classifier to compute the estimated percentage of depressed tweets and to add this value as a feature for the userlevel classifier"
Ethical Research Protocols for Social Media Health Research,"Adrian Benton, Glen Coppersmith, MarkDredze",ACL,,"Social media have transformed data-driven research in political science, the social sciences, health, and medicine. Since health research often touches on sensitive topics that relate to ethics of treatment and patient privacy, similar ethical considerations should be acknowledged when using social media data in health research. While much has been said regarding the ethical considerations of social media research, health research leads to an additional set of concerns. We provide practical suggestions in the form of guidelines for researchers working with social media data in health research. These guidelines can inform an IRB proposal for researchers new to social media health research."
Assessing Suicide Risk and Emotional Distress in Chinese Social Media: A Text Mining and Machine Learning Study,"Qijin Cheng, Tim Mh Li, Chi-LeungKwok, Tingshao Zhu, Paul Sf Yip",Journal of Medical Internet Research,"suicide; psychological stress; social media; Chinese; natural language; machine learning 
","Early identification and intervention are imperative for suicide prevention. However, at-risk people often neither seek help nor take professional assessment. A tool to automatically assess their risk levels in natural settings can increase the opportunity for early intervention. The aim of this study was to explore whether computerized language analysis methods can be utilized to assess one's suicide risk and emotional distress in Chinese social media. A Web-based survey of Chinese social media (ie, Weibo) users was conducted to measure their suicide risk factors including suicide probability, Weibo suicide communication (WSC), depression, anxiety, and stress levels. Participants' Weibo posts published in the public domain were also downloaded with their consent. The Weibo posts were parsed and fitted into Simplified Chinese-Linguistic Inquiry and Word Count (SC-LIWC) categories. The associations between SC-LIWC features and the 5 suicide risk factors were examined by logistic regression. Furthermore, the support vector machine (SVM) model was applied based on the language features to automatically classify whether a Weibo user exhibited any of the 5 risk factors. A total of 974 Weibo users participated in the survey. Those with high suicide probability were marked by a higher usage of pronoun (odds ratio, OR=1.18, P=.001), prepend words (OR=1.49, P=.02), multifunction words (OR=1.12, P=.04), a lower usage of verb (OR=0.78, P<.001), and a greater total word count (OR=1.007, P=.008). Second-person plural was positively associated with severe depression (OR=8.36, P=.01) and stress (OR=11, P=.005), whereas work-related words were negatively associated with WSC (OR=0.71, P=.008), severe depression (OR=0.56, P=.005), and anxiety (OR=0.77, P=.02). Inconsistently, third-person plural was found to be negatively associated with WSC (OR=0.02, P=.047) but positively with severe stress (OR=41.3, P=.04). Achievement-related words were positively associated with depression (OR=1.68, P=.003), whereas health- (OR=2.36, P=.004) and death-related (OR=2.60, P=.01) words positively associated with stress. The machine classifiers did not achieve satisfying performance in the full sample set but could classify high suicide probability (area under the curve, AUC=0.61, P=.04) and severe anxiety (AUC=0.75, P<.001) among those who have exhibited WSC. SC-LIWC is useful to examine language markers of suicide risk and emotional distress in Chinese social media and can identify characteristics different from previous findings in the English literature. Some findings are leading to new hypotheses for future verification. Machine classifiers based on SC-LIWC features are promising but still require further optimization for application in real life."
A Taxonomy of Ethical Tensions in Inferring Mental Health States from Social Media,"Stevie Chancellor, Michael L. Birnbaum,Eric D. Caine, Vincent Silenzio, MunmunDe Choudhury",ACM,mental health; ethics; machine learning; algorithms; social media,"Powered by machine learning techniques, social media provides an unobtrusive lens into individual behaviors, emotions, and psychological states. Recent research has successfully employed social media data to predict mental health states of individuals, ranging from the presence and severity of mental disorders like depression to the risk of suicide. These algorithmic inferences hold great potential in supporting early detection and treatment of mental disorders and in the design of interventions. At the same time, the outcomes of this research can pose great risks to individuals, such as issues of incorrect, opaque algorithmic predictions, involvement of bad or unaccountable actors, and potential biases from intentional or inadvertent misuse of insights. Amplifying these tensions, there are also divergent and sometimes inconsistent methodological gaps and under-explored ethics and privacy dimensions. This paper presents a taxonomy of these concerns and ethical challenges, drawing from existing literature, and poses questions to be resolved as this research gains traction. We identify three areas of tension: ethics committees and the gap of social media research; questions of validity, data, and machine learning; and implications of this research for key stakeholders. We conclude with calls to action to begin resolving these interdisciplinary dilemmas."
Detecting Suicidal Ideation in Chinese Microblogs with Psychological Lexicons,"Xiaolei Huang, Lei Zhang, David Chiu,Tianli Liu, Xin Li, Tingshao Zhu",arXiv,,"Suicide is among the leading causes of death in China. However, technical approaches toward preventing suicide are challenging and remaining under development. Recently, several actual suicidal cases were preceded by users who posted microblogs with suicidal ideation to Sina Weibo, a Chinese social media network akin to Twitter. It would therefore be desirable to detect suicidal ideations from microblogs in real-time, and immediately alert appropriate support groups, which may lead to successful prevention. In this paper, we propose a real-time suicidal ideation detection system deployed over Weibo, using machine learning and known psychological techniques. Currently, we have identified 53 known suicidal cases who posted suicide notes on Weibo prior to their deaths.We explore linguistic features of these known cases using a psychological lexicon dictionary, and train an effective suicidal Weibo post detection model. 6714 tagged posts and several classifiers are used to verify the model. By combining both machine learning and psychological knowledge, SVM classifier has the best performance of different classifiers, yielding an F-measure of 68:3%, a Precision of 78:9%, and a Recall of 60:3%."
MIDAS: Mental illness detection and analysis via social media,"Elvis Saravia, Chun-Hao Chang, RenaudJollet De Lorenzo, Yi-Shin Chen",IEEE,,"Mental illnesses rank as some of the most disabling conditions, affecting millions of people, across the globe. In general, the main challenge of mental disorders is that they remain difficult to detect on suffering patients. In an online environment, the challenge extends to the collection of patients data and the implementation of proper algorithms to assist in the detection of such illnesses. In this paper, we propose a novel data collection mechanism and build predictive models that leverage language and behavioral patterns, used particularly on Twitter, to determine whether a user is suffering from a mental disorder. After training the predictive models, they are further pre-trained to serve as the backend for our demonstration, MIDAS. MIDAS offers an analytics web-service to explore several characteristics pertaining to user's linguistic and behavioral patterns on social media, with respect to mental illnesses."
Detecting Cognitive Distortions Through Machine Learning Text Analytics,"T. Simms, C. Ramstedt, M. Rich, M.Richards, Tony R. Martinez, ChristopheG. Giraud-Carrier",IEEE,Machine Learning; Social Media Data; Cognitive Distortion,"Machine learning and text analytics have proven increasingly useful in a number of health-related applications, particularly in the context of analyzing online data for disease epidemics and warning signs of a variety of mental health issues. We follow in this tradition here, but focus our attention on cognitive distortion, a precursor and symptom of disruptive psychological disorders such as anxiety, anorexia and depression. We collected a number of personal blogs from the Tumblr API, and labeled them based on whether they exhibited distorted thought patterns. We then used LIWC to extract textual features and applied machine learning to the resulting vectors. Our findings show that it is possible to detect cognitive distortions automatically from personal blogs with relatively good accuracy (73.0%) and false negative rate (30.4%)."
Natural Language Processing of Social Media as Screening for Suicide Risk,"Glen Coppersmith, Ryan Leary, PatrickCrutchley, Alex Fine",Biomedical Informatics Insights ,"Suicide, suicide screening, suicide prevention, social media, data science, natural language processing","Suicide is among the 10 most common causes of death, as assessed by the World Health Organization. For every death by suicide, an estimated 138 people’s lives are meaningfully affected, and almost any other statistic around suicide deaths is equally alarming. The pervasiveness of social media—and the near-ubiquity of mobile devices used to access social media networks—offers new types of data for understanding the behavior of those who (attempt to) take their own lives and suggests new possibilities for preventive intervention. We demonstrate the feasibility of using social media data to detect those at risk for suicide. Specifically, we use natural language processing and machine learning (specifically deep learning) techniques to detect quantifiable signals around suicide attempts, and describe designs for an automated system for estimating suicide risk, usable by those without specialized mental health training (eg, a primary care doctor). We also discuss the ethical use of such technology and examine privacy implications. Currently, this technology is only used for intervention for individuals who have “opted in” for the analysis and intervention, but the technology enables scalable screening for suicide risk, potentially identifying many people who are at risk preventively and prior to any engagement with a health care system. This raises a significant cultural question about the trade-off between privacy and prevention—we have potentially life-saving technology that is currently reaching only a fraction of the possible people at risk because of respect for their privacy. Is the current trade-off between privacy and prevention the right one?"
Methods in predictive techniques for mental health status on social media: a critical review,"Stevie Chancellor, Munmun DeChoudhury",NPJ Digital Medicine ,,"Social media is now being used to model mental well-being, and for understanding health outcomes. Computer scientists are now using quantitative techniques to predict the presence of specific mental disorders and symptomatology, such as depression, suicidality, and anxiety. This research promises great benefits to monitoring efforts, diagnostics, and intervention design for these mental health statuses. Yet, there is no standardized process for evaluating the validity of this research and the methods adopted in the design of these studies. We conduct a systematic literature review of the state-of-the-art in predicting mental health status using social media data, focusing on characteristics of the study design, methods, and research design. We find 75 studies in this area published between 2013 and 2018. Our results outline the methods of data annotation for mental health status, data collection and quality management, pre-processing and feature selection, and model selection and verification. Despite growing interest in this field, we identify concerning trends around construct validity, and a lack of reflection in the methods used to operationalize and identify mental health status. We provide some recommendations to address these challenges, including a list of proposed reporting standards for publications and collaboration opportunities in this interdisciplinary space."
Emotional and Linguistic Cues of Depression from Social Media,"Nikhita Vedula, SrinivasanParthasarathy",ACM,,"Health outcomes in modern society are often shaped by peer interactions. Increasingly, a significant fraction of such interactions happen online and can have an impact on various mental health and behavioral health outcomes. Guided by appropriate social and psychological research, we conduct an observational study to understand the interactions between clinically depressed users and their ego-network when contrasted with a differential control group of normal users and their ego-network. Specifically, we examine if one can identify relevant linguistic and emotional signals from social media exchanges to detect symptomatic cues of depression. We observe significant deviations in the behavior of depressed users from the control group. Reduced and nocturnal online activity patterns, reduced active and passive network participation, increase in negative sentiment or emotion, distinct linguistic styles (e.g. self-focused pronoun usage), highly clustered and tightly-knit neighborhood structure, and little to no exchange of influence between depressed users and their ego-network over time are some of the observed characteristics. Based on our observations, we then describe an approach to extract relevant features and show that building a classifier to predict depression based on such features can achieve an F-score of 90%."
Methodological Gaps in Predicting Mental Health States from Social Media: Triangulating Diagnostic Signals,"Sindhu Kiranmai Ernala, Michael L.Birnbaum, Kristin A. Candan, Asra F.Rizvi, William A. Sterling, John M. Kane,Munmun De Choudhury",ACM,,"A growing body of research is combining social media data with machine learning to predict mental health states of individuals. An implication of this research lies in informing evidence-based diagnosis and treatment. However, obtaining clinically valid diagnostic information from sensitive patient populations is challenging. Consequently, researchers have operationalized characteristic online behaviors as “proxy diagnostic signals” for building these models. This paper posits a challenge in using these diagnostic signals, purported to support clinical decision-making. Focusing on three commonly used proxy diagnostic signals derived from social media, we find that predictive models built on these data, although offer strong internal validity, suffer from poor external validity when tested onmental health patients.A deeper dive revealsissues of population and sampling bias, as well as of uncertainty in construct validity inherent in these proxies. We discuss the methodological and clinical implications of these gaps and provide remedial guidelines for future research."
Automatic extraction of informal topics from online suicidal ideation,"Reilly Grant, David Kucher, Ana M. Leon,Jonathan Gemmell, Daniela Stan Raicu,Samah J. Fodeh",BMC Bioinformatics,"Suicidal ideation, Word2Vec, Text mining","Suicide is an alarming public health problem accounting for a considerable number of deaths each year worldwide. Many more individuals contemplate suicide. Understanding the attributes, characteristics, and exposures correlated with suicide remains an urgent and significant problem. As social networking sites have become more common, users have adopted these sites to talk about intensely personal topics, among them their thoughts about suicide. Such data has previously been evaluated by analyzing the language features of social media posts and using factors derived by domain experts to identify at-risk users. In this work, we automatically extract informal latent recurring topics of suicidal ideation found in social media posts. Our evaluation demonstrates that we are able to automatically reproduce many of the expertly determined risk factors for suicide. Moreover, we identify many informal latent topics related to suicide ideation such as concerns over health, work, self-image, and financial issues. These informal topics topics can be more specific or more general. Some of our topics express meaningful ideas not contained in the risk factors and some risk factors do not have complimentary latent topics. In short, our analysis of the latent topics extracted from social media containing suicidal ideations suggests that users of these systems express ideas that are complementary to the topics defined by experts but differ in their scope, focus, and precision of language."
"Who is the ""Human"" in Human-Centered Machine Learning: The Case of Predicting Mental Health from Social Media","Stevie Chancellor, Eric Baumer,Munmun De Choudhury",ACM,human-centered machine learning; machine learning; social media; research ethics; mental health,"“Human-centered machine learning” (HCML) combines human insights and domain expertise with datadriven predictions to answer societal questions. This area’s inherent interdisciplinarity causes tensions in the obligations researchers have to the humans whose data they use. This paper studies how scientific papers represent human research subjects in HCML. Using mental health status prediction on social media as a case study, we conduct thematic discourse analysis on 55 papers to examine these representations. We identify five discourses that weave a complex narrative of who the human subject is in this research: Disorder/Patient, Social Media, Scientific, Data/Machine Learning, and Person. We show how these five discourses create paradoxical subject and object representations of the human, which may inadvertently risk dehumanization. We also discuss the tensions and impacts of interdisciplinary research; the risks of this work to scientific rigor, online communities, and mental health; and guidelines for stronger HCML research in this nascent area."
Hierarchical neural model with attention mechanisms for the classification of social media text related to mental health,"Julia Ive, George Gkotsis, Rina Dutta,Robert Stewart, Sumithra Velupillai",ACL,,"Mental health problems represent a major public health challenge. Automated analysis of text related to mental health is aimed to help medical decision-making, public health policies and to improve health care. Such analysis may involve text classification. Traditionally, automated classification has been performed mainly using machine learning methods involving costly feature engineering. Recently, the performance of those methods has been dramatically improved by neural methods. However, mainly Convolutional neural networks (CNNs) have been explored. In this paper, we apply a hierarchical Recurrent neural network (RNN) architecture with an attention mechanism on social media data related to mental health. We show that this architecture improves overall classification results as compared to previously reported results on the same data. Benefitting from the attention mechanism, it can also efficiently select text elements crucial for classification decisions, which can also be used for in-depth analysis."
Harnessing Reddit to Understand the Written-Communication Challenges Experienced by Individuals With Mental Health Disorders: Analysis of Texts From Mental Health Communities,"Albert Park, Mike Conway",Journal of Medical Internet Research,"bipolar; bipolar and related disorders; bipolar disorder; communications media; community networks; consumer health information; depression; depressive disorder; depressive disorder, major; informatics; information science; mental health; psychosocial support system; schizophrenia; schizophrenia spectrum and other psychotic disorders; schizotypal personality disorder; self-help groups; social support.","Mental disorders such as depression, bipolar disorder, and schizophrenia are common, incapacitating, and have the potential to be fatal. Despite the prevalence and gravity of mental disorders, our knowledge concerning everyday challenges associated with them is relatively limited. One of the most studied deficits related to everyday challenges is language impairment, yet we do not know how mental disorders can impact common forms of written communication, for example, social media. The aims of this study were to investigate written communication challenges manifest in online mental health communities focusing on depression, bipolar disorder, and schizophrenia, as well as the impact of participating in these online mental health communities on written communication. As the control, we selected three online health communities focusing on positive emotion, exercising, and weight management. We examined lexical diversity and readability, both important features for measuring the quality of writing. We used four well-established readability metrics that consider word frequencies and syntactic complexity to measure writers' written communication ability. We then measured the lexical diversity by calculating the percentage of unique words in posts. To compare lexical diversity and readability among communities, we first applied pairwise independent sample t tests, followed by P value adjustments using the prespecified Hommel procedure to adjust for multiple comparison. To measure the changes, we applied linear least squares regression to the readability and lexical diversity scores against the interaction sequence for each member, followed by pairwise independent sample t tests and P value adjustments. Given the large sample of members, we also report effect sizes and 95% CIs for the pairwise comparisons. On average, members of depression, bipolar disorder, and schizophrenia communities showed indications of difficulty expressing their ideas compared with three other online health communities. Our results also suggest that participating in these platforms has the potential to improve members' written communication. For example, members of all three mental health communities showed statistically significant improvement in both lexical diversity and readability compared with members of the OHC focusing on positive emotion. We provide new insights into the written communication challenges faced by individuals suffering from depression, bipolar disorder, and schizophrenia. A comparison with three other online health communities suggests that written communication in mental health communities is significantly more difficult to read, while also consisting of a significantly less diverse lexicon. We contribute practical suggestions for utilizing our findings in Web-based communication settings to enhance members' communicative experience. We consider these findings to be an important step toward understanding and addressing everyday written communication challenges among individuals suffering from mental disorders."
Modelling Context with User Embeddings for Sarcasm Detection in Social Media,"Silvio Amir, Byron C. Wallace, Hao Lyu,Paula Carvalho, Mário J. Silva",ACL,,"We introduce a deep neural network for automated sarcasm detection. Recent work has emphasized the need for models to capitalize on contextual features, beyond lexical and syntactic cues present in utterances. For example, different speakers will tend to employ sarcasm regarding different subjects and, thus, sarcasm detection models ought to encode such speaker information. Current methods have achieved this by way of laborious feature engineering. By contrast, we propose to automatically learn and then exploit user embeddings, to be used in concert with lexical signals to recognize sarcasm. Our approach does not require elaborate feature engineering (and concomitant data scraping); fitting user embeddings requires only the text from their previous posts. The experimental results show that the our model outperforms a state-of-the-art approach leveraging an extensive set of carefully crafted features."
Detecting depression and mental illness on social media: an integrative review,"Sharath Chandra Guntuku, David BryceYaden, Margaret L. Kern, Lyle H. Ungar,Johannes C. Eichstaedt",Current Opinion in Behavioral Sciences,,"Although rates of diagnosing mental illness have improved over the past few decades, many cases remain undetected. Symptoms associated with mental illness are observable on Twitter, Facebook, and web forums, and automated methods are increasingly able to detect depression and other mental illnesses. In this paper, recent studies that aimed to predict mental illness using social media are reviewed. Mentally ill users have been identified using screening surveys, their public sharing of a diagnosis on Twitter, or by their membership in an online forum, and they were distinguishable from control users by patterns in their language and online activity. Automated detection methods may help to identify depressed or otherwise at-risk individuals through the large-scale passive monitoring of social media, and in the future may complement existing screening procedures."
Identifying Chinese Microblog Users With High Suicide Probability Using Internet-Based Profile and Linguistic Features: Classification Model,"Li Guan, Bibo Hao, Qijin Cheng, Paul SiuFai Yip, Tingshao Zhu",JMIR Mental Health,"suicide probability, microblog, Chinese, classification model","Traditional offline assessment of suicide probability is time consuming and difficult in convincing at-risk individuals to participate. Identifying individuals with high suicide probability through online social media has an advantage in its efficiency and potential to reach out to hidden individuals, yet little research has been focused on this specific field. The objective of this study was to apply two classification models, Simple Logistic Regression (SLR) and Random Forest (RF), to examine the feasibility and effectiveness of identifying high suicide possibility microblog users in China through profile and linguistic features extracted from Internet-based data. There were nine hundred and nine Chinese microblog users that completed an Internet survey, and those scoring one SD above the mean of the total Suicide Probability Scale (SPS) score, as well as one SD above the mean in each of the four subscale scores in the participant sample were labeled as high-risk individuals, respectively. Profile and linguistic features were fed into two machine learning algorithms (SLR and RF) to train the model that aims to identify high-risk individuals in general suicide probability and in its four dimensions. Models were trained and then tested by 5-fold cross validation; in which both training set and test set were generated under the stratified random sampling rule from the whole sample. There were three classic performance metrics (Precision, Recall, F1 measure) and a specifically defined metric “Screening Efficiency” that were adopted to evaluate model effectiveness. Classification performance was generally matched between SLR and RF. Given the best performance of the classification models, we were able to retrieve over 70% of the labeled high-risk individuals in overall suicide probability as well as in the four dimensions. Screening Efficiency of most models varied from 1/4 to 1/2. Precision of the models was generally below 30%. Individuals in China with high suicide probability are recognizable by profile and text-based information from microblogs. Although there is still much space to improve the performance of classification models in the future, this study may shed light on preliminary screening of risky individuals via machine learning algorithms, which can work side-by-side with expert scrutiny to increase efficiency in large-scale-surveillance of suicide probability from online social media."
A Collaborative Approach to Identifying Social Media Markers of Schizophrenia by Employing Machine Learning and Clinical Appraisals,"Michael L. Birnbaum, Sindhu KiranmaiErnala, Asra F. Rizvi, Munmun DeChoudhury, John M. Kane",Journal of Medical Internet Research,Twitter; linguistic analysis; machine learning; online social networks; psychotic disorders; schizophrenia,"inguistic analysis of publicly available Twitter feeds have achieved success in differentiating individuals who self-disclose online as having schizophrenia from healthy controls. To date, limited efforts have included expert input to evaluate the authenticity of diagnostic self-disclosures. This study aims to move from noisy self-reports of schizophrenia on social media to more accurate identification of diagnoses by exploring a human-machine partnered approach, wherein computational linguistic analysis of shared content is combined with clinical appraisals. Twitter timeline data, extracted from 671 users with self-disclosed diagnoses of schizophrenia, was appraised for authenticity by expert clinicians. Data from disclosures deemed true were used to build a classifier aiming to distinguish users with schizophrenia from healthy controls. Results from the classifier were compared to expert appraisals on new, unseen Twitter users. Significant linguistic differences were identified in the schizophrenia group including greater use of interpersonal pronouns (P<.001), decreased emphasis on friendship (P<.001), and greater emphasis on biological processes (P<.001). The resulting classifier distinguished users with disclosures of schizophrenia deemed genuine from control users with a mean accuracy of 88% using linguistic data alone. Compared to clinicians on new, unseen users, the classifier's precision, recall, and accuracy measures were 0.27, 0.77, and 0.59, respectively. These data reinforce the need for ongoing collaborations integrating expertise from multiple fields to strengthen our ability to accurately identify and effectively engage individuals with mental illness online. These collaborations are crucial to overcome some of mental illnesses' biggest challenges by using digital technology."
Discovery of Informal Topics from Post Traumatic Stress Disorder Forums,"Reilly Grant, David Kucher, Ana M. Leon,Jonathan Gemmell, Daniela Raicu",IEEE,"Post Traumatic Stress Disorder (PTSD), Topic Modeling, Word Embeddings, Association Rules","Post Traumatic Stress Disorder (PTSD) is a public health problem afflicting millions of people each year. It is especially prominent among military veterans. Understanding the language, attitudes, and topics associated with PTSD presents an important and challenging problem. Based on their expertise, mental health professionals have constructed a formal definition of PTSD. However, even the most assiduous mental health professionals can care for only a small fraction of those suffering from PTSD, limiting their perspective of the disorder. As social networking sites have grown in acceptance, users have begun to express personal thoughts and feelings, such as those related to PTSD. This wealth of content can be viewed as an enormous collective description of PTSD and its related issues. We automatically extract informal latent topics from thousands of social media posts in which users describe their experience with PTSD and compare these topics to the formal description generated by mental health professionals. We then explore the pattern and associations of these topics. Our informal topic discovery evaluation reveals that we can successfully identify meaningful topics in PTSD social media related data. When comparing our topics to the criteria included in the Diagnostic and Statistical Manual of Mental Disorders (DSM), we found that we were able to automatically reproduce many of the criteria. We also discovered new topics which were not mentioned in the DSM, but were prevalent across the collaborative narrative of thousands of user's experience with PTSD."
Statistical analysis of the social network and discussion threads in slashdot,"Vicenç Gómez, Andreas Kaltenbrunner,Vicente López",ACM,"social networks, online communities, bulletin board, weblogs, h-index, log-normal, power-law, thread, radial tree","We analyze the social network emerging from the user comment activity on the website Slashdot. The network presents common features of traditional social networks such as a giant component, small average path length and high clustering, but differs from them showing moderate reciprocity and neutral assortativity by degree. Using Kolmogorov-Smirnov statistical tests, we show that the degree distributions are better explained by log-normal instead of power-law distributions. We also study the structure of discussion threads using an intuitive radial tree representation. Threads show strong heterogeneity and self-similarity throughout the different nesting levels of a conversation. We use these results to propose a simple measure to evaluate the degree of controversy provoked by a post."
Shepherding and Censorship: Discourse Management in the Tea Party Patriots Facebook Group,"Christopher M. Mascaro, Alison N.Novak, Sean P. Goggins",IEEE,,"Political groups on social networking sites enable a new type of collaborative, political discourse among citizens. In this study, we show how political discourse in social media is distinct from prior studies of political groups on the Internet. Specifically, we use network analysis in combination with communication theory to examine conversational social networks that emerge from direct addressals between participants in 10 discussions on the Tea Party Patriots Face book page associated with the shooting of US Representative Gabrielle Giffords. Our findings identify singling out of other participants as a key tactic for clarifying and questioning inaccurate information, apply social network analysis to identify different behaviors between networks and describe the elimination of dissent from the Tea Party Patriots Face book page over time. Important questions of how users experience political discourse online, including the impact of the traceless removal of discourse by group administrators are framed in the conclusion."
Homogeneous Temporal Activity Patterns in a Large Online Communication Space,"Andreas Kaltenbrunner, Vicenç Gómez,Ayman Moghnieh, Rodrigo Meza, JosepBlat, Vicente López",arXiv,"Social interaction, information diffusion, log-normal activity, heavy tails, Slashdot","The many-to-many social communication activity on the popular technology-news website Slashdot has been studied. We have concentrated on the dynamics of message production without considering semantic relations and have found regular temporal patterns in the reaction time of the community to a news-post as well as in single user behavior. The statistics of these activities follow log-normal distributions. Daily and weekly oscillatory cycles, which cause slight variations of this simple behavior, are identified. A superposition of two log-normal distributions can account for these variations. The findings are remarkable since the distribution of the number of comments per users, which is also analyzed, indicates a great amount of heterogeneity in the community. The reader may find surprising that only a few parameters allow a detailed description, or even prediction, of social many-to-many information exchange in this kind of popular public spaces."
Brewing up citizen engagement: the coffee party on facebook,"Christopher M. Mascaro, Sean P.Goggins",ACM,"Issue entrepreneurship, deliberative discourse, democratic discourse, politics, social networking, group formation","With this study we seek to provide an understanding of the discourse and agenda setting practices of an online issue based political group, ""Join the Coffee Party Movement"" (JCPM) in the United States. The stated goals of JCPM are to establish a place for individuals who identify themselves as disenfranchised to discuss and take action on issues of social and economic policy in the US. JCPM is one example of hundreds of issue-based organizations emerging on Facebook worldwide. Since its inception in January 2010, over 344,000 Facebook members have become followers of the JCPM page. Our analysis of the text of the discourse and the social networks, which emerge on the JCPM page, show three surprising results. First, in contrast to prior studies, significant deliberative discourse among members emerges in this open, public space without prompting. Second, the discourse practices and structure that emerge on the JCPM Facebook page show two types of leadership: Centralized, organizational leadership, and decentralized leadership from participants. Third, we identify two structural characteristics of this virtual political organization using social network analysis of trace data: a) Organizational leaders are not central to discussions of controversial topics; b) Advocacy and dissent behavior in the discussions are reflected in the social network structure. Our findings have implications for the practices and technology designs used to engage citizens through social and participatory media."
Description and Prediction of Slashdot Activity,"Andreas Kaltenbrunner, Vicenç Gómez,Vicente López",IEEE,,"We perform a statistical analysis of user's reaction time to a new discussion thread in online debates on the popular news site Slashdot. First, we show with Kolmogorov-Smirnov tests that a mixture of two log-normal distributions combined with the circadian rhythm of the community is able to explain with surprising accuracy the reaction time of comments within a discussion thread. Second, this characterization allows to predict intermediate and long-term user behavior with acceptable precision. The prediction method is based on activity-prototypes, which consist of a mixture of two log-normal distributions, and represent the average activity in a particular region of the circadian cycle."
Analyzing and ranking the Spanish speaking MySpace community by their contributions in forums,"Andreas Kaltenbrunner, Erika Bondia,Rafael Enrique Banchs",IW3C2,"social network, forum, post, online demography, h-index","This study analyzes the MySpace forums in Spanish language, which permits to extract otherwise restricted demographic data from the social network and leads to a detailed description of the Spanish speaking community in MySpace. Important differences in age and gender structures are found for users with different countries of origin. The distribution of activity among different threads and users is very heterogeneous and follows heavy tailed distributions. We furthermore propose two variants of the h-index which allow the ranking of users and threads by their importance in the forums."
The Daily Brew: The Structural Evolution of the Coffee Party on Facebook during the 2010 United States Midterm Election Season,"Christopher M. Mascaro, Alison N.Novak, Sean P. Goggins",Journal of Information Technology & Politics,"Coffee Party, Facebook, network analysis, political discourse, social networking sites","The activity of the Facebook Group, “Join the Coffee Party Movement” (Coffee Party), is studied during a seven-month period leading up to and following the 2010 United States Midterm election. During this time period, the Coffee Party Facebook Group Administrator account posted 872 parent posts, which received 152,762 comments from participants. We examine the resulting electronic trace data utilizing a method for analyzing weighted social networks of discourse (Mascaro & Goggins, 2011). Our findings explore the network centralization and total post activity across three units of analysis: (a) time, (b) parent post category, and (c) specific parent posts. We report three key findings. First, the structure, centralization, and leadership within the network differ in four key time periods: the time preceding the midterm election, the week of the midterm election, the time following the midterm election, and the time period when the new Congress was sworn in. Second, the Coffee Party Administrators act as agenda-setters with the parent posts, but are also significant contributors to the discourse. Third, participants in the discourse alter their roles depending on the specific parent post and category. Our findings have implications for issue groups and candidates who utilize social media tools to mobilize support and engage with supporters, and also provide a methodological contribution for computational social scientists who examine these groups."
Off the wall political discourse: Facebook use in the 2008 U.S. presidential election,"Scott P. Robertson, Ravikiran Vatrapu,Richard Medina",Information Polity,"Digital government, social networking, e-participation, e-citizenship","Both candidates and voters have increased their use of the Internet for political campaigns. Candidates have adopted many internet tools, including social networking websites, for the purposes of communicating with constituents and voters, collecting donations, fostering community, and organizing events. On the other side, voters have adopted Internet tools such as blogs and social networking sites to relate to candidates, engage in political dialogue, pursue activist causes, and share information. In this paper we examine two years of posts on the Facebook walls of the three major contenders for the U.S. Presidency in 2008: Barack Obama, Hillary Clinton, and John McCain. We analyze participation patterns of usage along dimensions of breadth and frequency, and interpret them in terms of the concept of the “public sphere”."
When the Wikipedians Talk: Network and Tree Structure of Wikipedia Discussion Pages,"David Laniado, Riccardo Tasso, YanaVolkovich, Andreas Kaltenbrunner",AAAI,,"Talk pages play a fundamental role in Wikipedia as the place for discussion and communication. In this work we use the comments on these pages to extract and study three networks, corresponding to different kinds of interactions. We find evidence of a specific assortativity profile which differentiates article discussions from personal conversations. An analysis of the tree structure of the article talk pages allows to capture patterns of interaction, and reveals structural differences among the discussions about articles from different semantic areas."
Collaborative Information Seeking in an Online Political Group Environment,"Christopher M. Mascaro, Sp Goggins",ACM,"Information sharing, politics, social networking, group identity,group formation, collaborative information seeking, collaborativeinformation behavior","In this paper, we present a framework for examination of groupformation and information exchange on a Facebook Group, “Jointhe Coffee Party Movement”, that was created in response to theTea Party Movement in the US. The stated goals of “Join theCoffee Party Movement” are to establish a place for otherwisedisenfranchised individuals to share information and engage in productive dialogue and to develop solutions for problems facingthe USA. Similar movements exist in other countries and socialnetworking technology has been utilized to further the ideologyand mobilize supporters of various national and internationalcauses. Since its inception in January 2010, over 300,000Facebook members have become followers of the Coffee Party.The Group’s page has over 155,000 discussion comments toofficial postings. Preliminary analysis of this dialogue suggeststwo intertwined avenues for investigation. First, it is clear that theCoffee Party Facebook page represents one virtual group throughwhich many different virtual subgroups emerge from onlinediscourse. Second, the groups that are emerging do so as aconsequence of having a shared information need, which isfulfilled to some extent through participation in this group. Thesegroups exhibit a certain type of completely online collaborativeinformation behavior that we think warrants investigation frommultiple perspectives. How members of online groups like thesecollaboratively seek information is of importance for thisworkshop; but we believe our broader perspective will be of interest"
Detecting platform effects in online discussions,"Pablo Aragón, Vicenç Gómez, AndreasKaltenbrunner",Policy & Internet,"platform effects, online deliberation, public spheres, online discussion, discussion threads","Online discussions are the essence of many social platforms on the Internet. These platforms are receiving increasing interest because of their potential to become deliberative spaces. Many studies have proposed approaches to measure online deliberation and to evaluate which are the best design principles for deliberative online platforms. However, little research has focused on how deliberation in online platforms is affected by the arrival of events like the emergence of new topics or the modification of platform features. In this article we present a methodology to detect events that affect online deliberation in online discussions. Our results on Menéame, the most popular Spanish social news site, show that a change in how discussions are shown to the user, from a linear to a hierarchical conversation view, significantly enhanced deliberation. In particular we observe that this type of interface induced argumentative structures of online discussion."
A likelihood-based framework for the analysis of discussion threads,"Vicenç Gómez, Hilbert J. Kappen, NellyLitvak, Andreas Kaltenbrunner",arXiv,"discussion threads, information cascades, preferential attachment, novelty, maximum likelihood, Slashdot, Wikipedia","Online discussion threads are conversational cascades in the form of posted messages that can be generally found in social systems that comprise many-to-many interaction such as blogs, news aggregators or bulletin board systems. We propose a framework based on generative models of growing trees to analyse the structure and evolution of discussion threads. We consider the growth of a discussion to be determined by an interplay between popularity, novelty and a trend (or bias) to reply to the thread originator. The relevance of these features is estimated using a full likelihood approach and allows to characterize the habits and communication patterns of a given platform and/or community."
Changes in Referents and Emotions over Time in Election-Related Social Networking Dialog,Scott P. Robertson,,,
The social life of social networks: Facebook linkage patterns in the 2008 U.S. presidential election,"Scott P. Robertson, Ravikiran Vatrapu,Richard Medina",ACM,"Digital government, social networking, e-participation, ecitizenship","This paper examines the linkage patterns of people who posted links on the Facebook “walls” of Barack Obama, Hillary Clinton, and John McCain over two years prior to the 2008 U.S. Presidential election. Linkage patterns indicate the destinations to which participants in these social networking dialogues wished to send other participants. We show a strong integration of the Web 2.0 and new media technologies of social networking, online video, and blogs. Outside of video content, users tended to direct others to groups and applications within the Facebook community, but this homophilous behavior was more common for infrequent posters. Ten internet domains accounted for 90% of all links, and the top ten contained a mixture of news, candidate, and blog sites. We offer a discussion of the Facebook candidate walls as a public sphere for political discourse and introduce some design concepts for visualizing and navigating the walls."
Social Media Discourse and Culture: A Proposal for Comparative Informatics Research,"Sp Goggins, Colin Mascaro",Drexel University ,,"Public discourse is rapidly evolving through the use of social media platforms including Facebook, Twitter and others. Though often discussed in terms like “social media”, or even more general terms like “web 2.0”, social media platforms are not homogeneous. The reflexive relationship between social media and culture will be different for each combination of culture and social media platform. The Comparative Informatics community focuses attention on the role of culture in ICT uptake and use. Comparative Informatics examines the need for governments to consider the diverse cultures they serve when developing ICTs for eGovernment (Robertson, 2010), reflects on the cultural biases embedded in current technology, including the keyboard (Nardi, Vatrapu, & Clemmensen, 2011) and questions web 2.0 visions of global collaboration and remixing (Hughes & Lang, 2006) unencumbered by cultural differences (Cervantes, Nardi, & Kow, 2010). Social media is one component of web 2.0 that affords many opportunities for Comparative Informatics research. One important contribution of Comparative Informatics research in the area of social media will be the development of a more thorough understanding of the relationship between culture and social media uptake and use. This proposal focuses on the reflexive construction of culture through discourse using social media."
Modeling the structure and evolution of discussion cascades,"Vicenç Gómez, Hilbert J. Kappen,Andreas Kaltenbrunner",arXiv,"discussion cascades, threads, conversations, preferential attachment, maximum likelihood, Slashdot, Wikipedia","We analyze the structure and evolution of discussion cascades in four popular websites: Slashdot, Barrapunto, Meneame and Wikipedia. Despite the big heterogeneities between these sites, a preferential attachment (PA) model with bias to the root can capture the temporal evolution of the observed trees and many of their statistical properties, namely, probability distributions of the branching factors (degrees), subtree sizes and certain correlations. The parameters of the model are learned efficiently using a novel maximum likelihood estimation scheme for PA and provide a figurative interpretation about the communication habits and the resulting discussion cascades on the four different websites."
Dynamics of message Interchange between stochastic Units in the contexts of human communication behaviour and spiking neurons,Andreas Kaltenbrunner,Universitat Pompeu Fabra,,"Quisiera agradecer a mi tutor de tesis, Vicente López, el haber confiado en mí cuando me presenté en su despacho hace cuatro a nos, diciéndole que quería hacer un doctorado sin saber ni dónde
me metía ni qué significaba hacer ciencia. Por darme esa oportunidad de crecimiento personal, profesional e intelectual que significa hacer un doctorado. No sólo ha estado siempre disponible para
compartir conmigo sus amplios conocimientos, sino que ha sabido transmitirme lo esencial de la ciencia: los mecanismos básicos para a la generación y presentación de nuevos conocimientos.
También quisiera agradecer a quienes han contribuido en la realización de este trabajo: Ayman Moghnieh, Rodrigo Meza, Josep Blat y sobre todo a Vicenç Gómez por un sinfín de discusiones y
por estar siempre disponible para ayudar en la solución de cualquier problema. Tampoco puedo olvidarme de quienes me han ayudado con sus comentarios a mejorar el trabajo presentado: Alberto Suárez, Serge Thill, Adan Garriga, Ernest Montbrió, Anders Ledberg, Alex Roxin y Gustavo Deco. Muchas gracias también a los organizadores de mi estancia en la University of Leicester: Ralph
Andrzejak y sobre todo a Rodrigo Quian Quiroga, por su cordial acogida. Gracias a mis compañeros de doctorado por compartir buenos y malos momentos y por acompañarme en una parte tan importante de mi vida. Y por último, aunque sin restarles por ello protagonismo, doy las gracias a mis padres y a mis hermanos Martin y Karin, y de manera muy especial a Nikolas por llenar mi vida con sus risas y a Yolanda por apoyarme siempre"
"YouTube and Facebook: Online Video ""Friends"" Social Networking","Scott P. Robertson, Ravi Vatrapu,Richard Medina",,,
Political dialog evolution in a social network,"Scott P. Robertson, Sara K. Douglas,Misa Maruyama, Lik-Wai Chen",ACM,"Digital government, social networking, e-participation, ecitizenship","User comments posted on the Facebook walls of the two major 2010 California gubernatorial candidates were analyzed for their trends over a 22-month time period leading up to the election. Changes in content reflected an early emphasis on community building, establishment of common identity, and enthusiasm building with considerable dialog directed toward the candidates themselves. Later comments reflected a more outward turn toward other participants. The two communities of interest did not behave in exactly the same ways through time. Designers seeking to create socio-technical environments for political and civic engagement must face the fact that users’ goals and activities change dynamically in response to the evolving characteristics of the group and external events affecting the group members. Implications for the design of “social affect” and “social intention” browsers are discussed."
Emergent Networks of Topical Discourse: A Comparative Framing and Social Network Analysis of the Coffee Party and Tea Party Patriots Groups on Facebook,"Christopher M. Mascaro, Alison N.Novak, Sean P. Goggins",Web 2.0 Technologies and Democratic Governance,"Social Network Analysis, Parent Post, Betweenness Centrality, Agenda Setting, Online Group","In this chapter, we examine and compare the activity in the two politically focused Facebook groups, “Join the Coffee Party Movement” and “Tea Party Patriots,” from the time period immediately preceding the 2010 mid-term elections through the week following the seating of the newly elected Congress (October 25, 2010–January 12, 2011). We incorporate social network analysis of electronic trace data coupled with a framing analysis of the topics posted by the group administrators (parent posts) to provide an understanding of the agenda setting practices of administrators and subsequent discourse from the participants that occur in these two groups. Through this analysis we identify three interesting findings. First, there are shared topics of discourse that are framed differently in the two groups."
"Algorithms and complex phenomena in networks: Neural ensembles, statistical, interference and online communities",Vicenç Gómez i Cerdà,Universitat Pompeu Fabra,,"Vull agrair especialment a Vicente López la seva confiança durant tots aquests anys i el ser una font inesgotable d’idees i inspiració. Malgrat ser una persona molt ocupada, sempre ha trobat temps per atendre els meus dubtes i aconsellar-me quan més ho he necessitat. Moltes gràcies també a Bert Kappen per donar-me l’oportunitat de treballar amb ell i per compartir amb mi els seus amplis coneixements. Agraeixo a tots els que d’una manera o altra han col·laborat en la realització d’aquesta tesi: a Andreas Kaltenbrunner, per les seves lliçons i per ser company i un gran amic. Gràcies a Alberto Suárez, Joris Mooij i a Bastian Wemmenhove, a Adan Garriga, Ayman Moghnieh, Rodrigo Meza i a Josep Blat. Gràcies també a Hector Geffner per ser referent en el meu curt recorregut docent i en molts aspectes de la meva recerca. Gràcies a Hector Palacios per la seva amistat, i a la resta de membres del grup d’Intel·ligència Artificial de la UPF. Agraeixo a Gustavo Deco haber-me aconsellat durant el primer període de tesi, a Ralph Andrzejak i Anders Ledberg els fructífers journal clubs setmanals. Gràcies a Dani Martí, Ernest Montbrió, i a la resta de membres del grup de Neurociència Computacional de la UPF. Vull agrair també a Misha Chertkov per la seva invitació a Santa Fe, i a la gent de Nijmegen per ser tant amables durant la meva estància. Finalment, seria un desagraït sino m’enrecordés d’aquells amb qui he compartit grans moments durant aquest anys: Pau Arumí, Òscar Civit, Ernic Meinhardt, Juan Cardelino, Lucas Vallejos, Stelios Kourakis, Gabriele Facciolo, Carles Castellví i Sergi Masip. Gràcies Laura, per haver estat al meu costat."
Challenges for the Facilitation of Political Discourse in Technologically-Mediated Environments,Christopher M. Mascaro,ACM,"Collective intelligence, deliberative discourse, politics, democracy, citizenry","In the following workshop paper we provide a brief overview of existing research on technologies that have been used to engage the citizenry in the electoral process in the United States. We trace the early use of USENET for political discourse through the recent reliance of political candidates on social networking technologies for mobilizing support and engaging with the public. We use this prior research to identify a series of challenges that campaigns and issue groups may face when utilizing technology to engage in public discourse. Although we focus on the political discourse in the United States, our research has broader applications for understanding political coordination and discourse throughout the world."
One-Sided Conversations: The 2012 Presidential Election on Twitter,"Christopher M. Mascaro, Denise E.Agosto, Sean P. Goggins",ACM,"Social Media, Politics, Technology, Twitter, Deliberative Discourse","Technology has been promoted as a way to facilitate interactions across disparate groups of people. Political discourse has been historically constrained by geographic proximity of participants. The introduction of the Internet and specifically social media has altered these geographic constraints and political discourse is now one of the most prevalent activities in social media. As more individuals begin to use technology for political activity, understanding how the technology is used becomes increasingly important. Previous research exploring political discourse on social media has focused on one discrete event or a narrow time period. This narrow focus limits the understanding of the complex election environment. This study takes a longitudinal approach to examine the use of conversational syntactical features in Twitter derived from a 53 million Twitter message corpus collected during the 2012 Presidential Election (August 20, 2012 – November 13, 2012). This study identifies that, although candidates and media are the most talked about and talked to, these interactions elicit no response. The lack of response is counter to many of the perceived benefits of social media. These findings have implications for understanding how the public uses social media to engage with political candidates and the possibilities for how technology could be altered to better facilitate these interactions."
From popularity prediction to ranking online news,"Alexandru-Florin Tatar, PanayotisAntoniadis, Marcelo Dias de Amorim,Serge Fdida",Social Network Analysis and Mining,,"News articles are an engaging type of online content that captures the attention of a significant amount of Internet users. They are particularly enjoyed by mobile users and massively spread through online social platforms. As a result, there is an increased interest in discovering the articles that will become popular among users. This objective falls under the broad scope of content popularity prediction and has direct implications in the development of new services for online advertisement and content distribution. In this paper, we address the problem of predicting the popularity of news articles based on user comments. We formulate the prediction task as a ranking problem, where the goal is not to infer the precise attention that a content will receive but to accurately rank articles based on their predicted popularity. Using data obtained from two important news sites in France and Netherlands, we analyze the ranking effectiveness of two prediction models. Our results indicate that popularity prediction methods are adequate solutions for this ranking task and could be considered as a valuable alternative for automatic online news ranking."
Leave a Reply: An Analysis of Weblog Comments,"Gilad Mishne, Natalie S. Glance",WWW,,"Access to weblogs, both through commercial services and in academic studies, is usually limited to the content of the weblog posts. This overlooks an important aspect distinguishing weblogs from other web pages: the ability of weblog readers to respond to posts directly, by posting comments. In this paper we present a large-scale study of weblog comments and their relation to the posts. Using a sizable corpus of comments, we estimate the overall volume of comments in the blogosphere; analyze the relation between the weblog popularity and commenting patterns in it; and measure the contribution of comment content to various aspects of weblog access."
Technologically Mediated Political Discourse During a Nationally Televised GOP Primary Debate,"Christopher M. Mascaro, Sean P.Goggins",Journal of Information Technology & Politics,"Debate, electoral politics, political discourse, social media, technology, Twitter","Social media creates a geographically independent commons that transforms citizen participation in political discourse. In our study, we examine 185,420 publicly available Twitter messages during a Republican primary debate in November 2011, hosted by CNN and viewed by over 3.5 million individuals in the United States. We identify how activity differs at various phases of a televised debate and who the subjects of this discourse are through analysis of how individuals use the syntactical features of Twitter such as at-mentions, at-replies, and URLs. Understanding how individuals engage with each other in an open forum has broad implications for understanding social media’s effect on civic engagement and information diffusion among elected officials, candidates, and citizens. Our findings suggest that a significant number of the syntactical features specific to Twitter are used to relay information, engage in discourse, and create new threads of discourse related to issues that are brought up during the debate. Although syntactical features signaling conversation are used, actual engagement is limited. "
"Political discourse on social networking sites: Sentiment, in-group/out-group orientation and rationality","Scott P. Robertson, Sara K. Douglas,Misa Maruyama, Bryan C. Semaan",Syracruse University,"Digital government, e-citizenship, e-participation, social networking, virtual public sphere","The news feeds of two U.S. politicians' Facebook sites were examined across 22 months leading up to an election in order to explore changes in social-network-mediated public political discourse over time. Changes over time were observed in who was being addressed and in the affective valence of comments. A complex flow of attention between in-group and out-group concerns was observed, with in-group comments dominant both in early and late phases. Also, positive comments decreased and negative comments increased over time. These phenomena, dubbed ""reflection-to-selection"" and ""converging sentiment"", were refined to explain the observed nonlinearities. The flow of rational versus affective comments in politicians' Facebook data across time was also explored. Comments reflecting cognition were more prevalent at all times than comments reflecting affect, but their distribution also varied in complex ways over time. Finally, the concept of potential public sphere in contrast to realized public sphere in virtual spaces is introduced."
Human Activity Pattern on Microblogging Interaction,"Bao Yuan-yuan, Xin Zhan-hong",IEEE,"Microblogging, Human Dynamics, time interval distribution, power law distribution","By analyzing the operational data of Sina microblogging, which is the most popular microblogging interactive platform of China, this paper studies the human activity pattern on microblogging interaction, especially analyzes the top fifteen individuals' behavioral characteristic chosen based on the quantity of their followers. The result shows that an individual's microblogging pattern has a bursty non-Poisson character, the time interval between consecutive blogs sent obeys power-law distribution, where index of this distribution is 1.4. The result provides a basis for further research on microblogging as an emerging mode of communication, and also provides strong evidence for human dynamics."
Effects of Group Categories on the Structure of Online Social Networks,"Stanley Laine, M. Easterbrook Steve",University of Kansas,,"Over the past few years there has been increasing research interests spent on online social networks. While some social networking sites such as Orkut, Facebook and Friendster are purely social, others such as YouTube, Flickr, and LiveJournal are highly content oriented while maintaining a social component too. The nature of the interaction between content and connections is fundamentally important not just from a social science perspective but also to answer how the relevant content and connections can be found more easily. YouTube more recently added the ability for users to form explicit groups, in which explicit category affiliation is noted too. YouTube is ripe for consideration of how content and contacts are related. We study YouTube groups in general not only in the context of categories but also study what motivates group membership in YouTube in the context of other observable group activities. We also investigate the role of users in groups, how groups evolve and the structure of these groups organized under a category change over time. Finally we find what form of linkage motivates new members to join these groups in YouTube."
From user comments to on-line conversations,"Chunyan Wang, Mao Ye, Bernardo A.Huberman",arXiv,"conversation dynamics, social networks","We present an analysis of user conversations in on-line social media and their evolution over time. We propose a dynamic model that accurately predicts the growth dynamics and structural properties of conversation threads. The model successfully reconciles the differing observations that have been reported in existing studies. By separating artificial factors from user behaviors, we show that there are actually underlying rules in common for on-line conversations in different social media websites. Results of our model are supported by empirical measurements throughout a number of different social media websites."
Predicting the volume of comments on online news stories,"Manos Tsagkias, Wouter Weerkamp,Maarten de Rijke",ACM,"Comment volume, prediction, feature engineering","On-line news agents provide commenting facilities for readers to express their views with regard to news stories. The number of user supplied comments on a news article may be indicative of its importance or impact. We report on exploratory work that predicts the comment volume of news articles prior to publication using five feature sets. We address the prediction task as a two stage classification task: a binary classification identifies articles with the potential to receive comments, and a second binary classification receives the output from the first step to label articles “low” or “high” comment volume. The results show solid performance for the former task, while performance degrades for the latter."
"News Comments: Exploring, Modeling, and Online Prediction","Manos Tsagkias, Wouter Weerkamp,Maarten de Rijke",Advances in Information Retrieval ,"Negative Binomial Distribution, News Article, News Story, Comment Volume, News Source ","Online news agents provide commenting facilities for their readers to express their opinions or sentiments with regards to news stories. The number of user supplied comments on a news article may be indicative of its importance, interestingness, or impact. We explore the news comments space, and compare the log-normal and the negative binomial distributions for modeling comments from various news agents. These estimated models can be used to normalize raw comment counts and enable comparison across different news sites. We also examine the feasibility of online prediction of the number of comments, based on the volume observed shortly after publication. We report on solid performance for predicting news comment volume in the long run, after short observation. This prediction can be useful for identifying news stories with the potential to “take off,” and can be used to support front page optimization for news sites."
Optimization in task-completion networks,"Luca Dall'Asta, Matteo Marsili, PaoloPin",arXiv,,"We discuss the collective behavior of a network of individuals that receive, process and forward to each other tasks. Given costs they store those tasks in buffers, choosing optimally the frequency at which to check and process the buffer. The individual optimizing strategy of each node determines the aggregate behavior of the network. We find that, under general assumptions, the whole system exhibits coexistence of equilibria and hysteresis."
"Debate, Division, and Diversity: Political Discourse Networks in USENET Newsgroups",J Kelly Smith,,,
Exploring Asynchronous Online Discussions through Hierarchical Visualisation,"Victor Pascual-Cid, AndreasKaltenbrunner",IEEE,,"We introduce a highly customizable social visualization system for exploring online discussions through visual representations of conversation threads. The tool provides users with an interface that allows the navigation and exploration through the often intricate structure of online discussions. Apart from being useful for readers and participants of these forums, the interactive capabilities of our system makes it appealing for social researchers interested in understanding the phenomena and intrinsic structure of online conversations. We also show a use case where we applied the tool to visualize discussions from Slashdot.org, showing its capabilities to represent new, in this case Slashdot specific, metrics. The visual representation of discussion threads has arisen as a complement for supporting investigation,as it helps to understand such large amount of information and contributes to the generation of new research ideas."
Who Wants to Deliberate - and Why?,"Michael Neblo, Kevin Esterling, RyanKennedy, David Lazer, Anand E. Sokhey",The American Political Science Association,,"Interest in deliberative theories of democracy has grown tremendously among political theorists, /'nterest political scientists, activists, and even government officials. Many scholars, however, are skeptical that it is a practically viable theory, even on its own terms. They argue (inter alia) that most people dislike politics and that deliberative initiatives would amount to a paternalistic imposition. Using two large national samples investigating people's hypothetical willingness to deliberate and their actual participation in response to a real invitation to deliberate with their member of Congress, we find that (1) willingness to deliberate in the United States is much more widespread than expected, and (2) it is precisely those people less likely to participate in traditional partisan politics who are most interested in deliberative participation. They are attracted to such participation as a partial alternative to ""politics as usual """
The Role of Media Discourse in Diplomatic Behavior,"Fatemeh Barzin, Ali Samiei",International Journal of Business and Social Science,"media, discourse making, anti-discourse making, diplomacy, western media, Persian media, BBC, VOA, Iran’s nuclear activities","This article aims to study the role of media discourse in diplomatic behavior concentrating on discourse making in the Persian media of BBC and Voice of America and anti-discourse making in IRIB. The main problem for the media discourse here is nuclear activities in Iran. Using Van Leeuwen and Van Dijk’s theories, this research has compared the approaches used in both eastern and western media as well as BBC and VOA"
Online Video “Friends” Social Networking: Overlapping Online Public Spheres in the 2008 U.S. Presidential Election,"Scott P. Robertson, Ravi Vatrapu,Richard Medina",Journal of Information Technology & Politics ,"E-participation, Internet and politics, online video, social networking","This article examines the links to YouTube from the Facebook “walls” of the three major candidates in the 2008 U.S. Presidential election. User-generated linkage patterns show how participants in these politically related social networking dialogs used online video to make their points. We show how different types of individuals inhabit these overlapping public spheres and how they provide structure and interpretive information for others. Civic life is becoming more sociotechnical, and will therefore involve engagements with ideas as they are constructed by others out of disparate information sources and their interlinkages."
The Architecture of Complexity From network structure to human dynamics,Albert-László Barabási,IEEE,,"We are surrounded by complex systems, from cells made of thousands of molecules to society, a collection of billions of interacting individuals. These systems display signatures of order and self-organization. Understanding and quantifying this complexity is a grand challenge for science. Kinetic theory, developed at the end of the 19th century, shows that the measurable properties of gases, from pressure to temperature, can be reduced to the random motion of atoms and molecules. In the 1960s and 1970s, researchers developed systematic approaches to quantifying the transition from disorder to order in material systems such as magnets and liquids. Chaos theory dominated the quest to understand complex behavior in the 1980s with the message that unpredictable behavior can emerge from the nonlinear interactions of a few components. The 1990s was the decade of fractals, quantifying the geometry of patterns emerging in self-organized systems, from leaves to snowflakes."
Understanding the human-bus interaction patterns based on IC card data,"Zhang Na-n, Li Hong-min, Lu Min, KeMingmin",IEEE,IC card data; human dynamics; power-law distribution; time granularity,"The study of power-law scaling characteristics of real-life networks, which deviates from the Poisson process, has gained the focus from scholars. Most researches put the emphasis on the mobility patterns of passengers in a public transport network, but ignore the work patterns between the bus and passengers, which also plays an important role in urban planning, traffic forecasting and the spread of biological and mobile viruses. In this paper, we take the IC card payment behavior on a bus as the empirical object. By applying logarithmic binning to the construction of distribution plots, we found that the statistical variables display a power-law distribution at both the micro and macro levels, and the exponent of them are 2.36 and 2.8 when the time granularity is one minute. Further investigations suggest that the distribution of the frequency of the inter-event time present the same characteristic at both the micro and macro levels when the time granularity is one second. However, the distributions at the same level differ from each other when the time granularity changes. There must be some reasons result in the differences."
Mining phenotypic keywords from a large collection of clinical narratives,"Cosmin Adrian Bejan, Robertson Nash,Erica A. Bowton, Kevin Boland Johnson,Joshua C. Denny",,,
Detecting Earlier Indicators of Homelessness in the Free Text of Medical Records,"Andrew Redd, Marjorie Carter, GuyDivita, Shuying Shen, Miland N. Palmer,Matthew H. Samore, Adi V. Gundlapalli",Studies in Health Technology and Informatics,,"Early warning indicators to identify US Veterans at risk of homelessness are currently only inferred from administrative data. References to indicators of risk or instances of homelessness in the free text of medical notes written by Department of Veterans Affairs (VA) providers may precede formal identification of Veterans as being homeless. This represents a potentially untapped resource for early identification. Using natural language processing (NLP), we investigated the idea that concepts related to homelessness written in the free text of the medical record precede the identification of homelessness by administrative data. We found that homeless Veterans were much higher utilizers of VA resources producing approximately 12 times as many documents as non-homeless Veterans. NLP detected mentions of either direct or indirect evidence of homelessness in a significant portion of Veterans earlier than structured data."
The Feasibility of Using Large-Scale Text Mining to Detect Adverse Childhood Experiences in a VA-Treated Population.,"Kenric W. Hammond, Alon Y. Ben-Ari,Ryan J Laundry, Edward J Boyko,Matthew Samore",Journal of Traumatic Stress,,"Free text in electronic health records resists large-scale analysis. Text records facts of interest not found in encoded data, and text mining enables their retrieval and quantification. The U.S. Department of Veterans Affairs (VA) clinical data repository affords an opportunity to apply text-mining methodology to study clinical questions in large populations. To assess the feasibility of text mining, investigation of the relationship between exposure to adverse childhood experiences (ACEs) and recorded diagnoses was conducted among all VA-treated Gulf war veterans, utilizing all progress notes recorded from 2000-2011. Text processing extracted ACE exposures recorded among 44.7 million clinical notes belonging to 243,973 veterans. The relationship of ACE exposure to adult illnesses was analyzed using logistic regression. Bias considerations were assessed. ACE score was strongly associated with suicide attempts and serious mental disorders (ORs = 1.84 to 1.97), and less so with behaviorally mediated and somatic conditions (ORs = 1.02 to 1.36) per unit. Bias adjustments did not remove persistent associations between ACE score and most illnesses. Text mining to detect ACE exposure in a large population was feasible. Analysis of the relationship between ACE score and adult health conditions yielded patterns of association consistent with prior research."
Open-Source Search Engines in the Cloud,Khaled Nagi,"Knowledge Discovery, Knowledge Engineering and Knowledge Management ","Full-text searching, Indexing, Distributed ecosystems, NoSQL, Cloud 
","The key to the success of the analysis of petabytes of textual data available at our fingertips is to do it in the cloud. Today, several extensions exist that bring Lucene, the open-source de facto standard of textual search engine libraries, to the cloud. These extensions come in three main directions: implementing scalable distribution of the indices over the file system, storing them in NoSQL databases, and porting them to inherently distributed ecosystems. In this work, we evaluate the existing efforts in terms of distribution, high availability, fault tolerance, manageability, and high performance. We are committed to using common open-source technology only. So, we restrict our evaluation to publicly available open-source libraries and eventually fix their bugs. For each system under investigation, we build a benchmarking system by indexing the whole Wikipedia content and submitting hundreds of simultaneous search requests. By measuring the performance of both indexing and searching operations, we report of the most favorable constellation of open-source libraries that can be installed in the cloud."
Mining 100 million notes to find homelessness and adverse childhood experiences: 2 case studies of rare and severe social determinants of health in electronic health records,"Cosmin Adrian Bejan, John Angiolillo,Douglas Conway, Robertson Nash,Jana Shirey-Rice, Loren Lipworth-Elliot,Robert Michael Cronin, Jill M. Pulley,Sunil Kripalani, Shari L. Barkin, Kevin B.Johnson, Joshua C. Denny",,,"Understanding how to identify the social determinants of health from electronic health records (EHRs) could provide important insights to understand health or disease outcomes. We developed a methodology to capture 2 rare and severe social determinants of health, homelessness and adverse childhood experiences (ACEs), from a large EHR repository.We first constructed lexicons to capture homelessness and ACE phenotypic profiles. We employed word2vec and lexical associations to mine homelessness-related words. Next, using relevance feedback, we refined the 2 profiles with iterative searches over 100 million notes from the Vanderbilt EHR. Seven assessors manually reviewed the top-ranked results of 2544 patient visits relevant for homelessness and 1000 patients relevant for ACE. word2vec yielded better performance (area under the precision-recall curve [AUPRC] of 0.94) than lexical associations (AUPRC = 0.83) for extracting homelessness-related words. A comparative study of searches for the 2 phenotypes revealed a higher performance achieved for homelessness (AUPRC = 0.95) than ACE (AUPRC = 0.79). A temporal analysis of the homeless population showed that the majority experienced chronic homelessness. Most ACE patients suffered sexual (70%) and/or physical (50.6%) abuse, with the top-ranked abuser keywords being ""father"" (21.8%) and ""mother"" (15.4%). Top prevalent associated conditions for homeless patients were lack of housing (62.8%) and tobacco use disorder (61.5%), while for ACE patients it was mental disorders (36.6%-47.6%). We provide an efficient solution for mining homelessness and ACE information from EHRs, which can facilitate large clinical and genetic studies of these social determinants of health."
Application of a Hybrid Text Mining Approach to the Study of Suicidal Behavior in a Large Population,"Kenric W. Hammond, Ryan Laundry",JAMIA,EHR; adverse childhood experiences; homelessness; social determinants of health; text mining,
Validating a strategy for psychosocial phenotyping using a large corpus of clinical text.,"Adi V. Gundlapalli, Andrew Redd,Marjorie Carter, Guy Divita, ShuyingShen, Miland N. Palmer, Matthew H.Samore",JAMIA,clinical informatics; high through-put; natural language processing; patient phenotype; psychosocial concepts,"To develop algorithms to improve efficiency of patient phenotyping using natural language processing (NLP) on text data. Of a large number of note titles available in our database, we sought to determine those with highest yield and precision for psychosocial concepts. From a database of over 1 billion documents from US Department of Veterans Affairs medical facilities, a random sample of 1500 documents from each of 218 enterprise note titles were chosen. Psychosocial concepts were extracted using a UIMA-AS-based NLP pipeline (v3NLP), using a lexicon of relevant concepts with negation and template format annotators. Human reviewers evaluated a subset of documents for false positives and sensitivity. High-yield documents were identified by hit rate and precision. Reasons for false positivity were characterized. A total of 58 707 psychosocial concepts were identified from 316 355 documents for an overall hit rate of 0.2 concepts per document (median 0.1, range 1.6-0). Of 6031 concepts reviewed from a high-yield set of note titles, the overall precision for all concept categories was 80%, with variability among note titles and concept categories. Reasons for false positivity included templating, negation, context, and alternate meaning of words. The sensitivity of the NLP system was noted to be 49% (95% CI 43% to 55%). Phenotyping using NLP need not involve the entire document corpus. Our methods offer a generalizable strategy for scaling NLP pipelines to large free text corpora with complex linguistic annotations in attempts to identify patients of a certain phenotype."
Improving identification of fall-related injuries in ambulatory care using statistical text mining.,"Stephen L Luther, James A. McCart,Donald J. Berndt, Bridget Hahm, DezonFinch, Jay Jarman, Philip Foulis,William Lapcevic, Robert R. Campbell,Ronald I Shorr, Keryl Motta Valencia,Gail Powell-Cope",AMerican Public Health Association ,prevention; suicide; veterans,"We determined whether statistical text mining (STM) can identify fall-related injuries in electronic health record (EHR) documents and the impact on STM models of training on documents from a single or multiple facilities. We obtained fiscal year 2007 records for Veterans Health Administration (VHA) ambulatory care clinics in the southeastern United States and Puerto Rico, resulting in a total of 26 010 documents for 1652 veterans treated for fall-related injury and 1341 matched controls. We used the results of an STM model to predict fall-related injuries at the visit and patient levels and compared them with a reference standard based on chart review. STM models based on training data from a single facility resulted in accuracy of 87.5% and 87.1%, F-measure of 87.0% and 90.9%, sensitivity of 92.1% and 94.1%, and specificity of 83.6% and 77.8% at the visit and patient levels, respectively. Results from training data from multiple facilities were almost identical. STM has the potential to improve identification of fall-related injuries in the VHA, providing a model for wider application in the evolving national EHR system."
VA Suicide Prevention Applications Network,"Claire A. Hoffmire, Brady Stephens,Sybil W Morley, Caitlin Thompson,Janet E Kemp, Robert M Bossarte",Public Health Reports ,"veterans, suicide, prevention","The US Department of Veterans Affairs' Suicide Prevention Applications Network (SPAN) is a national system for suicide event tracking and case management. The objective of this study was to assess data on suicide attempts among people using Veterans Health Administration (VHA) services. We assessed the degree of data overlap on suicide attempters reported in SPAN and the VHA's medical records from October 1, 2010, to September 30, 2014-overall, by year, and by region. Data on suicide attempters in the VHA's medical records consisted of diagnoses documented with E95 codes from the International Classification of Diseases, Ninth Revision. Of 50 518 VHA patients who attempted suicide during the 4-year study period, data on fewer than half (41%) were reported in both SPAN and the medical records; nearly 65% of patients whose suicide attempt was recorded in SPAN had no data on attempted suicide in the VHA's medical records. Evaluation of administrative data suggests that use of SPAN substantially increases the collection of data on suicide attempters as compared with the use of medical records alone, but neither SPAN nor the VHA's medical records identify all suicide attempters. Further research is needed to better understand the strengths and limitations of both systems and how to best combine information across systems."
Large Scale Clinical Text Processing and Process Optimization,"Scott L. DuVall, Patrick R. Alba, Olga V.Patterson",,,
First Day of Summer,Leah A. Zuidema,Pro Rege,,"Chairs and desks line the college halls, tipped bottoms up like a tornado drill in progress. T-shirted 19 year olds wash windows and walls energetically: it is early in their custodial tenure. The heat was turned off last Friday (by calendar’s decree), and now we faculty burrow in to damp, chilly offices. We are thankful, we say, for time to read to think to write. We imagine ourselves such hermits, yet whispers about campus politics bring us popping out like prairie dogs sniffing the wind. Not till later— full of summer sun— will we bask in the warmth of books, time, friendship."
Anonymizing Temporal Phrases in Natural Language Text to be Posted on Social Networking Services,"Hoang-Quoc Nguyen-Son, Anh-TuHoang, Minh-Triet Tran, HiroshiYoshiura, Noboru Sonehara, IsaoEchizen",Digital-forensics and Watermarking,"Anonymization, Temporal phrase deletion, Social networking service","Time-related information in text posted on-line is one type of personal information targeted by attackers, one reason that sharing information online can be risky. Therefore, time information should be anonymized before it is posted on social networking services. One approach to anonymizing information is to replace sensitive phrases with anonymous phrases, but attackers can usually spot such anonymization due to its unnaturalness. Another approach is to detect temporal passages in the text, but removal of these passages can make the meaning of the text unnatural. We have developed an algorithm that can be used to anonymize time-related personal information by removing the temporal passages when doing so will not change the natural meaning of the message. The temporal phrases are detected by using machine-learned patterns, which are represented by a subtree of the sentence parsing tree. The temporal phrases in the parsing tree are distinguished from other parts of the tree by using temporal taggers integrated into the algorithm. In an experiment with 4008 sentences posted on a social network, 84.53 % of them were anonymized without changing their intended meaning. This is significantly better than the 72.88 % rate of the best previous temporal phrase detection algorithm. Of the learned patterns, the top ten most common ones were used to detect 87.78 % the temporal phrases. This means that only some of the most common patterns can be used to the anonymize temporal phrases in most messages to be posted on an SNS. The algorithm works well not only for temporal phrases in text posted on social networks but also for other types of phrases (such as location and objective ones), other areas (religion, politics, military, etc.), and other languages."
Large Multivariate Time Series Forecasting: Survey on Methods and Scalability,"Youssef Hmamouche, Piotr Przymus,Hana Alouaoui, Alain Casali, LotfiLakhal",Utilizing Big Data Paradigms for Business Intelligence,,"Research on the analysis of time series has gained momentum in recent years, as knowledge derived from time series analysis can improve the decision-making process for industrial and scientific fields. Furthermore, time series analysis is often an essential part of business intelligence systems. With the growing interest in this topic, a novel set of challenges emerges. Utilizing forecasting models that can handle a large number of predictors is a popular approach that can improve results compared to univariate models. However, issues arise for high dimensional data. Not all variables will have direct impact on the target variable and adding unrelated variables may make the forecasts less accurate. Thus, the authors explore methods that can effectively deal with time series with many predictors. The authors discuss state-of-the-art methods for optimizing the selection, dimension reduction, and shrinkage of predictors. While similar research exists, it exclusively targets small and medium datasets, and thus, the research aims to fill the knowledge gap in the context of big data applications."
Clustering with Confidence: Finding Clusters with Statistical Guarantees,"Andreas Henelius, Kai Puolamäki,Henrik Boström, Panagiotis Papapetrou",arXiv,Clustering,"Clustering is a widely used unsupervised learning method for finding structure in the data. However, the resulting clusters are typically presented without any guarantees on their robustness; slightly changing the used data sample or re-running a clustering algorithm involving some stochastic component may lead to completely different clusters. There is, hence, a need for techniques that can quantify the instability of the generated clusters. In this study, we propose a technique for quantifying the instability of a clustering solution and for finding robust clusters, termed core clusters, which correspond to clusters where the co-occurrence probability of each data item within a cluster is at least 1−α. We demonstrate how solving the core clustering problem is linked to finding the largest maximal cliques in a graph. We show that the method can be used with both clustering and classification algorithms. The proposed method is tested on both simulated and real datasets. The results show that the obtained clusters indeed meet the guarantees on robustness."
View project Proportion of surgical site infections occurring after discharge: A systematic review,"Meliha Yetisgen-Yildiz, Cosmin AdrianBejan, Lucy Vanderwende, Fei Xia,Heather L. Evans, Mark Matsuo Wurfel",Surgical Infection,,"Surgical site infection (SSI) is the most common type of healthcare-associated infection, contributing to substantial annual morbidity, costs, and deaths. In the United States it is the number one reason for hospital re-admission after surgery. Relatively little attention has been paid to the proportion of SSIs that occur after discharge. This paper systematically reviews two decades of publications to characterize better the proportion of SSIs that are identified after discharge and the need for better early detection and treatment. A restricted systematic literature search was conducted in PubMed to identify English-language studies published after 1995 that include the occurrence of pre-discharge and post-discharge SSIs. The data abstracted were the date of publication, country of origin, procedure, study design, surveillance system, population size, follow-up rate, and SSI counts and proportions. Descriptive statistics and forest plots were used to characterize the data set, represent the overall proportion of SSIs occurring after discharge, and assess the heterogeneity of the studies. A total of 55 articles met the inclusion criteria, with data from 1,432,293 operations and 141,347 SSIs based on studies from 15 countries. The overall proportion of operations leading to SSI was 9.9%. Of the 141,347 infections, 84,984 (60.1%) appeared after discharge. The proportion of SSIs after discharge differed among studies, from 13.5 to 94.8, and was heterogeneous for all studies and for most individual surgery types. Post-discharge SSIs constitute the majority of these infections and pose a substantial disease burden for surgical patients globally and for different surgery types. Further examination is warranted to determine the methodologic and clinical factors moderating the proportion of post-discharge SSIs."
Automated tools for phenotype extraction from medical records.,"Meliha Yetisgen-Yildiz, Cosmin AdrianBejan, Lucy Vanderwende, Fei Xia,Heather L. Evans, Mark M. Wurfel",AMIA,,"Clinical research studying critical illness phenotypes relies on the identification of clinical syndromes defined by consensus definitions. Historically, identifying phenotypes has required manual chart review, a time and resource intensive process. The overall research goal of Critical Illness PHenotype ExtRaction (deCIPHER) project is to develop automated approaches based on natural language processing and machine learning that accurately identify phenotypes from EMR. We chose pneumonia as our first critical illness phenotype and conducted preliminary experiments to explore the problem space. In this abstract, we outline the tools we built for processing clinical records, present our preliminary findings for pneumonia extraction, and describe future steps."
Assertion modeling and its role in clinical phenotype identification,"Cosmin Adrian Bejan, LucyVanderwende, Fei Xia, Meliha Yetisgen-Yildiz",Journal of Biomedical Informatics,"Natural language processing, Clinical information extraction, Assertion classification, Pneumonia identification, Statistical feature selection","This paper describes an approach to assertion classification and an empirical study on the impact this task has on phenotype identification, a real world application in the clinical domain. The task of assertion classification is to assign to each medical concept mentioned in a clinical report (e.g., pneumonia, chest pain) a specific assertion category (e.g., present, absent, and possible). To improve the classification of medical assertions, we propose several new features that capture the semantic properties of special cue words highly indicative of a specific assertion category. The results obtained outperform the current state-of-the-art results for this task. Furthermore, we confirm the intuition that assertion classification contributes in significantly improving the results of phenotype identification from free-text clinical records."
873 Using natural language processing on electronic medical notes to detect the presence of an indwelling urinary catheter,"Adi V. Gundlapalli, Guy Divita, TylerForbush, Andrew Redd, Marjorie Carter,Ashley J. Gendrett, Kalpana Gupta, YingSuo, B.S. Begum Durgahee, Sarah L.Krein, Michael A. Rubin, Anne Sales,Matthew H. Samore, Barbara W.Trautner",Open Forum Infectious Diseases,,"We set out to develop a natural language processing (NLP) algorithm to extract concepts related to indwelling urinary catheters from electronic medical notes. A concept lexicon was developed based on domain knowledge, prior expertise and review of medical notes. Concepts were classified as evidence of either catheter presence or catheter absence. A reference standard set of 1595 randomly selected documents from inpatient admissions were annotated by human reviewers to identify all positively and negatively asserted concepts. An NLP algorithm was tuned using 100 documents from the set. Novel lexicon semantics including evidence of catheter absence and inherently negated terms were used. Electronic medical record note titles with the highest hit rate for concepts were identified. The NLP algorithm was then tested on a set of 1495 documents to determine agreement between NLP and human reference standard, sensitivity and positive predictive value (PPV). The overall cohort included 5,589 unique patients with 77,938 hospital days from two VA hospitals over a one-year period. The lexicon contained 590 concepts for catheter presence (e.g., Foley catheter was placed) and 18 for evidence of absence (e.g., Patient has bathroom privileges). Iterative review of NLP outputs on the training set included false positive analyses and fine-tuning of the algorithm. Overall, nurse's notes were the most frequent inpatient note titles; these also yielded the highest number of concepts with respect to urinary catheters. The overall agreement between the NLP and reference standard was 71%. With 348 instances of ‘evidence of catheter presence’ the system found 246 for a sensitivity of 87%. With 84 false positive concepts associated with catheter presence, the PPV was 59%. For ‘evidence of catheter absence’, the agreement was 72% (450 instances), sensitivity was 77% and PPV was 68%. We have shown that it is possible to identify the presence of an indwelling urinary catheter from the free text of electronic medical notes. Further refinement and scaling-up of NLP algorithms to large document sets is ongoing. This is the first key step in developing protocols to assist humans in large-scale review of patient charts for CAUTI."
Learning From Design Facilitating Multidisciplinary Design Teams,Monika Eisenhower,,,
Semi-automatic keyword based approach for FIRE 2016 Microblog Track,"Ganchimeg Lkhagvasuren, TeresaGonçalves, José Saias",CEUR Workshop Proceedings,Supervised classification; Information extraction; Terrier; Twitter,"This paper describes our semi-automatic keyword based approach for the four topics of Information Extraction from Microblogs Posted during Disasters task at Forum for Information Retrieval Evaluation (FIRE) 2016. The approach consists three phases; Keywords extraction, Retrieval, and Classification."
Data mining meets hci: making sense of large graphs,"Christos Faloutsos, Jason I. Hong,Aniket Kittur, Duen Horng Chau",Carnegie Mellon University,"Graph Mining, Data Mining, Machine Learning, Human-Computer Interaction, HCI, Graphical Models, Inference, Big Data, Sensemaking, Visualization, eBay Auction Fraud Detection, Symantec Malware Detection, Belief Propagation, Random Walk, Guilt by Association, Polonium, NetProbe, Apolo, Feldspar, Graphite","We have entered the age of big data. Massive datasets are now common in science, government and enterprises. Yet, making sense of these data remains a fundamental challenge. Where do we start our analysis? Where to go next? How to visualize our findings? We answers these questions by bridging Data Mining and HumanComputer Interaction (HCI) to create tools for making sense of graphs with billions of nodes and edges, focusing on: (1) Attention Routing: we introduce this idea, based on anomaly detection, that automatically draws people’s attention to interesting areas of the graph to start their analyses. We present three examples: Polonium unearths malware from 37 billion machine-file relationships; NetProbe fingers bad guys who commit auction fraud. (2) Mixed-Initiative Sensemaking: we present two examples that combine machine inference and visualization to help users locate next areas of interest: Apolo guides users to explore large graphs by learning from few examples of user interest; Graphite finds interesting subgraphs, based on only fuzzy descriptions drawn graphically. (3) Scaling Up: we show how to enable interactive analytics of large graphs by leveraging Hadoop, staging of operations, and approximate computation. This thesis contributes to data mining, HCI, and importantly their intersection, including: interactive systems and algorithms that scale; theoriesthat unify graph mining approaches; and paradigmsthat overcome fundamental challenges in visual analytics. Our work is making impact to academia and society: Polonium protects 120 million people worldwide from malware; NetProbe made headlines on CNN, WSJ and USA Today; Pegasus won an opensource software award; Apolo helps DARPA detect insider threats and prevent exfiltration. We hope our Big Data Mantra “Machine for Attention Routing, Human for Interaction” will inspire more innovations at the crossroad of data mining and HCI."
Automated Identification of Surveillance Colonoscopy in Inflammatory Bowel Disease Using Natural Language Processing,"Jason Ken Hou, Mimi Chang, Thien PNguyen, Jennifer R Kramer, PeterRichardson, Shubhada Sansgiry,Leonard W. D'Avolio, Hashem B. El-Serag",Digestive Diseases and Sciences ,"Crohn’s disease, Ulcerative colitis, Machine learning, Automated retrieval console","Differentiating surveillance from non-surveillance colonoscopy for colorectal cancer in patients with inflammatory bowel disease (IBD) using electronic medical records (EMR) is important for practice improvement and research purposes, but diagnosis code algorithms are lacking. The automated retrieval console (ARC) is natural language processing (NLP)-based software that allows text-based document-level classification. The purpose of this study was to test the feasibility and accuracy of ARC in identifying surveillance and non-surveillance colonoscopy in IBD using EMR. We performed a split validation study of electronic reports of colonoscopy pathology for patients with IBD from the Michael E. DeBakey VA Medical Center. A gastroenterologist manually classified pathology reports as either derived from surveillance or non-surveillance colonoscopy. Pathology reports were randomly split into two sets: 70 % for algorithm derivation and 30 % for validation. An ARC generated classification model was applied to the validation set of pathology reports. The performance of the model was compared with manual classification for surveillance and non-surveillance colonoscopy. A total of 575 colonoscopy pathology reports were available on 195 IBD patients, of which 400 reports were designated as training and 175 as testing sets. Within the testing set, a total of 69 pathology reports were classified as surveillance by manual review, whereas the ARC model classified 66 reports as surveillance for a recall of 0.77, precision of 0.80, and specificity of 0.88. ARC was able to identify surveillance colonoscopy for IBD without customized software programming. NLP-based document-level classification may be used to differentiate surveillance from non-surveillance colonoscopy in IBD."
Methodological advances in statistical prediction.,"Howard N. Garb, James M Wood",Psychological Assessment,,"Thirty years ago, Dawes, Faust, and Meehl (1989) argued that mental health professionals should routinely use statistical prediction rules to describe and diagnose clients, predict behaviors, and formulate treatment plans. Subsequent research has supported their claim that statistical prediction performs well when compared to clinical judgment. However, many of the things we thought we knew about statistical prediction have changed. The purpose of this literature review is to describe methodological advances in statistical prediction. Three broad areas are covered. First, while statistical prediction rules are valuable for criterion-referenced assessment (e.g., predicting violence, recidivism, treatment outcomes), they are valuable only for some norm-referenced assessment tasks (e.g., diagnosis but not describing personality and psychopathology). Second, statistical prediction is particularly prominent for the prediction of violence and criminal recidivism. Results from this area will be used to describe the validity of traditional clinical judgment, structured professional judgment, and statistical prediction. The results support the use of both structured professional judgment and statistical prediction. The effect of allowing professionals to override statistical predictions consistently led to lower validity. Third, issues in building statistical prediction rules are described, including the assignment of weights to predictors, the emergence of new statistical analyses (e.g., machine learning), and the role of theory. As research has progressed, statistical prediction has become one of the most exciting areas of psychological assessment. (PsycINFO Database Record (c) 2019 APA, all rights reserved)."
Psychiatric Hospitalization after Emergency Treatment for Deliberate Self-Harm is Associated with Repeated Deliberate Self-Harm.,"Atshushi Ichimura, Koji Kato, TakayukiTaira, Hiroyuki Otsuka, Tomoko Seki,Yoshihide Nakagawa, Sadaki Inokuchi",Archives of Suicide Research,emergency department; intervention; multimodal support; prevention; psychiatric hospitalization; repeated deliberate self-harm,"The objective of this study was to evaluate whether treatment at a psychiatric hospital reduces the risk of repeating parasuicide. Participants were 4,483 parasuicide patients admitted to an emergency department between July 2003 and March 2012. We analyzed the effectiveness of psychiatric hospitalization in preventing repeated parasuicide. We adjusted for background factors using multivariate logistic regression. Effects of psychiatric hospitalization upon the likelihood of repeated parasuicide within 1 year varied by age (especially those aged <35 years), indicating that hospitalization was a significant risk factor. We must be mindful of the risk of repeated parasuicide following discharge in young patients and to provide them with ongoing outpatient care and multimodal support."
Data points: trends in mortality among homeless VA patients with severe mental illness.,"Denis G. Birgenheir, Zongshan Lai, AmyM Kilbourne",Psychiatric Services,,"Both homelessness and severe mental illness are known to increase the likelihood of early mortality. We determined years of potential life lost (YPLL) over an 11-year period among Department of Veterans Affairs (VA) patients using homeless services, assessing for the impact of severe mental illness. Using the VA National Patient Care Database (NPCD), we analyzed allcause mortality for fiscal years (FYs) 2000–2009 among VA patients by severe mental illness status and use of VA homelessness services for each FY. All patients with a severe mental illness diagnosis from each FY were identified by ICD-9 codes. We also used NPCD data to identify a 5% random sample of individuals without a severe mental illness diagnosis for each FY. The primary analyses were hazard ratio calculations on all-cause mortality, comparing differences in YPLL adjusted for age and gender by homelessness and severe mental illness status."
Automated Extraction of Substance Use Information from Clinical Texts,"Yan Wang, Elizabeth S. Chen, SergueiV. S. Pakhomov, Elliot G. Arsoniadis,Elizabeth W. Carter, ElizabethLindemann, Indra Neil Sarkar,Genevieve B. Melton",AMIA Annual Symposium Proceedings Archive,,"Within clinical discourse, social history (SH) includes important information about substance use (alcohol, drug, and nicotine use) as key risk factors for disease, disability, and mortality. In this study, we developed and evaluated a natural language processing (NLP) system for automated detection of substance use statements and extraction of substance use attributes (e.g., temporal and status) based on Stanford Typed Dependencies. The developed NLP system leveraged linguistic resources and domain knowledge from a multi-site social history study, Propbank and the MiPACQ corpus. The system attained F-scores of 89.8, 84.6 and 89.4 respectively for alcohol, drug, and nicotine use statement detection, as well as average F-scores of 82.1, 90.3, 80.8, 88.7, 96.6, and 74.5 respectively for extraction of attributes. Our results suggest that NLP systems can achieve good performance when augmented with linguistic resources and domain knowledge when applied to a wide breadth of substance use free text clinical notes."
Pneumonia identification using statistical feature selection,"Cosmin Adrian Bejan, Fei Xia, LucyVanderwende, Mark M. Wurfel, MelihaYetisgen-Yildiz",JAMIA,,"This paper describes a natural language processing system for the task of pneumonia identification. Based on the information extracted from the narrative reports associated with a patient, the task is to identify whether or not the patient is positive for pneumonia. A binary classifier was employed to identify pneumonia from a dataset of multiple types of clinical notes created for 426 patients during their stay in the intensive care unit. For this purpose, three types of features were considered: (1) word n-grams, (2) Unified Medical Language System (UMLS) concepts, and (3) assertion values associated with pneumonia expressions. System performance was greatly increased by a feature selection approach which uses statistical significance testing to rank features based on their association with the two categories of pneumonia identification. Besides testing our system on the entire cohort of 426 patients (unrestricted dataset), we also used a smaller subset of 236 patients (restricted dataset). The performance of the system was compared with the results of a baseline previously proposed for these two datasets. The best results achieved by the system (85.71 and 81.67 F1-measure) are significantly better than the baseline results (50.70 and 49.10 F1-measure) on the restricted and unrestricted datasets, respectively. Using a statistical feature selection approach that allows the feature extractor to consider only the most informative features from the feature space significantly improves the performance over a baseline that uses all the features from the same feature space. Extracting the assertion value for pneumonia expressions further improves the system performance."
"Scaling Out and Evaluation of OBSecAn, an Automated Section Annotator for Semi-Structured Clinical Documents, on a Large VA Clinical Corpus","Le-Thuy T. Tran, Guy Divita, AndrewRedd, Marjorie Carter, Matthew H.Samore, Adi V. Gundlapalli",AMIA Annual Symposium Proceedings Archive,,"“Identifying and labeling” (annotating) sections improves the effectiveness of extracting information stored in the free text of clinical documents. OBSecAn, an automated ontology-based section annotator, was developed to identify and label sections of semi-structured clinical documents from the Department of Veterans Affairs (VA). In the first step, the algorithm reads and parses the document to obtain and store information regarding sections into a structure that supports the hierarchy of sections. The second stage detects and makes correction to errors in the parsed structure. The third stage produces the section annotation output using the final parsed tree. In this study, we present the OBSecAn method and its scale to a million document corpus and evaluate its performance in identifying family history sections. We identify high yield sections for this use case from note titles such as primary care and demonstrate a median rate of 99% in correctly identifying a family history section."
Symptom recognition issue,"Laure Martin, Delphine Battistelli,Thierry Charnois",ACL,,"This work focuses on signs and symptoms recognition in biomedical texts abstracts. First, this specific task is described from a linguistic point of view. Then a methodology combining pattern mining and language processing is proposed. In the absence of an authoritative annotated corpus, our approach has the advantage of being weakly-supervised. Preliminary experimental results are discussed and reveal promising avenues."
Supporting Experts to Handle Tweet Collections About Significant Events,"Ali Hurriyetoglu, Nelleke Oostdijk,Mustafa Erkan Basar, Antal van denBosch",Natural Language Processing and Information Systems,"Social media, Text mining, Machine learning, Twitter ","We introduce Relevancer that processes a tweet set and enables generating an automatic classifier from it. Relevancer satisfies information needs of experts during significant events. Enabling experts to combine automatic procedures with expertise is the main contribution of our approach and the added value of the tool. Even a small amount of feedback enables the tool to distinguish between relevant and irrelevant information effectively. Thus, Relevancer facilitates the quick understanding of and proper reaction to events presented on Twitter."
Psychiatric hospitalisation and the risk ofsuicide.,"M Large, Nav Kapur",The British Journal of Psychiatry,,"The association between current or recent psychiatric hospitalisation and increased suicide risk is well described. This relationship is generally assumed to be due to the selection of people at increased risk of suicide for psychiatric admission and subsequent failure of protection from suicide once admitted. Here, Matthew Large and Nav Kapur debate whether or not admission to hospital also selects for vulnerability to certain harmful aspects of hospitalisation and whether the increased rate of suicide in current and recently discharged psychiatric patients is, in fact, due to psychiatric hospitalisation itself.Declaration of interestM.M.L. has provided expert testimony in legal proceedings following in-patient suicide. N.K. sits on the Department of Health (England) National Suicide Prevention Strategy Advisory group."
"Adverse childhood experiences, exposure to a natural disaster and post traumatic stress disorder among survivors of the 2011 Great East Japan earthquake and tsunami.","Yosuke Inoue, Andrew Stickley, AkiYazawa, Jaffar Aida, Ichiro Kawachi,Katsunori Kondo, T. Fujiwara",Epidemiology and Psychiatric Sciences,PTSD; elderly; epidemiology; population survey.,"To investigate whether adverse childhood experiences (ACEs) modify the impact of exposure to a natural disaster (the 2011 Great East Japan earthquake and tsunami) on the occurrence of posttraumatic stress disorder (PTSD) among older people. Data were collected as part of the Japan Gerontological Evaluation Study (JAGES), which is an on-going epidemiological survey investigating social determinants of health among older people across Japan. Information on PTSD symptoms based on the Screening Questionnaire for Disaster Mental Health, traumatic exposure to the earthquake (i.e., house damage and loss of relatives/friends during the earthquake/tsunami) and ACEs was obtained from 580 participants aged 65 or older living in Iwanuma City, Miyagi Prefecture, which suffered severe damage as a result of the earthquake and the subsequent tsunami in March 2011. Associations were examined using Poisson regression analysis with a robust variance estimator after adjusting for covariates. The prevalence of PTSD was 9.7% in this population; compared to those with no traumatic experience, the prevalence of PTSD was approximately two times higher among those who experienced the loss of close friends/relatives (PR = 1.84, 95% CI = 1.11-3.03, p = 0.018), or whose house was damaged (PR = 2.15, 95% CI = 1.07-4.34, p = 0.032). ACE was not significantly associated with PTSD. Stratified analyses by the presence of ACE showed that damage due to the earthquake/tsunami was associated with PTSD only among those without ACEs; more specifically, among non-ACE respondents the PR of PTSD associated with house damage was 6.67 (95% CI = 1.66-26.80), while for the loss of a relative or a close friend it was 3.56 (95% CI = 1.18-10.75). In contrast, no statistically significant associations were observed among those with ACEs. Following the Great East Japan earthquake/tsunami in 2011 a higher risk of developing PTSD symptoms was observed in 2013 especially among older individuals without ACEs. This suggests that ACEs might affect how individuals respond to subsequent traumatic events later in life."
Meta-analysis of suicide rates in the first week and the first month after psychiatric hospitalisation,"Daniel Chung, Dusan Hadzi-Pavlovic,Maggie Wang, Sascha Swaraj, MarkOlfson, M Large",BMJ Open,,"To assess the magnitude of suicide rates in the first week and first month postdischarge following psychiatric hospitalisation. Meta-analysis of relevant English-language, peer-reviewed papers published in MEDLINE, PsycINFO or Embase between 01 January 1945 and 31 March 2017 and supplemented by hand searching and personal communication. A generalised linear effects model was fitted to the number of suicides, with a Poisson distribution, log link and log of person years as an offset. A random effects model was used to calculate the overall pooled rates and within subgroups in sensitivity analyses. measures Suicides per 100 000 person years in the first week and the first month after discharge from psychiatric hospitalisation. Thirty-four included papers comprised 29 studies that reported suicides in the first month postdischarge (3551 suicides during 222 546 patient years) and 24 studies that reported suicides in the first week postdischarge (1928 suicides during 60 880 patient years). The pooled estimate of the suicide rate in the first month postdischarge suicide was 2060 per 100 000 person years (95% CI=1300 to 3280, I2=90). The pooled estimate of the suicide rate in the first week postdischarge suicide was 2950 suicides per 100 000 person years (95% CI=1740 to 5000, I2=88). Eight studies that were included after personal communication had lower pooled rates of suicide than studies included after data extraction and there was evidence of publication bias towards papers reporting a higher rate of postdischarge suicide. Acknowledging the presence of marked heterogeneity between studies and the likelihood of bias towards publication of studies reporting a higher postdischarge suicide rate, the first week and first month postdischarge following psychiatric hospitalisation are periods of extraordinary suicide risk. Short-term follow-up of discharged patients should be augmented with greater focus on safe transition from hospital to community care."
Suicide Reduction and Research Efforts in Service Members and Veterans-Sobering Realities.,Charles William Hoge,Jama Psychiatry,,"The rate of death by suicide in the United States has risen33% between 1999 and 2017, with a steeper climb in recent years and disproportionate increases in female and rural demographics. Particular concern has emerged for veterans, whoexperience a50%higher incidence than the general adult populationoverall,with an 80% higher incidence in female veterans.1 Suicide incidence in service members is now comparablewith the general population after decades of being significantly lower. These concerning trends have prompted an unprecedented expansion of suicide prevention, treatment, and research initiatives, with Department of Defense (DoD) and Veterans Affairs (VA) leading the field."
Suicide and all-cause mortality following routine hospital management of self-harm: Propensity score analysis using multicentre cohort data,"Sarah Steeg, Matthew Carr, RichardEmsley, Keith Hawton, Keith Waters,Harriet Bickley, Jennifer Ness, GalitGeulayov, Nav Kapur",Plos One,,"Observational studies are suited to examining links between the routine hospital management of self-harm and future suicide and all-cause mortality due to their large scale. However, care must be taken when attempting to infer causal associations in non-experimental settings. Data from the Multicentre Study of Self-Harm in England were used to examine associations between four types of hospital management (specialist psychosocial assessment, general hospital admission, psychiatric outpatient referral and psychiatric admission) following self-harm and risks of suicide and all-cause mortality in the subsequent 12 months. Missing data were handled by multiple imputation and propensity score (PS) methods were used to address observed differences between patients at baseline. Unadjusted, PS stratified and PS matched risk ratios (RRs) were calculated.The PSs balanced the majority of baseline differences between treatment groups. Unadjusted RRs showed that all four treatment types were associated with either increased risks or no change in risks of suicide and all-cause mortality within a year. None of the four types of hospital management were associated with lowered risks of suicide or all-cause mortality following propensity score stratification (psychosocial assessment and medical admission) and propensity score matching (psychiatric outpatient referral and psychiatric admission), though there was no longer an increased risk among people admitted to a psychiatric bed. Individuals who self-cut were at an increased risk of death from any cause following psychosocial assessment and medical admission. Medical admission appeared to be associated with reduced risk of suicide in individuals already receiving outpatient or GP treatment for a psychiatric disorder. More intensive forms of hospital management following self-harm appeared to be appropriately allocated to individuals with highest risks of suicide and all-cause mortality. PS adjustment appeared to attenuate only some of the observed increased risks, suggesting that either differences between treatment groups remained, or that some treatments had little impact on reducing subsequent suicide or all-cause mortality risk. These findings are in contrast to some previous studies that have suggested psychosocial assessment by a mental health specialist reduces risk of repeat self-harm. Future observational self-harm studies should consider increasing the number of potential confounding variables collected."
Clinical Epidemiological Research on Suicide-Related Behaviors-Where We Are and Where We Need to Go.,Ronald C. Kessler,Jama Psychiatry,,"Clinicalepidemiologicalresearchonsuicide-related behaviors (SRBs) is characterized by weak associations, weak effect sizes of clinical interventions, and strong effect sizes ofsomemeans-restriction interventions.These results have led several recent JAMAPsychiatry articles to conclude that nonclinical interventions must be central components in any successful multimodal SRB prevention
strategy. I agree. But I disagree with the pessimism about components of this strategy in 2 of these recent articles: an editorial byHoge1 about the low value of existing SRB-focused clinical trials and an article by Belsher et al2 about the low value of machine-learning (ML) methods."
Research Domain Criteria scores estimated through natural language processing are associated with risk for suicide and accidental death,"Thomas H. McCoy, Amelia M Pellegrini,Roy H. Perlis",Depression & Anxiety,Research Domain Criteria; accidental death; electronic health records; natural language processing; suicide; survival analysis,"Identification of individuals at increased risk for suicide is an important public health priority, but the extent to which considering clinical phenomenology improves prediction of longer term outcomes remains understudied. Hospital discharge provides an opportunity to stratify risk using readily available clinical records and details. We applied a validated natural language processing tool to generate estimated Research Domain Criteria (RDoC) scores for a cohort of 444,317 individuals drawn from 815,457 hospital discharges between 2005 and 2013. We used survival analysis to examine the association of this risk with suicide and accidental death, adjusted for sociodemographic features. In adjusted models, symptoms in each of the five domains contributed to incremental risk (log rank P < 0.001), with greatest increase observed with positive valence. The contribution of each domain to risk was time dependent. RDoC symptom scores parsed from clinical documentation are associated with suicide and illustrates that multiple domains contribute to risk in a time-varying fashion."
Validation of Case Finding Algorithms for Hepatocellular Cancer From Administrative Data and Electronic Health Records Using Natural Language Processing,"Yvonne H Sada, Jason Hou, PeterRichardson, Hashem B. El-Serag,Jessica Davila",Medical Care,"hepatocellular cancer, natural language processing, pathology, radiology","Accurate identification of hepatocellular cancer (HCC) cases from automated data is needed for efficient and valid quality improvement initiatives and research. We validated HCC International Classification of Diseases, 9th Revision (ICD-9) codes, and evaluated whether natural language processing by the Automated Retrieval Console (ARC) for document classification improves HCC identification. We identified a cohort of patients with ICD-9 codes for HCC during 2005-2010 from Veterans Affairs administrative data. Pathology and radiology reports were reviewed to confirm HCC. The positive predictive value (PPV), sensitivity, and specificity of ICD-9 codes were calculated. A split validation study of pathology and radiology reports was performed to develop and validate ARC algorithms. Reports were manually classified as diagnostic of HCC or not. ARC generated document classification algorithms using the Clinical Text Analysis and Knowledge Extraction System. ARC performance was compared with manual classification. PPV, sensitivity, and specificity of ARC were calculated. A total of 1138 patients with HCC were identified by ICD-9 codes. On the basis of manual review, 773 had HCC. The HCC ICD-9 code algorithm had a PPV of 0.67, sensitivity of 0.95, and specificity of 0.93. For a random subset of 619 patients, we identified 471 pathology reports for 323 patients and 943 radiology reports for 557 patients. The pathology ARC algorithm had PPV of 0.96, sensitivity of 0.96, and specificity of 0.97. The radiology ARC algorithm had PPV of 0.75, sensitivity of 0.94, and specificity of 0.68. A combined approach of ICD-9 codes and natural language processing of pathology and radiology reports improves HCC case identification in automated data."
Human Identification using X-Ray Image Matching,"Ryudo Ishigami, Thi Thi Zin",IMECS,"Biometric identifier, Human behavior, Stochastic model, X-Ray image matching","Human identification both prior to death and after death is becoming one of the major worldwide issues nowadays for law enforcement aspect as well as social and security aspects. General identification prior to death is possible through comparison of many biometric identifiers. However identification after death is impossible using behavioral biometric such as speech and actions. Moreover, in many circumstances such as natural disasters, air plane crash or a case of identification a couple of weeks later, most of physical biometrics may not be useful for identification due to the decay of some soft tissues. A lot of research has been done in the field of different biometric modalities like Finger-print, Iris, Hand-Veins, Dental biometrics etc. to identify humans. However only a little has been known the chest X-Ray biometric which was very powerful method for identification especially during the mass disasters in which most of other biometrics are unidentifiable. Therefore in this paper, we propose a stochastic modelling approach for human identification after death by using chest X- Ray prior to death database. Some experimental results are shown based on real life dataset and confirmed."
Detection and Classification of Lung Disease – Pneumonia and Lung Cancer in Chest Radiology Using Artificial Neural Network,S. Y. Pattar,International Journal of Scientific and Research Publications,"feature extraction, classification, Neural Networks","Chest radiology is the most common method used for diagnosis of lung diseases, the term lung disease refers to the abnormalities that effect the lung organ, diseases are such as asthma, COPD, lung cancer, pneumonia and many other breathing problems, in this paper, we develop a system that defects and classify the lung diseases as either pneumonia or lung cancer, this is accomplished by two stages they are feature extraction and classification, feature extraction is done through the use of Gabor filter, classification is through the use of neural network’s like feed forward neural network(FFNN), Multi-layer perceptron neural network(MLPNN), Radial Basis Function(RBF)"
On the bias of BFS,"Maciej Kurant, Athina Markopoulou,Patrick Thiran",arXives,"BFS, Breadth First Search, graph sampling, degree bias, Online Social Networks (OSN)","Breadth First Search (BFS) and other graph traversal techniques are widely used for measuring large unknown graphs, such as online social networks. It has been empirically observed that an incomplete BFS is biased toward high degree nodes. In contrast to more studied sampling techniques, such as random walks, the precise bias of BFS has not been characterized to date. In this paper, we quantify the degree bias of BFS sampling. In particular, we calculate the node degree distribution expected to be observed by BFS as a function of the fraction of covered nodes, in a random graph RG(pk) with a given degree distribution pk. Furthermore, we also show that, for RG(pk), all commonly used graph traversal techniques (BFS, DFS, Forest Fire, and Snowball Sampling) lead to the same bias, and we show how to correct for this bias. To give a broader perspective, we compare this class of exploration techniques to random walks that are well-studied and easier to analyze. Next, we study by simulation the effect of graph properties not captured directly by our model. We find that the bias gets amplified in graphs with strong positive assortativity. Finally, we demonstrate the above results by sampling the Facebook social network, and we provide some practical guidelines for graph sampling in practice."
Multigraph Sampling of Online Social Networks,"Minas Gjoka, Carter T. Butts, MaciejKurant, Athina Markopoulou",IEEE,"Sampling methods, Social network services, Last.fm, Random walks, Multigraph, Graph sampling","State-of-the-art techniques for probability sampling of users of online social networks (OSNs) are based on random walks on a single social relation (typically friendship). While powerful, these methods rely on the social graph being fully connected. Furthermore, the mixing time of the sampling process strongly depends on the characteristics of this graph. In this paper, we observe that there often exist other relations between OSN users, such as membership in the same group or participation in the same event. We propose to exploit the graphs these relations induce, by performing a random walk on their union multigraph. We design a computationally efficient way to perform multigraph sampling by randomly selecting the graph on which to walk at each iteration. We demonstrate the benefits of our approach through (i) simulation in synthetic graphs, and (ii) measurements of Last.fm- an Internet website for music with social networking features. More specifically, we show that multigraph sampling can obtain a representative sample and faster convergence, even when the individual graphs fail, i.e., are disconnected or highly clustered."
Walking in Facebook: A Case Study of Unbiased Sampling of OSNs,"Minas Gjoka, Maciej Kurant, Carter T.Butts, Athina Markopoulou",IEEE,"Measurements, online social networks, Facebook, graph sampling, crawling, bias","With more than 250 million active users, Facebook (FB) is currently one of the most important online social networks. Our goal in this paper is to obtain a representative (unbiased) sample of Facebook users by crawling its social graph. In this quest, we consider and implement several candidate techniques. Two approaches that are found to perform well are the Metropolis-Hasting random walk (MHRW) and a re-weighted random walk (RWRW). Both have pros and cons, which we demonstrate through a comparison to each other as well as to the ""ground-truth"" (UNI - obtained through true uniform sampling of FB userIDs). In contrast, the traditional Breadth-First-Search (BFS) and Random Walk (RW) perform quite poorly, producing substantially biased results. In addition to offline performance assessment, we introduce online formal convergence diagnostics to assess sample quality during the data collection process. We show how these can be used to effectively determine when a random walk sample is of adequate size and quality for subsequent use (i.e., when it is safe to cease sampling). Using these methods, we collect the first, to the best of our knowledge, unbiased sample of Facebook. Finally, we use one of our representative datasets, collected through MHRW, to characterize several key properties of Facebook."
Unbiased Sampling of Facebook,"Minas Gjoka, Maciej Kurant, Carter T.Butts, Athina Markopoulou",,,"The popularity of online social networks (OSNs) has given rise to a number of measurements studies that provide a first step towards their understanding. So far, such studies have been based either on complete data sets provided directly by the OSN itself or on Breadth-First-Search (BFS) crawling of the social graph, which does not guarantee good statistical properties of the collected sample. In this paper, we crawl the publicly available social graph and present the first unbiased sampling of Facebook (FB) users using a MetropolisHastings random walk with multiple chains. We study the convergence properties of the walk and demonstrate the uniformity of the collected sample with respect to multiple metrics of interest. We provide a comparison of our crawling technique to baseline algorithms, namely BFS and simple random walk, as well as to the “ground truth” obtained through truly uniform sampling of userIDs. Our contributions lie both in the measurement methodology and in the collected sample. With regards to the methodology, our measurement technique (i) applies and combines known results from random walk sampling specifically in the OSN context and (ii) addresses system implementation aspects that have made the measurement of Facebook challenging so far. With respect to the collected sample: (i) it is the first representative sample of FB users and we plan to make it publicly available; (ii) we perform a characterization of several key properties of the data set, and find that some of them are substantially different from what was previously believed based on non-representative OSN samples."
Walking on a graph with a magnifying glass: stratified sampling via weighted random walks,"Maciej Kurant, Minas Gjoka, Carter T.Butts, Athina Markopoulou",arXiv,,"Our objective is to sample the node set of a large unknown graph via crawling, to accurately estimate a given metric of interest. We design a random walk on an appropriately defined weighted graph that achieves high efficiency by preferentially crawling those nodes and edges that convey greater information regarding the target metric. Our approach begins by employing the theory of stratification to find optimal node weights, for a given estimation problem, under an independence sampler. While optimal under independence sampling, these weights may be impractical under graph crawling due to constraints arising from the structure of the graph. Therefore, the edge weights for our random walk should be chosen so as to lead to an equilibrium distribution that strikes a balance between approximating the optimal weights under an independence sampler and achieving fast convergence. We propose a heuristic approach (stratified weighted random walk, or S-WRW) that achieves this goal, while using only limited information about the graph structure and the node properties. We evaluate our technique in simulation, and experimentally, by collecting a sample of Facebook college users. We show that S-WRW requires 13-15 times fewer samples than the simple re-weighted random walk (RW) to achieve the same estimation accuracy for a range of metrics."
Unbiased Sampling of Facebook,"Maciej Kurant, Carter T. Butts, AthinaMarkopoulou",,,
Coarse-grained topology estimation via graph sampling,"Maciej Kurant, Minas Gjoka, Yan Wang,Zack W. Almquist, Carter T. Butts,Athina Markopoulou",arXiv,"Online Social Networks, coarse-grained topology, induced subgraph sampling, star sampling, Facebook","Many online networks are measured and studied via sampling techniques, which typically collect a relatively small fraction of nodes and their associated edges. Past work in this area has primarily focused on obtaining a representative sample of nodes and on efficient estimation of local graph properties (such as node degree distribution or any node attribute) based on that sample. However, less is known about estimating the global topology of the underlying graph. In this paper, we show how to efficiently estimate the coarse-grained topology of a graph from a probability sample of nodes. In particular, we consider that nodes are partitioned into categories (e.g., countries or work/study places in OSNs), which naturally defines a weighted category graph. We are interested in estimating (i) the size of categories and (ii) the probability that nodes from two different categories are connected. For each of the above, we develop a family of estimators for design-based inference under uniform or non-uniform sampling, employing either of two measurement strategies: induced subgraph sampling, which relies only on information about the sampled nodes; and star sampling, which also exploits category information about the neighbors of sampled nodes. We prove consistency of these estimators and evaluate their efficiency via simulation on fully known graphs. We also apply our methodology to a sample of Facebook users to obtain a number of category graphs, such as the college friendship graph and the country friendship graph;"
A Walk in Facebook: Uniform Sampling of Users in Online Social Networks,"Minas Gjoka, Maciej Kurant, Carter T.Butts, Athina Markopoulou",arXiv,"Sampling methods, Social network services, Facebook, Random Walks, Convergence, Measurements, Graph sampling","Our goal in this paper is to develop a practical framework for obtaining a uniform sample of users in an online social network (OSN) by crawling its social graph. Such a sample allows to estimate any user property and some topological properties as well. To this end, first, we consider and compare several candidate crawling techniques. Two approaches that can produce approximately uniform samples are the Metropolis-Hasting random walk (MHRW) and a re-weighted random walk (RWRW). Both have pros and cons, which we demonstrate through a comparison to each other as well as to the ""ground truth."" In contrast, using Breadth-First-Search (BFS) or an unadjusted Random Walk (RW) leads to substantially biased results. Second, and in addition to offline performance assessment, we introduce online formal convergence diagnostics to assess sample quality during the data collection process. We show how these diagnostics can be used to effectively determine when a random walk sample is of adequate size and quality. Third, as a case study, we apply the above methods to Facebook and we collect the first, to the best of our knowledge, representative sample of Facebook users. We make it publicly available and employ it to characterize several key properties of Facebook."
Coarse-Grained Topology Estimation via Graph Sampling,"Maciej Kurant, CalIT, Yan Wang, ZackW. Almquist, Carter T. Butts, AthinaMarkopoulou",,,
Unbiased Sampling over Online Social Networks,Mojtaba Torkjazi,University of Oregon,,"During recent years, Online Social Networks (OSNs) have evolved in many ways and attracted millions of users. The dramatic increase in the popularity of OSNs has encouraged network researchers to examine their connectivity structure. The majority of empirical studies for characterizing OSN connectivity graphs have analyzed snapshots of the system taken in different times. These snapshots are collected by measurements that crawl OSN connectivity graphs. However, OSN owners are often unwilling to expose their user information due to privacy concerns. On the other hand, because of large population and dynamics of OSNs, the task of crawling may result in an incomplete or distorted snapshot of the system. These challenges have clearly heightened the urgency for developing efficient and accurate graph sampling techniques. Although a couple of techniques, such as Metropolized Random Walk (MRW) and Respondent-Driven Sampling (RDS), have been proposed for P2P systems, little is known about their accuracy over connectivity graph of OSNs. In this paper, we focus on MRW and RDS sampling techniques and thoroughly investigate their performance in sampling OSN systems. Our main findings can be summarized as follows: (i) both techniques are sensitive to graph structure, but RDS exhibits better performance; (ii) heterogeneous degree distribution and high number of unbalanced edges in OSN graphs are the main factors for poor performance of MRW over such graphs; (iii) RDS is unable to properly sample low degree nodes which are hard to reach; and (iv) OSN graphs composes of a dense core in the middle and a large number of partitions hanging from the core. High internal and low external connectivity of this core make it almost infeasible for sampling techniques to explore all regions of OSN graphs."
Active exploration for large graphs,"Meng Fang, Jie Yin, Xingquan Zhu",Data Mining & Knowledge Discovery,"Active exploration, Supervised sampling, Random walks, Active learning, Networked data","Modern information networks, such as social networks, communication networks, and citation networks, are often characterized by very large sizes and dynamically changing structures. Common solutions to graph mining tasks (e.g., node classification) usually employ an unrestricted sampling-then-mining paradigm to reduce a large network to a manageable size, followed by subsequent mining tasks. However, real-world networks may be unaccessible at once and must be crawled progressively. This can be due to the fact that the size of the network is too large, or some privacy/legal concerns. In this paper, we propose an Active Exploration framework for large graphs, where the goal is to simultaneously carry out network sampling and node labeling in order to build a sampled network from which the trained classifier can have the maximum node classification accuracy. To achieve this goal, we consider a network as a Markov chain and compute the stationary distribution of the nodes by deriving supervised random walks. The stationary distribution helps identify specific nodes to be sampled in the next step, and the labeling process labels the most informative node which in turn strengthens the sampling of the network. To improve the scalability of active exploration for large graphs, we also propose a more efficient multi-seed algorithm that simultaneously runs multiple, parallel exploration processes, and makes joint decisions to determine which nodes are to be sampled and labeled next. The simultaneous, mutually enhanced sampling and labeling processes ensure that the final sampled network contains a maximum number of nodes directly related to the underlying mining tasks. Experiments on both synthetic and real-world networks demonstrate that our active exploration algorithms have much better chance to include target nodes in the sampled networks than baseline methods."
Sampling directed graphs with random walks,"Bruno Ribeiro, Pinghui Wang, FabricioMurai, Donald F. Towsley",University of Massachusetts Amherst,,"Despite recent efforts to characterize complex networks such as citation graphs or online social networks (OSNs), little attention has been given to developing tools that can be used to characterize directed graphs in the wild, where no preprocessed data is available. The presence of hidden incoming edges but observable outgoing edges poses a challenge to characterize large directed graphs through crawling. Unless we can crawl the entire graph or the directed graph edges are highly symmetrical, hidden incoming edges induce unknown biases in the sampled nodes. In this work we propose a random walk sampling algorithm that is less prone these biases. The driving principle behind our random walk is to construct, in real-time, an undirected graph from the directed graph in a way that is consistent with the sample path followed by the algorithm walking on either graph. We also study outdegree and indegree distribution estimation. Out-degrees are visible to the walker while indegrees are hidden (latent). This makes for strikingly different estimation accuracies of in- and outdegree distributions. Our algorithm accurately estimates outdegree distributions of a variety of real world graphs while we show that, in the same scenarios, no algorithm can accurately estimate unbiased indegree distributions unless the directed graph is highly symmetrical."
Estimating and sampling graphs with multidimensional random walks,"Bruno Ribeiro, Donald F. Towsley",arXiv,"Frontier Sampling, Random Walks, MCMC, Estimates, Power Laws, Assortativity, Global Clustering Coefficient","Estimating characteristics of large graphs via sampling is a vital part of the study of complex networks. Current sampling methods such as (independent) random vertex and random walks are useful but have drawbacks. Random vertex sampling may require too many resources (time, bandwidth, or money). Random walks, which normally require fewer resources per sample, can suffer from large estimation errors in the presence of disconnected or loosely connected graphs. In this work we propose a new m-dimensional random walk that uses m dependent random walkers. We show that the proposed sampling method, which we call Frontier sampling, exhibits all of the nice sampling properties of a regular random walk. At the same time, our simulations over large real world graphs show that, in the presence of disconnected or loosely connected components, Frontier sampling exhibits lower estimation errors than regular random walks. We also show that Frontier sampling is more suitable than random vertex sampling to sample the tail of the degree distribution of the graph."
Scrapy-Based Crawling and User-Behavior Characteristics Analysis on Taobao,"Jing Wang, Yuchun Guo",IEEE,Taobao; bipartite graph; sampling method; MHRW; Scrapy; user behavior,"The widespread use of Internet provides a good environment for e-commerce. Study on e-commerce network characteristics always focuses on the Taobao. So far, researches based on Taobao are related to credit rating system, marketing strategy, analysis of characteristics of the seller and so on. The purpose of all these studies is to analyze online marketing transactions in e-commerce. In this paper, we analyze e-commerce network from the perspective of graph theory. Our contributions lie in two aspects as following: (1) crawl Taobao share-platform using Scrapy crawl architecture. After analyzing format of web pages in Taobao deeply, combined with the BFS and MHRW two kinds of sampling methods, we ran crawler on five PCs for 30 days. Besides, we list some big problems encountered in the crawling process, then give the final solution. In addition, we crawled one type of sellers' data in order to analyze relationships between sellers and buyers. (2) Analyze characteristics of users' behavior in Taobao share-platform based on obtained dataset. We intend to find the relationships between sellers and buyers connected by items in share-platform. Surprisingly, we find that share-platform is a tool for some buyers to advertise items for sellers who have high credit score, and other buyers only to help them to support the platform"
Characterizing Twitter with Respondent-Driven Sampling,"Mostafa Salehi, Hamid R. Rabiee,Nasim Nabavi, Shayan Pooya",IEEE,"Twitter, Online Social Network, Sampling, Crawling, RDS, MHRW, Public Timeline, Uniform","Twitter as one of the most important microblogging online social networks has attracted more than 200 million users in recent years. Although there have been several attempts on characterizing the Twitter by using incomplete sampled data, they have not been very successful to estimate the characteristics of the whole network. In this paper, we characterize Twitter by sampling from its social graph and user behaviors through a random walk based sampling technique called Respondent-Driven Sampling (RDS). To the best of our knowledge, for the first time RDS method and its estimator are used in order to obtain uniform unbiased estimation of several key structural and behavioral properties of Twitter. We compared the performance of the proposed method with other sampling methods such as Metropolis-Hasting Random Walk (MHRW) and sampling from active users (Timeline) against the uniform sampling (UNI). In order to gather the required data, we have implemented four independent crawlers. Our experimental results indicate that the RDS method exhibits lower estimation errors to the sample in- and out-degree distribution compared to MHRW and Timeline. We also show that RDS is more suitable to sample the followers vs. followings ratio, and the correlation between followers/followings vs. tweets."
Respondent-Driven Sampling for Characterizing Unstructured Overlays,"Amir H. Rasti, Mojtaba Torkjazi, RezaRejaie, Nick G. Duffield, WalterWillinger, Daniel Stutzbach",IEEE,,"This paper presents Respondent-Driven Sampling (RDS) as a promising technique to derive unbiased estimates of node properties in unstructured overlay networks such as Gnutella. Using RDS and a previously proposed technique, namely Metropolized Random Walk (MRW) sampling, we examine the efficiency of estimating node properties in unstructured overlays and identify some of the key factors that determine the accuracy of sampling techniques. We evaluate the RDS and MRW techniques using simulation over a wide range of static and dynamic graphs as well as experiments over a widely deployed Gnutella network. Our study sheds light on how the connectivity structure among nodes and its dynamics affect the accuracy and efficiency of the two sampling techniques. Both techniques exhibit a rather similar performance over a wide range of scenarios. However, RDS significantly outperforms MRW when the overlay structure exhibits a combination of highly skewed node degrees and highly skewed (local) clustering coefficients."
Graph Size Estimation,"Maciej Kurant, Carter T. Butts, AthinaMarkopoulou",arXiv,"graph size estimation, network sampling, random walk, online social networks, measurement","Many online networks are not fully known and are often studied via sampling. Random Walk (RW) based techniques are the current state-of-the-art for estimating nodal attributes and local graph properties, but estimating global properties remains a challenge. In this paper, we are interested in a fundamental property of this type - the graph size N, i.e., the number of its nodes. Existing methods for estimating N are (i) inefficient and (ii) cannot be easily used with RW sampling due to dependence between successive samples. In this paper, we address both problems. First, we propose IE (Induced Edges), an efficient technique for estimating N from an independence sample of graph's nodes. IE exploits the edges induced on the sampled nodes. Second, we introduce SafetyMargin, a method that corrects estimators for dependence in RW samples. Finally, we combine these two stand-alone techniques to obtain a RW-based graph size estimator. We evaluate our approach in simulations on a wide range of real-life topologies, and on several samples of Facebook. IE with SafetyMargin typically requires at least 10 times fewer samples than the state-of-the-art techniques (over 100 times in the case of Facebook) for the same estimation error."
Unbiased Sampling of Bipartite Graph,"Jing Wang, Yuchun Guo",IEEE,online social networks; bipartite graph; crawling; random walks; sampling ratio,"Increasing size of online social networks (OSNs) has given rise to sampling method studies that provide a relatively small but representative sample of large-scale OSNs so that the measurement and analysis burden can be affordable. So far, a number of sampling methods already exist that crawl social graphs. Most of them are suitable for one-mode graph where there is only one type of nodes. Literatures show that Metropolis-Hastings Random Walk (MHRW) produces unbiased samples with better performance than other sampling methods. But there are more and more online social networking sites with two types of nodes, such as Taobao and eBay. Representing these two-mode networks as bipartite graphs, we study the sampling methods for bipartite graphs in this paper. Our contributions include analyze the effectiveness of extending MHRW algorithm to bipartite graphs and making a modification in sampling procedure to improve the stability. Finally, we compare our MHRW sampling algorithm with Random Walk (RW) over the generated bipartite graphs as well as real two-mode network graphs. Simulations show that MHRW outperforms RW over bipartite graphs."
Unbiased Sampling Method Analysis on Online Social Network,"Siyao Wang, Bo Liu, Jiajun Zhou,Guangpeng Li",ICMEIT,"OSN, Unbiased Sampling, online convergence test.","The study of social graph structure has become extremely popular with the development of the Online Social Network (OSN). The main bottleneck is that the large account of social data makes it difficult to obtain and analyze, which consume extensive bandwidth, storage and computing resources. Thus unbiased sampling of OSN makes it possible to get accurate and representative properties of OSN graph. The widely used algorithm, Breadth-First Sampling (BFS)and Random Walking (RW) both are proved that there exists substantial bias towards high-degree nodes. By contrast the Metropolis-Hasting random walking (MHRW), re-weighted random walking (RWRW) and the unbiased sampling with reduced self-loop (USRS)which are all based on Markov Chain Monte Carlo(MCMC) method could produce approximate uniform samples. In this paper, we analyze the similarities and differences among the four algorithms, and show the performance of unbiased estimation and crawling efficient on the data set of Facebook. In addition, we provide formal convergence test to determine when the crawling process attain an equilibrium state and the number of nodes should be discarded."
Time-based sampling of social network activity graphs,"Nesreen Ahmed, Fredrick Berchmans,Jennifer Neville, Ramana Rao Kompella",ACM,"Online Social Networks, Graph Sampling, Link Analysis","While most research in online social networks (OSNs) in the past has focused on static friendship networks, social network activity graphs are quite important as well. However, characterizing social network activity graphs is computationally intensive; reducing the size of these graphs using sampling algorithms is critical. There are two important requirements—the sampling algorithm must be able to preserve core graph characteristics and be amenable to a streaming implementation since activity graphs are naturally evolving in a streaming fashion. Existing approaches satisfy either one or the other requirement, but not both. In this paper, we propose a novel sampling algorithm called Streaming Time Node Sampling (STNS) that exploits temporal clustering often found in real social networks. Using real communication data collected from Facebook and Twitter, we show that STNS significantly out-performs stateof-the-art sampling mechanisms such as node sampling and Forest Fire sampling, across both averages and distributions of several graph properties."
Unbiased Characterization of Node Pairs over Large Graphs,"Pinghui Wang, Junzhou Zhao, John C.S. Lui, Donald F. Towsley, Xiao-HongGuan",ACM,"Social network, graph sampling, random walks, homophily","Characterizing user pair relationships is important for applications such as friend recommendation and interest targeting in online social networks (OSNs). Due to the large-scale nature of such networks, it is infeasible to enumerate all user pairs and thus sampling is used. In this article, we show that it is a great challenge for OSN service providers to characterize user pair relationships, even when they possess the complete graph topology. The reason is that when sampling techniques (i.e., uniform vertex sampling (UVS) and random walk (RW)) are naively applied, they can introduce large biases, particularly for estimating similarity distribution of user pairs with constraints like existence of mutual neighbors, which is important for applications such as identifying network homophily. Estimating statistics of user pairs is more challenging in the absence of the complete topology information, as an unbiased sampling technique like UVS is usually not allowed and exploring the OSN graph topology is expensive. To address these challenges, we present unbiased sampling methods to characterize user pair properties based on UVS and RW techniques. We carry out an evaluation of our methods to show their accuracy and efficiency. Finally, we apply our methods to three OSNs—Foursquare, Douban, and Xiami—and discover that significant homophily is present in these networks."
Supervised sampling for networked data,"Meng Fang, Jie Yin, Xingquan Zhu",Signal Processing,"Supervised sampling, Random walks, Information network","Traditional graph sampling methods reduce the size of a large network via uniform sampling of nodes from the original network. The sampled network can be used to estimate the topological properties of the original network. However, in some application domains (e.g., disease surveillance), the goal of sampling is also to help identify a specified category of nodes (e.g., affected individuals) in a large network. This work therefore aims to, given a large information network, sample a subgraph under a specific goal of acquiring as many nodes with a particular category as possible. We refer to this problem as supervised sampling, where we sample a large network for a specific category of nodes. To this end, we model a network as a Markov chain and derive supervised random walks to learn stationary distributions of the sampled network. The learned stationary distribution can help identify the best node to be sampled in the next iteration. The iterative sampling process ensures that with new sampled nodes being acquired, supervised sampling can be strengthened in turn. Experiments on synthetic as well as real-world networks show that our supervised sampling algorithm outperforms existing methods in obtaining target nodes in the sampled networks."
Sampling node pairs over large graphs,"Pinghui Wang, Junzhou Zhao, John C.S. Lui, Donald F. Towsley, XiaohongGuan",The Chinese University of Hong Kong,,"Characterizing user pair relationships is important for applications such as friend recommendation and interest targeting in online social networks (OSNs). Due to the large scale nature of such networks, it is infeasible to enumerate all user pairs and so sampling is used. In this paper, we show that it is a great challenge even for OSN service providers to characterize user pair relationships even when they posses the complete graph topology. The reason is that when sampling techniques (i.e., uniform vertex sampling (UVS) and random walk (RW)) are naively applied, they can introduce large biases, in particular, for estimating similarity distribution of user pairs with constraints such as existence of mutual neighbors, which is important for applications such as identifying network homophily. Estimating statistics of user pairs is more challenging in the absence of the complete topology information, since an unbiased sampling technique such as UVS is usually not allowed, and exploring the OSN graph topology is expensive. To address these challenges, we present asymptotically unbiased sampling methods to characterize user pair properties based on UVS and RW techniques respectively. We carry out an evaluation of our methods to show their accuracy and efficiency. Finally, we apply our methods to two Chinese OSNs, Doudan and Xiami, and discover significant homophily is present in these two networks."
Sampling online social networks via heterogeneous statistics,"Xin Wang, Richard T. B. Ma, Yinlong Xu,Zhipeng Li",IEEE,,"Most sampling techniques for online social networks (OSNs) are based on a particular sampling method on a single graph, which is referred to as a statistic. However, various realizing methods on different graphs could possibly be used in the same OSN, and they may lead to different sampling efficiencies, i.e., asymptotic variances. To utilize multiple statistics for accurate measurements, we formulate a mixture sampling problem, through which we construct a mixture unbiased estimator which minimizes the asymptotic variance. Given fixed sampling budgets for different statistics, we derive the optimal weights to combine the individual estimators; given a fixed total budget, we show that a greedy allocation towards the most efficient statistic is optimal. In practice, the sampling efficiencies of statistics can be quite different for various targets and are unknown before sampling. To solve this problem, we design a two-stage framework which adaptively spends a partial budget to test different statistics and allocates the remaining budget to the inferred best statistic. We show that our two-stage framework is a generalization of 1) randomly choosing a statistic and 2) evenly allocating the total budget among all available statistics, and our adaptive algorithm achieves higher efficiency than these benchmark strategies in theory and experiment."
Space-efficient sampling from social activity streams,"Nesreen Ahmed, Jennifer Neville,Ramana Rao Kompella",arXiv,,"In order to efficiently study the characteristics of network domains and support development of network systems (e.g. algorithms, protocols that operate on networks), it is often necessary to sample a representative subgraph from a large complex network. Although recent subgraph sampling methods have been shown to work well, they focus on sampling from memory-resident graphs and assume that the sampling algorithm can access the entire graph in order to decide which nodes/edges to select. Many large-scale network datasets, however, are too large and/or dynamic to be processed using main memory (e.g., email, tweets, wall posts). In this work, we formulate the problem of sampling from large graph streams. We propose a streaming graph sampling algorithm that dynamically maintains a representative sample in a reservoir based setting. We evaluate the efficacy of our proposed methods empirically using several real-world data sets. Across all datasets, we found that our method produce samples that preserve better the original graph distributions."
Improving Random Walk Estimation Accuracy with Uniform Restarts,"Konstantin Avrachenkov, Bruno Ribeiro,Donald F. Towsley",Algorithms and Models for the Web-graph,"Sampling, Random Walk, Spectral Gap, PageRank, Online Social Network","This work proposes and studies the properties of a hybrid sampling scheme that mixes independent uniform node sampling and random walk (RW)-based crawling. We show that our sampling method combines the strengths of both uniform and RW sampling while minimizing their drawbacks. In particular, our method increases the spectral gap of the random walk, and hence, accelerates convergence to the stationary distribution. The proposed method resembles PageRank but unlike PageRank preserves time-reversibility. Applying our hybrid RW to the problem of estimating degree distributions of graphs shows promising results."
Crawling Online Social Graphs,"Shaozhi Ye, Juan Lang, Shyhtsun FelixWu",IEEE,,"Extensive research has been conducted on top of online social networks (OSNs), while little attention has been paid to the data collection process. Due to the large scale of OSNs and their privacy control policies, a partial data set is often used for analysis. The data set analyzed is decided by many factors including the choice of seeds, node selection algorithms, and the sample size. These factors may introduce biases and further contaminate or even skew the results. To evaluate the impact of different factors, this paper examines the OSN graph crawling problem, where the nodes are OSN users and the edges are the links (or relationship) among these users. More specifically, by looking at various factors in the crawling process, the following problems are addressed in this paper: • Efficiency: How fast different crawlers discover nodes/links; • Sensitivity: How different OSNs and the number of protected users affect crawlers; • Bias: How major graph properties are skewed. To the best of our knowledge, our simulations on four real world online social graphs provide the first in-depth empirical answers to these questions."
On sampling social networking services,Baiyang Wang,arXiv,,"This article aims at summarizing existing methods for sampling social networking services and proposing a faster confidence interval for related sampling methods. Social networking services (SNSs), such as Facebook and Twitter, are an important part of the current Internet culture. Collecting samples from these networks, therefore, is necessary for learning more about sociological or cultural issues. However, typical sampling methods for networks, such as nodebased or link-based methods, are not always feasible for social networking services. Alternate approaches such as snowball sampling or random walk (RW) are applied to gather information from social networking services more efficiently. Thus it is beneficial to compare various sampling approaches for SNSs under different circumstances. Making statistical inference from the gathered information constitutes another problem, including the determination of the sampling probabilities and the estimation of related attributes for sampled networks. Many valuable approaches have been proposed and refined, yet their numerical properties have not been studied sufficiently, some of which will be shown in the following. Simulations will be carried out in terms of respondent driven sampling (RDS), which has many variations and comprises several important network sampling methods. Although it was initially invented to detect hidden population in society, it has been generalized and widely discussed in the related literature. Based on these existing methods, the author also proposes some modification of existing estimation methods and the construction of a faster confidence interval which has not been covered in the current literature."
Representing Sentences as Low-Rank Subspaces,"Jiaqi Mu, Suma Bhat, PramodViswanath",arXiv,,"Sentences are important semantic units of natural language. A generic, distributional representation of sentences that can capture the latent semantics is beneficial to multiple downstream applications. We observe a simple geometry of sentences -- the word representations of a given sentence (on average 10.23 words in all SemEval datasets with a standard deviation 4.84) roughly lie in a low-rank subspace (roughly, rank 4). Motivated by this observation, we represent a sentence by the low-rank subspace spanned by its word vectors. Such an unsupervised representation is empirically validated via semantic textual similarity tasks on 19 different datasets, where it outperforms the sophisticated neural network models, including skip-thought vectors, by 15% on average."
Unsupervised Learning of Sentence Embeddings using Compositional n-Gram Features,"Matteo Pagliardini, Prakhar Gupta,Martin Jaggi",arXiv,,"The recent tremendous success of unsupervised word embeddings in a multitude of applications raises the obvious question if similar methods could be derived to improve embeddings (i.e. semantic representations) of word sequences as well. We present a simple but efficient unsupervised objective to train distributed representations of sentences. Our method outperforms the state-of-the-art unsupervised models on most benchmark tasks, highlighting the robustness of the produced general-purpose sentence embeddings."
Context Aware Document Embedding,"Zhaocheng Zhu, Junfeng Hu",arXiv,,"Recently, doc2vec has achieved excellent results in different tasks. In this paper, we present a context aware variant of doc2vec. We introduce a novel weight estimating mechanism that generates weights for each word occurrence according to its contribution in the context, using deep neural networks. Our context aware model can achieve similar results compared to doc2vec initialized byWikipedia trained vectors, while being much more efficient and free from heavy external corpus. Analysis of context aware weights shows they are a kind of enhanced IDF weights that capture sub-topic level keywords in documents. They might result from deep neural networks that learn hidden representations with the least entropy."
Improving a tf-idf weighted document vector embedding,Craig W. Schmidt,arXiv,,"We examine a number of methods to compute a dense vector embedding for a document in a corpus, given a set of word vectors such as those from word2vec or GloVe. We describe two methods that can improve upon a simple weighted sum, that are optimal in the sense that they maximizes a particular weighted cosine similarity measure. We consider several weighting functions, including inverse document frequency (idf), smooth inverse frequency (SIF), and the sub-sampling function used in word2vec. We find that idf works best for our applications. We also use common component removal proposed by Arora et al. as a post-process and find it is helpful in most cases. We compare these embeddings variations to the doc2vec embedding on a new evaluation task using TripAdvisor reviews, and also on the CQADupStack benchmark from the literature."
Structural-Aware Sentence Similarity with Recursive Optimal Transport,"Zihao Wang, Yuhan Zhang, Hao Wu",arXiv,,"Measuring sentence similarity is a classic topic in natural language processing. Light-weighted similarities are still of particular practical significance even when deep learning models have succeeded in many other tasks. Some light-weighted similarities with more theoretical insights have been demonstrated to be even stronger than supervised deep learning approaches. However, the successful light-weighted models such as Word Mover's Distance [Kusner et al., 2015] or Smooth Inverse Frequency [Arora et al., 2017] failed to detect the difference from the structure of sentences, i.e. order of words. To address this issue, we present Recursive Optimal Transport (ROT) framework to incorporate the structural information with the classic OT. Moreover, we further develop Recursive Optimal Similarity (ROTS) for sentences with the valuable semantic insights from the connections between cosine similarity of weighted average of word vectors and optimal transport. ROTS is structural-aware and with low time complexity compared to optimal transport. Our experiments over 20 sentence textural similarity (STS) datasets show the clear advantage of ROTS over all weakly supervised approaches. Detailed ablation study demonstrate the effectiveness of ROT and the semantic insights."
"UWB at SemEval-2016 Task 1: Semantic Textual Similarity using Lexical, Syntactic, and Semantic Information","Tomas Brychcin, Lukás Svoboda",ACL,,"We present our UWB system for Semantic Textual Similarity (STS) task at SemEval 2016. Given two sentences, the system estimates the degree of their semantic similarity. We use state-of-the-art algorithms for the meaning representation and combine them with the best performing approaches to STS from previous years. These methods benefit from various sources of information, such as lexical, syntactic, and semantic. In the monolingual task, our system achieve mean Pearson correlation 75.7% compared with human annotators. In the cross-lingual task, our system has correlation 86.3% and is ranked first among 26 systems."
QLUT at SemEval-2017 Task 1: Semantic Textual Similarity Based on Word Embeddings,"Fanqing Meng, Wenpeng Lu, YutengZhang, Jinyong Cheng, Yuehan Du,Shuwang Han",ACL,,"This paper reports the details of our submissions in the task 1 of SemEval 2017. This task aims at assessing the semantic textual similarity of two sentences or texts. We submit three unsupervised systems based on word embeddings. The differences between these runs are the various preprocessing on evaluation data. The best performance of these systems on the evaluation of Pearson correlation is 0.6887. Unsurprisingly, results of our runs demonstrate that data preprocessing, such as tokenization, lemmatization, extraction of content words and removing stop words, is helpful and plays a significant role in improving the performance of models."
USFD at SemEval-2016 Task 1: Putting different State-of-the-Arts into a Box,"Ahmet Aker, Frédéric Blain, AndrésDuque, Marina Fomicheva, Jurica Seva,Kashif Shah, Daniel Beck",ACL,,In this paper we describe our participation in the STS Core subtask which is the determination of the monolingual semantic similarity between pair of sentences. In our participation we adapted state-ofthe-art approaches from related work applied on previous STS Core subtasks and run them on the 2016 data. We investigated the performance of single methods but also the combination of them. Our results show that Convolutional Neural Networks (CNN) are superior to both the Monolingual Word Alignment and the Word2Vec approaches. The combination of all the three methods performs slightly better than using CNN only. Our results also show that the performance of our systems varies between the datasets.
Learning Sentence Embeddings Based on Weighted Contexts from Unlabelled Data,"Yixin Ding, Liutong Xu",IEEE,unsupervised learning; sentence embeddings; semantic texual similarity,"Supervised learning and unsupervised learning are mainstream methods to solve semantic textual similarity tasks. However, it is obvious that supervised learning needs substantial labeled data which is hard to obtain in reality. Therefore, we turn our attention to construct sentence embeddings using unlabelled data due to lack of annotated data and success of unsupervised word embeddings in multiple tasks. We present a simple but efficient unsupervised learning method of sentence embeddings inspired by attention mechanism, in which weighted contexts are added to models to train distributed sentence representations inspired by word2vec. Our method outperforms state-of-the-art unsupervised models on semantic textual similarity tasks."
Unsupervised Random Walk Sentence Embeddings: A Strong but Simple Baseline,Kawin Ethayarajh,ACL,,"Using a random walk model of text generation, Arora et al. (2017) proposed a strong baseline for computing sentence embeddings: take a weighted average of word embeddings and modify with SVD. This simple method even outperforms far more complex approaches such as LSTMs on textual similarity tasks. In this paper, we first show that word vector length has a confounding effect on the probability of a sentence being generated in Arora et al.’s model. We propose a random walk model that is robust to this confound, where the probability of word generation is inversely related to the angular distance between the word and sentence embeddings. Our approach beats Arora et al.’s by up to 44.4% on textual similarity tasks and is competitive with state-of-the-art methods. Unlike Arora et al.’s method, ours requires no hyperparameter tuning, which means it can be used when there is no labelled data."
CBOS: Continuos bag of sentences for learning sentence embeddings,"Ye Yuan, Yue Zhang",IEEE,NN; sentence embeddings; distributed sentence representation,"There has been recent work learning distributed sentence representations, which utilise neighbouring sentences as context for learning the embedding of a sentence. The setting is reminiscent of training word embeddings, yet no work has reported a baseline using the same training objective as learning word vectors. We fill this gap by empirically investigating the use of a Continuous Bag-of-Word (CBOW) objective, predicting the current sentence using its context sentences. We name this method a Continuous Bag-of-Sentences (CBOS) method. Results on standard benchmark show that CBOS is a highly competitive baseline for training sentence embeddings, outperforming most existing methods for text similarity measurement."
Modelling Implicit Content Networks to Track Information Propagation Across Media Sources to Analyze News Events,"Anirudh Joshi, Richard O. Sinnott",IEEE,,"With the rise of the Internet as the premier news source for billions of people around the world, the propagation of news media online now influences many critical decisions made by society every day. Fake news is now a mainstream concern. In the context of news propagation, recent works in media analysis largely focus on extracting clusters, news events, stories or tracking links or conserved sentences at aggregate levels between sources. However, the insight provided by these approaches is limited for analysis and context for end users. To tackle this, we present an approach to model implicit content networks at a semantic level that is inherent within news event clusters as seen by users on a daily basis through the generation of semantic content indexes. The approach is based on an endto-end unsupervised machine learning system trained on real-life news data that combine together with algorithms to generate useful contextual views of the sources and the inter-relationships of news events. We illustrate how the approach is able to track conserved semantic context through the use of a combination of machine learning techniques, including document vectors, k-nearest neighbors and the use of hierarchical agglomerative clustering. We demonstrate the system by training semantic vector models on realistic real-world data taken from the Signal News dataset. We quantitatively evaluate the performance against existing state of the art systems to demonstrate the end-to-end capability. We then qualitatively demonstrate the usefulness of a news event centered semantic content index graph for enduser applications. This is evaluated with respect to the goal of generating rich contextual interconnections and providing differential background on how news media sources report, parrot and position information on ostensibly identical news events."
Siamese CBOW: Optimizing Word Embeddings for Sentence Representations,"Tom Kenter, Alexey Borisov, Maartende Rijke",ACL,,"We present the Siamese Continuous Bag of Words (Siamese CBOW) model, a neural network for efficient estimation of high-quality sentence embeddings. Averaging the embeddings of words in a sentence has proven to be a surprisingly successful and efficient way of obtaining sentence embeddings. However, word embeddings trained with the methods currently available are not optimized for the task of sentence representation, and, thus, likely to be suboptimal. Siamese CBOW handles this problem by training word embeddings directly for the purpose of being averaged. The underlying neural network learns word embeddings by predicting, from a sentence representation, its surrounding sentences. We show the robustness of the Siamese CBOW model by evaluating it on 20 datasets stemming from a wide variety of sources."
Evaluating Word Embedding Hyper-Parameters for Similarity and Analogy Tasks,"Maryam Fanaeepour, AdamMakarucha, Jey Han Lau",arXiv,,"The versatility of word embeddings for various applications is attracting researchers from various fields. However, the impact of hyper-parameters when training embedding model is often poorly understood. How much do hyper-parameters such as vector dimensions and corpus size affect the quality of embeddings, and how do these results translate to downstream applications? Using standard embedding evaluation metrics and datasets, we conduct a study to empirically measure the impact of these hyper-parameters."
MappSent at IJCNLP-2017 Task 5: A Textual Similarity Approach Applied to Multi-choice Question Answering in Examinations,Amir Hazem,ACL,,"In this paper we present MappSent, a textual similarity approach that we applied to the multi-choice question answering in exams shared task. MappSent has initially been proposed for question-to-question similarity hazem2017. In this work, we present the results of two adaptations of MappSent for the question answering task on the English dataset."
UMD-TTIC-UW at SemEval-2016 Task 1:Attention-Based Multi-Perspective Convolutional Neural Networks for Textual Similarity Measurement,"Hua He, John Wieting, Kevin Gimpel,Jinfeng Rao, Jimmy J. Lin",ACL,,"We describe an attention-based convolutional neural network for the English semantic textual similarity (STS) task in the SemEval2016 competition (Agirre et al., 2016). We develop an attention-based input interaction layer and incorporate it into our multiperspective convolutional neural network (He et al., 2015), using the PARAGRAM-PHRASE word embeddings (Wieting et al., 2016) trained on paraphrase pairs. Without using any sparse features, our final model outperforms the winning entry in STS2015 when evaluated on the STS2015 data."
Pushing the Limits of Paraphrastic Sentence Embeddings with Millions of Machine Translations,"John Wieting, Kevin Gimpel",ACL,,"We describe ParaNMT-50M, a dataset of more than 50 million English-English sentential paraphrase pairs. We generated the pairs automatically by using neural machine translation to translate the non-English side of a large parallel corpus, following Wieting et al. (2017). Our hope is that ParaNMT-50M can be a valuable resource for paraphrase generation and can provide a rich source of semantic knowledge to improve downstream natural language understanding tasks. To show its utility, we use ParaNMT-50M to train paraphrastic sentence embeddings that outperform all supervised systems on every SemEval semantic textual similarity competition, in addition to showing how it can be used for paraphrase generation."
Classifying Challenging Behaviors in Autism Spectrum Disorder with Neural Document Embeddings,Abigail Atchison,Chapman University,,"The understanding and treatment of challenging behaviors in individuals with Autism Spectrum Disorder is paramount to enabling the success of behavioral therapy; an essential step in this process being the labeling of challenging behaviors demonstrated in therapy sessions. These manifestations di↵er across individuals and within individuals over time and thus, the appropriate classification of a challenging behavior when considering purely qualitative factors can be unclear. In this thesis we seek to add quantitative depth to this otherwise qualitative task of challenging behavior classification. We do so through the application of natural language processing techniques to behavioral descriptions extracted from the CARD Skills dataset. Specifically, we construct 3 sets of 50-dimensional document embeddings to represent the 1,917 recorded instances of challenging behaviors demonstrated in Applied Behavior Analysis therapy. These embeddings are learned through three processes: a TF-IDF weighted sum of Word2Vec embeddings, Doc2Vec embeddings which use hierarchical softmax as an output layer, and Doc2Vec which optimizes the original Doc2Vec architecture through Negative Sampling. Once created, these embeddings are initially used as input to a Support Vector Machine classifier to demonstrate the success of binary classification within this problem set. This preliminary exploration achieves promising classification accuracies ranging from 78.2-100% and establishes the separability of challenging behaviors given their neural embeddings. We next construct a multi-class classification model via a Gaussian Process Classifier fitted with Laplace approximation. This classification model, trained on an 80/20 stratified split of the seven most frequently occurring behaviors in the dataset, produces an accuracy of 82.7%. Through this exploration we demonstrate that the semantic queues derived from the language of challenging behavior descriptions, modeled using natural language processing techniques, can be successfully leveraged in classification architectures. This study represents the first of its kind, providing a proof of concept for the application of machine learning to the observations of challenging behaviors demonstrated in ASD with the ultimate goal of improving the ecacy of the behavioral treatments which intrinsically rely on the accurate identification of these behaviors."
SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation,"Daniel M. Cer, Mona T. Diab, EnekoAgirre, Iñigo Lopez-Gazpio, LuciaSpecia",arXiv,,"Semantic Textual Similarity (STS) measures the meaning similarity of sentences. Applications include machine translation (MT), summarization, generation, question answering (QA), short answer grading, semantic search, dialog and conversational systems. The STS shared task is a venue for assessing the current state-of-the-art. The 2017 task focuses on multilingual and cross-lingual pairs with one sub-track exploring MT quality estimation (MTQE) data. The task obtained strong participation from 31 teams, with 17 participating in all language tracks. We summarize performance and review a selection of well performing methods. Analysis highlights common errors, providing insight into the limitations of existing models. To support ongoing work on semantic representations, the STS Benchmark is introduced as a new shared training and evaluation set carefully selected from the corpus of English STS shared task data (2012-2017)."
UMDeep at SemEval-2017 Task 1: End-to-End Shared Weight LSTM Model for Semantic Textual Similarity,"Joe Barrow, Denis Peskov",ACL,,"We describe a modified shared-LSTM network for the Semantic Textual Similarity (STS) task at SemEval-2017. The network builds on previously explored Siamese network architectures. We treat max sentence length as an additional hyperparameter to be tuned (beyond learning rate, regularization, and dropout). Our results demonstrate that hand-tuning max sentence training length significantly improves final accuracy. After optimizing hyperparameters, we train the network on the multilingual semantic similarity task using pre-translated sentences. We achieved a correlation of 0.4792 for all the subtasks. We achieved the fourth highest team correlation for Task 4b, which was our best relative placement."
IHS-RD-Belarus at SemEval-2016 Task 1: Multistage Approach for Measuring Semantic Similarity,"Maryna Beliuha, Maryna Chernyshevich",ACL,,This paper describes the system for rating the degree of semantic equivalence between two text snippets developed by IHS-RD-Belarus for the SemEval 2016 STS shared task (Task 1). To predict the human ratings of text similarity we use a support vector regression model with multiple features representing similarity and difference scores calculated for each pair of sentences.
All-but-the-Top: Simple and Effective Post processing for Word Representations,"Jiaqi Mu, Suma Bhat, PramodViswanath",arXiv,,"Real-valued word representations have transformed NLP applications; popular examples are word2vec and GloVe, recognized for their ability to capture linguistic regularities. In this paper, we demonstrate a {\em very simple}, and yet counter-intuitive, postprocessing technique -- eliminate the common mean vector and a few top dominating directions from the word vectors -- that renders off-the-shelf representations {\em even stronger}. The postprocessing is empirically validated on a variety of lexical-level intrinsic tasks (word similarity, concept categorization, word analogy) and sentence-level tasks (semantic textural similarity and { text classification}) on multiple datasets and with a variety of representation methods and hyperparameter choices in multiple languages; in each case, the processed representations are consistently better than the original ones."
ASOBEK at SemEval-2016 Task 1: Sentence Representation with Character N-gram Embeddings for Semantic Textual Similarity,"Asli Eyecioglu, Bill Keller",ACL,,"A growing body of research has recently been conducted on semantic textual similarity using a variety of neural network models. While recent research focuses on word-based representation for phrases, sentences and even paragraphs, this study considers an alternative approach based on character n-grams. We generate embeddings for character n-grams using a continuous-bag-of-n-grams neural network model. Three different sentence representations based on n-gram embeddings are considered. Results are reported for experiments with bigram, trigram and 4-gram embeddings on the STS Core dataset for SemEval-2016 Task 1."
"A SIMPLE BUT TOUGH-TO-BEAT BASELINE FOR SENTENCE EMBEDDINGS
","Sanjeev Arora, Yingyu Liang",,,
A Joint Model for Answer Sentence Ranking and Answer Extraction,"Md Arafat Sultan, Vittorio Castelli, RaduFlorian",ACL,,"Answer sentence ranking and answer extraction are two key challenges in question answering that have traditionally been treated in isolation, i.e., as independent tasks. In this article, we (1) explain how both tasks are related at their core by a common quantity, and (2) propose a simple and intuitive joint probabilistic model that addresses both via joint computation but task-specific application of that quantity. In our experiments with two TREC datasets, our joint model substantially outperforms state-of-the-art systems in both tasks."
Automatic Short Answer Scoring based on Paragraph Embeddings,"Sarah Mohamed Hassan, Aly Fahmy,Mohammad El-Ramly",International Journal of Advanced Computer Science and Applications,Automatic scoring; short answer; Pearson correlation coefficient; RMSE; deep learning,Automatic scoring systems for students’ short answers can eliminate from instructors the burden of grading large number of test questions and facilitate performing even more assessments during lectures especially when number of students is large. This paper presents a supervised learning approach for short answer automatic scoring based on paragraph embeddings. We review significant deep learning based models for generating paragraph embeddings and present a detailed empirical study of how the choice of paragraph embedding model influences accuracy in the task of automatic scoring.
Mapping sentences to concept transferred space for semantic textual similarity,"Heyan Huang, Hao Wu, Xiaochi Wei,Yang Gao, Shumin Shi",Knowledge and Information Systems,"Semantic textual similarity, Concept transferred space, Information content, WordNet","Semantic textual similarity (STS) seeks to assess the degree of semantic equivalence between two sentences or snippets of texts. Most methods of STS are based on word surface and deem words as meaning unrelated symbols, which makes these methods indiscriminative for ubiquitous conceptual association among words. Recently, concept transferred space (CTS) is proposed to solve word conceptual association problem. It is generated from the noun concepts with their IS-A relations in WordNet. However, the CTS-based model can only calculate nouns; as a result, a large number of words, i.e., verbs, adjectives, adverbs as well as out-of-vocabulary named entities (OOV NEs), are neglected, thus resulting in information loss in the semantic similarity evaluation. This paper presents ways to solve this problem: To involve words other than nouns, derivational links in WordNet are employed to associate verbs, adjectives, and adverbs with their corresponding noun concepts; to prevent information loss by OOV NEs, the increased quantity of information of them is predicted according to the tendency learned from known NEs. Moreover, to further improve the accuracy of the CTS-based model, we take the importance of different types of words into consideration by assigning corresponding weights for them. Experimental results suggest that the proposed comprehensive CTS-based model achieves significant improvement compared with the primitive one without the non-nominal words, OOV NEs, and word weights and also outperforms all the yearly state-of-the-art systems at the *SEM/SemEval 2013–2016 STS tasks. Additionally, at the SemEval 2017 STS task, our team with the comprehensive CTS-based model ranked the second and the first among all teams and on Track 1 dataset, respectively."
MIPA: Mutual Information Based Paraphrase Acquisition via Bilingual Pivoting,"Tomoyuki Kajiwara, Mamoru Komachi,Daichi Mochihashi",ACL,,"We present a pointwise mutual information (PMI)-based approach to formalize paraphrasability and propose a variant of PMI, called MIPA, for the paraphrase acquisition. Our paraphrase acquisition method first acquires lexical paraphrase pairs by bilingual pivoting and then reranks them by PMI and distributional similarity. The complementary nature of information from bilingual corpora and from monolingual corpora makes the proposed method robust. Experimental results show that the proposed method substantially outperforms bilingual pivoting and distributional similarity themselves in terms of metrics such as MRR, MAP, coverage, and Spearman’s correlation."
Decoding Decoders: Finding Optimal Representation Spaces for Unsupervised Similarity Tasks,"Vitalii Zhelezniak, Dan Busbridge, AprilShen, Samuel L. Smith, Nils Y.Hammerla",arXiv,,"Experimental evidence indicates that simple models outperform complex deep networks on many unsupervised similarity tasks. We provide a simple yet rigorous explanation for this behaviour by introducing the concept of an optimal representation space, in which semantically close symbols are mapped to representations that are close under a similarity measure induced by the model's objective function. In addition, we present a straightforward procedure that, without any retraining or architectural modifications, allows deep recurrent models to perform equally well (and sometimes better) when compared to shallow models. To validate our analysis, we conduct a set of consistent empirical evaluations and introduce several new sentence embedding models in the process. Even though this work is presented within the context of natural language processing, the insights are readily applicable to other domains that rely on distributed representations for transfer tasks."
A Bilingual Generative Transformer for Semantic Sentence Embedding,"John Wieting, Graham Neubig, Taylor Berg-Kirkpatrick",arXiv,,"Semantic sentence embedding models encode natural language sentences into vectors, such that closeness in embedding space indicates closeness in the semantics between the sentences. Bilingual data offers a useful signal for learning such embeddings: properties shared by both sentences in a translation pair are likely semantic, while divergent properties are likely stylistic or language-specific. We propose a deep latent variable model that attempts to perform source separation on parallel sentences, isolating what they have in common in a latent semantic vector, and explaining what is left over with language-specific latent vectors. Our proposed approach differs from past work on semantic sentence encoding in two ways. First, by using a variational probabilistic framework, we introduce priors that encourage source separation, and can use our model's posterior to predict sentence embeddings for monolingual data at test time. Second, we use high-capacity transformers as both data generating distributions and inference networks -- contrasting with most past work on sentence embeddings. In experiments, our approach substantially outperforms the state-of-the-art on a standard suite of unsupervised semantic similarity evaluations. Further, we demonstrate that our approach yields the largest gains on more difficult subsets of these evaluations where simple word overlap is not a good indicator of similarity."
Supervised Learning of Universal Sentence Representations from Natural Language Inference Data,"Alexis Conneau, Douwe Kiela, HolgerSchwenk, Loïc Barrault, Antoine Bordes",arXiv,,"Many modern NLP systems rely on word embeddings, previously trained in an unsupervised manner on large corpora, as base features. Efforts to obtain embeddings for larger chunks of text, such as sentences, have however not been so successful. Several attempts at learning unsupervised representations of sentences have not reached satisfactory enough performance to be widely adopted. In this paper, we show how universal sentence representations trained using the supervised data of the Stanford Natural Language Inference datasets can consistently outperform unsupervised methods like SkipThought vectors on a wide range of transfer tasks. Much like how computer vision uses ImageNet to obtain features, which can then be transferred to other tasks, our work tends to indicate the suitability of natural language inference for transfer learning to other NLP tasks. Our encoder is publicly available."
An efficient framework for learning sentence representations,"Lajanugen Logeswaran, Honglak Lee",arXiv,,"In this work we propose a simple and efficient framework for learning sentence representations from unlabelled data. Drawing inspiration from the distributional hypothesis and recent work on learning sentence representations, we reformulate the problem of predicting the context in which a sentence appears as a classification problem. Given a sentence and its context, a classifier distinguishes context sentences from other contrastive sentences based on their vector representations. This allows us to efficiently learn different types of encoding functions, and we show that the model learns high-quality sentence representations. We demonstrate that our sentence representations outperform state-of-the-art unsupervised and supervised representation learning methods on several downstream NLP tasks that involve understanding sentence semantics while achieving an order of magnitude speedup in training time."
Learning Paraphrastic Sentence Embeddings from Back-Translated Bitext,"John Wieting, Jonathan Mallinson,Kevin Gimpel",ACL,,"We consider the problem of learning general-purpose, paraphrastic sentence embeddings in the setting of Wieting et al. (2016b). We use neural machine translation to generate sentential paraphrases via back-translation of bilingual sentence pairs. We evaluate the paraphrase pairs by their ability to serve as training data for learning paraphrastic sentence embeddings. We find that the data quality is stronger than prior work based on bitext and on par with manually-written English paraphrase pairs, with the advantage that our approach can scale up to generate large training sets for many languages and domains. We experiment with several language pairs and data sources, and develop a variety of data filtering techniques. In the process, we explore how neural machine translation output differs from human-written sentences, finding clear differences in length, the amount of repetition, and the use of rare words."
Evaluation of Unsupervised Compositional Representations,"Hanan Aldarmaki, Mona T. Diab",ACL,,"We evaluated various compositional models, from bag-of-words representations to compositional RNN-based models, on several extrinsic supervised and unsupervised evaluation benchmarks. Our results confirm that weighted vector averaging can outperform context-sensitive models in most benchmarks, but structural features encoded in RNN models can also be useful in certain classification tasks. We analyzed some of the evaluation datasets to identify the aspects of meaning they measure and the characteristics of the various models that explain their performance variance."
Exploiting Invertible Decoders for Unsupervised Sentence Representation Learning,"Shuai Tang, Virginia R. de Sa",ACL,,"Encoder-decoder models for unsupervised sentence representation learning using the distributional hypothesis effectively constrain the learnt representation of a sentence to only that needed to reproduce the next sentence. While the decoder is important to constrain the representation, these models tend to discard the decoder after training since only the encoder is needed to map the input sentence into a vector representation. However, parameters learnt in the decoder also contain useful information about the language. In order to utilise the decoder after learning, we present two types of decoding functions whose inverse can be easily derived without expensive inverse calculation. Therefore, the inverse of the decoding function serves as another encoder that produces sentence representations. We show that, with careful design of the decoding functions, the model learns good sentence representations, and the ensemble of the representations produced from the encoder and the inverse of the decoder demonstrate even better generalisation ability and solid transferability."
"On the Benefit of Combining Neural, Statistical and External Features for Fake News Identification","Gaurav Bhatt, Aman Sharma, ShivamSharma, Ankush Nagpal,Balasubramanian Raman, AnkushMittal",arXiv,,"Identifying the veracity of a news article is an interesting problem while automating this process can be a challenging task. Detection of a news article as fake is still an open question as it is contingent on many factors which the current state-of-the-art models fail to incorporate. In this paper, we explore a subtask to fake news identification, and that is stance detection. Given a news article, the task is to determine the relevance of the body and its claim. We present a novel idea that combines the neural, statistical and external features to provide an efficient solution to this problem. We compute the neural embedding from the deep recurrent model, statistical features from the weighted n-gram bag-of-words model and handcrafted external features with the help of feature engineering heuristics. Finally, using deep neural layer all the features are combined, thereby classifying the headline-body news pair as agree, disagree, discuss, or unrelated. We compare our proposed technique with the current state-of-the-art models on the fake news challenge dataset. Through extensive experiments, we find that the proposed model outperforms all the state-of-the-art techniques including the submissions to the fake news challenge."
Tweaks and Tricks for Word Embedding Disruptions,"Amir Hazem, Nicolas Hernandez",ACL,,"Word embeddings are established as very effective models used in several NLP applications. If they differ in their architecture and training process, they often exhibit similar properties and remain vector space models with continuously-valued dimensions describing the observed data. The complexity resides in the developed strategies for learning the values within each dimensional space. In this paper, we introduce the concept of disruption which we define as a side effect of the training process of embedding models. Disruptions are viewed as a set of embedding values that are more likely to be noise than effective descriptive features. We show that dealing with disruption phenomenon is of a great benefit to bottom-up sentence embedding representation. By contrasting several in-domain and pre-trained embedding models, we propose two simple but very effective tweaking techniques that yield strong empirical improvements on textual similarity task."
Learning Distributed Representations of Sentences from Unlabelled Data,"Felix Hill, Kyunghyun Cho, AnnaKorhonen",arXiv,,"Unsupervised methods for learning distributed representations of words are ubiquitous in today's NLP research, but far less is known about the best ways to learn distributed phrase or sentence representations from unlabelled data. This paper is a systematic comparison of models that learn such representations. We find that the optimal approach depends critically on the intended application. Deeper, more complex models are preferable for representations to be used in supervised systems, but shallow log-linear models work best for building representation spaces that can be decoded with simple spatial distance metrics. We also propose two new unsupervised representation-learning objectives designed to optimise the trade-off between training time, domain portability and performance."
Correlation Coefficients and Semantic Textual Similarity,"Vitalii Zhelezniak, Aleksandar Savkov,April Shen, Nils Y. Hammerla",ACL,,"A large body of research into semantic textual similarity has focused on constructing state-of-the-art embeddings using sophisticated modelling, careful choice of learning signals and many clever tricks. By contrast, little attention has been devoted to similarity measures between these embeddings, with cosine similarity being used unquestionably in the majority of cases. In this work, we illustrate that for all common word vectors, cosine similarity is essentially equivalent to the Pearson correlation coefficient, which provides some justification for its use. We thoroughly characterise cases where Pearson correlation (and thus cosine similarity) is unfit as similarity measure. Importantly, we show that Pearson correlation is appropriate for some word vectors but not others. When it is not appropriate, we illustrate how common non-parametric rank correlation coefficients can be used instead to significantly improve performance. We support our analysis with a series of evaluations on word-level and sentence-level semantic textual similarity benchmarks. On the latter, we show that even the simplest averaged word vectors compared by rank correlation easily rival the strongest deep representations compared by cosine similarity."
A New Relational Networks Sampling Algorithm Using Topologically Divided Stratums,"Xiaolin Du, Yunming Ye, Yueping Li, GeSong",,,
Metropolis Algorithms for Representative Subgraph Sampling,"Christian Hübler, Hans-Peter Kriegel,Karsten M. Borgwardt, ZoubinGhahramani",IEEE,,"While data mining in chemoinformatics studied graph data with dozens of nodes, systems biology and the Internet are now generating graph data with thousands and millions of nodes. Hence data mining faces the algorithmic challenge of coping with this significant increase in graph size: Classic algorithms for data analysis are often too expensive and too slow on large graphs. While one strategy to overcome this problem is to design novel efficient algorithms, the other is to ’reduce’ the size of the large graph by sampling. This is the scope of this paper: We will present novel Metropolis algorithms for sampling a ’representative’ small subgraph from the original large graph, with ’representative’ describing the requirement that the sample shall preserve crucial graph properties of the original graph. In our experiments, we improve over the pioneering work of Leskovec and Faloutsos (KDD 2006), by producing representative subgraph samples that are both smaller and of higher quality than those produced by other methods from the literature."
Sampling community structure,"Arun S. Maiya, Tanya Y. Berger-Wolf",ACM,"sampling, social network analysis, community detection, complex networks, graphs, clustering","We propose a novel method, based on concepts from expander graphs, to sample communities in networks. We show that our sampling method, unlike previous techniques, produces subgraphs representative of community structure in the original network. These generated subgraphs may be viewed as stratified samples in that they consist of members from most or all communities in the network. Using samples produced by our method, we show that the problem of community detection may be recast into a case of statistical relational learning. We empirically evaluate our approach against several real-world datasets and demonstrate that our sampling method can effectively be used to infer and approximate community affiliation in the larger network."
Statistical properties of sampled networks.,"Sang Hoon Lee, Pan-Jun Kim, HawoongJeong",arXiv,,"We study the statistical properties of the sampled scale-free networks, deeply related to the proper identification of various real-world networks. We exploit three methods of sampling and investigate the topological properties such as degree and betweenness centrality distribution, average path length, assortativity, and clustering coefficient of sampled networks compared with those of original networks. It is found that the quantities related to those properties in sampled networks appear to be estimated quite differently for each sampling method. We explain why such a biased estimation of quantities would emerge from the sampling procedure and give appropriate criteria for each sampling method to prevent the quantities from being overestimated or underestimated."
A New Social Network Sampling Algorithm Based on Temperature Conduction Model,"Xiaolin Du, Yunming Ye, Yueping Li,Xiaohui Huang",Journal of Software,"Sampling algorithm, temperature conduction, conduction boundary, topology structure","A popular solution to dealing with large-scale social networks is to derive a representative sample from a social network. This sample is expected to represent the original social network well such that the sampled network can be used for simulations and analysis. In this paper, we propose a new social network sampling algorithm based on the Temperature Conduction model. Our sampling approach is able to effectively maintain the topological similarity between the sampled network and its original network. We have evaluated our algorithm on several wellknown data sets. The experimental results show that our algorithm outperforms the state-of-the-art methods."
On the design of methods to estimate network characteristics,"Don Towsley, Bruno Ribeiro",University of Massachusetts Amherst ,,"Social and computer networks permeate our lives. Large networks, such as the Internet, the World Wide Web (WWW), and wireless smartphones, have indisputable economic and social importance. These networks have non-trivial topological features, i.e., features that do not occur in simple networks such as lattices or random networks. Estimating characteristics of these networks from incomplete (sampled) data is a challenging task. This thesis provides two frameworks within which common measurement tasks are analyzed and new, principled, measurement methods are designed. The first framework focuses on sampling directly observable network characteristics. This framework is applied to design a novel multidimensional random walk to efficiently sample loosely connected networks. The second framework focuses on the design of measurement methods to estimate indirectly observable network characteristics. This framework is applied to design two new, principled, estimators of flow size distributions over Internet routers using (1) randomly sampled IP packets and (2) a data stream algorithm."
"Graphs over time: densification laws,shrinking diameters and possible explanations","Jure Leskovec, Jon M. Kleinberg,Christos Faloutsos",ACM,"densification power laws, graph generators, graph mining, heavy-tailed distributions, small-world phenomena","How do real graphs evolve over time? What are “normal” growth patterns in social, technological, and information networks? Many studies have discovered patterns in static graphs, identifying properties in a single snapshot of a large network, or in a very small number of snapshots; these include heavy tails for in- and out-degree distributions, communities, small-world phenomena, and others. However, given the lack of information about network evolution over long periods, it has been hard to convert these findings into statements about trends over time. Here we study a wide range of real graphs, and we observe some surprising phenomena. First, most of these graphs densify over time, with the number of edges growing superlinearly in the number of nodes. Second, the average distance between nodes often shrinks over time, in contrast to the conventional wisdom that such distance parameters should increase slowly as a function of the number of nodes (like O(log n) or O(log(log n)). Existing graph generation models do not exhibit these types of behavior, even at a qualitative level. We provide a new graph generator, based on a “forest fire” spreading process, that has a simple, intuitive justification, requires very few parameters (like the “flammability” of nodes), and produces graphs exhibiting the full range of properties observed both in prior work and in the present study."
On the estimation accuracy of degree distributions from graph sampling,"Bruno Ribeiro, Donald F. Towsley",IEEE,,"Estimating characteristics of large graphs via sampling is vital in the study of complex networks. In this work, we study the Mean Squared Error (MSE) associated with different sampling methods for the degree distribution. These sampling methods include independent random vertex (RV) and random edge (RE) sampling, and crawling methods such as random walks (RWs) and the widely used Metropolis-Hastings algorithm for uniformly sampling vertices (MHRWu). We see that the RW MSE is upper bounded by a quantity that is proportional to the RE MSE and inversely proportional to the spectral gap of the RW transition probability matrix. We also determine conditions under which RW is preferable to RV. Finally, we present an approximation of the MHRWu MSE. We evaluate the accuracy of our approximations and bounds through simulations on large real world graphs."
FURS: Fast and Unique Representative Subset selection retaining large-scale community structure,"Raghvendra Mall, Rocco Langone,Johan A. K. Suykens",Social Network Analysis and Mining ,,"We propose a novel algorithm, FURS (Fast and Unique Representative Subset selection) to deterministically select a set of nodes from a given graph which retains the underlying community structure. FURS greedily selects nodes with high-degree centrality from most or all the communities in the network. The nodes with high-degree centrality for each community are usually located at the center rather than the periphery and can better capture the community structure. The nodes are selected such that they are not isolated but can form disconnected components. The FURS is evaluated by quality measures, such as coverage, clustering coefficients, degree distributions and variation of information. Empirically, we observe that the nodes are selected such that most or all of the communities in the original network are retained. We compare our proposed technique with state-of-the-art methods like SlashBurn, Forest-Fire, Metropolis and Snowball Expansion sampling techniques. We evaluate FURS on several synthetic and real-world networks of varying size to demonstrate the high quality of our subset while preserving the community structure. The subset generated by the FURS method can be effectively utilized by model-based approaches with out-of-sample extension properties for inferring community affiliation of the large-scale networks. A consequence of FURS is that the selected subset is also a good candidate set for simple diffusion model. We compare the spread of information over time using FURS for several real-world networks with random node selection, hubs selection, spokes selection, high eigenvector centrality, high Pagerank, high betweenness centrality and low betweenness centrality-based representative subset selection."
Reducing Large Internet Topologies for Faster Simulations,"Vaishnavi Krishnamurthy, MichalisFaloutsos, Marek Chrobak, Li Lao, Jun-Hong Cui, Allon G. Percus","NETWORKING 2005. Networking Technologies, Services, and Protocols; Performance of Computer and Communication Networks; Mobile and Wireless Communications Systems","Degree Distribution, Average Degree, Constructive Method, Exploration Method, Graph Sampling ","In this paper, we develop methods to “sample” a small realistic graph from a large real network. Despite recent activity, the modeling and generation of realistic graphs is still not a resolved issue. All previous work has attempted to grow a graph from scratch. We address the complementary problem of shrinking a graph. In more detail, this work has three parts. First, we propose a number of reduction methods that can be categorized into three classes: (a) deletion methods, (b) contraction methods, and (c) exploration methods. We prove that some of them maintain key properties of the initial graph. We implement our methods and show that we can effectively reduce the nodes of a graph by as much as 70% while maintaining its important properties. In addition, we show that our reduced graphs compare favourably against construction-based generators. Apart from its use in simulations, the problem of graph sampling is of independent interest."
Network Sampling: From Static to Streaming Graphs,"Nesreen Ahmed, Jennifer Neville,Ramana Rao Kompella",arXiv,"Network sampling, statistical network analysis, relational classification","Network sampling is integral to the analysis of social, information, and biological networks. Since many real-world networks are massive in size, continuously evolving, and/or distributed in nature, the network structure is often sampled in order to facilitate study. For these reasons, a more thorough and complete understanding of network sampling is critical to support the field of network science. In this paper, we outline a framework for the general problem of network sampling, by highlighting the different objectives, population and units of interest, and classes of network sampling methods. In addition, we propose a spectrum of computational models for network sampling methods, ranging from the traditionally studied model based on the assumption of a static domain to a more challenging model that is appropriate for streaming domains. We design a family of sampling methods based on the concept of graph induction that generalize across the full spectrum of computational models (from static to streaming) while efficiently preserving many of the topological properties of the input graphs. Furthermore, we demonstrate how traditional static sampling algorithms can be modified for graph streams for each of the three main classes of sampling methods: node, edge, and topology-based sampling. Our experimental results indicate that our proposed family of sampling methods more accurately preserves the underlying properties of the graph for both static and streaming graphs. Finally, we study the impact of network sampling algorithms on the parameter estimation and performance evaluation of relational classification algorithms."
Measuring the Sensitivity of Graph Metrics to Missing Data,"Anita Zakrzewska, David A. Bader",Parallel Processing and Applied Mathematics,"Graphs, Graph algorithms, Sensitivity analysis, Missing data, Energy consumption, Power","The increasing energy consumption of high performance computing has resulted in rising operational and environmental costs. Therefore, reducing the energy consumption of computation is an emerging area of interest. We study the approach of data sampling to reduce the energy costs of sparse graph algorithms. The resulting error levels for several graph metrics are measured to analyze the trade-off between energy consumption reduction and error. The three types of graphs studied, real graphs, synthetic random graphs, and synthetic small-world graphs, each show distinct behavior. Across all graphs, the error cost is initially relatively low. For example, four of the five real graphs studied needed less than a third of total energy to retain a degree centrality rank correlation coefficient of 0.850.85 when random vertices were removed. However, the error incurred for further energy reduction grows at an increasing rate, providing diminishing returns."
Graph evolution: Densification and shrinking diameters,"Jure Leskovec, Jon M. Kleinberg,Christos Faloutsos",ACM,"Densification power laws, graph generators, graph mining, heavy-tailed distributions, small-world phenomena","How do real graphs evolve over time? What are normal growth patterns in social, technological, and information networks? Many studies have discovered patterns in static graphs, identifying properties in a single snapshot of a large network or in a very small number of snapshots; these include heavy tails for in- and out-degree distributions, communities, small-world phenomena, and others. However, given the lack of information about network evolution over long periods, it has been hard to convert these findings into statements about trends over time. Here we study a wide range of real graphs, and we observe some surprising phenomena. First, most of these graphs densify over time with the number of edges growing superlinearly in the number of nodes. Second, the average distance between nodes often shrinks over time in contrast to the conventional wisdom that such distance parameters should increase slowly as a function of the number of nodes (like O(log n) or O(log(log n)). Existing graph generation models do not exhibit these types of behavior even at a qualitative level. We provide a new graph generator, based on a forest fire spreading process that has a simple, intuitive justification, requires very few parameters (like the flammability of nodes), and produces graphs exhibiting the full range of properties observed both in prior work and in the present study. We also notice that the forest fire model exhibits a sharp transition between sparse graphs and graphs that are densifying. Graphs with decreasing distance between the nodes are generated around this transition point. Last, we analyze the connection between the temporal evolution of the degree distribution and densification of a graph. We find that the two are fundamentally related. We also observe that real
networks exhibit this type of relation between densification and the degree distribution"
Subnets of scale-free networks are not scale-free: sampling properties of networks.,"Michael P.H. Stumpf, Carsten Wiuf,Robert M. May",Remote Spectroscopic analysis of invading species ,"complex networks, protein interaction networks, random graphs, sampling theory","Most studies of networks have only looked at small subsets of the true network. Here, we discuss the sampling properties of a network's degree distribution under the most parsimonious sampling scheme. Only if the degree distributions of the network and randomly sampled subnets belong to the same family of probability distributions is it possible to extrapolate from subnet data to properties of the global network. We show that this condition is indeed satisfied for some important classes of networks, notably classical random graphs and exponential random graphs. For scale-free degree distributions, however, this is not the case. Thus, inferences about the scale-free nature of a network may have to be treated with some caution. The work presented here has important implications for the analysis of molecular networks as well as for graph theory and the theory of networks in general."
Analysis of topological characteristics of huge online social networking services,"Yong-Yeol Ahn, Seungyeop Han,Haewoon Kwak, Sue B. Moon,Hawoong Jeong",ACM,"Sampling, Social network","Social networking services are a fast-growing business in the Internet. However, it is unknown if online relationships and their growth patterns are the same as in real-life social networks. In this paper, we compare the structures of three online social networking services: Cyworld, MySpace, and orkut, each with more than 10 million users, respectively. We have access to complete data of Cyworld’s ilchon (friend) relationships and analyze its degree distribution, clustering property, degree correlation, and evolution over time. We also use Cyworld data to evaluate the validity of snowball sampling method, which we use to crawl and obtain partial network topologies of MySpace and orkut. Cyworld, the oldest of the three, demonstrates a changing scaling behavior over time in degree distribution. The latest Cyworld data’s degree distribution exhibits a multi-scaling behavior, while those of MySpace and orkut have simple scaling behaviors with different exponents. Very interestingly, each of the two exponents corresponds to the different segments in Cyworld’s degree distribution. Certain online social networking services encourage online activities that cannot be easily copied in real life; we show that they deviate from close-knit online social networks which show a similar degree correlation pattern to real-life social networks."
Benefits of bias: towards better characterization of network sampling,"Arun S. Maiya, Tanya Y. Berger-Wolf",arXiv,"sampling, bias, social network analysis, complex networks, graph mining, link mining, online sampling, crawling","From social networks to P2P systems, network sampling arises in many settings. We present a detailed study on the nature of biases in network sampling strategies to shed light on how best to sample from networks. We investigate connections between specific biases and various measures of structural representativeness. We show that certain biases are, in fact, beneficial for many applications, as they ""push"" the sampling process towards inclusion of desired properties. Finally, we describe how these sampling biases can be exploited in several, real-world applications including disease outbreak detection and market research."
A Survey and Taxonomy of Graph Sampling,"Pili Hu, Wing Cheong Lau",arXiv,,"Graph sampling is a technique to pick a subset of vertices and/ or edges from original graph. It has a wide spectrum of applications, e.g. survey hidden population in sociology [54], visualize social graph [29], scale down Internet AS graph [27], graph sparsification [8], etc. In some scenarios, the whole graph is known and the purpose of sampling is to obtain a smaller graph. In other scenarios, the graph is unknown and sampling is regarded as a way to explore the graph. Commonly used techniques are Vertex Sampling, Edge Sampling and Traversal Based Sampling. We provide a taxonomy of different graph sampling objectives and graph sampling approaches. The relations between these approaches are formally argued and a general framework to bridge theoretical analysis and practical implementation is provided. Although being smaller in size, sampled graphs may be similar to original graphs in some way. We are particularly interested in what graph properties are preserved given a sampling procedure. If some properties are preserved, we can estimate them on the sampled graphs, which gives a way to construct efficient estimators. If one algorithm relies on the perserved properties, we can expect that it gives similar output on original and sampled graphs. This leads to a systematic way to accelerate a class of graph algorithms. In this survey, we discuss both classical text-book type properties and some advanced properties. The landscape is tabularized and we see a lot of missing works in this field. Some theoretical studies are collected in this survey and simple extensions are made. Most previous numerical evaluation works come in an ad hoc fashion, i.e. evaluate different type of graphs, different set of properties, and different sampling algorithms. A systematical and neutral evaluation is needed to shed light on further graph sampling studies."
Sampling large Internet topologies for simulation purposes,"Vaishnavi Krishnamurthy, MichalisFaloutsos, Marek Chrobak, Jun-HongCui, Li Lao, Allon G. Percus",Computer Networks,Graph modeling; Graph sampling; Graph properties,"In this paper, we develop methods to ‘‘sample’’ a small realistic graph from a large Internet topology. Despite recent activity, modeling and generation of realistic graphs resembling the Internet is still not a resolved issue. All previous work has attempted to grow such graphs from scratch. We address the complementary problem of shrinking an existing topology. In more detail, this work has three parts. First, we propose a number of reduction methods that can be categorized into three classes: (a) deletion methods, (b) contraction methods, and (c) exploration methods. We prove that some of them maintain key properties of the initial graph. We implement our methods and show that we can effectively reduce the nodes of an Internet graph by as much as 70% while maintaining its important properties. Second, we show that our reduced graphs compare favorably against construction-based generators. Finally, we successfully validate the effectiveness of our best methods in an actual performance evaluation study of multicast routing. Apart from its practical applications, the problem of graph sampling is of independent interest."
Crawling Facebook for social network analysis purposes,"Salvatore Catanese, Pasquale De Meo,Emilio Ferrara, Giacomo Fiumara,Alessandro Provetti",arXiv,"Web data, Design, Experimentation, Human Factor","We describe our work in the collection and analysis of massive data describing the connections between participants to online social networks. Alternative approaches to social network data collection are defined and evaluated in practice, against the popular Facebook Web site. Thanks to our ad-hoc, privacy-compliant crawlers, two large samples, comprising millions of connections, have been collected; the data is anonymous and organized as an undirected graph. We describe a set of tools that we developed to analyze specific properties of such social-network graphs, i.e., among others, degree distribution, centrality measures, scaling laws and distribution of friendship."
Scalable modeling of real graphs using Kronecker multiplication,"Jure Leskovec, Christos Faloutsos",Carnegie Mellon University ,,"Given a large, real graph, how can we generate a synthetic graph that matches its properties, i.e., it has similar degree distribution, similar (small) diameter, similar spectrum, etc? We propose to use “Kronecker graphs”, which naturally obey all of the above properties, and we present KronFit, a fast and scalable algorithm for fitting the Kronecker graph generation model to real networks. A naive approach to fitting would take super-exponential time. In contrast, KronFit takes linear time, by exploiting the structure of Kronecker product and by using sampling. Experiments on large real and synthetic graphs show that KronFit indeed mimics very well the patterns found in the target graphs. Once fitted, the model parameters and the resulting synthetic graphs can be used for anonymization, extrapolations, and graph summarization."
Labeling mental illness: The effects of received services and perceived stigma on life satisfaction.,Sarah Rosenfield,American Sociological Review,,"Labeling theory proponents and the theory's critics have different views of stigma and thus differ on the consequences of labeling for people with men- tal illness. The labeling perspective posits that because of stigma, official labeling through treatment contact has negative consequences for mental patients. In contrast, critics of labeling theory claim that stigma is relatively inconsequential. Instead, they argue that because labeling results in receiv- ing needed services, it provides significant benefits for mental patients. Thus far, no study has tested the relative positive and negative effects of labeling. I examine these views by comparing the importance of perceived stigma ver- sus the receipt of services for the quality of life of persons with chronic men- tal illness. Results show that both stigma and services received are signifi- cantly associated with quality of life, but in opposite ways. These findings have important implications for interventions for mental illness."
The effectiveness of stigma coping orientations: can negative consequences of mental illness labeling be avoided?,"Bruce G Link, Jerrold Mirotznik, FrancisT. Cullen",Journal of Health and Social Behavior,,"Recent research has assigned a prominent role to labeling and stigma as factors that impair the social and psychological functioning of people officially labeled mentally ill. But can the effects of labeling and stigma be overcome by adopting a few simple approaches to coping with these problems? If so, the stigma-induced problems of social awkwardness, demoralization and unemployment emphasized by recent research may not be as severe as claimed. Using a sample of psychiatric patients, we examine this issue by assessing whether patients can ameliorate labeling effects by keeping their history of treatment a secret, educating others about their situation, or avoiding situations in which rejection might occur. None of these coping orientations were effective in diminishing negative labeling effects on unemployment or on psychological distress/demoralization. In fact, the three coping strategies show consistent effects in the direction of producing more harm than good, and with respect to withdrawal-avoidance this effect is significant. Based on these results we argue that stigma is powerfully reinforced by culture and that its effects are not easily overcome by the coping actions of individuals. Using C. Wright Mills's (1967) distinction we conclude that labeling and stigma are ""social problems"" not ""individual troubles."""
"Mental patient status, work, and income: an examination of the effects of a psychiatric label.",Bruce Link,Journal of Health and Social Behavior,,"Much controversy has focused on the effect of a label in bringing about the types of behavior the label connotes. This emphasis may have led some to ignore the possibility that a label can effect an individual in other ways. In the study ""treated cases,"" individuals who have been treated, are compared to ""untreated cases,"" individuals found to be similar in severity of psychiatric condition but who have not received an official label. Analyses controlling for psychiatric condition and other important variables show that a psychiatric label has a negative impact on income and work status. These results suggest that while a label may or may not directly affect the form of behavior for which it was affixed, it almost certainly has an impact on other areas. Finally, given these pejorative effects, there may be a partial role for labeling theory in understanding the stabilization of psychological disorder if a label increases environmental stress and decreases one's ability to cope with it."
"Deinstitutionalization, social rejection, and the self-esteem of former mental patients.","Eric R. Wright, William P. Gronfein,Timothy J. Owens",Journal of Health and Social Behavior,,"Modified labeling theorists have long argued that the stigma of mental illness has important consequences for the lives ofpeople with mental illness. We pro- pose that social rejection is an enduring force in the lives ofpeople with men- tal illness and that these experiences are central to understanding the poor self- concepts described by many former psychiatric patients. We explore changes in a cohort of recently deinstitutionalized mental patients' (N = 88) self-esteem and experiences with social rejection using data from a three wave panel sur- vey conducted while institutionalized and over a two-year periodfollowing the patients' discharge from a long-term state hospital. Our results indicate that social rejection is a persistent source of social stress for the discharged patients. Moreover, these experiences increase feelings of self-deprecation that, in turn, weaken their sense of mastery. Where the patients' received their fol- low-up care-whether in a community setting or in another state hospital-had little impact on their self-relatedfeelings or on their experiences of social rejec- tion. Our results provide further support for modified labeling theory and underscore the need to consider the dynamic relationship between stigmatizing experiences and self-related changes."
Correlates and consequences of internalized stigma for people living with mental illness: a systematic review and meta-analysis.,"James D. Livingston, Jennifer E Boyd",Social Science & Medicine,"Stigma, Mental illness, Meta-analysis, Systematic review","An expansive body of research has investigated the experiences and adverse consequences of internalized stigma for people with mental illness. This article provides a systematic review and meta-analysis of the extant research regarding the empirical relationship between internalized stigma and a range of sociodemographic, psychosocial, and psychiatric variables for people who live with mental illness. An exhaustive review of the research literature was performed on all articles published in English that assessed a statistical relationship between internalized stigma and at least one other variable for adults who live with mental illness. In total, 127 articles met the inclusion criteria for systematic review, of which, data from 45 articles were extracted for meta-analyses. None of the sociodemographic variables that were included in the study were consistently or strongly correlated with levels of internalized stigma. The review uncovered a striking and robust negative relationship between internalized stigma and a range of psychosocial variables (e.g., hope, self-esteem, and empowerment). Regarding psychiatric variables, internalized stigma was positively associated with psychiatric symptom severity and negatively associated with treatment adherence. The review draws attention to the lack of longitudinal research in this area of study which has inhibited the clinical relevance of findings related to internalized stigma. The study also highlights the need for greater attention on disentangling the true nature of the relationship between internalized stigma and other psychosocial variables."
"Being Mentally Ill, A Sociological Theory",Joe B. Buttram,Journal of Music Therapy,,"The volume is dedicated to the development of a sociological theory of mental illness. The theory is considered to be ""an approach to the study of mental illness which takes the motive forces out of the inidividual patient and puts them into the system constituted by the patient, other persons reacting to him, and the official agencies of control and treatment in society"". The position assumed is that ""most chronic mental illness is at least part a social role, and that the societal reaction is usually the most important determinant of entry into that role"". The avowed purpose of the author is to develop a ""social"" model which will complement the ""individual"" model which emanates from psychoanalytical and psychological sources, by providing a complete and explicit contrast. "
Perceived stigma as a predictor of treatment discontinuation in young and older outpatients with depression.,"Jo Anne Sirey, Martha L Bruce, GeorgeS. Alexopoulos, Deborah A Perlick,Patrick J Raue, Steven J. Friedman,Barnett S Meyers",The American Journal of Psychiatry,,"The authors' goal was to examine the extent to which perceived stigma affected treatment discontinuation in young and older adults with major depression. A two-stage sampling design identified 92 new admissions of outpatients with major depression. Perceived stigma was assessed at admission. Discontinuation of treatment was recorded at 3-month follow-up. Although younger patients reported perceiving more stigma than older patients, stigma predicted treatment discontinuation only among the older patients. Patients' perceptions of stigma at the start of treatment influence their subsequent treatment behavior. Stigma is an appropriate target for intervention aimed at improving treatment adherence and outcomes."
The effects of stigma on the psychological well-being and life satisfaction of persons with mental illness.,Fred E. Markowitz,Journal of Health and Social Behavior,,"Building on modified labeling theory, I examine the relationships between stigma, psychological well-being, and life satisfaction among persons with mental illness. The study uses longitudinal data from 610 individuals in self-help groups and outpatient treatment. Results from cross-sectional and lagged regression models show adverse effects of stigma on the outcomes considered. However, much of the effects of anticipated rejection are due to discriminatory experiences. The results also indicate that stigma is related to depressive-anxiety types of symptoms but not psychotic symptoms. Although the findings show that the negative effect of stigma on life satisfaction is partly mediated by self-concept, reciprocal effects models indicate that the relationship between self-concept and life satisfaction is bi-directional. The study suggests ways in which stigma processes need to be explored in greater detail."
"Experiences of mental illness stigma, prejudice and discrimination: a review of measures","Elaine Brohan, Mike Slade, SarahClement, G Thornicroft",BMC Health Services Research,,"There has been a substantial increase in research on mental illness related stigma over the past 10 years, with many measures in use. This study aims to review current practice in the survey measurement of mental illness stigma, prejudice and discrimination experienced by people who have personal experience of mental illness. We will identify measures used, their characteristics and psychometric properties. A narrative literature review of survey measures of mental illness stigma was conducted. The databases Medline, PsychInfo and the British Nursing Index were searched for the period 1990-2009. 57 studies were included in the review. 14 survey measures of mental illness stigma were identified. Seven of the located measures addressed aspects of perceived stigma, 10 aspects of experienced stigma and 5 aspects of self-stigma. Of the identified studies, 79% used one of the measures of perceived stigma, 46% one of the measures of experienced stigma and 33% one of the measures of self-stigma. All measures presented some information on psychometric properties. The review was structured by considering perceived, experienced and self stigma as separate but related constructs. It provides a resource to aid researchers in selecting the measure of mental illness stigma which is most appropriate to their purpose."
Stigma as a barrier to recovery: Adverse effects of perceived stigma on social adaptation of persons diagnosed with bipolar affective disorder.,"Deborah A Perlick, Robert A.Rosenheck, John F. Clarkin, Jo AnneSirey, Jamelah T. Salahi, Elmer L.Struening, Bruce G Link",Psychiatric Services ,,"The purpose of this study was to evaluate the effect of concerns about stigma on social adaptation among persons with a diagnosis of bipolar affective disorder. The sample comprised 264 persons who were consecutively admitted to a psychiatric inpatient or outpatient service at a university-affiliated hospital and who met research diagnostic criteria for bipolar I disorder, bipolar II disorder, or schizoaffective disorder, manic type. Patients were evaluated with use of the Schedule for Affective Disorders and Schizophrenia, Lifetime Version (SADS-L), the Brief Psychiatric Rating Scale (BPRS), and a measure of perceived stigma. Social adjustment was measured at baseline and seven months later with the Social Adjustment Scale (SAS). As predicted, patients who had concerns about stigma showed significantly more impairment at seven months on the social leisure subscale but not on the SAS extended family subscale, after baseline SAS score and symptom level had been controlled for. More refined models using SAS-derived factors as dependent variables indicated that concerns about stigma predicted higher avoidance of social interactions with persons outside the family and psychological isolation at seven-month follow-up, after baseline SAS and BPRS scores had been controlled for. Concerns about the stigma associated with mental illness reported by patients during an acute phase of bipolar illness predicted poorer social adjustment seven months later with individuals outside the patient's family. Greater attention to patients' concerns about stigma is needed from both researchers and clinicians."
Dimensionality reduction for visualizing single-cell data using UMAP,"Etienne Becht, Leland McInnes, JohnHealy, Charles-Antoine Dutertre,Immanuel Weng Han Kwok, Lai GuanNg, Florent Ginhoux, Evan WilliamNewell",Nature Biotechnology,,"Advances in single-cell technologies have enabled high-resolution dissection of tissue composition. Several tools for dimensionality reduction are available to analyze the large number of parameters generated in single-cell studies. Recently, a nonlinear dimensionality-reduction technique, uniform manifold approximation and projection (UMAP), was developed for the analysis of any type of high-dimensional data. Here we apply it to biological data, using three well-characterized mass cytometry and single-cell RNA sequencing datasets. Comparing the performance of UMAP with five other tools, we find that UMAP provides the fastest run times, highest reproducibility and the most meaningful organization of cell clusters. The work highlights the use of UMAP for improved visualization and interpretation of single-cell data."
Evaluation of UMAP as an alternative to t-SNE for single-cell data,"Etienne Becht, Charles-AntoineDutertre, Immanuel W.H. Kwok, LaiGuan Ng, Florent Ginhoux, Evan WilliamNewell",Nature Biotechnology,,"Uniform Manifold Approximation and Projection (UMAP) is a recently-published non-linear dimensionality reduction technique. Another such algorithm, t-SNE, has been the default method for such task in the past years. Herein we comment on the usefulness of UMAP high-dimensional cytometry and single-cell RNA sequencing, notably highlighting faster runtime and consistency, meaningful organization of cell clusters and preservation of continuums in UMAP compared to t-SNE."
Batch effects in single-cell RNA-sequencing data are corrected by matching mutual nearest neighbors,"Laleh Haghverdi, Aaron T. L. Lun,Michael D. Morgan, John C. Marioni",Nature Biotechnology,,"Large-scale single-cell RNA sequencing (scRNA-seq) data sets that are produced in different laboratories and at different times contain batch effects that may compromise the integration and interpretation of the data. Existing scRNA-seq analysis methods incorrectly assume that the composition of cell populations is either known or identical across batches. We present a strategy for batch correction based on the detection of mutual nearest neighbors (MNNs) in the high-dimensional expression space. Our approach does not rely on predefined or equal population compositions across batches; instead, it requires only that a subset of the population be shared between batches. We demonstrate the superiority of our approach compared with existing methods by using both simulated and real scRNA-seq data sets. Using multiple droplet-based scRNA-seq data sets, we demonstrate that our MNN batch-effect-correction method can be scaled to large numbers of cells."
"Integrating single-cell transcriptomic data across different conditions, technologies, and species","Andrew Butler, Paul Hoffman, PeterSmibert, Efthymia Papalexi, RahulSatija",Nature Biotechnology,,"Computational single-cell RNA-seq (scRNA-seq) methods have been successfully applied to experiments representing a single condition, technology, or species to discover and define cellular phenotypes. However, identifying subpopulations of cells that are present across multiple data sets remains challenging. Here, we introduce an analytical strategy for integrating scRNA-seq data sets based on common sources of variation, enabling the identification of shared populations across data sets and downstream comparative analysis. We apply this approach, implemented in our R toolkit Seurat (http://satijalab.org/seurat/), to align scRNA-seq data sets of peripheral blood mononuclear cells under resting and stimulated conditions, hematopoietic progenitors sequenced using two profiling technologies, and pancreatic cell 'atlases' generated from human and mouse islets. In each case, we learn distinct or transitional cell states jointly across data sets, while boosting statistical power through integrated analysis. Our approach facilitates general comparisons of scRNA-seq data sets, potentially deepening our understanding of how distinct cell states respond to perturbation, disease, and evolution."
SCANPY: large-scale single-cell gene expression data analysis,"F. Alexander Wolf, Philipp Angerer,Fabian Joachim Theis",Genome Biology,"Single-cell transcriptomics, Machine learning, Scalability, Graph analysis, Clustering, Pseudotemporal ordering, Trajectory inference, Differential expression testing, Visualization, Bioinformatics","SCANPY is a scalable toolkit for analyzing single-cell gene expression data. It includes methods for preprocessing, visualization, clustering, pseudotime and trajectory inference, differential expression testing, and simulation of gene regulatory networks. Its Python-based implementation efficiently deals with data sets of more than one million cells . Along with SCANPY, we present ANNDATA, a generic class for handling annotated data matrices."
Correcting batch effects in single-cell RNA sequencing data by matching mutual nearest neighbours,"Laleh Haghverdi, Aaron T. L. Lun,Michael D. Morgan, John C. Marioni",Nature Biotechnology,,"Large-scale single-cell RNA sequencing (scRNA-seq) data sets that are produced in different laboratories and at different times contain batch effects that may compromise the integration and interpretation of the data. Existing scRNA-seq analysis methods incorrectly assume that the composition of cell populations is either known or identical across batches. We present a strategy for batch correction based on the detection of mutual nearest neighbors (MNNs) in the high-dimensional expression space. Our approach does not rely on predefined or equal population compositions across batches; instead, it requires only that a subset of the population be shared between batches. We demonstrate the superiority of our approach compared with existing methods by using both simulated and real scRNA-seq data sets. Using multiple droplet-based scRNA-seq data sets, we demonstrate that our MNN batch-effect-correction method can be scaled to large numbers of cells."
Scanpy for analysis of large-scale single-cell gene expression data,"F. Alexander Wolf, Philipp Angerer,Fabian Joachim Theis",,,
Comprehensive integration of single cell data,"Tim Stuart, Andrew Butler, Paul JHoffman, Christoph Hafemeister,Efthymia Papalexi, William M. Mauck,Marlon Stoeckius, Peter Smibert, RahulSatija",Cell,integration; multi-modal; scATAC-seq; scRNA-seq; single cell; single-cell ATAC sequencing; single-cell RNA sequencing.,"Single-cell transcriptomics has transformed our ability to characterize cell states, but deep biological understanding requires more than a taxonomic listing of clusters. As new methods arise to measure distinct cellular modalities, a key analytical challenge is to integrate these datasets to better understand cellular identity and function. Here, we develop a strategy to ""anchor"" diverse datasets together, enabling us to integrate single-cell measurements not only across scRNA-seq technologies, but also across different modalities. After demonstrating improvement over existing methods for integrating scRNA-seq data, we anchor scRNA-seq experiments with scATAC-seq to explore chromatin differences in closely related interneuron subsets and project protein expression measurements onto a bone marrow atlas to characterize lymphocyte populations. Lastly, we harmonize in situ gene expression and scRNA-seq datasets, allowing transcriptome-wide imputation of spatial gene expression patterns. Our work presents a strategy for the assembly of harmonized references and transfer of information across datasets."
scmap: projection of single-cell RNA-seq data across data sets,"Vladimir Yu Kiselev, Andrew Yiu, MartinHemberg",Nature Methods,,"Single-cell RNA-seq (scRNA-seq) allows researchers to define cell types on the basis of unsupervised clustering of the transcriptome. However, differences in experimental methods and computational analyses make it challenging to compare data across experiments. Here we present scmap, a method for projecting cells from an scRNA-seq data set onto cell types or individual cells from other experiments."
Visual analysis of mass cytometry data by hierarchical stochastic neighbour embedding reveals rare cell types,"Vincent van Unen, Thomas Höllt, NicolaPezzotti, Nan Li, Marcel J. T. Reinders,Elmar Eisemann, Frits Koning, AnnaVilanova, Boudewijn P. F. Lelieveldt",Nature Communications,,"Mass cytometry allows high-resolution dissection of the cellular composition of the immune system. However, the high-dimensionality, large size, and non-linear structure of the data poses considerable challenges for the data analysis. In particular, dimensionality reduction-based techniques like t-SNE offer single-cell resolution but are limited in the number of cells that can be analyzed. Here we introduce Hierarchical Stochastic Neighbor Embedding (HSNE) for the analysis of mass cytometry data sets. HSNE constructs a hierarchy of non-linear similarities that can be interactively explored with a stepwise increase in detail up to the single-cell level. We apply HSNE to a study on gastrointestinal disorders and three other available mass cytometry data sets. We find that HSNE efficiently replicates previous observations and identifies rare cell populations that were previously missed due to downsampling. Thus, HSNE removes the scalability limit of conventional t-SNE analysis, a feature that makes it highly suitable for the analysis of massive high-dimensional data sets."
Massively parallel digital transcriptional profiling of single cells,"Grace X. Y. Zheng, Jessica M. Terry,Phillip Belgrader, Paul Ryvkin, ZacharyW. Bent, Ryan Wilson, Solongo B.Ziraldo, Tobias D. Wheeler, GeoffMcDermott, Junjie Zhu, Mark T.Gregory, Joe Shuga, Luz Montesclaros,Jason G. Underwood, Donald A.Masquelier, Stefanie Yukiko Nishimura,Michael Schnall-Levin, Paul W Wyatt,Christopher M. Hindson, RajivBharadwaj, Alexander Wong, Kevin DNess, Lan W Beppu, H. J. Deeg,Christopher McFarland, Keith R. Loeb,W J Valente, Nolan G. Ericson, Emily A.Stevens, Jerald P Radich, Tarjei S.Mikkelsen, Benjamin J. Hindson, JasonH. Bielas",Nature Communications,,"Characterizing the transcriptome of individual cells is fundamental to understanding complex biological systems. We describe a droplet-based system that enables 3′ mRNA counting of tens of thousands of single cells per sample. Cell encapsulation, of up to 8 samples at a time, takes place in ∼6 min, with ∼50% cell capture efficiency. To demonstrate the system’s technical performance, we collected transcriptome data from ∼250k single cells across 29 samples. We validated the sensitivity of the system and its ability to detect rare populations using cell lines and synthetic RNAs. We profiled 68k peripheral blood mononuclear cells to demonstrate the system’s ability to characterize large immune populations. Finally, we used sequence variation in the transcriptome data to determine host and donor chimerism at single-cell resolution from bone marrow mononuclear cells isolated from transplant patients."
Visualizing Data using t-SNE,"Laurens van der Maaten, Geoffrey E.Hinton",Journal of Machine Learning Research,"visualization, dimensionality reduction, manifold learning, embedding algorithms, multidimensional scaling","We present a new technique called “t-SNE” that visualizes high-dimensional data by giving each datapoint a location in a two or three-dimensional map. The technique is a variation of Stochastic Neighbor Embedding (Hinton and Roweis, 2002) that is much easier to optimize, and produces significantly better visualizations by reducing the tendency to crowd points together in the center of the map. t-SNE is better than existing techniques at creating a single map that reveals structure at many different scales. This is particularly important for high-dimensional data that lie on several different, but related, low-dimensional manifolds, such as images of objects from multiple classes seen from multiple viewpoints. For visualizing the structure of very large data sets, we show how t-SNE can use random walks on neighborhood graphs to allow the implicit structure of all of the data to influence the way in which a subset of the data is displayed. We illustrate the performance of t-SNE on a wide variety of data sets and compare it with many other non-parametric visualization techniques, including Sammon mapping, Isomap, and Locally Linear Embedding. The visualizations produced by t-SNE are significantly better than those produced by the other techniques on almost all of the data sets."
Two key properties of dimensionality reduction methods,"John A. Lee, Michel Verleysen",IEEE,,"Dimensionality reduction aims at providing faithful low-dimensional representations of high-dimensional data. Its general principle is to attempt to reproduce in a low-dimensional space the salient characteristics of data, such as proximities. A large variety of methods exist in the literature, ranging from principal component analysis to deep neural networks with a bottleneck layer. In this cornucopia, it is rather difficult to find out why a few methods clearly outperform others. This paper identifies two important properties that enable some recent methods like stochastic neighborhood embedding and its variants to produce improved visualizations of high-dimensional data. The first property is a low sensitivity to the phenomenon of distance concentration. The second one is plasticity, that is, the capability to forget about some data characteristics to better reproduce the other ones. In a manifold learning perspective, breaking some proximities typically allow for a better unfolding of data. Theoretical developments as well as experiments support our claim that both properties have a strong impact. In particular, we show that equipping classical methods with the missing properties significantly improves their results."
Graph abstraction reconciles clustering with trajectory inference through a topology preserving map of single cells,"F. Alexander Wolf, Fiona KathrynHamey, Mireya Plass, Jordi Solana,Joakim S. Dahlin, Berthold Göttgens,Nikolaus Rajewsky, Lukas M Simon,Fabian Joachim Theis",Genome Biology,,"Single-cell RNA-seq quantifies biological heterogeneity across both discrete cell types and continuous cell transitions. Partition-based graph abstraction (PAGA) provides an interpretable graph-like map of the arising data manifold, based on estimating connectivity of manifold partitions. PAGA maps preserve the global topology of data, allow analyzing data at different resolutions, and result in much higher computational efficiency of the typical exploratory data analysis workflow. We demonstrate the method by inferring structure-rich cell maps with consistent topology across four hematopoietic datasets, adult planaria and the zebrafish embryo and benchmark computational performance on one million neurons."
Highly Parallel Genome-wide Expression Profiling of Individual Cells Using Nanoliter Droplets,"Evan Z. Macosko, Anindita Basu, RahulSatija, James Nemesh, K. Shekhar,Melissa Tapper Goldman, Itay Tirosh,Allison R. Bialas, Nolan Kamitaki, EmilyM. Martersteck, John J. Trombetta,David A. Weitz, Joshua R. Sanes, AlexK. Shalek, Aviv Regev, Steven A.McCarroll",Cell,,"Cells, the basic units of biological structure and function, vary broadly in type and state. Single-cell genomics can characterize cell identity and function, but limitations of ease and scale have prevented its broad application. Here we describe Drop-seq, a strategy for quickly profiling thousands of individual cells by separating them into nanoliter-sized aqueous droplets, associating a different barcode with each cell's RNAs, and sequencing them all together. Drop-seq analyzes mRNA transcripts from thousands of individual cells simultaneously while remembering transcripts' cell of origin. We analyzed transcriptomes from 44,808 mouse retinal cells and identified 39 transcriptionally distinct cell populations, creating a molecular atlas of gene expression for known retinal cell classes and novel candidate cell subtypes. Drop-seq will accelerate biological discovery by enabling routine transcriptional profiling at single-cell resolution."
Interactive Visual Analysis of Mass Cytometry Data by Hierarchical Stochastic Neighbor Embedding Reveals Rare Cell Types,"Verna Van, Thomas Höllt, NicolaPezzotti, Na Li, M.J.T. Reinders, ElmarEisemann, Anna Vilanova, Frits Koning,Boudewijn P. F. Lelieveldt",Nature Biotechnology,,"Mass cytometry allows high-resolution dissection of the cellular composition of the immune system. However, the high-dimensionality, large size, and non-linear structure of the data poses considerable challenges for data analysis. In particular, dimensionality reduction-based techniques like t-SNE offer single-cell resolution but are limited in the number of cells that can be analysed. Here we introduce Hierarchical Stochastic Neighbor Embedding (HSNE) for the analysis of mass cytometry datasets. HSNE constructs a hierarchy of non-linear similarities that can be interactively explored with a stepwise increase in detail up to the single-cell level. We applied HSNE to a study on gastrointestinal disorders and three other available mass cytometry datasets. We found that HSNE efficiently replicates previous observations and identifies rare cell populations that were previously missed due to downsampling. Thus, HSNE removes the scalability limit of conventional t-SNE analysis, a feature that makes it highly suitable for the analysis of massive high-dimensional datasets.

"
The dynamics and regulators of cell fate decisions are revealed by pseudo temporal ordering of single cells,"Cole Trapnell, Davide Cacchiarelli,Jonna Grimsby, Prapti Pokharel,Shuqiang Li, Michael Morse, Niall J.Lennon, Kenneth J Livak, Tarjei S.Mikkelsen, John L. Rinn",Nature Biotechnology,,"Defining the transcriptional dynamics of a temporal process such as cell differentiation is challenging owing to the high variability in gene expression between individual cells. Time-series gene expression analyses of bulk cells have difficulty distinguishing early and late phases of a transcriptional cascade or identifying rare subpopulations of cells, and single-cell proteomic methods rely on a priori knowledge of key distinguishing markers. Here we describe Monocle, an unsupervised algorithm that increases the temporal resolution of transcriptome dynamics using single-cell RNA-Seq data collected at multiple time points. Applied to the differentiation of primary human myoblasts, Monocle revealed switch-like changes in expression of key regulatory factors, sequential waves of gene regulation, and expression of regulators that were not known to act in differentiation. We validated some of these predicted regulators in a loss-of function screen. Monocle can in principle be used to recover single-cell gene expression kinetics from a wide array of cellular processes, including differentiation, proliferation and oncogenic transformation"
Efficient integration of heterogeneous single-cell transcriptomes using Scanorama,"Brian Hie, Bryan Bryson, Bonnie Berger",Nature Biotechnology,,"Integration of single-cell RNA sequencing (scRNA-seq) data from multiple experiments, laboratories and technologies can uncover biological insights, but current methods for scRNA-seq data integration are limited by a requirement for datasets to derive from functionally similar cells. We present Scanorama, an algorithm that identifies and merges the shared cell types among all pairs of datasets and accurately integrates heterogeneous collections of scRNA-seq data. We applied Scanorama to integrate and remove batch effects across 105,476 cells from 26 diverse scRNA-seq experiments representing 9 different technologies. Scanorama is sensitive to subtle temporal changes within the same cell lineage, successfully integrating functionally similar cells across time series data of CD14+ monocytes at different stages of differentiation into macrophages. Finally, we show that Scanorama is orders of magnitude faster than existing techniques and can integrate a collection of 1,095,538 cells in just ~9 h."
Reversed graph embedding resolves complex single-cell trajectories,"Xiaojie Qiu, Qi Mao, Ying Tang, Li mengWang, Raghav Chawla, Hannah APliner, Cole Trapnell",Nature Methods,,"Single-cell trajectories can unveil how gene regulation governs cell fate decisions. However, learning the structure of complex trajectories with multiple branches remains a challenging computational problem. We present Monocle 2, an algorithm that uses reversed graph embedding to describe multiple fate decisions in a fully unsupervised manner. We applied Monocle 2 to two studies of blood development and found that mutations in the genes encoding key lineage transcription factors divert cells to alternative fates."
Recovering Gene Interactions from Single-Cell Data Using Data Diffusion,"David van Dijk, Roshan Sharma, JuozasNainys, Kristina M Yim, Dana Pe’er",Cell,EMT; imputation; manifold learning; regulatory networks; single-cell RNA sequencing,"Single-cell RNA sequencing technologies suffer from many sources of technical noise, including under-sampling of mRNA molecules, often termed ""dropout,"" which can severely obscure important gene-gene relationships. To address this, we developed MAGIC (Markov affinity-based graph imputation of cells), a method that shares information across similar cells, via data diffusion, to denoise the cell count matrix and fill in missing transcripts. We validate MAGIC on several biological systems and find it effective at recovering gene-gene relationships and additional structures. Applied to the epithilial to mesenchymal transition, MAGIC reveals a phenotypic continuum, with the majority of cells residing in intermediate states that display stem-like signatures, and infers known and previously uncharacterized regulatory interactions, demonstrating that our approach can successfully uncover regulatory relations without perturbations."
UMAP: Uniform Manifold Approximation and Projection,"Leland McInnes, John Healy, NathanielSaul, Lukas Großberger",arXiv,,"UMAP (Uniform Manifold Approximation and Projection) is a novel manifold learning technique for dimension reduction. UMAP is constructed from a theoretical framework based in Riemannian geometry and algebraic topology. The result is a practical scalable algorithm that applies to real world data. The UMAP algorithm is competitive with t-SNE for visualization quality, and arguably preserves more of the global structure with superior run time performance. Furthermore, UMAP has no computational restrictions on embedding dimension, making it viable as a general purpose dimension reduction technique for machine learning."
Diffusion pseudo time robustly reconstructs lineage branching,"Laleh Haghverdi, Maren Büttner, F.Alexander Wolf, Florian Buettner,Fabian Joachim Theis",Nature Methods,,"The temporal order of differentiating cells is intrinsically encoded in their single-cell expression profiles. We describe an efficient way to robustly estimate this order according to diffusion pseudotime (DPT), which measures transitions between cells using diffusion-like random walks. Our DPT software implementations make it possible to reconstruct the developmental progression of cells and identify transient or metastable states, branching decisions and differentiation endpoints."
Statistic Software for Neighbor Embedding,Jie Zhao,University of Helsinki,,"Dimension reduction presents expanding importance and prevalence since it lessens the challenge to data visualization and exploratory analysis that numerous science areas rely on. Recently, nonlinear dimension reduction (NLDR) methods have achieved superior performance in coping with complicated data manifolds embedded in high dimensional space. However, conventional statistic software for NLDR visualization purpose (e.g Multidimensional Scaling) often gives undesired desirable layouts. In this thesis work, to improve the performance of NLDR for data visualization, we study the recently proposed and efficient neighbor embedding (NE) framework and develop its software package in statistic software R. The neighbor embedding framework consists of a wide family of NLDR including stochastic neighbor embedding (SNE), symmetric SNE etc. Yet the original SNE optimization algorithm has several drawbacks. For example, it cannot be extended to other NE objective functions and requires quadratic computation cost. To address these drawbacks, we unify many different NE objective functions through several software layers and adopt a tree-based approach for computation acceleration. The core algorithm is implemented in C++ with an lightweight R wrapper. It thus provides an efficient and convenient package for researchers and engineers who work on statistics. We demonstrate the developed software by visualizing the two-dimensional layouts for several typical datasets in machine learning research including MNIST, COIL-20 and Phonemes etc. The results show that NE methods significantly outperform the traditional MDS visualization tool, indicating NE as a promising and useful dimension reduction tool for data visualization in statistics."
Missing data and technical variability in single‐cell RNA‐sequencing experiments,"Stephanie C. Hicks, William F Townes,Mingxiang Teng, Rafael A. Irizarry",Biostatistics,,"Until recently, high-throughput gene expression technology, such as RNA-Sequencing (RNA-seq) required hundreds of thousands of cells to produce reliable measurements. Recent technical advances permit genome-wide gene expression measurement at the single-cell level. Single-cell RNA-Seq (scRNA-seq) is the most widely used and numerous publications are based on data produced with this technology. However, RNA-seq and scRNA-seq data are markedly different. In particular, unlike RNA-seq, the majority of reported expression levels in scRNA-seq are zeros, which could be either biologically-driven, genes not expressing RNA at the time of measurement, or technically-driven, genes expressing RNA, but not at a sufficient level to be detected by sequencing technology. Another difference is that the proportion of genes reporting the expression level to be zero varies substantially across single cells compared to RNA-seq samples. However, it remains unclear to what extent this cell-to-cell variation is being driven by technical rather than biological variation. Furthermore, while systematic errors, including batch effects, have been widely reported as a major challenge in high-throughput technologies, these issues have received minimal attention in published studies based on scRNA-seq technology. Here, we use an assessment experiment to examine data from published studies and demonstrate that systematic errors can explain a substantial percentage of observed cell-to-cell expression variability. Specifically, we present evidence that some of these reported zeros are driven by technical variation by demonstrating that scRNA-seq produces more zeros than expected and that this bias is greater for lower expressed genes. In addition, this missing data problem is exacerbated by the fact that this technical variation varies cell-to-cell. Then, we show how this technical cell-to-cell variability can be confused with novel biological results. Finally, we demonstrate and discuss how batch-effects and confounded experiments can intensify the problem."
Panoramic stitching of heterogeneous single-cell transcriptomic data,"Brian Hie, Bryan Bryson, Bonnie Berger",Nature Biotechnology,,"Researchers are generating single-cell RNA sequencing (scRNA-seq) profiles of diverse biological systems1–4 and every cell type in the human body.5 Leveraging this data to gain unprecedented insight into biology and disease will require assembling heterogeneous cell populations across multiple experiments, laboratories, and technologies. Although methods for scRNA-seq data integration exist6,7, they often naively merge data sets together even when the data sets have no cell types in common, leading to results that do not correspond to real biological patterns. Here we present Scanorama, inspired by algorithms for panorama stitching, that overcomes the limitations of existing methods to enable accurate, heterogeneous scRNA-seq data set integration. Our strategy identifies and merges the shared cell types among all pairs of data sets and is orders of magnitude faster than existing techniques. We use Scanorama to combine 105,476 cells from 26 diverse scRNA-seq experiments across 9 different technologies into a single comprehensive reference, demonstrating how Scanorama can be used to obtain a more complete picture of cellular function across a wide range of scRNA-seq experiments."
"Fast, sensitive, and accurate integration of single cell data with Harmony","Ilya Korsunsky, Jean Fan, KamilSlowikowski, Fan Zhang, Kevin Wei,Yuriy Baglaenko, Michael B Brenner,Po-Ru Loh, Soumya Raychaudhuri",Nature Methods,,"The emerging diversity of single-cell RNA-seq datasets allows for the full transcriptional characterization of cell types across a wide variety of biological and clinical conditions. However, it is challenging to analyze them together, particularly when datasets are assayed with different technologies, because biological and technical differences are interspersed. We present Harmony , an algorithm that projects cells into a shared embedding in which cells group by cell type rather than dataset-specific conditions. Harmony simultaneously accounts for multiple experimental and biological factors. In six analyses, we demonstrate the superior performance of Harmony to previously published algorithms while requiring fewer computational resources. Harmony enables the integration of ~106 cells on a personal computer. We apply Harmony to peripheral blood mononuclear cells from datasets with large experimental differences, five studies of pancreatic islet cells, mouse embryogenesis datasets and the integration of scRNA-seq with spatial transcriptomics data."
Droplet Barcoding for Single-Cell Transcriptomics Applied to Embryonic Stem Cells,"Allon M. Klein, Linas Mazutis, IlkeAkartuna, Naren Tallapragada, AdrianVeres, Victor H. Li, Leonid Peshkin,David A. Weitz, Marc W Kirschner",Cell,,"It has long been the dream of biologists to map gene expression at the single cell level. With such data one might track heterogeneous cell sub-populations, and infer regulatory relationships between genes and pathways. Recently, RNA sequencing has achieved single cell resolution. What is limiting is an effective way to routinely isolate and process large numbers of individual cells for quantitative in-depth sequencing. We have developed a high-throughput droplet-microfluidic approach for barcoding the RNA from thousands of individual cells for subsequent analysis by next-generation sequencing. The method shows a surprisingly low noise profile and is readily adaptable to other sequencing-based assays. We analyzed mouse embryonic stem cells, revealing in detail the population structure and the heterogeneous onset of differentiation after LIF withdrawal. The reproducibility of these high-throughput single cell data allowed us to deconstruct cell populations and infer gene expression relationships."
PixelSNE: Visualizing Fast with Just Enough Precision via Pixel-Aligned Stochastic Neighbor Embedding,"Minjeong Kim, Minsuk Choi, SunwoongLee, Jian Tang, Haesun Park, JaegulChoo",arXiv,t-SNE; Barnes-Hut SNE; Dimension reduction; 2D embedding; Scatterplot; Visualization,"Embedding and visualizing large-scale high-dimensional data in a two-dimensional space is an important problem since such visualization can reveal deep insights out of complex data. Most of the existing embedding approaches, however, run on an excessively high precision, ignoring the fact that at the end, embedding outputs are converted into coarse-grained discrete pixel coordinates in a screen space. Motivated by such an observation and directly considering pixel coordinates in an embedding optimization process, we accelerate Barnes-Hut tree-based t-distributed stochastic neighbor embedding (BH-SNE), known as a state-of-the-art 2D embedding method, and propose a novel method called PixelSNE, a highly-efficient, screen resolution-driven 2D embedding method with a linear computational complexity in terms of the number of data items. Our experimental results show the significantly fast running time of PixelSNE by a large margin against BH-SNE, while maintaining the minimal degradation in the embedding quality."
Assessing the reliability of spike-in normalization for analyses of single-cell RNA sequencing data,"Aaron T. L. Lun, Fernando J. Calero-Nieto, Liora Haim-Vilmovsky, BertholdGöttgens, John C. Marioni",Genome Research,,"By profiling the transcriptomes of individual cells, single-cell RNA sequencing provides unparalleled resolution to study cellular heterogeneity. However, this comes at the cost of high technical noise, including cell-specific biases in capture efficiency and library generation. One strategy for removing these biases is to add a constant amount of spike-in RNA to each cell and to scale the observed expression values so that the coverage of spike-in transcripts is constant across cells. This approach has previously been criticized as its accuracy depends on the precise addition of spike-in RNA to each sample. Here, we perform mixture experiments using two different sets of spike-in RNA to quantify the variance in the amount of spike-in RNA added to each well in a plate-based protocol. We also obtain an upper bound on the variance due to differences in behavior between the two spike-in sets. We demonstrate that both factors are small contributors to the total technical variance and have only minor effects on downstream analyses, such as detection of highly variable genes and clustering. Our results suggest that scaling normalization using spike-in transcripts is reliable enough for routine use in single-cell RNA sequencing data analyses."
"Scater: pre-processing, quality control, normalization and visualization of single-cell RNA-seq data in R","Davis J. McCarthy, Kieran R. Campbell,Aaron T. L. Lun, Quin F. Wills",Bioinformatics ,,"Single-cell RNA sequencing (scRNA-seq) is increasingly used to study gene expression at the level of individual cells. However, preparing raw sequence data for further analysis is not a straightforward process. Biases, artifacts and other sources of unwanted variation are present in the data, requiring substantial time and effort to be spent on pre-processing, quality control (QC) and normalization. We have developed the R/Bioconductor package scater to facilitate rigorous pre-processing, quality control, normalization and visualization of scRNA-seq data. The package provides a convenient, flexible workflow to process raw sequencing reads into a high-quality expression dataset ready for downstream analysis. scater provides a rich suite of plotting tools for single-cell data and a flexible data structure that is compatible with existing tools and can be used as infrastructure for future software development."
A test metric for assessing single-cell RNA-seq batch correction,"Maren Büttner, Zhichao Miao, F.Alexander Wolf, Sarah A. Teichmann,Fabian Joachim Theis",Nature Methods,,"Single-cell transcriptomics is a versatile tool for exploring heterogeneous cell populations, but as with all genomics experiments, batch effects can hamper data integration and interpretation. The success of batch-effect correction is often evaluated by visual inspection of low-dimensional embeddings, which are inherently imprecise. Here we present a user-friendly, robust and sensitive k-nearest-neighbor batch-effect test for quantification of batch effects. We used kBET to assess commonly used batch-regression and normalization approaches, and to quantify the extent to which they remove batch effects while preserving biological variability. We also demonstrate the application of kBET to data from peripheral blood mononuclear cells (PBMCs) from healthy donors to distinguish cell-type-specific inter-individual variability from changes in relative proportions of cell populations. This has important implications for future data-integration efforts, central to projects such as the Human Cell Atlas."
Pooling across cells to normalize single-cell RNA sequencing data with many zerocounts,"Aaron T. L. Lun, Karsten Bach, John C.Marioni",Genome Biology,"Single-cell RNA-seq, Normalization, Differential expression","Normalization of single-cell RNA sequencing data is necessary to eliminate cell-specific biases prior to downstream analyses. However, this is not straightforward for noisy single-cell data where many counts are zero. We present a novel approach where expression values are summed across pools of cells, and the summed values are used for normalization. Pool-based size factors are then deconvolved to yield cell-based factors. Our deconvolution approach outperforms existing methods for accurate normalization of cell-specific biases in simulated data. Similar behavior is observed in real data, where deconvolution improves the relevance of results of downstream analyses."
Characterizing the replicability of cell types defined by single cell RNA-sequencing data using MetaNeighbor,"Megan Crow, Anirban Paul, SaraBallouz, Z. Josh Huang, Jesse Gillis",Nature Communications,,"Single-cell RNA-sequencing (scRNA-seq) technology provides a new avenue to discover and characterize cell types; however, the experiment-specific technical biases and analytic variability inherent to current pipelines may undermine its replicability. Meta-analysis is further hampered by the use of ad hoc naming conventions. Here we demonstrate our replication framework, MetaNeighbor, that quantifies the degree to which cell types replicate across datasets, and enables rapid identification of clusters with high similarity. We first measure the replicability of neuronal identity, comparing results across eight technically and biologically diverse datasets to define best practices for more complex assessments. We then apply this to novel interneuron subtypes, finding that 24/45 subtypes have evidence of replication, which enables the identification of robust candidate marker genes. Across tasks we find that large sets of variably expressed genes can identify replicable cell types with high accuracy, suggesting a general route forward for large-scale evaluation of scRNA-seq data."
Type 1 and 2 mixtures of Kullback-Leibler divergences as cost functions in dimensionality reduction based on similarity preservation,"John Aldo Lee, Emilie Renard,Guillaume Bernard, Pierre Dupont,Michel Verleysen",Neurocomputing,"Dimensionality reduction, Manifold learning, Stochastic neighbor embedding, Divergence","Stochastic neighbor embedding (SNE) and its variants are methods of dimensionality reduction (DR) that involve normalized softmax similarities derived from pairwise distances. These methods try to reproduce in the low-dimensional embedding space the similarities observed in the high-dimensional data space. Their outstanding experimental results, compared to previous state-of-the-art methods, originate from their capability to foil the curse of dimensionality. Previous work has shown that this immunity stems partly from a property of shift invariance that allows appropriately normalized softmax similarities to mitigate the phenomenon of norm concentration. This paper investigates a complementary aspect, namely, the cost function that quantifies the mismatch between similarities computed in the high- and low-dimensional spaces. Stochastic neighbor embedding and its variant t-SNE rely on a single Kullback–Leibler divergence, whereas a weighted mixture of two dual KL divergences is used in neighborhood retrieval and visualization (NeRV). We propose in this paper a different mixture of KL divergences, which is a scaled version of the generalized Jensen–Shannon divergence. We show experimentally that this divergence produces embeddings that better preserve small K-ary neighborhoods, as compared to both the single KL divergence used in SNE and t-SNE and the mixture used in NeRV. These results allow us to conclude that future improvements in similarity-based DR will likely emerge from better definitions of the cost function."
Multiplexed droplet single-cell RNA-sequencing using natural genetic variation,"Hyun Min Kang, Meena Subramaniam,Sasha Targ, Michelle Nguyen, LenkaMaliskova, Elizabeth Anne McCarthy,Eunice Wan, Sio Leng Wong, Lauren EByrnes, Cristina M Lanata, Rachel E.Gate, S. Mostafavi, Alexander Marson,Noah Zaitlen, Lindsey A. Criswell, ChunJimmie Ye",Nature Biotechnology,,"Droplet single-cell RNA-sequencing (dscRNA-seq) has enabled rapid, massively parallel profiling of transcriptomes. However, assessing differential expression across multiple individuals has been hampered by inefficient sample processing and technical batch effects. Here we describe a computational tool, demuxlet, that harnesses natural genetic variation to determine the sample identity of each droplet containing a single cell (singlet) and detect droplets containing two cells (doublets). These capabilities enable multiplexed dscRNA-seq experiments in which cells from unrelated individuals are pooled and captured at higher throughput than in standard workflows. Using simulated data, we show that 50 single-nucleotide polymorphisms (SNPs) per cell are sufficient to assign 97% of singlets and identify 92% of doublets in pools of up to 64 individuals. Given genotyping data for each of eight pooled samples, demuxlet correctly recovers the sample identity of >99% of singlets and identifies doublets at rates consistent with previous estimates. We apply demuxlet to assess cell-type-specific changes in gene expression in 8 pooled lupus patient samples treated with interferon (IFN)-β and perform eQTL analysis on 23 pooled samples."
"Bias, robustness and scalability in single-cell differential expression analysis","Charlotte Soneson, Mark D. Robinson",Nature Methods,,"Many methods have been used to determine differential gene expression from single-cell RNA (scRNA)-seq data. We evaluated 36 approaches using experimental and synthetic data and found considerable differences in the number and characteristics of the genes that are called differentially expressed. Prefiltering of lowly expressed genes has important effects, particularly for some of the methods developed for bulk RNA-seq data analysis. However, we found that bulk RNA-seq analysis methods do not generally perform worse than those developed specifically for scRNA-seq. We also present conquer, a repository of consistently processed, analysis-ready public scRNA-seq data sets that is aimed at simplifying method evaluation and reanalysis of published results. Each data set provides abundance estimates for both genes and transcripts, as well as quality control and exploratory analysis reports."
Interpretable dimensionality reduction of single cell transcriptome data with deep generative models,"Jiarui Ding, Anne Condon, Sohrab P.Shah",Nature Communications,,"Single-cell RNA-sequencing has great potential to discover cell types, identify cell states, trace development lineages, and reconstruct the spatial organization of cells. However, dimension reduction to interpret structure in single-cell sequencing data remains a challenge. Existing algorithms are either not able to uncover the clustering structures in the data or lose global information such as groups of clusters that are close to each other. We present a robust statistical model, scvis, to capture and visualize the low-dimensional structures in single-cell gene expression data. Simulation results demonstrate that low-dimensional representations learned by scvis preserve both the local and global neighbor structures in the data. In addition, scvis is robust to the number of data points and learns a probabilistic parametric mapping function to add new data points to an existing embedding. We then use scvis to analyze four single-cell RNA-sequencing datasets, exemplifying interpretable two-dimensional representations of the high-dimensional single-cell RNA-sequencing data."
Assessment of batch-correction methods for scRNA-seq data with a new test metric,"Maren Büttner, Zhichao Miao, F.Alexander Wolf, Sarah A. Teichmann,Fabian Joachim Theis",Nature Methods,,"Single-cell transcriptomics is a versatile tool for exploring heterogeneous cell populations, but as with all genomics experiments, batch effects can hamper data integration and interpretation. The success of batch-effect correction is often evaluated by visual inspection of low-dimensional embeddings, which are inherently imprecise. Here we present a user-friendly, robust and sensitive k-nearest-neighbor batch-effect test (kBET; https://github.com/theislab/kBET ) for quantification of batch effects. We used kBET to assess commonly used batch-regression and normalization approaches, and to quantify the extent to which they remove batch effects while preserving biological variability. We also demonstrate the application of kBET to data from peripheral blood mononuclear cells (PBMCs) from healthy donors to distinguish cell-type-specific inter-individual variability from changes in relative proportions of cell populations. This has important implications for future data-integration efforts, central to projects such as the Human Cell Atlas."
Visualizing Large-scale and High-dimensional Data,"Jian Tang, Jingzhou Liu, Ming Zhang,Qiaozhu Mei",arXiv,"Visualization, big data, high-dimensional data","We study the problem of visualizing large-scale and high-dimensional data in a low-dimensional (typically 2D or 3D) space. Much success has been reported recently by techniques that first compute a similarity structure of the data points and then project them into a low-dimensional space with the structure preserved. These two steps suffer from considerable computational costs, preventing the state-of-the-art methods such as the t-SNE from scaling to large-scale and high-dimensional data (e.g., millions of data points and hundreds of dimensions). We propose the LargeVis, a technique that first constructs an accurately approximated K-nearest neighbor graph from the data and then layouts the graph in the low-dimensional space. Comparing to t-SNE, LargeVis significantly reduces the computational cost of the graph construction step and employs a principled probabilistic model for the visualization step, the objective of which can be effectively optimized through asynchronous stochastic gradient descent with a linear time complexity. The whole procedure thus easily scales to millions of high-dimensional data points. Experimental results on real-world data sets demonstrate that the LargeVis outperforms the state-of-the-art methods in both efficiency and effectiveness. The hyper-parameters of LargeVis are also much more stable over different data sets."
Flexible Experimental Designs for Valid Single-cell RNA-sequencing Experiments Allowing Batch Effects Correction,"Fangda Song, Ga Ming Chan, YingyingWei",Nature Communications,,"Despite their widespread applications, single-cell RNA-sequencing (scRNA-seq) experiments are still plagued by batch effects and dropout events. Although the completely randomized experimental design has frequently been advocated to control for batch effects, it is rarely implemented in real applications due to time and budget constraints. Here, we mathematically prove that under two more flexible and realistic experimental designs—the reference panel and the chain-type designs—true biological variability can also be separated from batch effects. We develop Batch effects correction with Unknown Subtypes for scRNA-seq data (BUSseq), which is an interpretable Bayesian hierarchical model that closely follows the data-generating mechanism of scRNA-seq experiments. BUSseq can simultaneously correct batch effects, cluster cell types, impute missing data caused by dropout events, and detect differentially expressed genes without requiring a preliminary normalization step. We demonstrate that BUSseq outperforms existing methods with simulated and real data."
Embedded entrepreneurship: on the role of online communities in entrepreneurial activity,"Christine Moser, Peter P. Groenewegen,Ingrid Wakkee",,,"In the past, entrepreneurship theory has largely ignored social aspects. Dominant paradigms, such as the ‘soloist’ and even the network approach, center on the proactive role of individual entrepreneurs. We argue that these traditional perspectives on entrepreneurship should be extended to the idea of embedded entrepreneurship: the process of starting up an enterprise while and as a consequence of being part of a relevant social group. In order to support our theory, we offer empirical evidence from a case study that draws on interview, survey and archival data. Qualitative and quantitative analyses show that five widely recognized entrepreneurial processes - opportunity recognition, resource-building, organizing, legitimation, and opportunity exploitation – have a different meaning from an embedded entrepreneurship perspective. Here, the entrepreneur as individual and the community as a social group both contribute to the implementation of the five processes. We conclude by suggesting that community membership influences entrepreneurial activities positive as well as negative, and point out several directions for future research"
Detection of Imperative and Declarative Question-Answer Pairs in Email Conversations,"Helen Kwong, Neil Yorke-Smith",AI Communications,"Email, question–answer pairing, information extraction, NLP","Question–answer pairs extracted from email threads are valuable in constructing summaries of the content of the thread, as well as in providing data for semantic-based assistance with email. Previous work dedicated to extracting question–answer pairs from email threads considers only questions in interrogative form. We extend the scope of question and answer detection and pairing to encompass questions in imperative and declarative forms, and to operate at sentence-level fidelity. Building on prior work, our methods are based on learned models over a set of features that include the content, context, and structure of email threads. On multiple benchmark email corpora, we show that our methods balance precision and recall in extracting question–answer pairs, while maintaining a modest computation time."
Web Mining and Social Network Analysis,Roberto Marmo,"Visual Analytics and Interactive Technologies: Data, Text and Web Mining Applications",,"Research on social networks has advanced significantly due to wide variety of on-line social websites and very popular Web 2.0 application. Social network analysis views social relationships in terms of network and graph theory about nodes (individual actors within the network) and ties (relationships between the actors). Using web mining techniques and social networks analysis it is possible to process and analyze large amount of social data (such as blogtagging, online game playing, instant messenger etc.) and by this to discover valuable information from data. In this way, we can understand the social structure, social relationships and social behaviors. This new approach is also denoted as social network mining. These algorithms differ from established set of data mining algorithms developed to analyze individual records, because social network datasets are called relational due to centrality of relations among entities. This chapter also sets out a process to apply web mining."
A study of features on Primary Question detection in Chinese online forums,"Lin Sun, Bingquan Liu, Baoxun Wang,Deyuan Zhang, Xiaolong Wang",IEEE,primary question detection; textual feature; N-gram feature; classification; information extraction,"Primary Question detection in online forum is a subtask of extracting question-answer pairs. In this paper, by surveying the forms of questions in Chinese online forums, a combination of textual and N-gram features achieved via feature selection is adopted to help detecting primary questions. By viewing primary question detection a binary classification problem, decision tree classifier C4.5 and support vector machine are introduced to distinguish questions from non-questions separately. Experimental results across multiple datasets demonstrate that the mixture of textual and N-gram features performs better than using each of them separately under both C4.5 and support vector machine. By computing the weight of each feature in the two classifiers, the top 6 features are found the very same except for a little adjustment of order, showing that the combination of textual and N-gram features is universal and effective in detecting primary questions."
Continuous-spaced action selection for single- and multi-robot tasks using cooperative extended Kohonen maps,"Kian Hsiang Low, Wee Kheng Leow,Marcelo H. Ang",IEEE,,"Action selection is a central issue in the design of behavior-based control architectures for autonomous mobile robots. This paper presents an action selection framework based on an assemblage of self-organizing neural networks called Cooperative Extended Kohonen Maps. This framework encapsulates two features that significantly enhance a robot's action selection capability: self-organization in the continuous state and action spaces to provide smooth, efficient and fine motion control; action selection via the cooperation and competition of Extended Kohonen Maps so that more complex motion tasks can be achieved. Qualitative and quantitative comparisons for both single- and multi-robot motion tasks show that our framework can provide better action selection than do action superposition methods."
Our Achilles' Heel: Language Skills,John W. Davis,Military Review ,,"Imagine you are a Soldier in Iraq or Afghanistan. Wouldn't you feel safer if your combat leader was a linguist and conversant with local customs? What if your company's intelligence was provided by an illiterate? What if your best translator was someone the locals despised or considered to be a spy? How can we distinguish between the respected, the thugs, the honest, or the dregs of a foreign society, if we cannot understand what they say to us? We Americans have a cultural bias against learning languages other than English, but now our Soldiers' lives depend on our doing so. How accurately and well we analyze the indigenous people we deal with during the Global War on Terrorism might well determine the success or failure of counterinsurgency operations. Our combat training will be for nothing if our linguist does not tell us the truth or fails to recognize it because of a lack of training. A lack of foreign language skills is our Army's Achilles' heel. Timeliness and accuracy is everything in intelligence, and thus, a linguist's skills are more important than firepower. With the former, you might not need the latter. Foreign language skills are mission-essential for an expeditionary army. Our Soldiers die in foreign lands because American comrades they can absolutely trust lack those skills. We forget that our job is to move, shoot, and communicate, and we forget that ""communicate"" does not refer just to radios. When we conduct a raid and find no one there, what was the cause? Was the intelligence bad? Did we give the mission away because of poor operations security? Were we led to the wrong target? Were we too late in getting there? Was the enemy tipped off that we were coming? Is it possible our linguist missed a critical nuance because of his lack of skill? Where should the damage assessment begin? Who knew the truth? And who translated it for him?"
The icing on the cake - combining relational and semantic methods to extract meaning from online message board postings,"Christine Moser, Iina Hellsten, Peter P.Groenewegen",Proceedings of the ACM WebSci'11,Online Communities; Social Network Analysis; Semantic Maps; Content Analysis; Mixed Methods.,"In recent years, we have seen a rapid growth of online communities on the Web. These virtual communities serve as socio-technical platforms for various professionals, entrepreneurs and serious hobbyists to engage in discussion around a shared area of interest. They mostly use these platforms to exchange knowledge and expertise. So far, online communities have been analysed either via the structure of the communities or the content of messages and the motivations of members. We argue that in order to gain insight in the dynamics of online communities, we have to combine a set of methods that allows for the analysis of both the structure as well as the content of communications in these communities. Empirical studies in the domain of online communities usually employ a single method. Often, motivations to participate in these communities were investigated [e.g., 1, 2]. Other research focused on behaviour of community members [e.g., 3, 4]. Some of these studies employed qualitative methods, especially case studies [5-6] and ethnographies [7-8]. However, studies that combine different methods are scarce [9]. This holds in particular for studies that focus on relational (using social network analysis) and interpretational information (using for example semantic maps). To our knowledge, studies that employ both methods are lacking. With this paper, we want to contribute to the literature by proposing a way to combine both approaches. We illustrate the approach with data from an online community, and discuss implications for researchers."
Extracting Chinese question-answer pairs from online forums,"Baoxun Wang, Bingquan Liu, ChengjieSun, Xiaolong Wang, Lin Sun",IEEE,"question answering, labeled sequential rules, nontextual features, classification, information extraction","Extracting question-answer pairs from online forums is a meaningful work due to the huge amount of valuable user generated resource contained in forums. In this paper we consider the problem of extracting Chinese question-answer pairs for the first time. We present a strategy to detect Chinese questions and their answers. We propose a sequential rule based method to find questions in a forum thread, then we adopt non-textual features based on forum structure to improve the performance of answer detecting in the same thread. Experimental results show that our techniques are very effective."
Modeling Semantic Relevance for Question-Answer Pairs in Web Social Communities,"Baoxun Wang, Xiaolong Wang,Chengjie Sun, Bingquan Liu, Lin Sun",ACL,,"Quantifying the semantic relevance between questions and their candidate answers is essential to answer detection in social media corpora. In this paper, a deep belief network is proposed to model the semantic relevance for question-answer pairs. Observing the textual similarity between the community-driven questionanswering (cQA) dataset and the forum dataset, we present a novel learning strategy to promote the performance of our method on the social community datasets without hand-annotating work. The experimental results show that our method outperforms the traditional approaches on both the cQA and the forum corpora."
Enhancing Social Network Analysis with a Concept-Based Text Mining Approach to Discover Key Members on a Virtual Community of Practice,"Héctor Álvarez, Sebastián A. Ríos,Felipe Aguilera, Eduardo Merlo, Luis A.Guerrero",Knowledge-Based and Intelligent Information and Engineering Systems,"Social Network Analysis, Goal Accomplishment, Virtual Community, Social Network Analysis Technique, Goal Score ","In order to have a successful VCoP two important tasks must be performed: on the one hand, it is always important that community provide useful information to every member by a good organization of contents and topics; on the other hand, to understand the behavior of members (i.e. which are the key members or experts, discover communities, etc). Social Network Analysis (SNA) is a powerful tool to understand the communities’ members, however, our theses is that state-of-the-art in SNA it is not sufficient to obtain useful knowledge from a VCoP. Moreover, we think that traditional SNA may lead to discover wrong results. We propose to combine traditional SNA with data mining techniques in order to produce results closer to reality and gather useful knowledge for VCoPs’ enhancement. In this work, we focused in discovering key members on a VCoP combining SNA with concept-based text mining.We successfully tested our approach on a real VCoP with more than 2500 members and we validate our results asking the community administrators."
Using Social Network Analysis to Support Collective Decision-Making Process,"Simon Buckingham Shum, LorellaCannavacciuolo, Anna De Liddo, LucaIandoli, Ivana Quinto",International Journal of Decision Support System Technology,"Argument Mapping Tool,Concept Network Analysis,Decision-Making Process,Group Decision Support System, Knowledge Management, Online Collaborative Tools, Social and Concept Network Visualization, Social Network Analysis","Current traditional technologies, while enabling effective knowledge sharing and accumulation, seem to be lesssupportive of knowledge organization, use and consensusformation, as well as of collaborative decision making process. To address these limitations and thus to better foster collective decision-making around complex and controversial problems, a new family of tools is emerging able to support more structured knowledge representations known as collaborative argument mapping tools. This paper argues that online collaborative argumentation has the rather unique feature of combining knowledge organization with social mapping and thatsuch a combination can provide interesting insights on the social processes activatedwithin a collaborative decision making initiative. In particular, the authorsinvestigate how Social Network Analysis can be used for the analysis of the collective argumentation process to study the structural properties of the concepts and social networks emerging from users’interaction. Using Cohere, an online platform designed to support collaborative argumentation, some empirical findings obtained from two use cases are presented."
Ego-Centric Network Sampling in Viral Marketing Applications,"Huaiyu Ma, Steven Gustafson, AbhaMoitra, David B. Bracewell",Mining and Analyzing Social Networks,"Degree Distribution, Social Network Analysis, Marketing Campaign, Random Edge, Burning Probability ","Marketing is most successful when people spread the message within their social network. The Internet can serve as an approximation of the spread of messages, particularly marketing campaigns, to both measure marketing effectiveness and provide data for influencing future efforts. However, to measure the network of web sites spreading the marketing message potentially requires a massive amount of data collection over a long period of time. Additionally, collecting data from the Internet is very noisy and can create a false sense of precision. Therefore, we propose to use ego-centric network sampling to both reduce the amount of data required to collect as well as handle the inherent uncertainty of the data collected. In this the book chapter, we study whether the proposed ego-centric network sampling accurately captures the network structure.We use the Stanford-Berkeley network to show that the approach can capture the underlying structure with a minimal amount of data."
Using Ethnography of Communication in Organizational Research,"Zoi Kalou, Eugene Sadler-Smith",Organizational Research methods,"ethnography, qualitative research, narrative, content and semiotic analysis, qualitative research, interpretivism, qualitative research","Ethnography of Communication offers new analytical and interpretive possibilities for contextually sensitized, language- and communication-based ethnographic studies of management and organization. In this article we provide an introduction and overview of relevant linguistic and related fields, positioning Ethnography of Communication within the broader context of anthropology, ethnomethodology, and sociolinguistics. We describe Dell Hymes’s seminal contribution to theory and method of Ethnography of Communication (foregrounding Hymes’s signature concept of “communicative competence”) and outline what the application of an Ethnography of Communication approach in management research might entail (illustrating the application of Hymes’s SPEAKING grid). We conclude by offering an example of how the methods of Ethnography of Communication might be applied usefully to the study of organizational language, discourse, and communication."
Deep Learning Approaches to Semantic Relevance Modeling for Chinese Question-Answer Pairs,"Baoxun Wang, Bingquan Liu, XiaolongWang, Chengjie Sun, Deyuan Zhang",ACM,"Deep belief network, question-answer pairs, semantic relevance","The human-generated question-answer pairs in the Web social communities are of great value for the research of automatic question-answering technique. Due to the large amount of noise information involved in such corpora, it is still a problem to detect the answers even though the questions are exactly located. Quantifying the semantic relevance between questions and their candidate answers is essential to answer detection in social media corpora. Since both the questions and their answers usually contain a small number of sentences, the relevance modeling methods have to overcome the problem of word feature sparsity. In this article, the deep learning principle is introduced to address the semantic relevance modeling task. Two deep belief networks with different architectures are proposed by us to model the semantic relevance for the question-answer pairs. According to the investigation of the textual similarity between the communitydriven question-answering (cQA) dataset and the forum dataset, a learning strategy is adopted to promote our models’ performance on the social community corpora without hand-annotating work. The experimental results show that our method outperforms the traditional approaches on both the cQA and the forum corpora."
A classification-based approach to question answering in discussion boards,"Liangjie Hong, Brian D. Davison",ACM,"question answering, discussion boards, online forums, classification","Discussion boards and online forums are important platforms for people to share information. Users post questions or problems onto discussion boards and rely on others to provide possible solutions and such question-related content sometimes even dominates the whole discussion board. However, to retrieve this kind of information automatically and effectively is still a non-trivial task. In addition, the existence of other types of information (e.g., announcements, plans, elaborations, etc.) makes it difficult to assume that every thread in a discussion board is about a question. We consider the problems of identifying question-related threads and their potential answers as classification tasks. Experimental results across multiple datasets demonstrate that our method can significantly improve the performance in both question detection and answer finding subtasks. We also do a careful comparison of how different types of features contribute to the final result and show that non-content features play a key role in improving overall performance. Finally, we show that a ranking scheme based on our classification approach can yield much better performance than prior published methods."
Using Conditional Random Fields to Extract Contexts and Answers of Questions from Online Forums,"Shilin Ding, Gao Cong, Chin-Yew Lin,Xiaoyan Zhu",ACL,,"Online forum discussions often contain vast amounts of questions that are the focuses of discussions. Extracting contexts and answers together with the questions will yield not only a coherent forum summary but also a valuable QA knowledge base. In this paper, we propose a general framework based on Conditional Random Fields (CRFs) to detect the contexts and answers of questions from forum threads. We improve the basic framework by Skip-chain CRFs and 2D CRFs to better accommodate the features of forums for better performance. Experimental results show that our techniques are very promising."
Does Similarity Matter? The Case of Answer Extraction from Technical Discussion Forums,"Rose Catherine, Amit Singh, RashmiGangadharaiah, Dinesh Raghu, KarthikVisweswariah",ACL,"Question Answering, Information & Content Extraction, Text Mining","Extracting question–answer pairs from social media discussions has garnered much attention in recent times. Several methods have been proposed in the past that pose this task as a post or sentence classification problem, which label each entry as an answer or not. This paper makes the first attempt at the following two–fold objectives: (a) In all classification based approaches towards this direction, one of the foremost signals used to identify answers is their similarity to the question. We study the contribution of content similarity specifically in the context of technical problem–solving domain. (b) We introduce hitherto unexplored features that aid in high–precision extraction of answers, and present a thorough study of the contribution of all features to this task. Our results show that, it is possible to extract answers using these features with high accuracy, when their similarity to the question is unreliable."
Unsupervised deep semantic and logical analysis for identification of solution posts from community answers,"Niraj Kumar, K. Srinathan, VasudevaVarma",International Journal of Decision Support System Technology,,"These days' discussion forums provide dependable solutions to the problems related to multiple domains and areas. However, due to the presence of huge amount of less-informative/inappropriate posts, the identification of the appropriate problem-solution pairs has become a challenging task. The emergence of a variety of topics, domains and areas has made the task of manual labelling of the problem solution-post pairs a very costly and time consuming task. To solve these issues, we concentrate on deep semantic and logical relation between terms. For this, we introduce a novel semantic correlation graph to represent the text. The proposed representation helps us in the identification of topical and semantic relation between terms at a fine grain level. Next, we apply the improved version of personalised pagerank using random walk with restarts. The main aim is to improve the rank score of terms having direct or indirect relation with terms in the given question. Finally, we introduce the use of the node overlapping version of GAAC to find the actual span of answer text. Our experimental results show that the devised system performs better than the existing unsupervised systems."
Finding question-answer pairs from online forums,"Gao Cong, Long Wang, Chin-Yew Lin,Young-In Song, Yueheng Sun",ACM,"question answering, graph based ranking, labeled sequential patterns, classification, information extraction","Online forums contain a huge amount of valuable user generated content. In this paper we address the problem of extracting question-answer pairs from forums. Question-answer pairs extracted from forums can be used to help Question Answering services (e.g. Yahoo! Answers) among other applications. We propose a sequential patterns based classification method to detect questions in a forum thread, and a graph based propagation method to detect answers for questions in the same thread. Experimental results show that our techniques are very promising."
Thread Segmentation Based Answer Detection in Chinese Online Forums,"Baoxun Wang, Bingquan Liu, ChengjieSun, Xiaolong Wang, Lin Sun",Acta Automatica Sinica,"Thread segmentation, non-textual feature, answer detection, online forum, question-answer pair mining","Detecting answers in the threads is an essential task for the online forum oriented question-answer (QA) pair mining. In the forum threads, there normally exist implicit discussion structures with the valuable indicating information for the answer detecting models to locate the best answers. This paper proposes a thread segmentation based answer detecting approach: a forum thread is reorganized into several segments, and a group of features reflecting the discussion structures are extracted based on the segmentation results. Utilizing the segment information, a strategy is put forward to find the best answers. By evaluating the candidate answers in different types of segments with different models, the strategy filters the samples that mislead the decision. The experimental results show that our approach is promising for mining the QA resource in the online forums."
Enhancing the reactive capabilities of integrated planning and control with Cooperative Extended Kohonen Maps,"Kian Hsiang Low, Wee Kheng Leow,Marcelo H. Ang",IEEE,,"Despite the many significant advances made in robot motion research, few works have focused on the tight integration of high-level deliberative planning with reactive control at the lowest level. In particular, the real-time performance of existing integrated planning and control architectures is still not optimal because the reactive control capabilities have not been fully realized. This paper aims to enhance the low-level reactive capabilities of integrated planning and control with Cooperative Extended Kohonen Maps for handling complex, unpredictable environments so that the work-load of the high-level planner can be consequently eased. The enhancements include fine, smooth motion control, execution of more complex motion tasks such as overcoming unforeseen concave obstacles and traversing between closely spaced obstacles, and asynchronous execution of behaviors."
A structural support vector method for extracting contexts and answers of questions from online forums,"Yunbo Cao, Wen-Yun Yang, Chin-YewLin, Yong Yu",Information Processing & Management,"Question answering, Information extraction","This article addresses the issue of extracting contexts and answers of questions from posts of online discussion forums. In previous work, general-purpose graphical models have been employed without any customization to this specific extraction problem. Instead, in this article, we propose a unified approach to context and answer extraction by customizing the structural support vector machine method. The customization enables our proposal to explore various relations among sentences of posts and complex structures of threads. We design new inference algorithms to find or approximate the most violated constraint by utilizing the specific structure of forum threads, which enables us to efficiently find the global optimum of the customized optimizing problem. We also optimize practical performance measures by varying loss functions. Experimental results show that our methods are both promising and flexible."
Discourse Analysis for Knowledge Acquisition: The Coherence Method,"Abdulla H. Abdul-Gader, Kenneth A.Kozar",Journal of Management Information Systems,"knowledge-based systems, expert systems, knowledge acquisition, discourse analysis","Recently there has been a tremendous increase in the development of knowledge-based systems in organizations. The quality of these systems and the cost of their development are largely dependent on the validity and reliability of the techniques used to acquire an expert’s knowledge. Knowledge acquisition is the process of extracting domain knowledge from experts and organizing this knowledge into a computer understandable form. In order to improve knowledge-based system performance and make these systems less costly to build, knowledge acquisition techniques must be improved. This paper presents a knowledge acquisition method to augment the existing unstructured elicitation techniques such as protocol analysis and interviews. The Coherence Method is based on Al planning theory [31] and coherence theory [21]. The authors’ experience in applying this method to a knowledge-based systems development project is reported. The Coherence Method proved useful in facilitating the understanding of the experts’ discourse, especially in early knowledge acquisition interviews. It provided the core knowledge that can guide subsequent knowledge elicitation techniques."
Exploiting Salient Patterns for Question Detection and Question Retrieval in Community-based Question Answering,"Kai Wang, Tat-Seng Chua",ACL,,"Question detection serves great purposes in the cQA question retrieval task. While detecting questions in standard language data corpus is relatively easy, it becomes a great challenge for online content. Online questions are usually long and informal, and standard features such as question mark or 5W1H words are likely to be absent. In this paper, we explore question characteristics in cQA services, and propose an automated approach to detect question sentences based on lexical and syntactic features. Our model is capable of handling informal online languages. The empirical evaluation results further demonstrate that our model significantly outperforms traditional methods in detecting online question sentences, and it considerably boosts the question retrieval performance in cQA."
Unsupervised Solution Post Identification from Discussion Forums,"P Deepak, Karthik Visweswariah",ACL,,"Discussion forums have evolved into a dependable source of knowledge to solve common problems. However, only a minority of the posts in discussion forums are solution posts. Identifying solution posts from discussion forums, hence, is an important research problem. In this paper, we present a technique for unsupervised solution post identification leveraging a so far unexplored textual feature, that of lexical correlations between problems and solutions. We use translation models and language models to exploit lexical correlations and solution post character respectively. Our technique is designed to not rely much on structural features such as post metadata since such features are often not uniformly available across forums. Our clustering-based iterative solution identification approach based on the EM-formulation performs favorably in an empirical evaluation, beating the only unsupervised solution identification technique from literature by a very large margin. We also show that our unsupervised technique is competitive against methods that require supervision, outperforming one such technique comfortably."
Exploiting Bilingual Translation for Question Retrieval in Community-Based Question Answering,"Guangyou Zhou, Kang Liu, Jun Zhao",ACL,,"Community-based question answering (CQA) has become an important issue due to the popularity of CQA archives on the web. This paper is concerned with the problem of question retrieval. Question retrieval in CQA archives aims to find historical questions that are semantically equivalent or relevant to the queried questions. However, question retrieval is challenging partly due to the word ambiguity and lexical gap between the queried questions and the historical questions in the archives. To deal with these problems, we propose the use of translated words to enrich the question representation, going beyond the words in the original language to represent a question. In this paper, each original language question (e.g., English) is automatically translated into an foreign language (e.g., Chinese) by machine translation services, and the resulting translated questions serves as a semantically enhanced representation for supplementing the original bag of words. Experiments conducted on real CQA data set demonstrate that our proposed approach significantly outperforms several baseline methods and achieves the state-of-the-art performance."
On effectiveness of wiretap programs in mapping social networks,"Maksim Tsvetovat, Kathleen M. Carley",Computational and Mathematical Organization Theory,"Terrorism, Social networks, Dynamic network analysis, Multi-agent modeling, Counter-terrorism, Covert networks, Sampling, Snowball, Simulated annealing","Snowball sampling methods are known to be a biased toward highly connected actors and consequently produce core-periphery networks when these may not necessarily be present. This leads to a biased perception of the underlying network which can have negative policy consequences, as in the identification of terrorist networks. When snowball sampling is used, the potential overload of the information collection system is a distinct problem due to the exponential growth of the number of suspects to be monitored. In this paper, we focus on evaluating the effectiveness of a wiretapping program in terms of its ability to map the rapidly evolving networks within a covert organization. By running a series of simulation-based experiments, we are able to evaluate a broad spectrum of information gathering regimes based on a consistent set of criteria. We conclude by proposing a set of information gathering programs that achieve higher effectiveness then snowball sampling, and at a lower cost."
Rapid modeling and analyzing networks extracted from pre-structured news articles,"Jürgen Pfeffer, Kathleen M. Carley",Computational and Mathematical Organization Theory,"Rapid network analysis, Rapid assessment, Network text analysis, Dynamic networks, Two mode networks, Weighted networks","In the face of uprisings and revolutions happening in several countries within short period of time (Arab Spring 2011), the need for fast network assessments is compelling. In this article we present a rapid network assessment approach which uses a vast amount of pre-indexed news data to provide up-to-date overview and orientation in emerging and ongoing incidents. We describe the fully automated process of preparing the data and creating the dynamic meta-networks. We also describe the network analytical measures that we are using to identify important topics, persons, organizations, and locations in these networks. With our rapid network modeling and analysis approach first results can be provided within hours. In the explorative study of this article we use 108,000+ articles from 600+ English written news sources discussing Egypt, Libya, and Sudan within a time period of 18 months to show an application scenario of our approach. In particular we are looking at the involvement of other countries and their politicians during time periods of major incidents."
Classifying User Messages For Managing Web Forum Data,"Sumit Bhatia, Prakhar Biyani, PrasenjitMitra",Fifteenth International Workshop on the Web and Databases,"Online forums, message boards, classification, speech act classification, dialogue act classification.","Online discussion forums have become a popular medium for users to discuss with and seek information from other users having similar interests. A typical discussion thread consists of a sequence of posts posted by multiple users. All the posts in a thread are not equally useful and serve a different purpose providing different types of information (some posts contain questions, some answers, etc.). Identifying the purpose and nature of each post in a discussion thread is an interesting research problem as it can help in improving information extraction and intelligent assistance techniques [9]. We study the problem of classifying a given post as per its purpose in the discussion thread. We employ features based on the post’s content, structure of the thread, behavior of the participating users and sentiment analysis of post’s content. We achieve decent classification performance and also analyze the relative importance of different features used for the post classification task."
Learning to suggest questions in social media,"Tom Chao Zhou, Michael R. Lyu, IrwinKing, Jie Lou",Knowledge and Information Systems,"Social media, Online forum, Community-based Q&A, Question suggestion, Language model,Topic modeling","Social media systems with Q&A functionalities have accumulated large archives of questions and answers. Two representative types are online forums and community-based Q&A services. To enable users to explore the large number of questions and answers in social media systems effectively, it is essential to suggest interesting items to an active user. In this article, we address the problem of question suggestion, which targets at suggesting questions that are semantically related to a queried question. Existing bag-of-words approaches suffer from the shortcoming that they could not bridge the lexical chasm between semantically related questions. Therefore, we present a new framework, and propose the topic-enhanced translation-based language model (TopicTRLM), which fuses both the lexical and latent semantic knowledge. This fusing enables TopicTRLM to find semantically related questions to a given question even when there is little word overlap. Moreover, to incorporate the answer information into the model to make the model more complete, we also propose the topic-enhanced translation-based language model with answer ensemble. Extensive experiments have been conducted with real-world datasets. Experimental results indicate our approach is very effective and outperforms other popular methods in several metrics."
Learning the Latent Topics for Question Retrieval in Community QA,"Li Cai, Guangyou Zhou, Kang Liu, JunZhao",ACL,,"Community-based Question Answering (cQA) is a popular online service where users can ask and answer questions on any topics. This paper is concerned with the problem of question retrieval. Question retrieval in cQA aims to find historical questions that are semantically equivalent or relevant to the queried questions. Although the translation-based language model (Xue et al., 2008) has gained the state-of-the-art performance for question retrieval, they ignore the latent topic information in calculating the semantic similarity between questions. In this paper, we propose a topic model incorporated with the category information into the process of discovering the latent topics in the content of questions. Then we combine the semantic similarity based latent topics with the translation-based language model into a unified framework for question retrieval. Experiments are carried out on a real world cQA data set from Yahoo! Answers. The results show that our proposed method can significantly improve the question retrieval performance of translation-based language model."
Phrase-Based Translation Model for Question Retrieval in Community Question Answer Archives,"Guangyou Zhou, Li Cai, Jun Zhao, KangLiu",ACL,,"Community-based question answer (Q&A) has become an important issue due to the popularity of Q&A archives on the web. This paper is concerned with the problem of question retrieval. Question retrieval in Q&A archives aims to find historical questions that are semantically equivalent or relevant to the queried questions. In this paper, we propose a novel phrase-based translation model for question retrieval. Compared to the traditional word-based translation models, the phrasebased translation model is more effective because it captures contextual information in modeling the translation of phrases as a whole, rather than translating single words in isolation. Experiments conducted on real Q&A data demonstrate that our proposed phrasebased translation model significantly outperforms the state-of-the-art word-based translation model."
Retrieval models for question and answer archives,"Xiaobing Xue, Jiwoon Jeon, W. BruceCroft",ACM,"Question and Answer Retrieval, Translation Model, Language Model, Information Retrieval","Retrieval in a question and answer archive involves finding good answers for a user’s question. In contrast to typical document retrieval, a retrieval model for this task can exploit question similarity as well as ranking the associated answers. In this paper, we propose a retrieval model that combines a translation-based language model for the question part with a query likelihood approach for the answer part. The proposed model incorporates word-to-word translation probabilities learned through exploiting different sources of information. Experiments show that the proposed translation based language model for the question part outperforms baseline methods significantly. By combining with the query likelihood language model for the answer part, substantial additional effectiveness improvements are obtained."
CQADupStack: A Benchmark Data Set for Community Question-Answering Research,"Doris Hoogeveen, Karin M. Verspoor,Timothy Baldwin",ACM,,"This paper presents a benchmark dataset, CQADupStack, for use in community question-answering (cQA) research. It contains threads from twelve StackExchange subforums, annotated with duplicate question information. We provide pre-defined training and test splits, both for retrieval and classification experiments, to ensure maximum comparability between different studies using the set. Furthermore, it comes with a script to manipulate the data in various ways. We give an analysis of the data in the set, and report benchmark results on a duplicate question retrieval task using well established retrieval models"
A structural support vector method for extracting contexts and answers of questions from online forums,"Wenyun Yang, Yunbo Cao, Chin-Yew Lin",Information Processing & Management,"Question answering, Information extraction","This article addresses the issue of extracting contexts and answers of questions from posts of online discussion forums. In previous work, general-purpose graphical models have been employed without any customization to this specific extraction problem. Instead, in this article, we propose a unified approach to context and answer extraction by customizing the structural support vector machine method. The customization enables our proposal to explore various relations among sentences of posts and complex structures of threads. We design new inference algorithms to find or approximate the most violated constraint by utilizing the specific structure of forum threads, which enables us to efficiently find the global optimum of the customized optimizing problem. We also optimize practical performance measures by varying loss functions. Experimental results show that our methods are both promising and flexible."
Detecting Near-Duplicate Relations in User Generated Forum Content,"Klemens Muthmann, Alexander Löser",OTM 2010: On the Move to Meaningful Internet Systems: OTM 2010 Workshops,"Name Entity Recognition, Spam Detector, Semantical Data Structure, Name Entity Recognition System, Information Piece ","A webforum is a large database of community knowledge, with information of the most recent events and developments. Unfortunately this knowledge is presented in a format easily understood by humans but not automatically by machines. However, from observing several forums for a long time it seems obvious that there are several distinct types of postings and relations between them. One often occurring and very annoying relation between two contributions is the near-duplicate relation. In this paper we propose a work to detect and utilize contribution relations, concentrating on near-duplication. We propose ideas on how to calculate similarity, build groups of similar threads and thus make near-duplicates in forums evident. One of the core theses is, that it is possible to apply information from forum and thread structure to improve existing near-duplicate detection approaches. In addition, the proposed work shows the qualitative and quantitative results of applying such principles, thereby finding out which features are really useful in the near-duplicate detection process. Also proposed are several sample applications, which benefit from forum near-duplicate detection."
Identifying the role of individual user messages in an online discussion and its use in thread retrieval,"Sumit Bhatia, Prakhar Biyani, PrasenjitMitra",Journal of the Association for Information Science and Technology,,"Online discussion forums have become a popular medium for users to discuss with and seek information from other users having similar interests. A typical discussion thread consists of a sequence of posts posted by multiple users. Each post in a thread serves a different purpose providing different types of information and, thus, may not be equally useful for all applications. Identifying the purpose and nature of each post in a discussion thread is thus an interesting research problem as it can help in improving information extraction and intelligent assistance techniques. We study the problem of classifying a given post as per its purpose in the discussion thread and employ features based on the post's content, structure of the thread, behavior of the participating users, and sentiment analysis of the post's content. We evaluate our approach on two forum data sets belonging to different genres and achieve strong classification performance. We also analyze the relative importance of different features used for the post classification task. Next, as a use case, we describe how the post class information can help in thread retrieval by incorporating this information in a state‐of‐the‐art thread retrieval model."
Salient Region Detection for Biometric Watermarking,"Ma Bin, Li Chun-lei, Wang Yun-hong, BaiChuan Xiao",Computer Vision for Multimedia Applications: Methods and Solutions,,"Visual saliency, namely the perceptual significance to human vision system (HVS), is a quality that differentiates an object from its neighbors. Detection of salient regions which contain prominent features and represent main contents of the visual scene, has obtained wide utilization among computer vision based applications, such as object tracking and classification, region-of-interest (ROI) based image compression, etc. Specially, as for biometric authentication system, whose objective is to distinguish the identification of people through biometric data (e.g. fingerprint, iris, face etc.), the most important metric is distinguishability. Consequently, in biometric watermarking fields, there has been a great need of good metrics for feature prominency. In this chapter, we present two salient-region-detection based biometric watermarking scenarios, in which robust annotation and fragile authentication watermark are respectively applied to biometric systems. Saliency map plays an important role of perceptual mask that adaptively select watermarking strength and position, therefore controls the distortion introduced by watermark and preserves the identification accuracy of biometric images."
Multi-sentence Question Segmentation and Compression for Question Answering,"Yixiu Wang, Yunfang Wu, Xueqiang Lv",Natural Language Processing and Chinese Computing,"Question answering, Question compression, Question segmentation, Complex-question analysis ","We present a multi-sentence question segmentation strategy for community question answering services to alleviate the complexity of long sentences. We develop a complete scheme and make a solution to complex-question segmentation, including a question detector to extract question sentences, a question compression process to remove duplicate information, and a graph model to segment multi-sentence questions. In the graph model, we train a SVM classifier to compute the initial weight and we calculate the authority of a vertex to guide the propagating. The experimental results show that our method gets a good balance between completeness and redundancy of information, and significantly outperforms state-of-the-art methods."
Statistical Machine Translation Improves Question Retrieval in Community Question Answering via Matrix Factorization,"Guangyou Zhou, Fang Liu, Yang Liu,Shizhu He, Jun Zhao",ACL,,"Community question answering (CQA) has become an increasingly popular research topic. In this paper, we focus on the problem of question retrieval. Question retrieval in CQA can automatically find the most relevant and recent questions that have been solved by other users. However, the word ambiguity and word mismatch problems bring about new challenges for question retrieval in CQA. State-of-the-art approaches address these issues by implicitly expanding the queried questions with additional words or phrases using monolingual translation models. While useful, the effectiveness of these models is highly dependent on the availability of quality parallel monolingual corpora (e.g., question-answer pairs) in the absence of which they are troubled by noise issue. In this work, we propose an alternative way to address the word ambiguity and word mismatch problems by taking advantage of potentially rich semantic information drawn from other languages. Our proposed method employs statistical machine translation to improve question retrieval and enriches the question representation with the translated words from other languages via matrix factorization. Experiments conducted on a real CQA data show that our proposed approach is promising."
Accelerated Attributed Network Embedding,"Xiao Huang, Jundong Li, Xia Hu",Proceedings of the 2017 SIAM International Conference on Data Mining,,"Network embedding is to learn low-dimensional vector representations for nodes in a network. It has shown to be effective in a variety of tasks such as node classification and link prediction. While embedding algorithms on pure networks have been intensively studied, in many real-world applications, nodes are often accompanied with a rich set of attributes or features, aka attributed networks. It has been observed that network topological structure and node attributes are often strongly correlated with each other. Thus modeling and incorporating node attribute proximity into network embedding could be potentially helpful, though non-trivial, in learning better vector representations. Meanwhile, real-world networks often contain a large number of nodes and features, which put demands on the scalability of embedding algorithms. To bridge the gap, in this paper, we propose an accelerated attributed network embedding algorithm AANE, which enables the joint learning process to be done in a distributed manner by decomposing the complex modeling and optimization into many sub-problems. Experimental results on several real-world datasets demonstrate the effectiveness and efficiency of the proposed algorithm."
Dynamic Network Embedding by Modeling Triadic Closure Process,"Le-kui Zhou, Yang Yang, Xiang Ren, FeiWu, Yueting Zhuang",AAAI,,"Network embedding, which aims to learn the lowdimensional representations of vertices, is an important task and has attracted considerable research efforts recently. In real world, networks, like social network and biological networks, are dynamic and evolving over time. However, almost all the existing network embedding methods focus on static networks while ignore network dynamics. In this paper, we present a novel representation learning approach, DynamicTriad, to preserve both structural information and evolution patterns of a given network. The general idea of our approach is to impose triad, which is a group of three vertices and is one of the basic units of networks. In particular, we model how a closed triad, which consists of three vertices connected with each other, develops from an open triad that has two of three vertices not connected with each other. This triadic closure process is a fundamental mechanism in the formation and evolution of networks, thereby makes our model being able to capture the network dynamics and to learn representation vectors for each vertex at different time steps. Experimental results on three real-world networks demonstrate that, compared with several state-of-the-art techniques, DynamicTriad achieves substantial gains in several application scenarios. For example, our approach can effectively be applied and help to identify telephone frauds in a mobile network, and to predict whether a user will repay her loans or not in a loan network."
Bayesian stochastic blockmodeling,Tiago P. Peixoto,arXiv,,"This chapter provides a self-contained introduction to the use of Bayesian inference to extract large-scale modular structures from network data, based on the stochastic blockmodel (SBM), as well as its degree-corrected and overlapping generalizations. We focus on nonparametric formulations that allow their inference in a manner that prevents overfitting, and enables model selection. We discuss aspects of the choice of priors, in particular how to avoid underfitting via increased Bayesian hierarchies, and we contrast the task of sampling network partitions from the posterior distribution with finding the single point estimate that maximizes it, while describing efficient algorithms to perform either one. We also show how inferring the SBM can be used to predict missing and spurious links, and shed light on the fundamental limitations of the detectability of modular structures in networks."
Nonparametric Bayesian inference of the microcanonical stochastic block model.,Tiago P Peixoto,arXiv,,"A principled approach to characterize the hidden structure of networks is to formulate generative models, and then infer their parameters from data. When the desired structure is composed of modules or ""communities"", a suitable choice for this task is the stochastic block model (SBM), where nodes are divided into groups, and the placement of edges is conditioned on the group memberships. Here, we present a nonparametric Bayesian method to infer the modular structure of empirical networks, including the number of modules and their hierarchical organization. We focus on a microcanonical variant of the SBM, where the structure is imposed via hard constraints, i.e. the generated networks are not allowed to violate the patterns imposed by the model. We show how this simple model variation allows simultaneously for two important improvements over more traditional inference approaches: 1. Deeper Bayesian hierarchies, with noninformative priors replaced by sequences of priors and hyperpriors, that not only remove limitations that seriously degrade the inference on large networks, but also reveal structures at multiple scales; 2. A very efficient inference algorithm that scales well not only for networks with a large number of nodes and edges, but also with an unlimited number of modules. We show also how this approach can be used to sample modular hierarchies from the posterior distribution, as well as to perform model selection. We discuss and analyze the differences between sampling from the posterior and simply finding the single parameter estimate that maximizes it. Furthermore, we expose a direct equivalence between our microcanonical approach and alternative derivations based on the canonical SBM."
Estimating the number of communities in a network,"Mark E. J. Newman, Gesine Reinert",arXiv,,"Community detection, the division of a network into dense subnetworks with only sparse connections between them, has been a topic of vigorous study in recent years. However, while there exist a range of powerful and flexible methods for dividing a network into a specified number of communities, it is an open question how to determine exactly how many communities one should use. Here we describe a mathematically principled approach for finding the number of communities in a network using a maximum-likelihood method. We demonstrate the approach on a range of real-world examples with known community structure, finding that it is able to determine the number of communities correctly in every case."
"Inferring the mesoscale structure of layered, edge-valued, and time-varying networks.",Tiago P. Peixoto,arXiv,,"Many network systems are composed of interdependent but distinct types of interactions, which cannot be fully understood in isolation. These different types of interactions are often represented as layers, attributes on the edges or as a time-dependence of the network structure. Although they are crucial for a more comprehensive scientific understanding, these representations offer substantial challenges. Namely, it is an open problem how to precisely characterize the large or mesoscale structure of network systems in relation to these additional aspects. Furthermore, the direct incorporation of these features invariably increases the effective dimension of the network description, and hence aggravates the problem of overfitting, i.e. the use of overly-complex characterizations that mistake purely random fluctuations for actual structure. In this work, we propose a robust and principled method to tackle these problems, by constructing generative models of modular network structure, incorporating layered, attributed and time-varying properties, as well as a nonparametric Bayesian methodology to infer the parameters from data and select the most appropriate model according to statistical evidence. We show that the method is capable of revealing hidden structure in layered, edge-valued and time-varying networks, and that the most appropriate level of granularity with respect to the additional dimensions can be reliably identified. We illustrate our approach on a variety of empirical systems, including a social network of physicians, the voting correlations of deputies in the Brazilian national congress, the global airport network, and a proximity network of high-school students."
Parsimonious module inference in large networks.,Tiago P. Peixoto,arXiv,,"We investigate the detectability of modules in large networks when the number of modules is not known in advance. We employ the minimum description length (MDL) principle which seeks to minimize the total amount of information required to describe the network, and avoid overfitting. According to this criterion, we obtain general bounds on the detectability of any prescribed block structure, given the number of nodes and edges in the sampled network. We also obtain that the maximum number of detectable blocks scales as N−−√, where N is the number of nodes in the network, for a fixed average degree <k>. We also show that the simplicity of the MDL approach yields an efficient multilevel Monte Carlo inference algorithm with a complexity of O(τNlogN), if the number of blocks is unknown, and O(τN) if it is known, where τ is the mixing time of the Markov chain. We illustrate the application of the method on a large network of actors and films with over 106 edges, and a dissortative, bipartite block structure."
"Communities, modules and large-scale structure in networks",Mark E. J. Newman,Nature Physics ,,"Networks, also called graphs by mathematicians, provide a useful abstraction of the structure of many complex systems, ranging from social systems and computer networks to biological networks and the state spaces of physical systems. In the past decade there have been significant advances in experiments to determine the topological structure of networked systems, but there remain substantial challenges in extracting scientific understanding from the large quantities of data produced by the experiments. A variety of basic measures and metrics are available that can tell us about small-scale structure in networks, such as correlations, connections and recurrent patterns, but it is considerably more difficult to quantify structure on medium and large scales, to understand the ‘big picture’. Important progress has been made, however, within the past few years, a selection of which is reviewed here."
Model selection and hypothesis testing for large-scale network models with overlapping groups,Tiago P. Peixoto,arXiv,,"The effort to understand network systems in increasing detail has resulted in a diversity of methods designed to extract their large-scale structure from data. Unfortunately, many of these methods yield diverging descriptions of the same network, making both the comparison and understanding of their results a difficult challenge. A possible solution to this outstanding issue is to shift the focus away from ad hoc methods and move towards more principled approaches based on statistical inference of generative models. As a result, we face instead the more well-defined task of selecting between competing generative processes, which can be done under a unified probabilistic framework. Here, we consider the comparison between a variety of generative models including features such as degree correction, where nodes with arbitrary degrees can belong to the same group, and community overlap, where nodes are allowed to belong to more than one group. Because such model variants possess an increasing number of parameters, they become prone to overfitting. In this work, we present a method of model selection based on the minimum description length criterion and posterior odds ratios that is capable of fully accounting for the increased degrees of freedom of the larger models, and selects the best one according to the statistical evidence available in the data. In applying this method to many empirical unweighted networks from different fields, we observe that community overlap is very often not supported by statistical evidence and is selected as a better model only for a minority of them. On the other hand, we find that degree correction tends to be almost universally favored by the available data, implying that intrinsic node proprieties (as opposed to group properties) are often an essential ingredient of network formation."
On the consistency between model selection and link prediction in networks,"Toni Valles-Catala, Tiago P. Peixoto,Roger Guimerà, Marta Sales-Pardo",arXiv,,"A principled approach to understand network structures is to formulate generative models. Given a collection of models, however, an outstanding key task is to determine which one provides a more accurate description of the network at hand, discounting statistical fluctuations. This problem can be approached using two principled criteria that at first may seem equivalent: selecting the most plausible model in terms of its posterior probability; or selecting the model with the highest predictive performance in terms of identifying missing links. Here we show that while these two approaches yield consistent results in most of cases, there are also notable instances where they do not, that is, where the most plausible model is not the most predictive. We show that in the latter case the improvement of predictive performance can in fact lead to overfitting both in artificial and empirical settings. Furthermore, we show that, in general, the predictive performance is higher when we average over collections of models that are individually less plausible, than when we consider only the single most plausible model."
Stochastic block models: A comparison of variants and inference methods,"Thorben Funke, Till Becker",Plos One,,"Finding communities in complex networks is a challenging task and one promising approach is the Stochastic Block Model (SBM). But the influences from various fields led to a diversity of variants and inference methods. Therefore, a comparison of the existing techniques and an independent analysis of their capabilities and weaknesses is needed. As a first step, we review the development of different SBM variants such as the degree-corrected SBM of Karrer and Newman or Peixoto’s hierarchical SBM. Beside stating all these variants in a uniform notation, we show the reasons for their development. Knowing the variants, we discuss a variety of approaches to infer the optimal partition like the Metropolis-Hastings algorithm. We perform our analysis based on our extension of the Girvan-Newman test and the Lancichinetti-Fortunato-Radicchi benchmark as well as a selection of some real world networks. Using these results, we give some guidance to the challenging task of selecting an inference method and SBM variant. In addition, we give a simple heuristic to determine the number of steps for the Metropolis-Hastings algorithms that lack a usual stop criterion. With our comparison, we hope to guide researches in the field of SBM and highlight the problem of existing techniques to focus future research. Finally, by making our code freely available, we want to promote a faster development, integration and exchange of new ideas."
Efficient method for estimating the number of communities in a network,"Maria A. Riolo, George T. Cantwell,Gesine Reinert, Mark E. J. Newman",arXiv,,"While there exist a wide range of effective methods for community detection in networks, most of them require one to know in advance how many communities one is looking for. Here we present a method for estimating the number of communities in a network using a combination of Bayesian inference with a novel prior and an efficient Monte Carlo sampling scheme. We test the method extensively on both real and computer-generated networks, showing that it performs accurately and consistently, even in cases where groups are widely varying in size or structure."
Fast Stochastic Block Partitioning using a Single Commodity Machine,"Md Abdul Motaleb Faysal, ShaikhArifuzzaman",IEEE,,"Network (graph) is a powerful way of representing the relationship among different kinds of entities in a sociotechnical system. Network partitioning is a problem that has its applications in social networking, traffic and communication networks, biological networks, etc. Exact partitioning of a network is an NP-hard problem. There exist different stateof-the-art relaxation techniques for approximating network partitioning with varying accuracy. However, with the exponential growth of information technology and social media, the sizes of real-world networks now have reached millions to billions of vertices and edges. Processing such massive networks require fast and efficient algorithms. A good domain-specific heuristic can make a big change in the execution time of an algorithm while maintaining accuracy in effective sense-making from network data. Stochastic Block Partitioning (SBP) is one of the state-of-the-art relaxation techniques that combines a stochastic model and an information-theoretic approach for network partitioning. An SBP algorithm of sub-quadratic run time complexity is given as the baseline algorithm for MIT GraphChallenge competition, which uses OpenMP based parallelism for scaling. In this work, we improve the performance of the baseline algorithm to several folds for a single (multicore) commodity machine. We incorporate a refinement of the greedy agglomerative heuristic and modify the OpenMP based parallelism with more programmer-level control to gain up to 10´fold speedup over the baseline algorithm."
Reconstructing networks with unknown and heterogeneous errors,Tiago P. Peixoto,Physical Review X,"Complex Systems, Statistical Physics","The vast majority of network data sets contain errors and omissions, although this fact is rarely incorporated in traditional network analysis. Recently, an increasing effort has been made to fill this methodological gap by developing network-reconstruction approaches based on Bayesian inference. These approaches, however, rely on assumptions of uniform error rates and on direct estimations of the existence of each edge via repeated measurements, something that is currently unavailable for the majority of network data. Here, we develop a Bayesian reconstruction approach that lifts these limitations by allowing for not only heterogeneous errors, but also for single edge measurements without direct error estimates. Our approach works by coupling the inference approach with structured generative network models, which enable the correlations between edges to be used as reliable uncertainty estimates. Although our approach is general, we focus on the stochastic block model as the basic generative process, from which efficient nonparametric inference can be performed and yields a principled method to infer hierarchical community structure from noisy data. We demonstrate the efficacy of our approach with a variety of empirical and artificial networks."
Learning Latent Block Structure in Weighted Networks,"Christopher Aicher, Abigail Z. Jacobs,Aaron Clauset",,,"Community detection is an important task in network analysis, in which we aim to learn a network partition that groups together vertices with similar community-level connectivity patterns. By finding such groups of vertices with similar structural roles, we extract a compact representation of the network's large-scale structure, which can facilitate its scientific interpretation and the prediction of unknown or future interactions. Popular approaches, including the stochastic block model, assume edges are unweighted, which limits their utility by throwing away potentially useful information. We introduce the `weighted stochastic block model' (WSBM), which generalizes the stochastic block model to networks with edge weights drawn from any exponential family distribution. This model learns from both the presence and weight of edges, allowing it to discover structure that would otherwise be hidden when weights are discarded or thresholded. We describe a Bayesian variational algorithm for efficiently approximating this model's posterior distribution over latent block structures. We then evaluate the WSBM's performance on both edge-existence and edge-weight prediction tasks for a set of real-world weighted networks. In all cases, the WSBM performs as well or better than the best alternatives on these tasks."
Bayesian model selection of stochastic block models,Xiaoran Yan,arXiv,,"A central problem in analyzing networks is partitioning them into modules or communities. One of the best tools for this is the stochastic block model, which clusters vertices into blocks with statistically homogeneous pattern of links. Despite its flexibility and popularity, there has been a lack of principled statistical model selection criteria for the stochastic block model. Here we propose a Bayesian framework for choosing the number of blocks as well as comparing it to the more elaborate degreecorrected block models, ultimately leading to a universal model selection framework capable of comparing multiple modeling combinations. We will also investigate its connection to the minimum description length principle."
Evaluating Overfit and Underfit in Models of Network Community Structure,"Amir Ghasemian, Homa Hosseinmardi,Aaron Clauset",arXiv,"Community Detection, Model Selection, Overfitting, Underfitting, Link Prediction, Link Description","A common data mining task on networks is community detection, which seeks an unsupervised decomposition of a network into structural groups based on statistical regularities in the network's connectivity. Although many methods exist, the No Free Lunch theorem for community detection implies that each makes some kind of tradeoff, and no algorithm can be optimal on all inputs. Thus, different algorithms will over or underfit on different inputs, finding more, fewer, or just different communities than is optimal, and evaluation methods that use a metadata partition as a ground truth will produce misleading conclusions about general accuracy. Here, we present a broad evaluation of over and underfitting in community detection, comparing the behavior of 16 state-of-the-art community detection algorithms on a novel and structurally diverse corpus of 406 real-world networks. We find that (i) algorithms vary widely both in the number of communities they find and in their corresponding composition, given the same input, (ii) algorithms can be clustered into distinct high-level groups based on similarities of their outputs on real-world networks, and (iii) these differences induce wide variation in accuracy on link prediction and link description tasks. We introduce a new diagnostic for evaluating overfitting and underfitting in practice, and use it to roughly divide community detection methods into general and specialized learning algorithms. Across methods and inputs, Bayesian techniques based on the stochastic block model and a minimum description length approach to regularization represent the best general learning approach, but can be outperformed under specific circumstances. These results introduce both a theoretically principled approach to evaluate over and underfitting in models of network community structure and a realistic benchmark by which new methods may be evaluated and compared."
Model selection for stochastic blockmodels,"Cristopher Moore, Thomas P. Hayes,Xiaoran Yan",arXiv,,"The stochastic block model (SBM) provides a popular framework for modeling community structures in networks. However, more attention has been devoted to problems concerning estimating the latent node labels and the model parameters than the issue of choosing the number of blocks. We consider an approach based on the log likelihood ratio statistic and analyze its asymptotic properties under model misspecification. We show the limiting distribution of the statistic in the case of underfitting is normal and obtain its convergence rate in the case of overfitting. These conclusions remain valid when the average degree grows at a polylog rate. The results enable us to derive the correct order of the penalty term for model complexity and arrive at a likelihood-based model selection criterion that is asymptotically consistent. Our analysis can also be extended to a degree-corrected block model (DCSBM). In practice, the likelihood function can be estimated using more computationally efficient variational methods or consistent label estimation algorithms, allowing the criterion to be applied to large networks."
Efficient Monte Carlo and greedy heuristic for the inference of stochastic blockmodels,Tiago P. Peixoto,arXiv,,"We present an efficient algorithm for the inference of stochastic block models in large networks. The algorithm can be used as an optimized Markov chain Monte Carlo (MCMC) method, with a fast mixing time and a much reduced susceptibility to getting trapped in metastable states, or as a greedy agglomerative heuristic, with an almost linear O(Nln2N) complexity, where N is the number of nodes in the network, independent on the number of blocks being inferred. We show that the heuristic is capable of delivering results which are indistinguishable from the more exact and numerically expensive MCMC method in many artificial and empirical networks, despite being much faster. The method is entirely unbiased towards any specific mixing pattern, and in particular it does not favor assortative community structures."
Generalized network community detection,"Lovro Šubelj, Marko Bajec",arXiv,"link-density community, link-pattern community, propagation, community detection, data clustering","Community structure is largely regarded as an intrinsic property of complex real-world networks. However, recent studies reveal that networks comprise even more sophisticated modules than classical cohesive communities. More precisely, real-world networks can also be naturally partitioned according to common patterns of connections between the nodes. Recently, a propagation based algorithm has been proposed for the detection of arbitrary network modules. We here advance the latter with a more adequate community modeling based on network clustering. The resulting algorithm is evaluated on various synthetic benchmark networks and random graphs. It is shown to be comparable to current state-of-the-art algorithms, however, in contrast to other approaches, it does not require some prior knowledge of the true community structure. To demonstrate its generality, we further employ the proposed algorithm for community detection in different unipartite and bipartite real-world networks, for generalized community detection and also predictive data clustering."
Santo Consensus clustering in complex networks,"Andrea Lancichinetti, Santo Fortunato",Scientific Reports ,,"The community structure of complex networks reveals both their organization and hidden relationships among their constituents. Most community detection methods currently available are not deterministic and their results typically depend on the specific random seeds, initial conditions and tie-break rules adopted for their execution. Consensus clustering is used in data analysis to generate stable results out of a set of partitions delivered by stochastic methods. Here we show that consensus clustering can be combined with any existing method in a self-consistent way, enhancing considerably both the stability and the accuracy of the resulting partitions. This framework is also particularly suitable to monitor the evolution of community structure in temporal networks. An application of consensus clustering to a large citation network of physics papers demonstrates its capability to keep track of the birth, death and diversification of topics."
Nonparametric weighted stochastic blockmodels.,Tiago P Peixoto,arXiv,,"We present a Bayesian formulation of weighted stochastic block models that can be used to infer the large-scale modular structure of weighted networks, including their hierarchical organization. Our method is nonparametric, and thus does not require the prior knowledge of the number of groups or other dimensions of the model, which are instead inferred from data. We give a comprehensive treatment of different kinds of edge weights (i.e. continuous or discrete, signed or unsigned, bounded or unbounded), as well as arbitrary weight transformations, and describe an unsupervised model selection approach to choose the best network description. We illustrate the application of our method to a variety of empirical weighted networks, such as global migrations, voting patterns in congress, and neural connections in the human brain."
Community Detection via Measure Space Embedding,"Mark Kozdoba, Shie Mannor",Advances in Neural Information Processing Systems 28,,"We present a new algorithm for community detection. The algorithm uses random walks to embed the graph in a space of measures, after which a modification of k-means in that space is applied. The algorithm is therefore fast and easily parallelizable. We evaluate the algorithm on standard random graph benchmarks, including some overlapping community benchmarks, and find its performance to be better or at least as good as previously known algorithms. We also prove a linear time (in number of edges) guarantee for the algorithm on a p, q-stochastic block model with where p ≥ c · N − 1 2 + and p − q ≥ c 0 q pN − 1 2 + log N."
A community detection algorithm using network topologies and rule-based hierarchical arc-merging strategies,"Yu-Hsiang Fu, Chung-Yuan Huang,Chuen-Tsai Sun",Plos One,,"The authors use four criteria to examine a novel community detection algorithm: (a) effectiveness in terms of producing high values of normalized mutual information (NMI) and modularity, using well-known social networks for testing; (b) examination, meaning the ability to examine mitigating resolution limit problems using NMI values and synthetic networks; (c) correctness, meaning the ability to identify useful community structure results in terms of NMI values and Lancichinetti-Fortunato-Radicchi (LFR) benchmark networks; and (d) scalability, or the ability to produce comparable modularity values with fast execution times when working with large-scale real-world networks. In addition to describing a simple hierarchical arc-merging (HAM) algorithm that uses network topology information, we introduce rule-based arc-merging strategies for identifying community structures. Five well-studied social network datasets and eight sets of LFR benchmark networks were employed to validate the correctness of a ground-truth community, eight large-scale real-world complex networks were used to measure its efficiency, and two synthetic networks were used to determine its susceptibility to two resolution limit problems. Our experimental results indicate that the proposed HAM algorithm exhibited satisfactory performance efficiency, and that HAMidentified and ground-truth communities were comparable in terms of social and LFR benchmark networks, while mitigating resolution limit problems."
Overlapping Communities Detection via Measure Space Embedding,"Mark Kozdoba, Shie Mannor",arXiv,,"We present a new algorithm for community detection. The algorithm uses random walks to embed the graph in a space of measures, after which a modification of k-means in that space is applied. The algorithm is therefore fast and easily parallelizable. We evaluate the algorithm on standard random graph benchmarks, including some overlapping community benchmarks, and find its performance to be better or at least as good as previously known algorithms. We also prove a linear time (in number of edges) guarantee for the algorithm on a p,q-stochastic block model with p≥c⋅N−12+ϵ and p−q≥c′pN−12+ϵlogN−−−−−−−−−−−√."
Merge-split Markov chain Monte Carlo for community detection,Tiago P. Peixoto,arXiv,,"We present a Markov chain Monte Carlo scheme based on merges and splits of groups that is capable of efficiently sampling from the posterior distribution of network partitions, defined according to the stochastic block model (SBM). We demonstrate how schemes based on the move of single nodes between groups systematically fail at correctly sampling from the posterior distribution even on small networks, and how our merge-split approach behaves significantly better, and improves the mixing time of the Markov chain by several orders of magnitude in typical cases. We also show how the scheme can be straightforwardly extended to nested versions of the SBM, yielding asymptotically exact samples of hierarchical network partitions."
"Community structure in temporal multilayer networks, and its application to financial correlation networks",Marya Bazzi,arXiv,"Community structure, multilayer networks, temporal networks, modularity maximization, financial correlation networks","Networks are a convenient way to represent complex systems of interacting entities. Many networks contain ""communities"" of nodes that are more densely connected to each other than to nodes in the rest of the network. In this paper, we investigate the detection of communities in temporal networks represented as multilayer networks. As a focal example, we study time-dependent financial-asset correlation networks. We first argue that the use of the ""modularity"" quality function---which is defined by comparing edge weights in an observed network to expected edge weights in a ""null network""---is application-dependent. We differentiate between ""null networks"" and ""null models"" in our discussion of modularity maximization, and we highlight that the same null network can correspond to different null models. We then investigate a multilayer modularity-maximization problem to identify communities in temporal networks. Our multilayer analysis only depends on the form of the maximization problem and not on the specific quality function that one chooses. We introduce a diagnostic to measure \emph{persistence} of community structure in a multilayer network partition. We prove several results that describe how the multilayer maximization problem measures a trade-off between static community structure within layers and larger values of persistence across layers. We also discuss some computational issues that the popular ""Louvain"" heuristic faces with temporal multilayer networks and suggest ways to mitigate them."
Group detection in complex networks: An algorithm and comparison of the state of the art,"Lovro vSubelj, Marko Bajec",arXiv,"complex networks, group detection, hierarchy discovery, label propagation, clustering","Complex real-world networks commonly reveal characteristic groups of nodes like communities and modules. These are of value in various applications, especially in the case of large social and information networks. However, while numerous community detection techniques have been presented in the literature, approaches for other groups of nodes are relatively rare and often limited in some way. We present a simple propagation-based algorithm for general group detection that requires no a priori knowledge and has near ideal complexity. The main novelty here is that different types of groups are revealed through an adequate hierarchical group refinement procedure. The proposed algorithm is validated on various synthetic and real-world networks, and rigorously compared against twelve other state-of-the-art approaches on group detection, hierarchy discovery and link prediction tasks. The algorithm is comparable to the state of the art in community detection, while superior in general group detection and link prediction. Based on the comparison, we also dis- cuss some prominent directions for future work on group detection in complex networks."
An Ant-Based Algorithm with Local Optimization for Community Detection in Large-Scale Networks,"Dongxiao He, Jie Liu, Bo Yang, YuxiaoHuang, Dayou Liu, Di Jin",arXiv,Complex networks; community detection; ant-based algorithm; simulated annealing; modularity,"In this paper, we propose a multi-layer ant-based algorithm MABA, which detects communities from networks by means of locally optimizing modularity using individual ants. The basic version of MABA, namely SABA, combines a self-avoiding label propagation technique with a simulated annealing strategy for ant diffusion in networks. Once the communities are found by SABA, this method can be reapplied to a higher level network where each obtained community is regarded as a new vertex. The aforementioned process is repeated iteratively, and this corresponds to MABA. Thanks to the intrinsic multi-level nature of our algorithm, it possesses the potential ability to unfold multi-scale hierarchical structures. Furthermore, MABA has the ability that mitigates the resolution limit of modularity. The proposed MABA has been evaluated on both computer-generated benchmarks and widely used real-world networks, and has been compared with a set of competitive algorithms. Experimental results demonstrate that MABA is both effective and efficient (in near linear time with respect to the size of network) for discovering communities."
Multilevel Compression of Random Walks on Networks Reveals Hierarchical Organization in Large Integrated Systems,"Martin Rosvall, Carl T. Bergstrom",Plos One,,"To comprehend the hierarchical organization of large integrated systems, we introduce the hierarchical map equation, which reveals multilevel structures in networks. In this information-theoretic approach, we exploit the duality between compression and pattern detection; by compressing a description of a random walker as a proxy for real flow on a network, we find regularities in the network that induce this system-wide flow. Finding the shortest multilevel description of the random walker therefore gives us the best hierarchical clustering of the network — the optimal number of levels and modular partition at each level — with respect to the dynamics on the network. With a novel search algorithm, we extract and illustrate the rich multilevel organization of several large social and biological networks. For example, from the global air traffic network we uncover countries and continents, and from the pattern of scientific communication we reveal more than 100 scientific fields organized in four major disciplines: life sciences, physical sciences, ecology and earth sciences, and social sciences. In general, we find shallow hierarchical structures in globally interconnected systems, such as neural networks, and rich multilevel organizations in systems with highly separated regions, such as road networks."
Community Detection through Likelihood Optimization: In Search of a Sound Model,"Liudmila Ostroumova, Alexey Tikhonov",arXiv,Community detection; likelihood optimization; statistical inference; planted partition model; LFR benchmark,"Community detection is one of the most important problems in network analysis. Among many algorithms proposed for this task, methods based on statistical inference are of particular interest: they are mathematically sound and were shown to provide partitions of good quality. Statistical inference methods are based on fitting some random graph model (a.k.a. null model) to the observed network by maximizing the likelihood. The choice of this model is extremely important and is the main focus of the current study. We provide an extensive theoretical and empirical analysis to compare several models: the widely used planted partition model, recently proposed degree-corrected modification of this model, and a new null model having some desirable statistical properties. We also develop and compare two likelihood optimization algorithms suitable for the models under consideration. An extensive empirical analysis on a variety of datasets shows, in particular, that the new model is the best one for describing most of the considered real-world complex networks according to the likelihood of observed graph structures."
Community detection in networks: Modularity optimization and maximum likelihood are equivalent,Mark E. J. Newman,arXiv,,"We demonstrate an exact equivalence between two widely used methods of community detection in networks, the method of modularity maximization in its generalized form which incorporates a resolution parameter controlling the size of the communities discovered, and the method of maximum likelihood applied to the special case of the stochastic block model known as the planted partition model, in which all communities in a network are assumed to have statistically similar properties. Among other things, this equivalence provides a mathematically principled derivation of the modularity function, clarifies the conditions and assumptions of its use, and gives an explicit formula for the optimal value of the resolution parameter."
Model Selection for Degree-corrected Block Models,"Xiaoran Yan, Jacob E. Jensen, FlorentKrzakala, Cristopher Moore, CosmaRohilla Shalizi, Lenka Zdeborová, PanZhang, Yaojia Zhu",arXiv,Belief propagation; Block models; Likelihood ratio test; Model selection; Networks; Sparse graphs,"The proliferation of models for networks raises challenging problems of model selection: the data are sparse and globally dependent, and models are typically high-dimensional and have large numbers of latent variables. Together, these issues mean that the usual model-selection criteria do not work properly for networks. We illustrate these challenges, and show one way to resolve them, by considering the key network-analysis problem of dividing a graph into communities or blocks of nodes with homogeneous patterns of links to the rest of the network. The standard tool for doing this is the stochastic block model, under which the probability of a link between two nodes is a function solely of the blocks to which they belong. This imposes a homogeneous degree distribution within each block; this can be unrealistic, so degree-corrected block models add a parameter for each node, modulating its over-all degree. The choice between ordinary and degree-corrected block models matters because they make very different inferences about communities. We present the first principled and tractable approach to model selection between standard and degree-corrected block models, based on new large-graph asymptotics for the distribution of log-likelihood ratios under the stochastic block model, finding substantial departures from classical results for sparse graphs. We also develop linear-time approximations for log-likelihoods under both the stochastic block model and the degree-corrected model, using belief propagation. Applications to simulated and real networks show excellent agreement with our approximations. Our results thus both solve the practical problem of deciding on degree correction, and point to a general approach to model selection in network analysis."
Majority Vote Community Detection with Dynamic Threshold and Bootstrapped Rounds,"Guilherme Braga da Costa, Daniel R.Figueiredo, Giulio Iacobelli,SUBMETIDA AO CORPO, DOCENTE DOINSTITUTO, André Coimbra, DanielSadoc Menasché, LIMIAR DINÂMICO, ERODADAS BOOTSTRAP",The Federal University of Rio de Janeiro,,"Community detection is a fundamental problem in network science, where the vertices of a given network are to be partitioned such that vertices in the same group are structurally related. This problem finds applications in a wide range of areas and has attracted much attention towards both its theoretical and practical aspects. Label propagation algorithms are based on a procedure that iteratively updates the classification of each node by a majority vote of its neighbors’ community labels. These algorithms are known to be simple and fast, and are widely used in practical applications. In this dissertation, we study variations of a label propagation algorithm applied to the problem of recovering two communities embedded in a network (majority vote algorithm, or MVA), and propose the following new contributions: (i) a dynamic threshold that generalizes the fixed threshold used by the majority vote algorithm, (ii) a stopping criterion that solves the oscillation problem displayed by the solutions produced by label propagation, and (iii) bootstrapping strategies that re-utilize solutions to achieve better results. These modifications give rise to new label propagation algorithms which we call Global Average Majority (GAM) and Global Average Majority with Bootstrapping (GAMB). Finally, the behavior and performance of the new algorithms are evaluated by numerical experiments with synthetic networks generated by the stochastic block model (SBM) and real world networks with known communities."
Unfolding network communities by combining defensive and offensive label propagation,"Lovro Šubelj, Marko Bajec",arXiv,"Network communities, label propagation, defensive preservation, offensive expansion","Label propagation has proven to be a fast method for detecting communities in complex networks. Recent work has also improved the accuracy and stability of the basic algorithm, however, a general approach is still an open issue. We propose different label propagation algorithms that convey two unique strategies of community formation, namely, defensive preservation and offensive expansion of communities. Furthermore, the strategies are combined in an advanced label propagation algorithm that retains the advantages of both approaches; and are enhanced with hierarchical community extraction, prominent for the use on larger networks. The proposed algorithms were empirically evaluated on different benchmarks networks with planted partition and on over 30 real-world networks of various types and sizes. The results confirm the adequacy of the propositions and give promising grounds for future analysis of (large) complex networks. Nevertheless, the main contribution of this work is in showing that different types of networks (with different topological properties) favor different strategies of community formation."
Spectral methods for network community detection and graph partitioning,Mark E. J. Newman,arXiv,,"We consider three distinct and well studied problems concerning network structure: community detection by modularity maximization, community detection by statistical inference, and normalized-cut graph partitioning. Each of these problems can be tackled using spectral algorithms that make use of the eigenvectors of matrix representations of the network. We show that with certain choices of the free parameters appearing in these spectral algorithms the algorithms for all three problems are, in fact, identical, and hence that, at least within the spectral approximations used here, there is no difference between the modularity- and inference-based community detection methods, or between either and graph partitioning."
Clustering Scientific Publications Based on Citation Relations: A Systematic Comparison of Different Methods,"Lovro Šubelj, Nees Jan van Eck, LudoWaltman",Plos One,,"Clustering methods are applied regularly in the bibliometric literature to identify research areas or scientific fields. These methods are for instance used to group publications into clusters based on their relations in a citation network. In the network science literature, many clustering methods, often referred to as graph partitioning or community detection techniques, have been developed. Focusing on the problem of clustering the publications in a citation network, we present a systematic comparison of the performance of a large number of these clustering methods. Using a number of different citation networks, some of them relatively small and others very large, we extensively study the statistical properties of the results provided by different methods. In addition, we also carry out an expert-based assessment of the results produced by different methods. The expert-based assessment focuses on publications in the field of scientometrics. Our findings seem to indicate that there is a trade-off between different properties that may be considered desirable for a good clustering of publications. Overall, map equation methods appear to perform best in our analysis, suggesting that these methods deserve more attention from the bibliometric community."
Community detection in social networks using a hybrid swarm intelligence approach,"Alireza Ghasabeh, Mohammad SanieeAbadeh",International Journal of Knowledge-based and Intelligent Engineering Systems,"Community detection, ant colony optimization, swarm intelligence, honey-bees optimization","The problem of community detection has been widely studied in numerous research papers in the last decade. There have been several proposed solutions for this problem; however the challenges of this problem have not been fully addressed yet. In this paper, we hybridize the idea of Ant Colony clustering, which is a local search solution, with global search ability of Honey Bee Hive Optimization to detect communities faster and more accurately. We use the dancer bees for exchanging information among nodes, and a node is considered as an ant in the ant colony clustering. Experimental results on real world networks and also artificial generated graphs show superior performance of our algorithm in comparison to other previous approaches."
The Graph Neural Network Model,"Franco Scarselli, Marco Gori, Ah ChungTsoi, Markus Hagenbuchner, GabrieleMonfardini",IEEE,"Graphical domains, graph neural networks (GNNs), graph processing, recursive neural networks.","Many underlying relationships among data in several areas of science and engineering, e.g., computer vision, molecular chemistry, molecular biology, pattern recognition, and data mining, can be represented in terms of graphs. In this paper, we propose a new neural network model, called graph neural network (GNN) model, that extends existing neural network methods for processing the data represented in graph domains. This GNN model, which can directly process most of the practically useful types of graphs, e.g., acyclic, cyclic, directed, and undirected, implements a function that maps a graph and one of its nodes into an -dimensional Euclidean space. A supervised learning algorithm is derived to estimate the parameters of the proposed GNN model. The computational cost of the proposed algorithm is also considered. Some experimental results are shown to validate the proposed learning algorithm, and to demonstrate its generalization capabilities"
DeepInf : Modeling Influence Locality in Large Social Networks,"Jiezhong Qiu, Jian Tang, Hao Ma,Yuxiao Dong, Kuansan Wang, Jie Tang",,,
Topological Recurrent Neural Network for Diffusion Prediction,"Jia Wang, Vincent Wenchen Zheng,Zemin Liu, Kevin Chen-Chuan Chang",arXiv,,"In this paper, we study the problem of using representation learning to assist information diffusion prediction on graphs. In particular, we aim at estimating the probability of an inactive node to be activated next in a cascade. Despite the success of recent deep learning methods for diffusion, we find that they often underexplore the cascade structure. We consider a cascade as not merely a sequence of nodes ordered by their activation time stamps; instead, it has a richer structure indicating the diffusion process over the data graph. As a result, we introduce a new data model, namely diffusion topologies, to fully describe the cascade structure. We find it challenging to model diffusion topologies, which are dynamic directed acyclic graphs (DAGs), with the existing neural networks. Therefore, we propose a novel topological recurrent neural network, namely Topo-LSTM, for modeling dynamic DAGs. We customize Topo-LSTM for the diffusion prediction task, and show it improves the state-of-the-art baselines, by 20.1%--56.6% (MAP) relatively, across multiple real-world data sets."
NActSeer: Predicting User Actions in Social Network using Graph Augmented Neural Network,"Mohammad Raihanul Islam, SathappanMuthiah, Naren Ramakrishnan",ACM,"Social Network, User Activity Prediction, Representation Learning","Nowadays social network platforms like Twitter, Facebook, Weibo have created a new landscape to communicate with our friends and the world at large. In this landscape our social activities, purchase decisions, check-ins etc. become available immediately to our friends/followers and thus encouraging them to involve in the same activity. This gives rise to the question, given a user and her friends' previous actions, can we predict what is she going to do next? This problem can serve as a good indicator enabling policy research, targeted advertising, assortment planning etc. To capture such sequential mechanism two broad classes of methods have been proposed in the past. First one is the Markov Chain (MC), which assumes user's next action can be predicted based on her most recently taken actions while the second type of approach i.e. Recurrent Neural Network (RNN) tries to model both long and short term preferences of a user. However, none of the two classes of models contain any integrated mechanism to capture the preferences of neighbor's actions. To fill this gap, we propose a social network augmented neural network model named NActSeer which takes the neighbors' actions into account in addition to the user's history. To achieve this NActSeer maintains a dynamic user embedding based on the activities within a time window. It then learns a feature representation for each user which is augmented by her neighbors. Empirical studies on four real-world datasets show that NActSeer is able to outperform several classical and state-of-the-art models proposed for similar problems and achieves up to 71% performance boost."
Learning cascaded influence under partial monitoring,"Jie Zhang, Jiaqi Ma, Jie Tang",IEEE,,"Social influence has attracted tremendous attention from both academic and industrial communities due to the rapid development of online social networks. While most research has been focused on the direct influence between peers, learning cascaded indirect influence has not been previously studied. In this paper, we formulate the concept of cascade indirect influence based on the Independent Cascade model and then propose a novel online learning algorithm for learning the cascaded influence in the partial monitoring setting. We propose two bandit algorithms E-EXP3 and RE-EXP3 to address this problem. We theoretically prove that E-EXP3 has a cumulative regret bound of O( √ T) over T, the number of time stamps. We will also show that RE-EXP3, a relaxed version of E-EXP3, achieves a better performance in practice. We compare the proposed algorithms with three baseline methods on both synthetic and real networks (Weibo and AMiner). Our experimental results show that RE-EXP3 converges 100× faster than E-EXP3. Both of them significantly outperform the alternative methods in terms of normalized regret. Finally, we apply the learned cascaded influence to help behavior prediction and experiments show that our proposed algorithms can help achieve a significant improvement (10-15% by accuracy) for behavior prediction"
Inf2vec: Latent Representation Model for Social Influence Embedding,"Shanshan Feng, Gao Cong, Arijit Khan,Xiucheng Li, Yong Liu, Yeow MengChee",IEEE,,"As a fundamental problem in social influence propagation analysis, learning influence parameters has been extensively investigated. Most of the existing methods are proposed to estimate the propagation probability for each edge in social networks. However, they cannot effectively learn propagation parameters of all edges due to data sparsity, especially for the edges without sufficient observed propagation. Different from the conventional methods, we introduce a novel social influence embedding problem, which is to learn parameters for nodes rather than edges. Nodes are represented as vectors in a lowdimensional space, and thus social influence information can be reflected by these vectors. We develop a new model Inf2vec, which combines both the local influence neighborhood and global user similarity to learn the representations. We conduct extensive experiments on two real-world datasets, and the results indicate that Inf2vec significantly outperforms state-of-the-art baseline algorithms."
DeepCas: An End-to-end Predictor of Information Cascades,"Cheng Li, Jiaqi Ma, Xiaoxiao Guo,Qiaozhu Mei",arXiv,,"Information cascades, effectively facilitated by most social network platforms, are recognized as a major factor in almost every social success and disaster in these networks. Can cascades be predicted? While many believe that they are inherently unpredictable, recent work has shown that some key properties of information cascades, such as size, growth, and shape, can be predicted by a machine learning algorithm that combines many features. These predictors all depend on a bag of hand-crafting features to represent the cascade network and the global network structure. Such features, always carefully and sometimes mysteriously designed, are not easy to extend or to generalize to a different platform or domain. Inspired by the recent successes of deep learning in multiple data mining tasks, we investigate whether an end-to-end deep learning approach could effectively predict the future size of cascades. Such a method automatically learns the representation of individual cascade graphs in the context of the global network structure, without hand-crafted features and heuristics. We find that node embeddings fall short of predictive power, and it is critical to learn the representation of a cascade graph as a whole. We present algorithms that learn the representation of cascade graphs in an end-to-end manner, which significantly improve the performance of cascade prediction over strong baselines that include feature based methods, node embedding methods, and graph kernel methods. Our results also provide interesting implications for cascade prediction in general."
Representation Learning for Information Diffusion through Social Networks: an Embedded Cascade Model,"Simon Bourigault, Sylvain Lamprier,Patrick Gallinari",ACM,Machine learning; Information diffusion; Representation Learning,"In this paper, we focus on information diffusion through social networks. Based on the well-known Independent Cascade model, we embed users of the social network in a latent space to extract more robust diffusion probabilities than those defined by classical graphical learning approaches. Better generalization abilities provided by the use of such a projection space allows our approach to present good performances on various real-world datasets, for both diffusion prediction and influence relationships inference tasks. Additionally, the use of a projection space enables our model to deal with larger social networks."
StructInf: Mining Structural Influence from Social Streams,"Jing Zhang, Jie Tang, Yuanyi Zhong,Yuchen Mo, Juan-Zi Li, Guojie Song,Wendy Hall, Jimeng Sun",AAAI,,"Social influence is a fundamental issue in social network analysis and has attracted tremendous attention with the rapid growth of online social networks. However, existing research mainly focuses on studying peer influence. This paper introduces a novel notion of structural influence and studies how to efficiently discover structural influence patterns from social streams. We present three sampling algorithms with theoretical unbiased guarantee to speed up the discovery process. Experiments on a big microblogging dataset show that the proposed sampling algorithms can achieve a 10× speedup compared to the exact influence pattern mining algorithm, with an average error rate of only 1.0%. The extracted structural influence patterns have many applications. We apply them to predict retweet behavior, with performance being significantly improved."
Who Influenced You? Predicting Retweet via Social Influence Locality,"Jing Zhang, Jie Tang, Juan-Zi Li, YangP. Liu, Chunxiao Xing",ACM,"Social network, social influence, microblog network, retweet prediction","Social influence occurs when one’s opinions, emotions, or behaviors are affected by others in a social network. However, social influence takes many forms, and its underlying mechanism is still unclear. For example, how is one’s behavior influenced by a group of friends who know each other and by the friends from different ego friend circles? In this article, we study the social influence problem in a large microblogging network. Particularly, we consider users’ (re)tweet behaviors and focus on investigating how friends in one’s ego network influence retweet behaviors. We propose a novel notion of social influence locality and develop two instantiation functions based on pairwise influence and structural diversity. The defined influence locality functions have strong predictive power. Without any additional features, we can obtain an F1-score of 71.65% for predicting users’ retweet behaviors by training a logistic regression classifier based on the defined influence locality functions. We incorporate social influence locality into a factor graph model, which can further leverage the network-based correlation. Our experiments on the large microblogging network show that the model significantly improves the precision of retweet prediction. Our analysis also reveals several intriguing discoveries. For example, if you have six friends retweeting a microblog, the average likelihood that you will also retweet it strongly depends on the structure among the six friends: The likelihood will significantly drop (only 1 6 ) when the six friends do not know each other, compared with the case when the six friends know each other"
Distance-Aware DAG Embedding for Proximity Search on Heterogeneous Graphs,"Zemin Liu, Vincent Wenchen Zheng,Zhou Zhao, Fanwei Zhu, Kevin Chen-Chuan Chang, Minghui Wu, Jing Ying",AAAI,,"Proximity search on heterogeneous graphs aims to measure the proximity between two nodes on a graph w.r.t. some semantic relation for ranking. Pioneer work often tries to measure such proximity by paths connecting the two nodes. However, paths as linear sequences have limited expressiveness for the complex network connections. In this paper, we explore a more expressive DAG (directed acyclic graph) data structure for modeling the connections between two nodes. Particularly, we are interested in learning a representation for the DAGs to encode the proximity between two nodes. We face two challenges to use DAGs, including how to efficiently generate DAGs and how to effectively learn DAG embedding for proximity search. We find distance-awareness as important for proximity search and the key to solve the above challenges. Thus we develop a novel Distance-aware DAG Embedding (D2AGE) model. We evaluate D2AGE on three benchmark data sets with six semantic relations, and we show that D2AGE outperforms the state-of-the-art baselines. We release the code on https://github.com/shuaiOKshuai."
Robust Semi-supervised Representation Learning for Graph-Structured Data,"Lan-Zhe Guo, Tao Han, Yu-Feng Li",Advances in Knowledge Discovery and Data Mining,"Robust, Representation learning, Semi-supervised learning, Graph convolutional network ","The success of machine learning algorithms generally depends on data representation and recently many representation learning methods have been proposed. However, learning a good representation may not always benefit the classification tasks. It sometimes even hurt the performance as the learned representation maybe not related to the ultimate tasks, especially when the labeled examples are few to afford a reliable model selection. In this paper, we propose a novel robust semi-supervised graph representation learning method based on graph convolutional network. To make the learned representation more related to the ultimate classification task, we propose to extend label information based on the smooth assumption and obtain pseudo-labels for unlabeled nodes. Moreover, to make the model robust with noise in the pseudo-label, we propose to apply a large margin classifier to the learned representation. Influenced by the pseudo-label and the large-margin principle, the learned representation can not only exploit the label information encoded in the graph-structure sufficiently but also can produce a more rigorous decision boundary. Experiments demonstrate the superior performance of the proposal over many related methods."
Social Influence Locality for Modeling Retweeting Behaviors,"Jing Zhang, Biao Liu, Jie Tang, TingChen, Juan-Zi Li",IJCAI,,"We study an interesting phenomenon of social influence locality in a large microblogging network, which suggests that users’ behaviors are mainly influenced by close friends in their ego networks. We provide a formal definition for the notion of social influence locality and develop two instantiation functions based on pairwise influence and structural diversity. The defined influence locality functions have strong predictive power. Without any additional features, we can obtain a F1-score of 71.65% for predicting users’ retweet behaviors by training a logistic regression classifier based on the defined functions. Our analysis also reveals several intriguing discoveries. For example, though the probability of a user retweeting a microblog is positively correlated with the number of friends who have retweeted the microblog, it is surprisingly negatively correlated with the number of connected circles that are formed by those friends."
DeepDiffuse: Predicting the 'Who' and 'When' in Cascades,"Mohammad Raihanul Islam, SathappanMuthiah, Bijaya Adhikari, B. AdityaPrakash, Naren Ramakrishnan",IEEE,Social Networks; Cascade and Diffusion Prediction,"Cascades are an accepted model to capturing how information diffuses across social network platforms. A large body of research has been focused on dissecting the anatomy of such cascades and forecasting their progression. One recurring theme involves predicting the next stage(s) of cascades utilizing pertinent information such as the underlying social network, structural properties of nodes (e.g., degree) and (partial) histories of cascade propagation. However, such type of granular information is rarely available in practice. We study in this paper the problem of cascade prediction utilizing only two types of (coarse) information, viz. which node is infected and its corresponding infection time. We first construct several simple baselines to solve this cascade prediction problem. Then we describe the shortcomings of these methods and propose a new solution leveraging recent progress in embeddings and attention models from representation learning. We also perform an exhaustive analysis of our methods on several real world datasets. Our proposed model outperforms the baselines and several other state-of-the-art methods."
Cascade Dynamics Modeling with Attention-based Recurrent Neural Network,"Yongqing Wang, Huawei Shen,Shenghua Liu, Jinhua Gao, Xueqi Cheng",IJCAI,,"An ability of modeling and predicting the cascades of resharing is crucial to understanding information propagation and to launching campaign of viral marketing. Conventional methods for cascade prediction heavily depend on the hypothesis of diffusion models, e.g., independent cascade model and linear threshold model. Recently, researchers attempt to circumvent the problem of cascade prediction using sequential models (e.g., recurrent neural network, namely RNN) that do not require knowing the underlying diffusion model. Existing sequential models employ a chain structure to capture the memory effect. However, for cascade prediction, each cascade generally corresponds to a diffusion tree, causing cross-dependence in cascade— one sharing behavior could be triggered by its non-immediate predecessor in the memory chain. In this paper, we propose to an attention-based RNN to capture the cross-dependence in cascade. Furthermore, we introduce a coverage strategy to combat the misallocation of attention caused by the memoryless of traditional attention mechanism. Extensive experiments on both synthetic and real world datasets demonstrate the proposed models outperform state-of-the-art models at both cascade prediction and inferring diffusion tree."
Large-Scale Learnable Graph Convolutional Networks,"Hongyang Gao, Zhengyang Wang,Shuiwang Ji",arXiv,"Deep learning, graph convolutional networks, graph mining, largescale learning","Convolutional neural networks (CNNs) have achieved great success on grid-like data such as images, but face tremendous challenges in learning from more generic data such as graphs. In CNNs, the trainable local filters enable the automatic extraction of high-level features. The computation with filters requires a fixed number of ordered units in the receptive fields. However, the number of neighboring units is neither fixed nor are they ordered in generic graphs, thereby hindering the applications of convolutional operations. Here, we address these challenges by proposing the learnable graph convolutional layer (LGCL). LGCL automatically selects a fixed number of neighboring nodes for each feature based on value ranking in order to transform graph data into grid-like structures in 1-D format, thereby enabling the use of regular convolutional operations on generic graphs. To enable model training on large-scale graphs, we propose a sub-graph training method to reduce the excessive memory and computational resource requirements suffered by prior methods on graph convolutions. Our experimental results on node classification tasks in both transductive and inductive learning settings demonstrate that our methods can achieve consistently better performance on the Cora, Citeseer, Pubmed citation network, and protein-protein interaction network datasets. Our results also indicate that the proposed methods using sub-graph training strategy are more efficient as compared to prior approaches."
Neural Subgraph Isomorphism Counting,"Xin Liu, Hao-Jie Pan, Mutian He,Yangqiu Song, Xin Jiang",arXiv,"Subgraph Isomorphism, Dynamic Memory, Neural Network","In this paper, we study a new graph learning problem: learning to count subgraph isomorphisms. Different from other traditional graph learning problems such as node classification and link prediction, subgraph isomorphism counting is NP-complete and requires more global inference to oversee the whole graph. To make it scalable for large-scale graphs and patterns, we propose a learning framework which augments different representation learning architectures and iteratively attends pattern and target data graphs to memorize subgraph isomorphisms for the global counting. We develop both small graphs (<= 1,024 subgraph isomorphisms in each) and large graphs (<= 4,096 subgraph isomorphisms in each) sets to evaluate different models. A mutagenic compound dataset, MUTAG, is also used to evaluate neural models and demonstrate the success of transfer learning. While the learning based approach is inexact, we are able to generalize to count large patterns and data graphs in linear time compared to the exponential time of the original NP-complete problem. Experimental results show that learning based subgraph isomorphism counting can speed up the traditional algorithm, VF2, 10-1,000 times with acceptable errors. Domain adaptation based on fine-tuning also shows the usefulness of our approach in real-world applications."
Structural Graph Representations based on Multiscale Local Network Topologies,"Felix Borutta, Julian Busch, EvgeniyFaerman, Adina Klink, MatthiasSchubert",IEEE,"Representation Learning, Node Embedding, Graph Classification, Structural Embeddings","In many applications, it is required to analyze a graph merely based on its topology. In these cases, nodes can only be distinguished based on their structural neighborhoods and it is common that nodes having the same functionality or role yield similar neighbor-hood structures. In this work, we investigate two problems: (1) how to create structural node embeddings which describe a node's role and (2) how important the nodes' roles are for characterizing entire graphs. To describe the role of a node, we explore the structure within the local neighborhood (or multiple local neighborhoods of various extents) of the node in the vertex domain, compute the visiting probability distribution of nodes in the local neighborhoods and summarize each distribution to a single number by computing its entropy. Furthermore, we argue that the roles of nodes are important to characterize the entire graph. Therefore, we propose to aggregate the role representations to describe whole graphs for graph classification tasks. Our experiments show that our new role descriptors outperform state-of-the-art structural node representations that are usually more expensive to compute. Additionally, we achieve promising results compared to advanced state-of-the-art approaches for graph classification on various benchmark datasets often outperforming these approaches."
"An Empirical Evaluation of Social Influence Metrics by Nikhil Nanda Kumar A Thesis Presented in Partial Fulfillment of the Requirements for the Degree Master of Science Approved June 2016 by the Graduate Supervisory Committee: Paulo Shakarian, Chair","Arunabha Sen, Hasan Davulcu, PauloShakarian, Ashkan Aleali",Arizona State University ,,"Predicting when an individual will adopt a new behavior is an important problem in application domains such as marketing and public health. This thesis examines the performance of a wide variety of social network based measurements proposed in the literature - which have not been previously compared directly. This research studies the probability of an individual becoming influenced based on measurements derived from neighborhood (i.e. number of influencers, personal network exposure), structural diversity, locality, temporal measures, cascade measures, and metadata. It also examines the ability to predict influence based on choice of the classifier and how the ratio of positive to negative samples in both training and testing affect prediction results - further enabling practical use of these concepts for social influence applications."
Predict then Propagate: Graph Neural Networks meet Personalized PageRank,"Johannes Klicpera, AleksandarBojchevski, Stephan Günnemann",arXiv,,"Neural message passing algorithms for semi-supervised classification on graphs have recently achieved great success. However, for classifying a node these methods only consider nodes that are a few propagation steps away and the size of this utilized neighborhood is hard to extend. In this paper, we use the relationship between graph convolutional networks (GCN) and PageRank to derive an improved propagation scheme based on personalized PageRank. We utilize this propagation procedure to construct a simple model, personalized propagation of neural predictions (PPNP), and its fast approximation, APPNP. Our model's training time is on par or faster and its number of parameters on par or lower than previous models. It leverages a large, adjustable neighborhood for classification and can be easily combined with any neural network. We show that this model outperforms several recently proposed methods for semi-supervised classification in the most thorough study done so far for GCN-like models. Our implementation is available online."
Inf-VAE: A Variational Autoencoder Framework to Integrate Homophily and Influence in Diffusion Prediction,"Aravind Sankar, Xinyang Zhang, AditKrishnan, Jiawei Han",arXiv,"Social Network, Diffusion, Deep Learning, Autoencoder, Attention","Recent years have witnessed tremendous interest in understanding and predicting information spread on social media platforms such as Twitter, Facebook, etc. Existing diffusion prediction methods primarily exploit the sequential order of influenced users by projecting diffusion cascades onto their local social neighborhoods. However, this fails to capture global social structures that do not explicitly manifest in any of the cascades, resulting in poor performance for inactive users with limited historical activities."
An empirical evaluation of social influence metrics,"Nikhil Kumar, Ruocheng Guo, AshkanAleali, Paulo Shakarian",arXiv,,"In this paper, we present a novel variational autoencoder framework (Inf-VAE) to jointly embed homophily and influence through proximity-preserving social and position-encoded temporal latent variables. To model social homophily, Inf-VAE utilizes powerful graph neural network architectures to learn social variables that selectively exploit the social connections of users. Given a sequence of seed user activations, Inf-VAE uses a novel expressive co-attentive fusion network that jointly attends over their social and temporal variables to predict the set of all influenced users. Our experimental results on multiple real-world social network datasets, including Digg, Weibo, and Stack-Exchanges demonstrate significant gains (22% MAP@10) for Inf-VAE over state-of-the-art diffusion prediction models; we achieve massive gains for users with sparse activities, and users who lack direct social neighbors in seed sets."
DeepGraph: Graph Structure Predicts Network Growth,"Cheng Li, Xiaoxiao Guo, Qiaozhu Mei",arXiv,"Graph Representation, Network Growth, Deep Learning","The topological (or graph) structures of real-world networks are known to be predictive of multiple dynamic properties of the networks. Conventionally, a graph structure is represented using an adjacency matrix or a set of hand-crafted structural features. These representations either fail to highlight local and global properties of the graph or suffer from a severe loss of structural information. There lacks an effective graph representation, which hinges the realization of the predictive power of network structures. In this study, we propose to learn the represention of a graph, or the topological structure of a network, through a deep learning model. This end-to-end prediction model, named DeepGraph, takes the input of the raw adjacency matrix of a real-world network and outputs a prediction of the growth of the network. The adjacency matrix is first represented using a graph descriptor based on the heat kernel signature, which is then passed through a multi-column, multi-resolution convolutional neural network. Extensive experiments on five large collections of real-world networks demonstrate that the proposed prediction model significantly improves the effectiveness of existing methods, including linear or nonlinear regressors that use hand-crafted features, graph kernels, and competing deep learning methods."
Neural Graph Collaborative Filtering,"Xiang Wang, Xiangnan He, Meng Wang,Fuli Feng, Tat-Seng Chua",arXiv ,"Collaborative Filtering, Recommendation, High-order Connectivity, Embedding Propagation, Graph Neural Network","Learning vector representations (aka. embeddings) of users and items lies at the core of modern recommender systems. Ranging from early matrix factorization to recently emerged deep learning based methods, existing efforts typically obtain a user's (or an item's) embedding by mapping from pre-existing features that describe the user (or the item), such as ID and attributes. We argue that an inherent drawback of such methods is that, the collaborative signal, which is latent in user-item interactions, is not encoded in the embedding process. As such, the resultant embeddings may not be sufficient to capture the collaborative filtering effect. In this work, we propose to integrate the user-item interactions -- more specifically the bipartite graph structure -- into the embedding process. We develop a new recommendation framework Neural Graph Collaborative Filtering (NGCF), which exploits the user-item graph structure by propagating embeddings on it. This leads to the expressive modeling of high-order connectivity in user-item graph, effectively injecting the collaborative signal into the embedding process in an explicit manner. We conduct extensive experiments on three public benchmarks, demonstrating significant improvements over several state-of-the-art models like HOP-Rec and Collaborative Memory Network. Further analysis verifies the importance of embedding propagation for learning better user and item representations, justifying the rationality and effectiveness of NGCF."
DeepHawkes: Bridging the Gap between Prediction and Understanding of Information Cascades,"Qi Cao, Huawei Shen, Keting Cen,Wentao Ouyang, Xueqi Cheng",ACM,"popularity prediction, information cascade, Hawkes process, endto-end deep learning, interpretable factors","Online social media remarkably facilitates the production and delivery of information, intensifying the competition among vast information for users’ attention and highlighting the importance of predicting the popularity of information. Existing approaches for popularity prediction fall into two paradigms: feature-based approaches and generative approaches. Feature-based approaches extract various features (e.g., user, content, structural, and temporal features), and predict the future popularity of information by training a regression/classication model. Their predictive performance heavily depends on the quality of hand-crafted features. In contrast, generative approaches devote to characterizing and modeling the process that a piece of information accrues attentions, oering us high ease to understand the underlying mechanisms governing the popularity dynamics of information cascades. But they have less desirable predictive power since they are not optimized for popularity prediction. In this paper, we propose DeepHawkes to combat the defects of existing methods, leveraging end-to-end deep learning to make an analogy to interpretable factors of Hawkes process — a widely-used generative process to model information cascade. DeepHawkes inherits the high interpretability of Hawkes process and possesses the high predictive power of deep learning methods, bridging the gap between prediction and understanding of information cascades. We verify the eectiveness of DeepHawkes by applying it to predict retweet cascades of Sina Weibo and citation cascades of a longitudinal citation dataset. Experimental results demonstrate that DeepHawkes outperforms both feature-based and generative approaches."
Classifying Graphs as Images with Convolutional Neural Networks,"Antoine Jean-Pierre Tixier, GiannisNikolentzos, Polykarpos Meladianos,Michalis Vazirgiannis",arXiv,,"Graph learning is currently dominated by graph kernels, which, while powerful, suffer some significant limitations. Convolutional Neural Networks (CNNs) offer a very appealing alternative, but processing graphs with CNNs is not trivial. To address this challenge, many sophisticated extensions of CNNs have recently been introduced. In this paper, we reverse the problem: rather than proposing yet another graph CNN model, we introduce a novel way to represent graphs as multi-channel image-like structures that allows them to be handled by vanilla 2D CNNs. Experiments reveal that our method is more accurate than state-of-the-art graph kernels and graph CNNs on 4 out of 6 real-world datasets (with and without continuous node attributes), and close elsewhere. Our approach is also preferable to graph kernels in terms of time complexity. Code and data are publicly available."
Confluence: conformity influence in large social networks,"Jie Tang, Sen Wu, Jimeng Sun",ACM,Conformity; Social influence; Social network,"Conformity is a type of social influence involving a change in opinion or behavior in order to fit in with a group. Employing several social networks as the source for our experimental data, we study how the effect of conformity plays a role in changing users’ online behavior. We formally define several major types of conformity in individual, peer, and group levels. We propose Confluence model to formalize the effects of social conformity into a probabilistic model. Confluence can distinguish and quantify the effects of the different types of conformities. To scale up to large social networks, we propose a distributed learning method that can construct the Confluence model efficiently with near-linear speedup. Our experimental results on four different types of large social networks, i.e., Flickr, Gowalla, Weibo and Co-Author, verify the existence of the conformity phenomena. Leveraging the conformity information, Confluence can accurately predict actions of users. Our experiments show that Confluence significantly improves the prediction accuracy by up to 5-10% compared with several alternative methods."
COSINE: Community-Preserving Social Network Embedding From Information Diffusion Cascades,"Yuan Zhang, Tianshu Lyu, Yan Zhang",AAAI,,"This paper studies the problem of social network embedding without relying on network structures that are usually not observed in many cases. We address that the information diffusion process across networks naturally reflects rich proximity relationships between users. Meanwhile, social networks contain multiple communities regularizing communication pathways for information propagation. Based on the above observations, we propose a probabilistic generative model, called COSINE, to learn community-preserving social network embeddings from the recurrent and time-stamped social contagion logs, namely information diffusion cascades. The learned embeddings therefore capture the high-order user proximities in social networks. Leveraging COSINE, we are able to discover underlying social communities and predict temporal dynamics of social contagion. Experimental results on both synthetic and real-world datasets show that our proposed model significantly outperforms the existing approaches."
Information Diffusion Prediction with Network Regularized Role-based User Representation Learning,"Zhitao Wang, Chengyao Chen, Wenjie Li",ACM,"Information diffusion, representation learning, network regularization, diffusion role","In this article, we aim at developing a user representation learning model to solve the information diffusion prediction problem in social media. The main idea is to project the diffusion users into a continuous latent space as the role-based (sender and receiver) representations, which capture unique diffusion characteristics of users. The model learns the role-based representations based on a cascade modeling objective that aims at maximizing the likelihood of observed cascades, and employs the matrix factorization objective of reconstructing structural proximities as a regularization on representations. By jointly embedding the information of cascades and network, the learned representations are robust on different diffusion data. We evaluate the proposed model on three real-world datasets. The experimental results demonstrate the better performance of the proposed model than state-of-the-art diffusion embedding and network embedding models and other popular graph-based methods."
Neural Diffusion Model for Microscopic Cascade Prediction,"Cheng Yang, Maosong Sun, Haoran Liu,Shiyi Han, Zhiyuan Liu, Huanbo Luan",arXiv,"Information Diffusion, Neural Network","The prediction of information diffusion or cascade has attracted much attention over the last decade. Most cascade prediction works target on predicting cascade-level macroscopic properties such as the final size of a cascade. Existing microscopic cascade prediction models which focus on user-level modeling either make strong assumptions on how a user gets infected by a cascade or limit themselves to a specific scenario where ""who infected whom"" information is explicitly labeled. The strong assumptions oversimplify the complex diffusion mechanism and prevent these models from better fitting real-world cascade data. Also, the methods which focus on specific scenarios cannot be generalized to a general setting where the diffusion graph is unobserved. To overcome the drawbacks of previous works, we propose a Neural Diffusion Model (NDM) for general microscopic cascade prediction. NDM makes relaxed assumptions and employs deep learning techniques including attention mechanism and convolutional network for cascade modeling. Both advantages enable our model to go beyond the limitations of previous methods, better fit the diffusion data and generalize to unseen cascades. Experimental results on diffusion prediction task over four realistic cascade datasets show that our model can achieve a relative improvement up to 26% against the best performing baseline in terms of F1 score."
New Challenges For NLP Frameworks Programme,"Cartic Ramakrishnan, William A.Baumgartner, Judith A. Blake, Gully A.P. C. Burns, K. Bretonnel Cohen, HaroldJ. Drabkin, Janan T. Eppig, Eduard H.Hovy, Chun-Nan Hsu, Lawrence E.Hunter, Tommy Ingulfsen, HiroakiOnda, Sandeep Pokkunuri, Ellen Riloff,Christophe Roeder, Karin M. Verspoor",,,
Computer-aided Ontology Development: an integrated environment,"Manuel Fiorelli, Maria Teresa Pazienza,Steve Petruzza, Armando Stellato,Andrea Turbati",,,"In this paper we introduce CODA (Computer-aided Ontology Development Architecture), an Architecture and a Framework for semiautomatic development of ontologies through analysis of heterogeneous information sources. We have been motivated in its design by observing that several fields of research provided interesting contributions towards the objective of augmenting/enriching ontology content, but that they lack a common perspective and a systematic approach. While in the context of Natural Language Processing specific architectures and frameworks have been defined, time is not yet completely mature for systems able to reuse the extracted information for ontology enrichment purposes: several examples do exist, though they do not comply with any leading model or architecture. Objective of CODA is to acknowledge and improve existing frameworks to cover the above gaps, by providing: a conceptual systematization of data extracted from unstructured information to enrich ontology content, an architecture defining the components which take part in such a scenario, and a framework supporting all of the above through standard implementations. This paper provides a first overview of the whole picture, and introduces UIMAST, an extension for the Knowledge Management and Acquisition Platform Semantic Turkey, that implements CODA principles by allowing reuse of components developed inside UIMA framework to drive semi-automatic Acquisition of Knowledge from Web Content."
A knowledge based approach to matching human neurodegenerative disease and associated animal models,Martone Maryann,Frontiers in Neuroinformatics,Neuroscience Information Framework; neurodegenerative disease; ontology; phenotype; semantics,"Neurodegenerative diseases present a wide and complex range of biological and clinical features. Animal models are key to translational research, yet typically only exhibit a subset of disease features rather than being precise replicas of the disease. Consequently, connecting animal to human conditions using direct data-mining strategies has proven challenging, particularly for diseases of the nervous system, with its complicated anatomy and physiology. To address this challenge we have explored the use of ontologies to create formal descriptions of structural phenotypes across scales that are machine processable and amenable to logical inference. As proof of concept, we built a Neurodegenerative Disease Phenotype Ontology (NDPO) and an associated Phenotype Knowledge Base (PKB) using an entity-quality model that incorporates descriptions for both human disease phenotypes and those of animal models. Entities are drawn from community ontologies made available through the Neuroscience Information Framework (NIF) and qualities are drawn from the Phenotype and Trait Ontology (PATO). We generated ~1200 structured phenotype statements describing structural alterations at the subcellular, cellular and gross anatomical levels observed in 11 human neurodegenerative conditions and associated animal models. PhenoSim, an open source tool for comparing phenotypes, was used to issue a series of competency questions to compare individual phenotypes among organisms and to determine which animal models recapitulate phenotypic aspects of the human disease in aggregate. Overall, the system was able to use relationships within the ontology to bridge phenotypes across scales, returning non-trivial matches based on common subsumers that were meaningful to a neuroscientist with an advanced knowledge of neuroanatomy. The system can be used both to compare individual phenotypes and also phenotypes in aggregate. This proof of concept suggests that expressing complex phenotypes using formal ontologies provides considerable benefit for comparing phenotypes across scales and species."
Knowledge Discovery in Neuroinformatics,Bartlomiej Wilkowski,Medical Informatics in a United and Healthy Europe,"data sharing, neuroinformatics, medical ontology","Traditionally, the process of turning data into biomedical knowledge has involved “manual” meta-analyses of results reported in journals. Since the amount of scientific data produced in neuroscience today increases dramatically, the resultant expansion of the medical databases has created a significant potential for the design of new data modeling and information retrieval tools and services that
enable faster data processing, analysis and dissemination among a highly interdisciplinary community of researchers."
Web-based Collaborative Corpus Annotation: Requirements and a Framework Implementation,"Kalina Bontcheva, HamishCunningham, Ian Roberts, ValentinTablan",University of Sheffield,,"In this paper we present Teamware, a novel web-based collaborative annotation environment which enables users to carry out complex corpus annotation projects, involving less skilled, cheaper annotators working remotely. It has been evaluated by us through the creation of several gold standard corpora, as well as through external evaluation in commercial annotation projects."
"Using Metaneva for Structuring, Managing and Retrieving Animal Data in the Cognitive Neurosciences","Dirk Derom, Randall A. Schmidt, IanStewart Mcleod, Bruce A. Hewitt",Nature Precedings ,,"Contemporary cognitive neuroscience data sets are characterized by a lack of a standardized ontology, leading to shortcomings in data reports and data sharing along with possibly outdated modular models of functional brain mechanisms. Neuroinformatics is actively addressing these hiatuses, developing detailed and more powerful workbenches. However, the structuring of data is largely neglected due to the intrinsically different data sets in the neurosciences. Here we present a workbench called Metaneva addressing the need of data structures for the improvement of both data storage and data retrieval. We hereby present both our data structuring approach and the system developed specifically for the storage and retrieval of this Metaneva specific data structures."
"Integration of Brain-Gene Ontology and Simulation Systems for Learning, Modelling and Discovery","Nikola K. Kasabov, Vishal Jain, LubicaBenusková, Paulo C. M. Gottgtroy,Frances Joseph",Computational Intelligence in Medical Informatics,"Ontology, Brain, Genes, Knowledge Discovery, Computational Intelligence ","This chapter discusses and presents some preliminary results on the Brain-Gene Ontology project that is concerned with the collection, presentation and use of knowledge in the form of ontology equipped with the Knowledge Discovery means of Computational Intelligence. Brain-Gene Ontology system thus includes various concepts, facts, data, graphs, visualizations, animations, and other information forms, related to brain functions, brain diseases, their genetic basis and the relationship between all of them, and various software simulators. The first version of the Brain-Gene Ontology has been completed as an evolving hierarchical structure in the Protégé ontology building environment endowed with plugins into the CI knowledge discovery packages like NeuCom, Weka, Siftware, and others."
Brain maps and connectivity representation,Alessandro Vercelli,Neuroinformatics,,"In December 2006, we celebrate the centennial of the Nobel Prize to Camillo Golgi and Santiago Ramon y Cajal. These two pioneer neuroscientists began to study the nervous system not only in terms of morphology, but also in terms of connectivity: Golgi by introducing a staining method which is still in use, and Cajal by exploiting its usage for understanding the nervous system. At the beginning of the 20th century, the Golgi method was the only way to trace neural connections. It took several years to improve the technology aimed at tracing neural connection. The major breakpoints were the introduction of degeneration methods in the 1940s and finally that of neural tracers in the 1970s. Tracers (horseradish peroxidase and fluorescent tracers) were found first that worked more efficiently in retrograde transport. Then in the 1990s, other tracers were introduced for anterograde (biotinylated dextran, biocytin) and transneuronal (herpes and rhabdo viruses) transport that allow quantitative analysis of neural connections (for a review see Vercelli et al., 2000). More recently, several neuroimaging techniques were introduced to study neural connections in vivo, even in humans."
Towards the integration of mouse databases - definition and implementation of solutions to two use-cases in mouse functional genomics,"Michael Gruenberger, Rudi Alberts,Damian Smedley, Morris A. Swertz,Paul N. Schofield, Klaus Schughart",BMC Research Notes,,"The integration of information present in many disparate biological databases represents a major challenge in biomedical research. To define the problems and needs, and to explore strategies for database integration in mouse functional genomics, we consulted the biologist user community and implemented solutions to two user-defined use-cases. We organised workshops, meetings and used a questionnaire to identify the needs of biologist database users in mouse functional genomics. As a result, two use-cases were developed that can be used to drive future designs or extensions of mouse databases. Here, we present the use-cases and describe some initial computational solutions for them. The application for the gene-centric use-case, ""MUSIG-Gen"" starts from a list of gene names and collects a wide range of data types from several distributed databases in a ""shopping cart""-like manner. The iterative user-driven approach is a response to strongly articulated requests from users, especially those without computational biology backgrounds. The application for the phenotype-centric use-case, ""MUSIG-Phen"", is based on a similar concept and starting from phenotype descriptions retrieves information for associated genes. The use-cases created, and their prototype software implementations should help to better define biologists' needs for database integration and may serve as a starting point for future bioinformatics solutions aimed at end-user biologists."
"GATE Teamware: a web-based, collaborative text annotation framework","Kalina Bontcheva, HamishCunningham, Ian Roberts, AngusRoberts, Valentin Tablan, Niraj Aswani,Genevieve Gorrell",Language Resources and Evaluation,"Text annotation, Web-based annotation tool, GATE, Cloud-based text annotation service","This paper presents GATE Teamware—an open-source, web-based, collaborative text annotation framework. It enables users to carry out complex corpus annotation projects, involving distributed annotator teams. Different user roles are provided (annotator, manager, administrator) with customisable user interface functionalities, in order to support the complex workflows and user interactions that occur in corpus annotation projects. Documents may be pre-processed automatically, so that human annotators can begin with text that has already been pre-annotated and thus making them more efficient. The user interface is simple to learn, aimed at non-experts, and runs in an ordinary web browser, without need of additional software installation. GATE Teamware has been evaluated through the creation of several gold standard corpora and internal projects, as well as through external evaluation in commercial and EU text annotation projects. It is available as on-demand service on GateCloud.net, as well as open-source for self-installation."
Natural Language Processing with Python,"Steven Bird, Ewan Klein, Edward Loper",O'Reilly Media,,"This book offers a highly accessible introduction to natural language processing, the field that supports a variety of language technologies, from predictive text and email filtering to automatic summarization and translation. With it, you'll learn how to write Python programs that work with large collections of unstructured text. You'll access richly annotated datasets using a comprehensive range of linguistic data structures, and you'll understand the main algorithms for analyzing the content and structure of written communication. Packed with examples and exercises, Natural Language Processing with Python will help you: Extract information from unstructured text, either to guess the topic or identify ""named entities"", Analyze linguistic structure in text, including parsing and semantic analysis, Access popular linguistic databases, including WordNet and treebanks, Integrate techniques drawn from fields as diverse as linguistics and artificial intelligence. This book will help you gain practical skills in natural language processing using the Python programming language and the Natural Language Toolkit (NLTK) open source library. If you're interested in developing web applications, analyzing multilingual news sources, or documenting endangered languages -- or if you're simply curious to have a programmer's perspective on how human language works -- you'll find Natural Language Processing with Python both fascinating and immensely useful."
Recurrent Neural Network Language Model with Vector-space Word Representations,"Si Yujing, Xiao Yeming, X. Ji, Pan Jie-lin,Yan Yong-hong",ICSV,,"Recurrent neural network language model (RNNLM) has been proved to be more competitive than other neural network language models. However, the input-layer of most current RNNLMs only uses one single feature i.e. the index of the word, which is a unit vector. Previous studies proved that language models with additional linguistic information achieve better performance. In this study, the vector space word representations (word vector), which can capture syntactic and semantic regularities of language, is used as additional features in order to enhance RNNLM. Finally, experimental results showed that the word vector features is very useful to improve the performance of RNNLM. Evaluated on a Mandarin test set, 10% relative reduction on perplexity could be obtained and 0.5 points absolute character error rate reductions could be obtained, compared to the conventional RNNLM."
The semantic similarity relation of entities discovery: Using word embedding,"Dong-ru Ruan, Yu-xin Mao, Hong-yanPan, Kai Gao",IEEE,Word Embedding; Semantic Similarity; EntityVector; Continuous vector space,"Recently,word embedding performs well in many natural language processing tasks, which one of is capturing syntactic and semantic word relationships.It can be used in many other research fields, such as recommendation and knowledge base.In this paper, we propose amethod that uses the word embedding to capture the semantic similaritiesof entities. We divide the projection layer into two parts: one is entity, and the other is non-entity, and add the non-entities to the negative sampling of target entities. By iterating over each sentence, the entities are embedded in the entity vector space. For the experiments, we use two kinds oftext corpus, the total words of each approximates 50 million to learn the entity vectors. Finally, the experiments show that our model is faster than Skip-gram model in training task and do the better in the calculation of semantic similarity entities."
Density based clustering for Cricket World Cup tweets using Cosine similarity and time parameter,Nilang Pandey,IEEE,"Density based clustering, geo-referenced documents, spatio-temporal clusters, spatial clusters, topic retrieval, location detection","The rapid spread of location-based devices and cheap storage mechanisms, as well as fast development of Internet technology, allowed collection and distribution of huge amounts of user-generated data. These user generated data sometimes are known as georeferenced documents, they have their location information and time of posting embedded with them. These parameters help to retrieve the location information and the time of posting. We need to retrieve the topic from those geo-referenced documents and determine the local topics and events for a particular region. All these clusters are geospatial in arbitrary shape hence density based clustering is the most appropriate clustering algorithm. Here we used tweets from Twitter, while the DBSCAN method is used for generating clusters. Here for finding similarity between tweets cosine similarity is used, but because of its low value we increase its value by adding weight to it by matching the keywords in tweets. Also another parameter of time is used for separating clusters temporally. Results have shown that weighted keyword based method gives more specific clusters than DBSCAN method, while using the time parameter in it we get clusters time separated. Hence for purpose of information retrieval or building marketing strategy by tweets we can use this method."
Professionalizing and Profiting: The Rise of Intermediaries in the Social Media Influencer Industry:,"Ryan G. Stoldt, Mariah Wellman, BrianEkdale, Melissa Tully",Social Media + Society,"influencers, social media, risk, blogging, travel and tourism","This study examines the relationship between travel influencers (e.g., bloggers and social media personalities) and destination marketers within the changing travel and tourism industry. Through in-depth interviews, observations, and document analysis, we explore the tensions between travel influencers and destination marketers that shape the way travel is promoted, labor is compensated, and professional structures are negotiated. We examine a new breed of travel and tourism worker—intermediaries who seek to professionalize and formalize the relationship between influencers and destination marketers while simultaneously solidifying their own role within the industry. Intermediaries promote and facilitate relationships based on structured flexibility—formalized agreements designed to satisfy a brand’s campaign goals yet open enough for influencers to pursue their unique needs. By examining the relationships between digital content creators, destination marketers, and third-party intermediaries, this article provides insight into how digital media industries negotiate the tension between participation and control."
Qualitative Comparison of Nutrition Content and Advice From Registered Dietitian and Non-Registered Dietitian Bloggers,"Taylor Chan, Teresa Drake, Rachel LVollmer",Journal of Nutrition Education and Behavior,,"Regardless of credentials, anyone can disseminate nutrition information online, putting the public at risk of receiving unreliable and harmful advice. Registered Dietitians (RD) are nutrition professionals, however, it is unknown how nutrition information or advice online differs between RDs and non-RDs. The objective of this study was to compare nutrition content and advice between published blogs by RD and non-RD bloggers.  A blog-ranking platform, based on search and social media metrics, was used to identify the top-ranked, English-language nutrition blogs written by RDs (n = 10) and non-RDs (n = 10). From each blog, the 20 most recent nutrition-related posts were selected, resulting in a final sample of 400 blog posts (RD = 200 blog posts; non-RD = 200 blog posts). Blog posts were separated into two groups by author credentials (RD vs. non-RD). Content analysis was applied to all blog posts by three investigators to develop codes and themes. The investigators conducted the qualitative analysis independently, then met to discuss codes and themes.  A total of 400 blog posts from 20 bloggers were analyzed. Bloggers were primarily from the U.S. (n = 13), and all were female. Although three themes were found for both RD and non-RD blogs: food quality/purity, advice to increase fruit/vegetable intake, and service promotion/sponsorship, several themes were unique to RD or non-RD blogs. For example, RD blogs emphasized moderation and utilized non-technical discourse. Whereas, non-RD blogs focused on micronutrients and supplementation and used technical, fear-based discourse. Furthermore, non-RDs strongly promoted themselves as credible, nutrition professionals. The internet is an effective tool for sharing nutrition information to a wide audience; however, readers may not be able to recognize misinformation. RD bloggers can optimize their impact by providing evidence-based nutrition education, addressing current health trends, and advocating for the dietetics profession."
Microblogging Hash Tag Recommendation System Based on Semantic TF-IDF: Twitter Use Case,"Mir Saman Tajbakhsh, JamshidBagherzadeh",IEEE,Semantic Similarity; Tag Recommendation; TF-IDF; Microblogging; Twitter,"Limitation in the number of characters in microblogging systems, such as Twitter, forces users to use various terms for the same meaning, object, or concept. Sometimes the same term is used in a shorter form (e.g. #friend and #frnd) in a tweet. This problem makes finding similarities between such tags and their corresponding tweets harder. The classical text mining methods cannot be used efficiently in the short tweets. Thus tweets similarity and subsequently tag recommendation, as one of the problems in microblogging social networks, needs a new method with higher efficiency. In this paper we have defined a new semantic based method to find similarities among short messages. We have modeled each short message as a semantic vector which can be used along with any similarity method such as cosine similarity. Then we evaluated the accuracy of the new semantic similarity based tag recommendation system using various semantic based algorithms and compare their results. The semantic based algorithms used are: Shortest Path, Wu & Palmer, Lin, JiangConrath, Resnik, Lesk, LeacockChodorow, and HirstStOnge . Results are evaluated using 8396744 real English tweets and show around 6 times improvement in accuracy over normal TF-IDF"
Social Network Analysis (Social Media),Itai Himelboim,The International Encyclopedia of Communication Research Methods,,"The study of social media networks has evolved in the last two decades into an interdisciplinary scientific area of research. Network analysis of social media data emerged toward the end of the twentieth century when, for the first time in history, immense social interactions were recorded and became available for researchers. At that point in history, decades of social science literature, theoretical and empirical, about network analysis of small and medium‐sized social (i.e., symbolic) networks intersected with a growing body of literature in hard sciences, from biology to computer science and physics, that examined much larger physical networks. Social scientists contributed the theoretical and conceptual foundations for understanding social network structures and the role of key players and communities in these communication networks, within the broader sociological, political, economic, and psychological levels, to name a few. Natural scientists introduced an understanding of the structures and dynamics of large networks (neurological, genetic, statistics, and computers, for instance) as well as the methods and algorithms required for analyzing social networks in a magnitude that had never been seen before. Network analysis of social media data is blooming within this unique intersection of social and natural sciences."
A Medical Profession in Transition: Exploring Naturopathic Physician Blogging Behaviors,Justin Walden,Health Communication,,"Naturopathic medicine is a holistic healing approach involving natural remedies, wellness, and disease prevention. A literature review shows the discipline is attempting to overcome several professional obstacles and expand into new areas. Amid this transition, the naturopathic community—like other groups—has adopted Web 2.0 technologies such as blogs. This article features interviews with one naturopathic medical student and 17 naturopathic physicians and reviews of interviewee blogs to understand this group’s communication activities. Findings suggest blogs are venues for projecting both individual and group credibility to stakeholders. I conclude that blogs serve a “represent all of us” group function and are new examples of gray or alternative health literature."
Structural changes of employment in EUNUTS 2 regions evaluated with Bray & Curtis measure,Małgorzata Markowska,Changes of the industry and services structures in regional systems,"NUTS 2 regions, economic sectors, employment structure, structure diversity","The aim of the paper is the evaluation of the changes observed in the employment structure at the European regional space of NUTS 2 level. The employment structure is expressed in three elements: agriculture, industry and services. Data covers two overlapping periods: 2000–2008 and 2008–2012. This is because of the changes in Eurostat data bases imposed by the update of European Classification of Economic Activities introduced in 2008 to the original regulation from 1997. New activities were defined, mainly in the field of information services and technologies. In new system, information on enterprises and labour market and some definitions in high-tech industries and services are not fully comparable with the old one. This problem is discussed in the paper. The measure of structures diversity is the basic research method for the analysis presented in the paper. It makes it possible to identify the intensity of labour market changes in both time and space."
A New Density-based Spatial Clustering Algorithm for Extracting Attractive Local Regions in Georeferenced Documents,"Tatsuhiro Sakai, Keiichi Tamura,Hajime Kitakami",IMECS,"density-based clustering, spatial cluster, DBSCAN, social media, local topic extraction","Nowadays, with the increasing attention being paid to social media, a huge number of georeferenced documents, which include location information, are posted on social media sites via the Internet. People have been transmitting and collecting information through these georeferenced documents. Georeferenced documents are usually related to not only personal topics but also local topics and events. Therefore, extracting “attractive” local regions associated with local topics from georeferenced documents is one of the most important challenges in different application domains. In this paper, a novel spatial clustering algorithm, called the (ǫ, σ)-densitybased spatial clustering algorithm, for extracting “attractive” local regions in georeferenced documents is proposed. We defined a new type of spatial cluster called an (ǫ, σ)-densitybased spatial cluster. The proposed clustering algorithm can recognize not only semantically-separated but also spatiallyseparated spatial clusters. To evaluate our proposed clustering algorithm, geo-tagged tweets posted on the Twitter site are used. The experimental results show that the (ǫ, σ)-densitybased spatial clustering algorithm can extract “attractive” local regions as (ǫ, σ)-density-based spatial clusters."
Density-Based Spatiotemporal Clustering Algorithm for Extracting Bursty Areas from Georeferenced Documents,"Keiichi Tamura, Takumi Ichimura",IEEE,Spatiotemporal clustering algorithm; Densitybased clustering; Georeferenced document; Spatiotemporal data stream; Topic and event detection,"Nowadays, with the increasing attention being paid to social media, a huge number of georeferenced documents, which include location information, are posted on social media sites. People transmit and collect information over the Internet through these georeferenced documents. Georeferenced documents are usually related to not only personal topics but also local topics and events. Therefore, extracting bursty areas associated with local topics and events from georeferenced documents is one of the most important challenges in different application domains. In this paper, a novel spatiotemporal clustering algorithm, called the (, τ )-density-based spatiotemporal clustering algorithm, for extracting bursty areas from georeferenced documents is proposed. The proposed clustering algorithm can recognize not only temporally-separated but also spatially-separated clusters. To evaluate our proposed clustering algorithm, geo-tagged tweets posted on the Twitter site are used. The experimental results show that the (, τ )-density-based spatiotemporal clustering algorithm can extract bursty areas as (, τ )-density-based spatiotemporal clusters associated with local topics and events."
Tweet Data mining: the Cultural Microblog Contextualization Data Set,"Clémentine Scohy, Yassine RkhaChaham, Sébastien Déjean, JosianeMothe",CEUR Workshop Proceedings,Tweet mining ; Cultural Microblog Contextualization ; descriptive analysis,This paper presents an overview of the data set that was used for the Cultural Microblog Contextualization Workshop at CLEF 2016 and more specifically for the task 1: tweet contextualization. In this paper we first present a descriptive analysis of the data: we consider the variables or features associated with the tweets and analyse them. Then we also analyse the tweet textual content. The results of this work correspond to a first step toward data quality checking. It can also useful in order to understand better the data and its usefulness for some tasks or case studies.
Is Category Spanning Truly Disadvantageous?: New Evidence from Primary and Secondary Movie Markets,"Marc Keuschnigg, Marc ThomasWimmer",Social Forces ,,"Genre assignments help audiences make sense of new releases. Studies from a wide range of market contexts have shown that generalists defying clear mapping to established categories suffer penalties in market legitimacy, perceived quality, or audience attention. We introduce an empirical strategy to disentangle two mechanisms, reduced niche fitness and audience confusion, causing devaluation or ignorance of boundary-crossing offers. Our data on 2,971 feature films released to US theaters and subsequently made available on DVD further reveal that consequences of category spanning are subject to strong moderating influences. Negative effects are far from universal, manifesting only if (a) combined genres are culturally distant, (b) products are released to a stable and highly institutionalized market context, and (c) offers lack familiarity as an alternative source of market recognition. Our study provides ramifications as to the scope conditions of categorization effects and modifies some widely acknowledged truisms regarding boundary crossing in cultural markets."
Building a Knowledge Base Using Microblogs: the Case of Festivals and Location-Based Events,"Thi Bich Ngoc Hoang, Josiane Mothe",ARIA,"Domain knowledge base, Microblog, Information extraction from tweets","Social media like Twitter are used during an event (catastrophe, cultural events ...) to collaboratively comment or advise on that event. Social network users are then notified through the people they follow or by seeking tweets related to the event. However, given the size of a tweet, the information obtained by a single post is often very partial. Using a set of tweets about an event makes it possible to have a more complete view by combining all the information posted. In this paper, we propose a model to represent a collection of micro-blogs based on a domain ontology. We also show how to populate this ontology based on both the collection of tweets and external collections. We apply our model to the case of tweets on festivals (a collection of the CLEF 2016 challenge) and show how it can be used to make recommendations."
Object retrieval with image graph traversal-based re-ranking,"Siyuan Qi, Yupin Luo",Signal Processing: Image Communication,"Image graph traversal, Image attribute, Object retrieval, Re-ranking","The topic of this paper is the retrieval of a particular object. A graph traversal-based re-ranking framework for the baseline bag-of-words (BOW) approach is proposed. For an image, we consider not only its similarity with the query image, but also the relationship between other dataset images. We integrate these information as image attributes via an extended image graph and propose a graph traversal algorithm to efficiently obtain their values. By comprehensively considering these attributes, we propose an attribute similarity measure for re-ranking, which brings much performance improvement. We further use our method for the multiple-query retrieval with a simple extension of the virtual query. The experimental results show that our method significantly improve the baseline approach and achieves competitive performance compared with the other state-of-the-art methods. Additionally, our re-ranking method requires only a little extra memory space and time costs."
Genre‐deviating artist entry: the role of authenticity and fuzziness,"Juha T. Mattsson, Mirva Peltoniemi,Petri Parvinen",Management Decision,"Music industry, Music, Consumers, Classification schemes","The purpose of the paper is to conceptually elaborate two important mechanisms, authenticity and fuzziness, that affect how audiences react to deviations from existing genres by artists that are making their first entry. In cultural industries such as music, social categorization systems play an important role in the success of actors. Audience members evaluate entering artists vis-a`-vis the existing, collective system of categories and related normative social codes, and may or may not impose penalties for code violations.This is a conceptual paper and the conceptual framework is built on recent theorization regarding social categories in organizational fields. A key premise is that such categories, including musical genres, are fuzzy with blurred boundaries and partial membership. Such fuzziness is likely to affect organizational viability and dynamics. Based on the conceptualization, the baseline proposition is that artists making their first entry are likely to face higher penalties by audiences if they deviate from existing genres. However, the higher the idiosyncratic authenticity of an artist, the smaller such penalties are. Moreover, we expect penalties to be smaller when genre fuzziness increases. Besides contributions to theory, the propositions that are stated in the paper should have relevance to record companies and artists when they are making strategic decisions regarding artist identity upon first entry. The paper offers a novel perspective to extant research in music regarding genres, categories, and organizational identities. Furthermore, the paper contributes to recently emerged sociological theory on fuzzy categories and authenticity."
Forecasting share price movements using news sentiment analysis in a multinational environment,"Sándor Molnár, Mark Molnar, Zs. Naár-Tóth, Tamás Timár",Hungarian Agricultural Engineering,"textual news stories, finance, alternative metrics, software, investment decision making","Using a common definition we can define news analysis as the measurement of the various qualitative and quantitative elements of textual news stories. These elements include sentiment, relevance and novelty. By quantifying news stories we can gain a useful way to manipulate and use everyday information in a mathematically concise manner. In this article a framework for news analytics techniques used in finance is provided. Various news analytic methods and software are discussed, and a set of metrics is given that may be applied to assess the performance of analytics. Various directions for this field are discussed. The proposed methods can help the valuation and trading of securities, facilitate investment decision making, meet regulatory requirements, or manage risk."
Oriented graphs with high reliable nodes,Gurami Sh. Tsitsiashvili,Applied Mathematical Sciences,"a cycle, an oriented and acyclic graph, an asymptotic of a failing probability","In this paper an oriented and acyclic graph G with nodes which have a failure probability 1 − exp(−h), h → 0 is considered. The node i in the graph stops its work if there exists a failing node from which there is a way to i. General conditions when the probability Q(R) of finite set R of the graph G nodes stopping satisfies the equality Q(R) = O(h t+1), t ≥ 2, are obtained."
Using data on communications traffic in a new approach to analyzing large-scale social networks and user-dynamics,"M. Aida, K. Ishibashit, Chisa Takano,Hiroyoshi Miwa",IEEE,,"Many studies of social networks have recently been published. Interest in topological structures, such as scale-free characteristics, has been particularly strong. In this paper, we focus on the analysis of traffic data in a communications network as a way of investigating large-scale social networks. Behaviors of information exchange between pairs of cellular phone users are reflected in traffic data, which thus reflects interesting features of social networks. We analyze the relation between the number of the customers and the volume of traffic with a view to finding clues to the structure of social networks among the very large set of potential customers of the service. We then demonstrate some interesting features that our analysis reveals: a scale-free topology of human relations, and behaviors of user-dynamics. Through these discussions, we emphasize the importance of traffic analysis for investigating social issues."
LIG at CLEF 2016 Cultural Microblog Contextualization: TimeLine illustration based on Microblogs,"Nayanika Dogra, Philippe Mulhem,Nawal Ould Amer, Lorraine Goeuriot",CEUR Workshop Proceedings,"tweet retrieval, diversification, reranking","This paper presents the approach used by the LIG-MRIM research group to the participation of the task 3 (TimeLine illustration based on Microblogs) for the CLEF of Cultural Microblog Contextualization track. This task deals with the retrieval of tweets related to cultural events (music festivals) . For the content-based elements, we use the classical BM25 model [4]. Then, we diversify the results based on duplicate removal, using tf-based representations of tweets. In a third step, we apply optional re-ranking related to time-line, activity and popularity of authors of tweets."
Density-based adaptive spatial clustering algorithm for identifying local high-density areas in georeferenced documents,"Tatsuhiro Sakai, Keiichi Tamura,Hajime Kitakami",IEEE,"density-based cluster, spatial cluster, DBSCAN, social media, local topic extraction, adaptive spatial clustering.","An emerging topic in social media is the increase in the number of geo-annotated documents, which include not only posted time but also posted location. Social media users have been transmitting information about things they witnessed themselves in their daily life through such geo-annotated (georeferenced) documents. Georeferenced documents are usually related to not only personal topics but also local topics and events. Therefore, identifying high-density areas associated with local “attractive” topics in georeferenced documents is one of the most important challenges in many application domains. In this study, we propose a novel density-based spatial clustering algorithm called the (ε,σ)- density-based adaptive spatial clustering algorithm for identifying high-density areas in which geo-related local topics in georeferenced documents are located. The (ε,σ)-density-based adaptive spatial clustering algorithm can identify local high-density areas by using adaptive spatial clustering criteria."
A new semantic similarity measure evaluated in word sense disambiguation,"Ergin Altintas, M. Elif Karsligil, VedatCoskun",ACL,,"In this paper, a new conceptual hierarchy based semantic similarity measure is presented, and it is evaluated in word sense disambiguation using a well known algorithm which is called Maximum Relatedness Disambiguation. In this study, WordNet’s conceptual hierarchy is utilized as the data source, but the methods presented are suitable to other resources."
The business of blogging: Effective approaches of women food bloggers,"Elzbieta Lepkowska-White, EmilyKortright",Journal of Foodservice Business Research,Food blogs; food marketing; meanings of food; social media,"Consumer trust and loyalty to bloggers presents opportunities for businesses to reach consumers in inconspicuous and effective ways. The study explores successful business practices used by popular female food bloggers to market food products and services. Content analysis of these food blogs shows that female bloggers construct personas on their blogs that emphasize specific meanings and motivations of food in very intentional ways. Female bloggers use a variety of business tactics to ensure that these personas are credible, professional, trustworthy, and fully intermingled in the lifestyles and beliefs of their target consumers."
How Low-Income Mothers Select and Adapt Recipes and Implications for Promoting Healthy Recipes Online,"Lauren N Tobey, Christine Mouzong,Joyce Senior Angulo, Sally R. Bowman,Melinda Manore",Nutrients,low-income mothers; focus group; nutrition; Supplemental Nutrition Assistance Program (SNAP); social media; recipe; social marketing; children; feeding behavior; website development,"We describe a 5-year (2011⁻2015) qualitative evaluation to refine the content/delivery of the Food Hero social marketing campaign recipes to low-income mothers. Objectives were to: (1) identify characteristics looked for in recipes; (2) determine recipe sources; (3) understand motivation for seeking new recipes and recipe adaptations; and (4) identify recipe website characteristics users valued. Nine focus groups (n = 55) were conducted in Portland, Oregon. Participants (35⁻52 years) were primary caregivers for ≥ one child, the primary household food shoppers/preparers, enrolled in the Supplemental Nutrition Assistance Program (SNAP) and able to speak/read English. Participants reported having ""go-to"" family recipes and regularly searching online for new recipes, especially those using ingredients available/preferred by family members. Recipe websites with highest appeal were polished and engaging to mothers/children, offered user-ratings/comments and were reachable from search engines. Results identified key recommendations: (1) understand the target audience; (2) aim to add healthy/customizable recipes to family ""go-to' recipe rotations and understand the impact of generational influences (e.g. how mothers/grandmothers cooked) on family meals; and (3) create websites that meet target audience criteria. Seeking the target audience's input about the content/delivery of recipes is an important formative step for obesity-prevention projects that include healthy recipes."
Testing theories of preferential attachment in random networks of citations,"Lawrence J. Smolinsky, Aaron Lercher,Andrew McDaniel",JASIST,,"In this article we examine 2 classic stochastic models of the accumulation of citations introduced by H.A . S imon and D erek J ohn de S olla P rice. These models each have 2 distinct aspects: growth, which is the introduction of new articles, and preferential attachment, which describes how established articles accumulate new citations. The attachment rules are the subtle portion of these models that supply the interesting explanatory power. Previous treatments included both aspects. Here we separate preferential attachment from the growth aspect of the model. This separation allows us to examine the results of the preferential attachment rules without confounding these with growth in the number of articles available to receive citations. We introduce the method using M arkov chains. We show how to overcome the mathematical and computational complexity to obtain results. A comparison of S imon's and P rice's rules are computed in 3 J ournal  C itation  R eports subject categories using articles published in the 1960s and allowed to accumulate citations to 1980. This comparison cannot be made through analysis of power laws."
Beverage Bloggers: A Developing Relationship Between Wine Blogger Expertise and Twitter Followers,"Byron Marlowe, Eric A. Brown, ThomasSchrier, Tianshu Zheng",International Journal of Hospitality Beverage Management,,"This pilot study examines how beverage bloggers’ beverage experience and certified wine knowledge influences their wine destination recommendations on Twitter. Microblogging a wine destination through Twitter is explored in this study. In the context of social media, the role of Twitter as a microblog in promoting wine destinations is specifically examined. The present study examines the food and beverage experience and wine credentials of bloggers through survey and correlations of their wine destination recommendations, travel habits and geographic home. This exploratory study finds that different levels of wine credentials have an influence on blogger's recommendation of both international and domestic wine destinations. The analysis shows that the increasing number of wine credentials possessed by a blogger influences the number of followers they have on Twitter."
Opinion mining on Twitter microblogging using Support Vector Machine: Public opinion about State Islamic University of Bandung,"Jumadi, Dian Sa'adillah Maylawati, BekiSubaeki, Taufik Ridwan",IEEE,"Opinion mining, twitter, support vector machine, machine learning, pre-processing","Tweet data on Twitter as microblogging can be processed to be an important and useful information. We propose opinion mining with Support Vector Machine (SVM) algorithm to classify tweet opinion data which is a huge data. This opinion mining will be used to get insight of public opinion about State Islamic University of Sunan Gunung Djati Bandung which is one of large university in Indonesia. We have two classes for opinion classification that is negative and positive opinions. Pre-processing phase before classifying consists of cleaning data, emotion tokenizing, case folding, stop words removal, and stemming process. The result of this research is 0.838 precision value and 0.76 recall for positive class. Then, 0.78 precision value and 0.853 recall for negative class. Opinion classification with SVM of this research has accuracy 78.75%."
Dominating sets of random recursive trees,"Michele Zito, Colin S. Cooper",Discrete Applied Mathematics,"Random trees, Algorithms, Dominating sets","A random recursive tree on n vertices is either a single isolated vertex (for n=1) or is a vertex v""n connected to a vertex chosen uniformly at random from a random recursive tree on n-1 vertices. Such trees have been studied before [R. Smythe, H. Mahmoud, A survey of recursive trees, Theory of Probability and Mathematical Statistics 51 (1996) 1-29] as models of boolean circuits. More recently, Barabasi and Albert [A. Barabasi, R. Albert, Emergence of scaling in random networks, Science 286 (1999) 509-512] have used modifications of such models to model for the web and other ''power-law'' networks. A minimum (cardinality) dominating set in a tree can be found in linear time using the algorithm of Cockayne et al. [E. Cockayne, S. Goodman, S. Hedetniemi, A linear algorithm for the domination number of a tree, Information Processing Letters 4 (1975) 41-44]. We prove that there exists a constant d~0.3745... such that the size of a minimum dominating set in a random recursive tree on n vertices is dn+o(n) with probability approaching one as n tends to infinity. The result is obtained by analysing the algorithm of Cockayne, Goodman and Hedetniemi."
Beyond the blog: The networked self of travel bloggers on Twitter,Deepti Ruth Azariah,Journal of Media and Communication,"microblogging, blogging, travel, self­presentation, discourse","Studies of the use of social media in tourism rarely discuss various tools in conjunction with each other. The growth of Twitter has attracted the attention of tourism researchers interested in the platform as a marketing tool and a source of information about consumers (Claster, Cooper, & Sallis, 2010; Hay, 2010). Similar studies of travel blogs largely focus on what tourists say about destinations and their own experiences (Akehurst, 2009; Bosangit, McCabe, & Hibbert, 2009; Schmallegger & Carson, 2008). Blogs in general, and travel blogs in particular, are widely regarded as providing credible information about their authors. Both the content and formal features of these online narratives shape the self-presentation and positioning of their authors as bloggers. Given that blogs are increasingly ""distributed"" (Helmond, 2010) and that independent travel bloggers often link to other platforms, it is necessary to consider author-created content beyond the blog to understand the presentation of what Papacharissi (2010) calls a ""networked self."" Drawing on the theories of Bakhtin and Goffman, which have informed previous analyses of blogs, and Dann’s (1996) concept of tourist discourse, this paper argues that the Twitter pages of independent travel bloggers extend the self-presentation in their blogs.In particular, it focuses on how travel bloggers use specific conventions, formal features, and narrative techniques of Twitter to express a networked self and reiterate themes of the blog. Through a random selection and textual analysis of various messages it finds that while there is some mention of the travel experience, the various conventions and conversations on Twitter are self-presentational elements that generally strengthen the authors’ position as travel bloggers. The characteristic narrative techniques of Twitter also reveal tensions between the discourses of travel and tourism. The networked self of the independent travel blogger is negotiated in these discursive tensions."
Réseaux et signal : des outils de traitementdu signal pour l'analyse des réseaux,Nicolas Tremblay,ENS Lyon ,"Graph resampling, Multiscale, Community Detection, Spectral graph wavelets, complex networks, graph signal processing","This thesis describes new tools specifically designed for the analysis of networks such as social, transportation, neuronal, protein, communication networks... These networks, along with the rapid expansion of electronic, IT and mobile technologies are increasingly monitored and measured. Adapted tools of analysis are therefore very much in demand, which need to be universal, powerful, and precise enough to be able to extract useful information from very different possibly large networks. To this end, a large community of researchers from various disciplines have concentrated their efforts on the analysis of graphs, well define mathematical tools modeling the interconnected structure of networks. Among all the considered directions of research, graph signal processing brings a new and promising vision : a signal is no longer defined on a regular n-dimensional topology, but on a particular topology defined by the graph. To apply these new ideas on the practical problems of network analysis paves the way to an analysis firmly rooted in signal processing theory. It is precisely this frontier between signal processing and network science that we explore throughout this thesis, as shown by two of its major contributions. Firstly, a multiscale version of community detection in networks is proposed, based on the recent definition of graph wavelets. Then, a network-adapted bootstrap method is introduced, that enables statistical estimation based on carefully designed graph resampling schemes."
Sinhala Short Sentence Similarity Measures using Corpus-Based Similarity for Short Answer Grading,"J. C. S. Kadupitiya, SurangikaRanathunga, Gihan Dias",University of Moratuwa Sri Lanka,,"Currently, corpus based-similarity, string-based similarity, and knowledge-based similarity techniques are used to compare short phrases. However, no work has been conducted on the similarity of phrases in Sinhala language. In this paper, we present a hybrid methodology to compute the similarity between two Sinhala sentences using a Semantic Similarity Measurement technique (corpus-based similarity measurement plus knowledge-based similarity measurement) that makes use of word order information. Since Sinhala WordNet is still under construction, we used lexical resources in performing this semantic similarity calculation. Evaluation using 4000 sentence pairs yielded an average MSE of 0.145 and a Pearson correlation factor of 0.832."
Construction of a word similarity dataset and evaluation of word similarity techniques for Vietnamese,"Bui Van Tan, Nguyen Phuong Thai,Pham Van Lam",IEEE,word similarity; sematic similarity; WordNet; word embeddings.,"Measuring word similarity is a core issue because it has many applications in natural language processing. Although many studies have been reported and the techniques have been developed for addressing this issue for English, however, the study dealing with the applications, analyses and evaluation word similarity techniques to Vietnamese still has not reported yet. Especially, there is still lack of the benchmark Vietnamese dataset for evaluating these techniques. In this paper, we report three main topics including: firstly, construct a benchmark dataset for evaluation of similar techniques to the Vietnamese language; secondly, experiment with some similarity techniques based on WordNet and word embeddings; and finally, propose an extension for Lesk algorithm in order to improving the efficiency of similar measuring with Vietnamese language."
Building semantic corpus from wordNet,Lubomir Stanchev,IEEE,,"We propose a novel methodology for extracting semantic similarity knowledge from semi-structured sources, such as WordNet. Unlike existing approaches that only explore the structured information (e.g., the hypernym relationship in WordNet), we present a framework that allows us to utilize all available information, including natural language descriptions. Our approach constructs a semantic corpus. It is represented using a graph that models the relationship between phrases using numbers. The data in the semantic corpus can be used to measure the similarity between phrases, the similarity between documents, or to perform a semantic search in a set of documents that uses the meaning of words and phrases (i.e., search that is not keyword-based)."
Performance Evaluation of WordNet-based Semantic Relatedness Measures for Word Prediction in Conversational Speech,Michael Pucher,IWCS,,The performance of eight WordNet-based semantic similarity/relatedness measures for word prediction in conversational speech was evaluated. We give a ranking of the different measures which shows that the performance of the measures differs significantly for noun and verb prediction. We also varied the dialog context and used cross part-of-speech comparison.
An Approach of Semantic Similarity by Combining HowNet and Cilin,"Peiying Zhang, Zhanshan Zhang,Weishan Zhang",IEEE,semantic similarity; Tongyici Cilin; similarity computing; HowNet,Knowing semantic similarity is very important for many applications of computational linguistics and artificial intelligence. This paper proposes a hybrid approach that combines HowNet and Cilin to calculate semantic similarities in order to address the issue of absence or roughness of words in HowNet. We compare experiment results of our approach with those tests with those produced by Word Net-based similarity measurements. One of the benchmarks is Miller and Charles' list of 30 noun pairs which had been manually designated similarity measurements. We correlate our experiments with those computed by several other methods. Experiments on Chinese word pairs show that our approach is the closet to human similarity judgments.
Conceptual discovery of Web services using WordNet,"Amineh Ghorbani, Fattaneh Taghiyareh",IEEE,ReST; Semantic Annotation; Service Discovery,"With the emergence of Web service mashups, selecting the appropriate Web services from the vast amount of available services has emphasized the role of service discovery. In this research, we present a new way of enhancing Web services semantically using WordNet concepts (synsets). The important advantage of our solution is that it allows developers to enhance Web services with semantic information without semantic annotation against an ontology. This is different from traditional, ontology-based researches, which require significant cost and effort for semantic annotation and ontology management. Our proposed solution allows associating semantic tags on the message parts of Web services. We solve the semantic service discovery problem with a domain neutral service annotation technique. Additionally we test the precision of system by using different similarity measures on a tagged service data set. In addition, we provide a service description binding for WADL documents."
Real-time clustering of massive geodata for online maps to improve visual analysis,"Aragats Amirkhanyan, Feng Cheng,Christoph Meinel",IEEE,,"Nowadays, we have a lot of data produced by social media services, but more and more often these data contain information about a location that gives us the wide range of possibilities to analyze them. Since we can be interested not only in the content, but also in the location where this content was produced. For good analyzing geo-spatial data, we need to find the best approaches for geo clustering. And the best approach means real-time clustering of massive geodata with high accuracy. In this paper, we present a new approach of clustering geodata for online maps, such as Google Maps, OpenStreetMap and others. Clustered geodata based on their location improve visual analysis of them and improve situational awareness. Our approach is the server-side online algorithm that does not need the entire data to start clustering. Also, this approach works in real-time and could be used for clustering of massive geodata for online maps in reasonable time. We implemented the proposed approach to prove the concept, and also, we provided experiments and evaluation of our approach."
Identifying main topics in density-based spatial clusters using network-based representative document extraction,"Tatsuhiro Sakai, Keiichi Tamura,Hajime Kitakami",IEEE,"Density-based spatial clustering, PageRank algorithm, Node-based betweenness centrality, Geo-tagged tweet, Local topic extraction","Geo-tagged documents on social media are usually related to local topics and events. Extracting areas of interest associated with local “attractive” topics from geo-tagged documents is one of the most important challenges in many application domains. In this paper, we propose a novel method for extracting the areas of interest from geo-tagged documents. There are two main steps in the proposed method. First, the (ε, σ)-density-based adaptive spatial clustering algorithm extracts areas where local topics are attracting attention as spatial clusters. Second, representative geo-tagged documents are detected to identify the main topic in each spatial cluster. The (ε, σ)-density-based adaptive spatial clustering algorithm changes the threshold for seamlessly extracting spatial clusters regardless of the local densities of the posted geo-tagged documents. Moreover, the proposed method utilizes the network-based important sentence extraction method in order to extract representative geo-tagged documents from each spatial cluster. The experimental results show that the proposed method can extract the areas of interest as spatial clusters and representative documents as main topics."
Text similarity analysis using IR lists,"Senem Kumova Metin, BaharKaraoglan, Tarik Kisla",IEEE,"signal information, statistical signal processing; web based text similarity, similarity methods","Natural language processing can be seen as a signal processing problem when the characters, syllabi, words, punctuations in a text are considered as signals. In this article, we present a novel approach that detects text similarity in Turkish, based on the similarities of the lists of retrieved documents when the texts are given as queries to web search engines. The similarities between the URLs contained in the items of the returned lists are measured using statistical methods like euclidean, city-block, chebychev, cosine, correlation, spearman and hamming distances. For experimenting, a corpus of 150 news is developed by gathering news in 50 different topics from 3 Turkish newspapers published during a certain time slot. News on the same topic published in different newspapers are considered as similar texts. Statistical methods are applied on the formed newsXterms matrix; and for each news similar news are ranked from the most similar to least similar. If at least one of the top two is the same with the ones marked manully as similar, it is counted as success. Experimental results show that cosines and correlation distances give the best performance with 84% precision"
GECS: Graph Embedding Using Connection Subgraphs,Saba A. Al-Sayouri,MLG,"information networks, network flow, learning graph representations, node embedding","This paper studies the problem of learning large-scale graph representations (a.k.a. embeddings). Such representations encode the relations among distinct nodes on the continuous feature space. The learned representations generalize over various tasks, such as node classification, link prediction, and recommendation. Learning nodes representations aims to map proximate nodes close to one another in the low-dimension vector space. Thus, embedding algorithms pursue to preserve local and global network structure by identifying nodes neighborhood notions. However, the means proposed methods have been employed in order to identify nodes neighborhoods fail to precisely capture network structure. In this paper, we propose a novel scalable graph embedding algorithmic framework called GECS, which aims to learn graph representations using connection subgraphs, where analogy with electrical circuits has been employed. The connection subgraphs are created to address the proximity among each two non-adjacent nodes, which are abundant in real-world networks, by maximizing the amount of flow between them. Although a subgraph captures proximity between two non-adjacent nodes, the formation of the subgraph addresses the direct connections with immediate neighbors as well. Therefore, our algorithm better preserves the local and global structure of a network. Further, despite the fact that non-adjacent nodes are numerous in real-world networks, our algorithm can scale to large-scale graphs, because we do not deal with the graph as a whole, instead, with much more smaller extracted subgraphs. Since our algorithm is not yet empirically examined, we here introduce a potential solution that can better learn graph representations comparing to existing embedding methods accompanied by rational reasoning."
Deep Learning for Learning Graph Representations,"Wenwu Zhu, Xin Wang, Peng Cui",arXiv,"Deep Learning, Graph Representation, Network Embedding","Mining graph data has become a popular research topic in computer science and has been widely studied in both academia and industry given the increasing amount of network data in the recent years. However, the huge amount of network data has posed great challenges for efficient analysis. This motivates the advent of graph representation which maps the graph into a low-dimension vector space, keeping original graph structure and supporting graph inference. The investigation on efficient representation of a graph has profound theoretical significance and important realistic meaning, we therefore introduce some basic ideas in graph representation/network embedding as well as some representative models in this chapter."
Variational Graph Auto-Encoders,"Thomas N. Kipf, Max Welling",arXiv,,"We introduce the variational graph auto-encoder (VGAE), a framework for unsupervised learning on graph-structured data based on the variational auto-encoder (VAE). This model makes use of latent variables and is capable of learning interpretable latent representations for undirected graphs. We demonstrate this model using a graph convolutional network (GCN) encoder and a simple inner product decoder. Our model achieves competitive results on a link prediction task in citation networks. In contrast to most existing models for unsupervised learning on graph-structured data and link prediction, our model can naturally incorporate node features, which significantly improves predictive performance on a number of benchmark datasets."
Knowledge Graph Completion with Adaptive Sparse Transfer Matrix,"Guoliang Ji, Kang Liu, Shizhu He, JunZhao",AAAI,,"We model knowledge graphs for their completion by encoding each entity and relation into a numerical space. All previous work including Trans(E, H, R, and D) ignore the heterogeneity (some relations link many entity pairs and others do not) and the imbalance (the number of head entities and that of tail entities in a relation could be different) of knowledge graphs. In this paper, we propose a novel approach TranSparse to deal with the two issues. In TranSparse, transfer matrices are replaced by adaptive sparse matrices, whose sparse degrees are determined by the number of entities (or entity pairs) linked by relations. In experiments, we design structured and unstructured sparse patterns for transfer matrices and analyze their advantages and disadvantages. We evaluate our approach on triplet classification and link prediction tasks. Experimental results show that TranSparse outperforms Trans(E, H, R, and D) significantly, and achieves state-of-the-art performance."
Text-Enhanced Representation Learning for Knowledge Graph,"Zhigang Wang, Juan-Zi Li",IJCAI,,"Learning the representations of a knowledge graph has attracted significant research interest in the field of intelligent Web. By regarding each relation as one translation from head entity to tail entity, translation-based methods including TransE, TransH and TransR are simple, effective and achieving the state-of-the-art performance. However, they still suffer the following issues: (i) low performance when modeling 1-to-N, N-to-1 and Nto-N relations. (ii) limited performance due to the structure sparseness of the knowledge graph. In this paper, we propose a novel knowledge graph representation learning method by taking advantage of the rich context information in a text corpus. The rich textual context information is incorporated to expand the semantic structure of the knowledge graph and each relation is enabled to own different representations for different head and tail entities to better handle 1-to-N, N-to-1 and N-to-N relations. Experiments on multiple benchmark datasets show that our proposed method successfully addresses the above issues and significantly outperforms the state-of-the-art methods."
A Translation-Based Knowledge Graph Embedding Preserving Logical Property of Relations,"Hee-Geun Yoon, Hyun-Je Song, Seong-Bae Park, Se-Young Park",ACL,,"This paper proposes a novel translation-based knowledge graph embedding that preserves the logical properties of relations such as transitivity and symmetricity. The embedding space generated by existing translation-based embeddings do not represent transitive and symmetric relations precisely, because they ignore the role of entities in triples. Thus, we introduce a role-specific projection which maps an entity to distinct vectors according to its role in a triple. That is, a head entity is projected onto an embedding space by a head projection operator, and a tail entity is projected by a tail projection operator. This idea is applied to TransE, TransR, and TransD to produce lppTransE, lppTransR, and lppTransD, respectively. According to the experimental results on link prediction and triple classification, the proposed logical property preserving embeddings show the state-of-the-art performance at both tasks. These results prove that it is critical to preserve logical properties of relations while embedding knowledge graphs, and the proposed method does it effectively."
From One Point to a Manifold: Knowledge Graph Embedding for Precise Link Prediction,"Han Xiao, Minlie Huang, Xiaoyan Zhu",arXiv,,"Knowledge graph embedding aims at offering a numerical knowledge representation paradigm by transforming the entities and relations into continuous vector space. However, existing methods could not characterize the knowledge graph in a fine degree to make a precise prediction. There are two reasons: being an ill-posed algebraic system and applying an overstrict geometric form. As precise prediction is critical, we propose an manifold-based embedding principle (\textbf{ManifoldE}) which could be treated as a well-posed algebraic system that expands the position of golden triples from one point in current models to a manifold in ours. Extensive experiments show that the proposed models achieve substantial improvements against the state-of-the-art baselines especially for the precise prediction task, and yet maintain high efficiency."
ProjE: Embedding Projection for Knowledge Graph Completion,"Baoxu Shi, Tim Weninger",AAAI,,"With the large volume of new information created every day, determining the validity of information in a knowledge graph and filling in its missing parts are crucial tasks for many researchers and practitioners. To address this challenge, a number of knowledge graph completion methods have been developed using low-dimensional graph embeddings. Although researchers continue to improve these models using an increasingly complex feature space, we show that simple changes in the architecture of the underlying model can outperform state-of-the-art models without the need for complex feature engineering. In this work, we present a shared variable neural network model called ProjE that fills-in missing information in a knowledge graph by learning joint embeddings of the knowledge graph's entities and edges, and through subtle, but important, changes to the standard loss function. In doing so, ProjE has a parameter size that is smaller than 11 out of 15 existing methods while performing 37% better than the current-best method on standard datasets. We also show, via a new fact checking task, that ProjE is capable of accurately determining the veracity of many declarative statements."
Jointly Embedding Knowledge Graphs and Logical Rules,"Shu Guo, Quan Wang, Lihong Wang, BinWang, Li Guo",ACL,,"Embedding knowledge graphs into continuous vector spaces has recently attracted increasing interest. Most existing methods perform the embedding task using only fact triples. Logical rules, although containing rich background information, have not been well studied in this task. This paper proposes a novel method of jointly embedding knowledge graphs and logical rules. The key idea is to represent and model triples and rules in a unified framework. Specifically, triples are represented as atomic formulae and modeled by the translation assumption, while rules represented as complex formulae and modeled by t-norm fuzzy logics. Embedding then amounts to minimizing a global loss over both atomic and complex formulae. In this manner, we learn embeddings compatible not only with triples but also with rules, which will certainly be more predictive for knowledge acquisition and inference. We evaluate our method with link prediction and triple classification tasks. Experimental results show that joint embedding brings significant and consistent improvements over stateof-the-art methods. Particularly, it enhances the prediction of new facts which cannot even be directly inferred by pure logical inference, demonstrating the capability of our method to learn more predictive embeddings."
From One Point to A Manifold: Orbit Models for Precise and Efficient Knowledge Graph Embedding,"Han Xiao, Minlie Huang, Hao Yu,Xiaoyan Zhu",arXiv,,"Knowledge graph embedding aims at offering a numerical representation paradigm for knowledge by transforming the entities and relations into continuous vector space. This paper studies the problem of unsatisfactory precise prediction, that existing methods could not express the knowledge in a fine degree to make a precise prediction. To alleviate this issue, we propose an orbit-based embedding model (OrbitE). which is a well-posed algebraic system that expands the position of golden triples from one point in current models to a manifold. Extensive experiments show that the proposed model achieves substantial improvements against the state-of-the-art baselines especially for precise prediction task, with almost the fastest speed."
STransE: a novel embedding model of entities and relationships in knowledge bases,"Dat Quoc Nguyen, Kairit Sirts, LizhenQu, Mark Johnson",ACL,,"Knowledge bases of real-world facts about entities and their relationships are useful resources for a variety of natural language processing tasks. However, because knowledge bases are typically incomplete, it is useful to be able to perform link prediction, i.e., predict whether a relationship not in the knowledge base is likely to be true. This paper combines insights from several previous link prediction models into a new embedding model STransE that represents each entity as a lowdimensional vector, and each relation by two matrices and a translation vector. STransE is a simple combination of the SE and TransE models, but it obtains better link prediction performance on two benchmark datasets than previous embedding models. Thus, STransE can serve as a new baseline for the more complex models in the link prediction task."
Aligning Knowledge and Text Embeddings by Entity Descriptions,"Huaping Zhong, Jianwen Zhang, ZhenWang, Hai Wan, Zhigang Chen",ACL,,"We study the problem of jointly embedding a knowledge base and a text corpus. The key issue is the alignment model making sure the vectors of entities, relations and words are in the same space. Wang et al. (2014a) rely on Wikipedia anchors, making the applicable scope quite limited. In this paper we propose a new alignment model based on text descriptions of entities, without dependency on anchors. We require the embedding vector of an entity not only to fit the structured constraints in KBs but also to be equal to the embedding vector computed from the text description. Extensive experiments show that, the proposed approach consistently performs comparably or even better than the method of Wang et al. (2014a), which is encouraging as we do not use any anchor information."
Learning Entity and Relation Embeddings for Knowledge Graph Completion,"Yankai Lin, Zhiyuan Liu, Maosong Sun,Yang Liu, Xuan Zhu",AAAI,,"Knowledge graph completion aims to perform link prediction between entities. In this paper, we consider the approach of knowledge graph embeddings. Recently, models such as TransE and TransH build entity and relation embeddings by regarding a relation as translation from head entity to tail entity. We note that these models simply put both entities and relations within the same semantic space. In fact, an entity may have multiple aspects and various relations may focus on different aspects of entities, which makes a common space insufficient for modeling. In this paper, we propose TransR to build entity and relation embeddings in separate entity space and relation spaces. Afterwards, we learn embeddings by first projecting entities from entity space to corresponding relation space and then building translations between projected entities. In experiments, we evaluate our models on three tasks including link prediction, triple classification and relational fact extraction. Experimental results show significant and consistent improvements compared to state-of-the-art baselines including TransE and TransH. The source code of this paper can be obtained from https://github.com/mrlyk423/relation_extraction."
"Knowledge Representation Learning with Entities, Attributes and Relations","Yankai Lin, Zhiyuan Liu, Maosong Sun",IJCAI,,"Distributed knowledge representation (KR) encodes both entities and relations in a lowdimensional semantic space, which has significantly promoted the performance of relation extraction and knowledge reasoning. In many knowledge graphs (KG), some relations indicate attributes of entities (attributes) and others indicate relations between entities (relations). Existing KR models regard all relations equally, and usually suffer from poor accuracies when modeling one-to-many and many-to-one relations, mostly composed of attribute. In this paper, we distinguish existing KGrelations into attributes and relations, and propose a new KR model with entities, attributes and relations (KR-EAR). The experiment results show that, by special modeling of attribute, KR-EAR can significantly outperform state-of-the-art KR models in prediction of entities, attributes and relations. The source code of this paper can be obtained from https://github.com/thunlp/KR-EAR."
Composing Knowledge Graph Embeddings via Word Embeddings,"Lianbo Ma, Peng Sun, Zhiwei Lin,Hanrou Wang",arXiv,,"Learning knowledge graph embedding from an existing knowledge graph is very important to knowledge graph completion. For a fact (h,r,t) with the head entity h having a relation r with the tail entity t, the current approaches aim to learn low dimensional representations (h,r,t), each of which corresponds to the elements in (h,r,t), respectively. As (h,r,t) is learned from the existing facts within a knowledge graph, these representations can not be used to detect unknown facts (if the entities or relations never occur in the knowledge graph). This paper proposes a new approach called TransW, aiming to go beyond the current work by composing knowledge graph embeddings using word embeddings. Given the fact that an entity or a relation contains one or more words (quite often), it is sensible to learn a mapping function from word embedding spaces to knowledge embedding spaces, which shows how entities are constructed using human words. More importantly, composing knowledge embeddings using word embeddings makes it possible to deal with the emerging new facts (either new entities or relations). Experimental results using three public datasets show the consistency and outperformance of the proposed TransW."
Neighborhood Mixture Model for Knowledge Base Completion,"Dat Quoc Nguyen, Kairit Sirts, LizhenQu, Mark Johnson",ACL,"Knowledge base completion, embedding model, mixture model, link prediction, triple classification, entity prediction, relation prediction.","Knowledge bases are useful resources for many natural language processing tasks, however, they are far from complete. In this paper, we define a novel entity representation as a mixture of its neighborhood in the knowledge base and apply this technique on TransE—a well-known embedding model for knowledge base completion. Experimental results show that the neighborhood information significantly helps to improve the results of the TransE, leading to better performance than obtained by other state-of-the-art embedding models on three benchmark datasets for triple classification, entity prediction and relation prediction tasks."
Knowledge Graph Embedding with Triple Context,"Jun Shi, Huan Gao, Guilin Qi,Zhangquan Zhou",ACM,Knowledge Graph; Representation Learning; Triple Context,"Knowledge graph embedding, which aims to represent entities and relations in vector spaces, has shown outstanding performance on a few knowledge graph completion tasks. Most existing methods are based on the assumption that a knowledge graph is a set of separate triples, ignoring rich graph features, i.e., structural information in the graph. In this paper, we take advantages of structures in knowledge graphs, especially local structures around a triple, which we refer to as triple context. We then propose a TripleContext-based knowledge Embedding model (TCE). For each triple, two kinds of structure information are considered as its context in the graph; one is the outgoing relations and neighboring entities of an entity and the other is relation paths between a pair of entities, both of which reflect various aspects of the triple. Triples along with their contexts are represented in a unified framework, in which way structural information in triple contexts can be embodied. The experimental results show that our model outperforms the state-of-the-art methods for link prediction"
From One Point to A Manifold: Orbit Models for Knowledge Graph Embedding,"Han Xiao, Minlie Huang, Yu Hao,Xiaoyan Zhu",arXiv,,"Knowledge graph embedding aims at offering a numerical paradigm for knowledge representation by translating the entities and relations into continuous vector space. This paper studies the problem of unsatisfactory precise knowledge embedding and attributes a new issue to this problem that \textbf{\textit{inaccuracy of truth characterization}}, indicating that existing methods could not express the true facts in a fine degree. To alleviate this issue, we propose the orbit-based embedding model, \textbf{OrbitE}. The new model is a well-posed algebraic system that expands the position of golden triples from one point in current models to a manifold. Extensive experiments show that the proposed model achieves substantial improvements against the state-of-the-art baselines, especially for precise prediction."
Learning to Represent Knowledge Graphs with Gaussian Embedding,"Shizhu He, Kang Liu, Guoliang Ji, JunZhao",ACM,"Distributed Representation, Gaussian Embedding, Knowledge Graph","The representation of a knowledge graph (KG) in a latent space recently has attracted more and more attention. To this end, some proposed models (e.g., TransE) embed entities and relations of a KG into a “point” vector space by optimizing a global loss function which ensures the scores of positive triplets are higher than negative ones. We notice that these models always regard all entities and relations in a same manner and ignore their (un)certainties. In fact, different entities and relations may contain different certainties, which makes identical certainty insufficient for modeling. Therefore, this paper switches to density-based embedding and propose KG2E for explicitly modeling the certainty of entities and relations, which learn the representations of KGs in the space of multi-dimensional Gaussian distributions. Each entity/relation is represented by a Gaussian distribution, where the mean denotes its position and the covariance (currently with diagonal covariance) can properly represent its certainty. In addition, compared with the symmetric measures used in point-based methods, we employ the KL-divergence for scoring triplets, which is a natural asymmetry function for effectively modeling multiple types of relations. We have conducted extensive experiments on link prediction and triplet classification with multiple benchmark datasets (WordNet and Freebase). Our experimental results demonstrate that our method can effectively model the (un)certainties of entities and relations in a KG, and it significantly outperforms state-of-the-art methods (including TransH and TransR)."
Context-Dependent Knowledge Graph Embedding,"Yuanfei Luo, Quan Wang, Bin Wang, LiGuo",ACL,,"We consider the problem of embedding knowledge graphs (KGs) into continuous vector spaces. Existing methods can only deal with explicit relationships within each triple, i.e., local connectivity patterns, but cannot handle implicit relationships across different triples, i.e., contextual connectivity patterns. This paper proposes context-dependent KG embedding, a twostage scheme that takes into account both types of connectivity patterns and obtains more accurate embeddings. We evaluate our approach on the tasks of link prediction and triple classification, and achieve significant and consistent improvements over state-of-the-art methods."
Modeling Relation Paths for Representation Learning of Knowledge Bases,"Yankai Lin, Zhiyuan Liu, Huanbo Luan,Maosong Sun, Siwei Rao, Song Liu",ACL,,"Representation learning of knowledge bases aims to embed both entities and relations into a low-dimensional space. Most existing methods only consider direct relations in representation learning. We argue that multiple-step relation paths also contain rich inference patterns between entities, and propose a path-based representation learning model. This model considers relation paths as translations between entities for representation learning, and addresses two key challenges: (1) Since not all relation paths are reliable, we design a path-constraint resource allocation algorithm to measure the reliability of relation paths. (2) We represent relation paths via semantic composition of relation embeddings. Experimental results on real-world datasets show that, as compared with baselines, our model achieves significant and consistent improvements on knowledge base completion and relation extraction from text."
Collective Classification via Discriminative Matrix Factorization on Sparsely Labeled Networks,"Daokun Zhang, Jie Yin, Xingquan Zhu,Chengqi Zhang",ACM,"Collective classification; network representation learning; matrix factorization, sparsely labeled networks","We address the problem of classifying sparsely labeled networks, where labeled nodes in the network are extremely scarce. Existing algorithms, such as collective classification, have been shown to be effective for jointly deriving labels of related nodes, by exploiting label dependencies among neighboring nodes. However, when the network is sparsely labeled, most nodes have too few or even no connections to labeled nodes. This makes it very difficult to leverage supervised knowledge from labeled nodes to accurately estimate label dependencies, thereby largely degrading classification accuracy. In this paper, we propose a novel discriminative matrix factorization (DMF) based algorithm that effectively learns a latent network representation by exploiting topological paths between labeled and unlabeled nodes, in addition to nodes’ content information. The main idea is to use matrix factorization to obtain a compact representation of the network that fully encodes nodes’ content information and network structure, and unleash discriminative power inferred from labeled nodes to directly benefit collective classification. We formulate a new matrix factorization objective function that integrates network representation learning with an empirical loss minimization for classifying node labels. An efficient optimization algorithm based on conjugate gradient methods is proposed to solve the new objective function. Experimental results on real-world networks show that DMF yields superior performance gain over the stateof-the-art baselines on sparsely labeled networks."
Attributed Social Network Embedding,"Lizi Liao, Xiangnan He, HanwangZhang, Tat-Seng Chua",arXiv,"Social Network Representation, Homophily, Deep Learning","Embedding network data into a low-dimensional vector space has shown promising performance for many real-world applications, such as node classification and entity retrieval. However, most existing methods focused only on leveraging network structure. For social networks, besides the network structure, there also exists rich information about social actors, such as user profiles of friendship networks and textual content of citation networks. These rich attribute information of social actors reveal the homophily effect, exerting huge impacts on the formation of social networks. In this paper, we explore the rich evidence source of attributes in social networks to improve network embedding. We propose a generic Social Network Embedding framework (SNE), which learns representations for social actors (i.e., nodes) by preserving both the structural proximity and attribute proximity. While the structural proximity captures the global network structure, the attribute proximity accounts for the homophily effect. To justify our proposal, we conduct extensive experiments on four real-world social networks. Compared to the state-of-the-art network embedding approaches, SNE can learn more informative representations, achieving substantial gains on the tasks of link prediction and node classification. Specifically, SNE significantly outperforms node2vec with an 8.2% relative improvement on the link prediction task, and a 12.7% gain on the node classification task."
From Properties to Links: Deep Network Embedding on Incomplete Graphs,"Dejian Yang, Senzhang Wang,Chaozhuo Li, Xiaoming Zhang, ZhoujunLi",ACM,"Network Embedding, Incomplete Graph, Deep Learning","As an effective way of learning node representations in networks, network embedding has attracted increasing research interests recently. Most existing approaches use shallow models and only work on static networks by extracting local or global topology information of each node as the algorithm input. It is challenging for such approaches to learn a desirable node representation on incomplete graphs with a large number of missing links or on dynamic graphs with new nodes joining in. It is even challenging for them to deeply fuse other types of data such as node properties into the learning process to help better represent the nodes with insufficient links. In this paper, we for the first time study the problem of network embedding on incomplete networks. We propose a MultiView Correlation-learning based Deep Network Embedding method named MVC-DNE to incorporate both the network structure and the node properties for more effectively and efficiently perform network embedding on incomplete networks. Specifically, we consider the topology structure of the network and the node properties as two correlated views. The insight is that the learned representation vector of a node should reflect its characteristics in both views. Under a multi-view correlation learning based deep autoencoder framework, the structure view and property view embeddings are integrated and mutually reinforced through both self-view and cross-view learning. As MVC-DNE can learn a representation mapping function, it can directly generate the representation vectors for the new nodes without retraining the model. Thus it is especially more efficient than previous methods. Empirically, we evaluate MVC-DNE over three real network datasets on two data mining applications, and the results demonstrate that MVC-DNE significantly outperforms state-of-the-art methods."
Learning Graph Representations with Embedding Propagation,"Alberto García-Durán, Mathias Niepert",NIPS,,"We propose Embedding Propagation (EP), an unsupervised learning framework for graph-structured data. EP learns vector representations of graphs by passing two types of messages between neighboring nodes. Forward messages consist of label representations such as representations of words and other attributes associated with the nodes. Backward messages consist of gradients that result from aggregating the label representations and applying a reconstruction loss. Node representations are finally computed from the representation of their labels. With significantly fewer parameters and hyperparameters an instance of EP is competitive with and often outperforms state of the art unsupervised and semi-supervised learning methods on a range of benchmark data sets."
Motif-Aware Graph Embeddings,"Hoang Nguyen, Tsuyoshi Murata",IJCAI,,"In this paper, we propose our motif-aware approaches to the unsupervised network embedding and semi-supervised network labeling task. Our first algorithm is an unsupervised network embedding algorithm which uses the most statistically significant network motif as the guiding pattern for random walks to generate network context. We then use a Skipgram neural network to learn the latent network node representations from the generated context via Noise Contrastive Estimation. The second algorithm employs the Graph Convolution Network model on motif Laplacian matrices to inject the higher-order network structure into the neural network. Both of our algorithms utilize the higher-order organization (i.e. motifs organization) of complex networks. We demonstrate the effectiveness of our algorithms in comparison with other state-of-the-art network embedding algorithms."
Enhancing the Network Embedding Quality with Structural Similarity,"Tianshu Lyu, Yuan Zhang, Yan Zhang",ACM,"Network Embedding, Graphlet, Latent Representation","Neural network techniques are widely used in network embedding, boosting the result of node classification, link prediction, visualization and other tasks in both aspects of efficiency and quality. All the state of art algorithms put effort on the neighborhood information and try to make full use of it. However, it is hard to recognize core periphery structures simply based on neighborhood. In this paper, we first discuss the influence brought by randomwalk based sampling strategies to the embedding results. Theoretical and experimental evidences show that random-walk based sampling strategies fail to fully capture structural equivalence. We present a new method, SNS, that performs network embeddings using structural information (namely graphlets) to enhance its quality. SNS effectively utilizes both neighbor information and localsubgraphs similarity to learn node embeddings. This is the first framework that combines these two aspects as far as we know, positively merging two important areas in graph mining and machine learning. Moreover, we investigate what kinds of local-subgraph features matter the most on the node classification task, which enables us to further improve the embedding quality. Experiments show that our algorithm outperforms other unsupervised and semisupervised neural network embedding algorithms on several realworld datasets."
edge2vec: Learning Node Representation Using Edge Semantics,"Zheng Gao, Gang Fu, Chunping Ouyang,Satoshi Tsutsui, Xiaozhong Liu, YingDing",BMC Bioinformatics,"Knowledge graph, Heterogeneous network, Biomedical knowledge discovery, Representation learning, Graph embedding, Node embedding, Edge semantics, Applied machine learning, Data science, Linked data, Semantic web, Network science, Systems biology","Representation learning provides new and powerful graph analytical approaches and tools for the highly valued data science challenge of mining knowledge graphs. Since previous graph analytical methods have mostly focused on homogeneous graphs, an important current challenge is extending this methodology for richly heterogeneous graphs and knowledge domains. The biomedical sciences are such a domain, reflecting the complexity of biology, with entities such as genes, proteins, drugs, diseases, and phenotypes, and relationships such as gene co-expression, biochemical regulation, and biomolecular inhibition or activation. Therefore, the semantics of edges and nodes are critical for representation learning and knowledge discovery in real world biomedical problems. In this paper, we propose the edge2vec model, which represents graphs considering edge semantics. An edge-type transition matrix is trained by an Expectation-Maximization approach, and a stochastic gradient descent model is employed to learn node embedding on a heterogeneous graph via the trained transition matrix. edge2vec is validated on three biomedical domain tasks: biomedical entity classification, compound-gene bioactivity prediction, and biomedical information retrieval. Results show that by considering edge-types into node embedding learning in heterogeneous graphs, edge2vec significantly outperforms state-of-the-art models on all three tasks. We propose this method for its added value relative to existing graph analytical methodology, and in the real world context of biomedical knowledge discovery applicability."